===============================
2387901.pbshpc
vsky019.hpc.iitd.ac.in
===============================
/home/cse/phd/anz208849/Mod_for_night
_____params______
blocks.0.0.conv1.weight torch.Size([64, 19, 3, 3])
blocks.0.0.conv1.bias torch.Size([64])
blocks.0.0.conv2.weight torch.Size([64, 64, 3, 3])
blocks.0.0.conv2.bias torch.Size([64])
blocks.0.0.conv_sc.weight torch.Size([64, 19, 1, 1])
blocks.0.0.conv_sc.bias torch.Size([64])
blocks.1.0.conv1.weight torch.Size([128, 64, 3, 3])
blocks.1.0.conv1.bias torch.Size([128])
blocks.1.0.conv2.weight torch.Size([128, 128, 3, 3])
blocks.1.0.conv2.bias torch.Size([128])
blocks.1.0.conv_sc.weight torch.Size([128, 64, 1, 1])
blocks.1.0.conv_sc.bias torch.Size([128])
blocks.2.0.conv1.weight torch.Size([256, 128, 3, 3])
blocks.2.0.conv1.bias torch.Size([256])
blocks.2.0.conv2.weight torch.Size([256, 256, 3, 3])
blocks.2.0.conv2.bias torch.Size([256])
blocks.2.0.conv_sc.weight torch.Size([256, 128, 1, 1])
blocks.2.0.conv_sc.bias torch.Size([256])
blocks.3.0.conv1.weight torch.Size([512, 256, 3, 3])
blocks.3.0.conv1.bias torch.Size([512])
blocks.3.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.3.0.conv2.bias torch.Size([512])
blocks.3.0.conv_sc.weight torch.Size([512, 256, 1, 1])
blocks.3.0.conv_sc.bias torch.Size([512])
blocks.4.0.conv1.weight torch.Size([512, 512, 3, 3])
blocks.4.0.conv1.bias torch.Size([512])
blocks.4.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.4.0.conv2.bias torch.Size([512])
blocks.4.0.conv_sc.weight torch.Size([512, 512, 1, 1])
blocks.4.0.conv_sc.bias torch.Size([512])
blocks.5.0.conv1.weight torch.Size([1024, 512, 3, 3])
blocks.5.0.conv1.bias torch.Size([1024])
blocks.5.0.conv2.weight torch.Size([1024, 1024, 3, 3])
blocks.5.0.conv2.bias torch.Size([1024])
blocks.5.0.conv_sc.weight torch.Size([1024, 512, 1, 1])
blocks.5.0.conv_sc.bias torch.Size([1024])
blocks.6.0.conv1.weight torch.Size([512, 1024, 3, 3])
blocks.6.0.conv1.bias torch.Size([512])
blocks.6.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.6.0.conv2.bias torch.Size([512])
blocks.6.0.conv_sc.weight torch.Size([512, 1024, 1, 1])
blocks.6.0.conv_sc.bias torch.Size([512])
blocks.7.0.conv1.weight torch.Size([512, 1024, 3, 3])
blocks.7.0.conv1.bias torch.Size([512])
blocks.7.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.7.0.conv2.bias torch.Size([512])
blocks.7.0.conv_sc.weight torch.Size([512, 1024, 1, 1])
blocks.7.0.conv_sc.bias torch.Size([512])
blocks.8.0.conv1.weight torch.Size([256, 1024, 3, 3])
blocks.8.0.conv1.bias torch.Size([256])
blocks.8.0.conv2.weight torch.Size([256, 256, 3, 3])
blocks.8.0.conv2.bias torch.Size([256])
blocks.8.0.conv_sc.weight torch.Size([256, 1024, 1, 1])
blocks.8.0.conv_sc.bias torch.Size([256])
blocks.9.0.conv1.weight torch.Size([128, 512, 3, 3])
blocks.9.0.conv1.bias torch.Size([128])
blocks.9.0.conv2.weight torch.Size([128, 128, 3, 3])
blocks.9.0.conv2.bias torch.Size([128])
blocks.9.0.conv_sc.weight torch.Size([128, 512, 1, 1])
blocks.9.0.conv_sc.bias torch.Size([128])
blocks.10.0.conv1.weight torch.Size([64, 256, 3, 3])
blocks.10.0.conv1.bias torch.Size([64])
blocks.10.0.conv2.weight torch.Size([64, 64, 3, 3])
blocks.10.0.conv2.bias torch.Size([64])
blocks.10.0.conv_sc.weight torch.Size([64, 256, 1, 1])
blocks.10.0.conv_sc.bias torch.Size([64])
blocks.11.0.conv1.weight torch.Size([64, 128, 3, 3])
blocks.11.0.conv1.bias torch.Size([64])
blocks.11.0.conv2.weight torch.Size([64, 64, 3, 3])
blocks.11.0.conv2.bias torch.Size([64])
blocks.11.0.conv_sc.weight torch.Size([64, 128, 1, 1])
blocks.11.0.conv_sc.bias torch.Size([64])
blocks.12.weight torch.Size([1, 64, 1, 1])
blocks.12.bias torch.Size([1])
wait
['so_run_btad_2.py']
Snapshot stored in: ../scratch/saved_models/acdc/dannet/train
                     note : train          
                    model : deeplab        
                    train : 1              
                 multigpu : 0              
                    fixbn : 0              
                 fix_seed : 1              
            learning_rate : 7.5e-05        
                num_steps : 5000           
                   epochs : 1000           
             weight_decay : 0.0005         
                 momentum : 0.9            
                    power : 0.9            
                    round : 6              
               print_freq : 372            
                save_freq : 372            
              tensorboard : 1              
                  neptune : 0              
                   screen : 1              
                      val : 1              
                 val_freq : 5              
                   source : acdc_train_rf_tensor
                   target : acdc_val_rf_tensor
                   worker : 4              
               batch_size : 8              
              num_classes : 2              
                input_src : 720            
                input_tgt : 720            
                 crop_src : 600            
                 crop_tgt : 600            
                   mirror : 1              
                scale_min : 0.5            
                scale_max : 1.5            
                      rec : 0              
              init_weight : ./save/model410_city_deeplabv2.pth
             restore_from : None           
                 snapshot : ../scratch/saved_models/acdc/dannet/train
                   result : ./miou_result/ 
                      log : ./log/         
                   plabel : ./plabel       
                       tb : ./log/train    

_____params______
blocks.0.0.conv1.weight torch.Size([64, 19, 3, 3])
blocks.0.0.conv1.bias torch.Size([64])
blocks.0.0.conv2.weight torch.Size([64, 64, 3, 3])
blocks.0.0.conv2.bias torch.Size([64])
blocks.0.0.conv_sc.weight torch.Size([64, 19, 1, 1])
blocks.0.0.conv_sc.bias torch.Size([64])
blocks.1.0.conv1.weight torch.Size([128, 64, 3, 3])
blocks.1.0.conv1.bias torch.Size([128])
blocks.1.0.conv2.weight torch.Size([128, 128, 3, 3])
blocks.1.0.conv2.bias torch.Size([128])
blocks.1.0.conv_sc.weight torch.Size([128, 64, 1, 1])
blocks.1.0.conv_sc.bias torch.Size([128])
blocks.2.0.conv1.weight torch.Size([256, 128, 3, 3])
blocks.2.0.conv1.bias torch.Size([256])
blocks.2.0.conv2.weight torch.Size([256, 256, 3, 3])
blocks.2.0.conv2.bias torch.Size([256])
blocks.2.0.conv_sc.weight torch.Size([256, 128, 1, 1])
blocks.2.0.conv_sc.bias torch.Size([256])
blocks.3.0.conv1.weight torch.Size([512, 256, 3, 3])
blocks.3.0.conv1.bias torch.Size([512])
blocks.3.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.3.0.conv2.bias torch.Size([512])
blocks.3.0.conv_sc.weight torch.Size([512, 256, 1, 1])
blocks.3.0.conv_sc.bias torch.Size([512])
blocks.4.0.conv1.weight torch.Size([512, 512, 3, 3])
blocks.4.0.conv1.bias torch.Size([512])
blocks.4.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.4.0.conv2.bias torch.Size([512])
blocks.4.0.conv_sc.weight torch.Size([512, 512, 1, 1])
blocks.4.0.conv_sc.bias torch.Size([512])
blocks.5.0.conv1.weight torch.Size([1024, 512, 3, 3])
blocks.5.0.conv1.bias torch.Size([1024])
blocks.5.0.conv2.weight torch.Size([1024, 1024, 3, 3])
blocks.5.0.conv2.bias torch.Size([1024])
blocks.5.0.conv_sc.weight torch.Size([1024, 512, 1, 1])
blocks.5.0.conv_sc.bias torch.Size([1024])
blocks.6.0.conv1.weight torch.Size([512, 1024, 3, 3])
blocks.6.0.conv1.bias torch.Size([512])
blocks.6.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.6.0.conv2.bias torch.Size([512])
blocks.6.0.conv_sc.weight torch.Size([512, 1024, 1, 1])
blocks.6.0.conv_sc.bias torch.Size([512])
blocks.7.0.conv1.weight torch.Size([512, 1024, 3, 3])
blocks.7.0.conv1.bias torch.Size([512])
blocks.7.0.conv2.weight torch.Size([512, 512, 3, 3])
blocks.7.0.conv2.bias torch.Size([512])
blocks.7.0.conv_sc.weight torch.Size([512, 1024, 1, 1])
blocks.7.0.conv_sc.bias torch.Size([512])
blocks.8.0.conv1.weight torch.Size([256, 1024, 3, 3])
blocks.8.0.conv1.bias torch.Size([256])
blocks.8.0.conv2.weight torch.Size([256, 256, 3, 3])
blocks.8.0.conv2.bias torch.Size([256])
blocks.8.0.conv_sc.weight torch.Size([256, 1024, 1, 1])
blocks.8.0.conv_sc.bias torch.Size([256])
blocks.9.0.conv1.weight torch.Size([128, 512, 3, 3])
blocks.9.0.conv1.bias torch.Size([128])
blocks.9.0.conv2.weight torch.Size([128, 128, 3, 3])
blocks.9.0.conv2.bias torch.Size([128])
blocks.9.0.conv_sc.weight torch.Size([128, 512, 1, 1])
blocks.9.0.conv_sc.bias torch.Size([128])
blocks.10.0.conv1.weight torch.Size([64, 256, 3, 3])
blocks.10.0.conv1.bias torch.Size([64])
blocks.10.0.conv2.weight torch.Size([64, 64, 3, 3])
blocks.10.0.conv2.bias torch.Size([64])
blocks.10.0.conv_sc.weight torch.Size([64, 256, 1, 1])
blocks.10.0.conv_sc.bias torch.Size([64])
blocks.11.0.conv1.weight torch.Size([64, 128, 3, 3])
blocks.11.0.conv1.bias torch.Size([64])
blocks.11.0.conv2.weight torch.Size([64, 64, 3, 3])
blocks.11.0.conv2.bias torch.Size([64])
blocks.11.0.conv_sc.weight torch.Size([64, 128, 1, 1])
blocks.11.0.conv_sc.bias torch.Size([64])
blocks.12.weight torch.Size([1, 64, 1, 1])
blocks.12.bias torch.Size([1])
Mode --> Train
Lets ride...
epoch =      0/  1000, exp = train
train_iter_loss: 0.0777808427810669
train_iter_loss: 0.06072124093770981
train_iter_loss: 0.07720684260129929
train_iter_loss: 0.06286489963531494
train_iter_loss: 0.0791216567158699
train_iter_loss: 0.07135200500488281
train_iter_loss: 0.07257650792598724
train_iter_loss: 0.07301696389913559
train_iter_loss: 0.0680667981505394
train_iter_loss: 0.06477677822113037
train_iter_loss: 0.06356345117092133
train_iter_loss: 0.06261336803436279
train_iter_loss: 0.05525236204266548
train_iter_loss: 0.06377550959587097
train_iter_loss: 0.05751317739486694
train_iter_loss: 0.0635625422000885
train_iter_loss: 0.06148386374115944
train_iter_loss: 0.07245771586894989
train_iter_loss: 0.0645691379904747
train_iter_loss: 0.0615701861679554
train_iter_loss: 0.05768459290266037
train_iter_loss: 0.051439981907606125
train_iter_loss: 0.048919908702373505
train_iter_loss: 0.07416186481714249
train_iter_loss: 0.06698732823133469
train_iter_loss: 0.06880040466785431
train_iter_loss: 0.060891713947057724
train_iter_loss: 0.04323200136423111
train_iter_loss: 0.05551119148731232
train_iter_loss: 0.062403108924627304
train_iter_loss: 0.04853947088122368
train_iter_loss: 0.06471864879131317
train_iter_loss: 0.04758523777127266
train_iter_loss: 0.06593351811170578
train_iter_loss: 0.06159716844558716
train_iter_loss: 0.04823499172925949
train_iter_loss: 0.06033749505877495
train_iter_loss: 0.055421456694602966
train_iter_loss: 0.047974273562431335
train_iter_loss: 0.056625399738550186
train_iter_loss: 0.04653949290513992
train_iter_loss: 0.05572236329317093
train_iter_loss: 0.04856359586119652
train_iter_loss: 0.04933200031518936
train_iter_loss: 0.06177106127142906
train_iter_loss: 0.05331774428486824
train_iter_loss: 0.053852953016757965
train_iter_loss: 0.04986405745148659
train_iter_loss: 0.04934243857860565
train_iter_loss: 0.06117374822497368
train loss :0.0602
---------------------
Validation seg loss: 0.05285161510461344 at epoch 0
********************
best_val_epoch_loss:  0.05285161510461344
MODEL UPDATED
epoch =      1/  1000, exp = train
train_iter_loss: 0.04815389961004257
train_iter_loss: 0.05161271244287491
train_iter_loss: 0.04084374010562897
train_iter_loss: 0.05003385245800018
train_iter_loss: 0.04899787902832031
train_iter_loss: 0.07220148295164108
train_iter_loss: 0.050447527319192886
train_iter_loss: 0.05572747066617012
train_iter_loss: 0.05072122812271118
train_iter_loss: 0.04822057485580444
train_iter_loss: 0.03990967199206352
train_iter_loss: 0.05103472247719765
train_iter_loss: 0.049316223710775375
train_iter_loss: 0.04293210059404373
train_iter_loss: 0.04297459498047829
train_iter_loss: 0.03484883904457092
train_iter_loss: 0.03995828703045845
train_iter_loss: 0.038195159286260605
train_iter_loss: 0.03868482634425163
train_iter_loss: 0.03747433051466942
train_iter_loss: 0.03558875247836113
train_iter_loss: 0.03590323030948639
train_iter_loss: 0.04189673811197281
train_iter_loss: 0.04179149493575096
train_iter_loss: 0.0387297123670578
train_iter_loss: 0.06444384902715683
train_iter_loss: 0.046368516981601715
train_iter_loss: 0.03543466329574585
train_iter_loss: 0.04264358431100845
train_iter_loss: 0.03065934218466282
train_iter_loss: 0.036648355424404144
train_iter_loss: 0.029154328629374504
train_iter_loss: 0.0383310541510582
train_iter_loss: 0.03253399580717087
train_iter_loss: 0.03716505691409111
train_iter_loss: 0.026612931862473488
train_iter_loss: 0.03633442893624306
train_iter_loss: 0.033539749681949615
train_iter_loss: 0.04901919513940811
train_iter_loss: 0.046520963311195374
train_iter_loss: 0.06587657332420349
train_iter_loss: 0.043154213577508926
train_iter_loss: 0.03554292768239975
train_iter_loss: 0.048453301191329956
train_iter_loss: 0.02539089508354664
train_iter_loss: 0.03212130442261696
train_iter_loss: 0.027169013395905495
train_iter_loss: 0.02309420146048069
train_iter_loss: 0.030217880383133888
train_iter_loss: 0.0361655093729496
train loss :0.0428
---------------------
Validation seg loss: 0.04522599619022518 at epoch 1
********************
best_val_epoch_loss:  0.04522599619022518
MODEL UPDATED
epoch =      2/  1000, exp = train
train_iter_loss: 0.04042048752307892
train_iter_loss: 0.033729929476976395
train_iter_loss: 0.054875995963811874
train_iter_loss: 0.04047301784157753
train_iter_loss: 0.04327772557735443
train_iter_loss: 0.04250070080161095
train_iter_loss: 0.05966570973396301
train_iter_loss: 0.03730648756027222
train_iter_loss: 0.03879610821604729
train_iter_loss: 0.03017137013375759
train_iter_loss: 0.040258582681417465
train_iter_loss: 0.03331959620118141
train_iter_loss: 0.029538149014115334
train_iter_loss: 0.04493192955851555
train_iter_loss: 0.02421410195529461
train_iter_loss: 0.037147246301174164
train_iter_loss: 0.04512719810009003
train_iter_loss: 0.04256729781627655
train_iter_loss: 0.0413002148270607
train_iter_loss: 0.03096185065805912
train_iter_loss: 0.021409790962934494
train_iter_loss: 0.03125270828604698
train_iter_loss: 0.03603847697377205
train_iter_loss: 0.03593454509973526
train_iter_loss: 0.03818447142839432
train_iter_loss: 0.03239155560731888
train_iter_loss: 0.022424614056944847
train_iter_loss: 0.04155275970697403
train_iter_loss: 0.028344959020614624
train_iter_loss: 0.025830278173089027
train_iter_loss: 0.027232082560658455
train_iter_loss: 0.022252006456255913
train_iter_loss: 0.023696839809417725
train_iter_loss: 0.029242023825645447
train_iter_loss: 0.02246135100722313
train_iter_loss: 0.02229182980954647
train_iter_loss: 0.03347804397344589
train_iter_loss: 0.040265362709760666
train_iter_loss: 0.06679899245500565
train_iter_loss: 0.02985810674726963
train_iter_loss: 0.02918262965977192
train_iter_loss: 0.041372206062078476
train_iter_loss: 0.02668805606663227
train_iter_loss: 0.048283323645591736
train_iter_loss: 0.02512136846780777
train_iter_loss: 0.020604614168405533
train_iter_loss: 0.023267928510904312
train_iter_loss: 0.02260800451040268
train_iter_loss: 0.033538952469825745
train_iter_loss: 0.02306748554110527
train loss :0.0352
---------------------
Validation seg loss: 0.04340305980207082 at epoch 2
********************
best_val_epoch_loss:  0.04340305980207082
MODEL UPDATED
epoch =      3/  1000, exp = train
train_iter_loss: 0.03455263748764992
train_iter_loss: 0.043275728821754456
train_iter_loss: 0.04788796231150627
train_iter_loss: 0.023964613676071167
train_iter_loss: 0.05147552117705345
train_iter_loss: 0.019409649074077606
train_iter_loss: 0.03073255717754364
train_iter_loss: 0.05004173889756203
train_iter_loss: 0.03820759057998657
train_iter_loss: 0.03275366500020027
train_iter_loss: 0.026896581053733826
train_iter_loss: 0.023476826027035713
train_iter_loss: 0.026002027094364166
train_iter_loss: 0.03726232424378395
train_iter_loss: 0.019785162061452866
train_iter_loss: 0.023743700236082077
train_iter_loss: 0.026243701577186584
train_iter_loss: 0.029179276898503304
train_iter_loss: 0.030051328241825104
train_iter_loss: 0.028944185003638268
train_iter_loss: 0.029691582545638084
train_iter_loss: 0.021580204367637634
train_iter_loss: 0.047398075461387634
train_iter_loss: 0.05291130021214485
train_iter_loss: 0.026997532695531845
train_iter_loss: 0.02666633389890194
train_iter_loss: 0.045161813497543335
train_iter_loss: 0.05179225280880928
train_iter_loss: 0.020145326852798462
train_iter_loss: 0.01856241375207901
train_iter_loss: 0.019069937989115715
train_iter_loss: 0.02114241197705269
train_iter_loss: 0.028301777318120003
train_iter_loss: 0.031745217740535736
train_iter_loss: 0.023267259821295738
train_iter_loss: 0.024703258648514748
train_iter_loss: 0.023040104657411575
train_iter_loss: 0.03386307135224342
train_iter_loss: 0.018578851595520973
train_iter_loss: 0.02203979343175888
train_iter_loss: 0.0357339046895504
train_iter_loss: 0.02811850979924202
train_iter_loss: 0.01796332187950611
train_iter_loss: 0.028838178142905235
train_iter_loss: 0.04327267035841942
train_iter_loss: 0.022141674533486366
train_iter_loss: 0.026722166687250137
train_iter_loss: 0.020023353397846222
train_iter_loss: 0.020277325063943863
train_iter_loss: 0.044187407940626144
train loss :0.0311
---------------------
Validation seg loss: 0.04372283991619523 at epoch 3
epoch =      4/  1000, exp = train
train_iter_loss: 0.020019492134451866
train_iter_loss: 0.03518921136856079
train_iter_loss: 0.04607550427317619
train_iter_loss: 0.030174585059285164
train_iter_loss: 0.013368013314902782
train_iter_loss: 0.019965892657637596
train_iter_loss: 0.018488585948944092
train_iter_loss: 0.026525788009166718
train_iter_loss: 0.022289976477622986
train_iter_loss: 0.043837741017341614
train_iter_loss: 0.0183103084564209
train_iter_loss: 0.025993378832936287
train_iter_loss: 0.04159339517354965
train_iter_loss: 0.018154989928007126
train_iter_loss: 0.020893653854727745
train_iter_loss: 0.02796890027821064
train_iter_loss: 0.02238057181239128
train_iter_loss: 0.025837939232587814
train_iter_loss: 0.03191642835736275
train_iter_loss: 0.023533185943961143
train_iter_loss: 0.015280828811228275
train_iter_loss: 0.01751803606748581
train_iter_loss: 0.023607678711414337
train_iter_loss: 0.01996697299182415
train_iter_loss: 0.03172352910041809
train_iter_loss: 0.02040187269449234
train_iter_loss: 0.06958645582199097
train_iter_loss: 0.07876110076904297
train_iter_loss: 0.022834785282611847
train_iter_loss: 0.014918765053153038
train_iter_loss: 0.015253659337759018
train_iter_loss: 0.01613440364599228
train_iter_loss: 0.013152798637747765
train_iter_loss: 0.01315473672002554
train_iter_loss: 0.018518075346946716
train_iter_loss: 0.012393036857247353
train_iter_loss: 0.02845366857945919
train_iter_loss: 0.032119035720825195
train_iter_loss: 0.046298086643218994
train_iter_loss: 0.025037726387381554
train_iter_loss: 0.023906497284770012
train_iter_loss: 0.046505264937877655
train_iter_loss: 0.01925242692232132
train_iter_loss: 0.02439747005701065
train_iter_loss: 0.009693590924143791
train_iter_loss: 0.03153557702898979
train_iter_loss: 0.030892377719283104
train_iter_loss: 0.02864304557442665
train_iter_loss: 0.01715935207903385
train_iter_loss: 0.03790318965911865
train loss :0.0274
---------------------
Validation seg loss: 0.04790757651625307 at epoch 4
epoch =      5/  1000, exp = train
train_iter_loss: 0.02914029359817505
train_iter_loss: 0.023235145956277847
train_iter_loss: 0.03405141830444336
train_iter_loss: 0.04070696234703064
train_iter_loss: 0.017901983112096786
train_iter_loss: 0.028225596994161606
train_iter_loss: 0.035514988005161285
train_iter_loss: 0.035885632038116455
train_iter_loss: 0.033975277096033096
train_iter_loss: 0.02276942878961563
train_iter_loss: 0.022993920370936394
train_iter_loss: 0.03890479728579521
train_iter_loss: 0.011487447656691074
train_iter_loss: 0.024891654029488564
train_iter_loss: 0.030910268425941467
train_iter_loss: 0.011900395154953003
train_iter_loss: 0.019299721345305443
train_iter_loss: 0.031233638525009155
train_iter_loss: 0.026995833963155746
train_iter_loss: 0.01383086945861578
train_iter_loss: 0.010286143980920315
train_iter_loss: 0.013905848376452923
train_iter_loss: 0.016715699806809425
train_iter_loss: 0.02034614235162735
train_iter_loss: 0.024220680817961693
train_iter_loss: 0.06995823234319687
train_iter_loss: 0.01024184562265873
train_iter_loss: 0.025473449379205704
train_iter_loss: 0.022016264498233795
train_iter_loss: 0.009492084383964539
train_iter_loss: 0.01424485445022583
train_iter_loss: 0.011710870079696178
train_iter_loss: 0.012304876931011677
train_iter_loss: 0.018782591447234154
train_iter_loss: 0.018342480063438416
train_iter_loss: 0.013615184463560581
train_iter_loss: 0.02071825973689556
train_iter_loss: 0.018991658464074135
train_iter_loss: 0.022803138941526413
train_iter_loss: 0.014749850146472454
train_iter_loss: 0.03395654261112213
train_iter_loss: 0.025974255055189133
train_iter_loss: 0.03876684978604317
train_iter_loss: 0.016058633103966713
train_iter_loss: 0.012763362377882004
train_iter_loss: 0.02118745446205139
train_iter_loss: 0.013581058010458946
train_iter_loss: 0.008456625044345856
train_iter_loss: 0.042839519679546356
train_iter_loss: 0.012670514173805714
train loss :0.0235
---------------------
Validation seg loss: 0.044702682683666076 at epoch 5
epoch =      6/  1000, exp = train
train_iter_loss: 0.05291012302041054
train_iter_loss: 0.013651959598064423
train_iter_loss: 0.023669276386499405
train_iter_loss: 0.02458798885345459
train_iter_loss: 0.0309477336704731
train_iter_loss: 0.02510574273765087
train_iter_loss: 0.03574554622173309
train_iter_loss: 0.043494462966918945
train_iter_loss: 0.028471477329730988
train_iter_loss: 0.019456399604678154
train_iter_loss: 0.04207818955183029
train_iter_loss: 0.025199366733431816
train_iter_loss: 0.00958893820643425
train_iter_loss: 0.02040558122098446
train_iter_loss: 0.011736470274627209
train_iter_loss: 0.015292326919734478
train_iter_loss: 0.04146715626120567
train_iter_loss: 0.0121215945109725
train_iter_loss: 0.02459721639752388
train_iter_loss: 0.025364728644490242
train_iter_loss: 0.018015585839748383
train_iter_loss: 0.026860911399126053
train_iter_loss: 0.012749163433909416
train_iter_loss: 0.02619979903101921
train_iter_loss: 0.029161183163523674
train_iter_loss: 0.01694975234568119
train_iter_loss: 0.037308335304260254
train_iter_loss: 0.015859490260481834
train_iter_loss: 0.012564555741846561
train_iter_loss: 0.008322104811668396
train_iter_loss: 0.009492313489317894
train_iter_loss: 0.00998771097511053
train_iter_loss: 0.015098179690539837
train_iter_loss: 0.011585220694541931
train_iter_loss: 0.004717022646218538
train_iter_loss: 0.020911751314997673
train_iter_loss: 0.027646148577332497
train_iter_loss: 0.021972447633743286
train_iter_loss: 0.018428996205329895
train_iter_loss: 0.015053264796733856
train_iter_loss: 0.011753310449421406
train_iter_loss: 0.016338368877768517
train_iter_loss: 0.018308833241462708
train_iter_loss: 0.023787416517734528
train_iter_loss: 0.009106708690524101
train_iter_loss: 0.008144861087203026
train_iter_loss: 0.00858937855809927
train_iter_loss: 0.019718235358595848
train_iter_loss: 0.02818981558084488
train_iter_loss: 0.018245894461870193
train loss :0.0214
---------------------
Validation seg loss: 0.044396082124945196 at epoch 6
epoch =      7/  1000, exp = train
train_iter_loss: 0.04452939331531525
train_iter_loss: 0.020123589783906937
train_iter_loss: 0.028795845806598663
train_iter_loss: 0.01564786583185196
train_iter_loss: 0.024228475987911224
train_iter_loss: 0.030802560970187187
train_iter_loss: 0.04462280869483948
train_iter_loss: 0.03316193446516991
train_iter_loss: 0.01904922164976597
train_iter_loss: 0.02317035384476185
train_iter_loss: 0.020595960319042206
train_iter_loss: 0.019870592281222343
train_iter_loss: 0.01573389768600464
train_iter_loss: 0.020692473277449608
train_iter_loss: 0.013632722198963165
train_iter_loss: 0.00940928515046835
train_iter_loss: 0.01176497433334589
train_iter_loss: 0.014043815433979034
train_iter_loss: 0.020331092178821564
train_iter_loss: 0.02910761348903179
train_iter_loss: 0.009980238974094391
train_iter_loss: 0.020045559853315353
train_iter_loss: 0.0070162611082196236
train_iter_loss: 0.010285629890859127
train_iter_loss: 0.01717318594455719
train_iter_loss: 0.04325181618332863
train_iter_loss: 0.031223298981785774
train_iter_loss: 0.013389886356890202
train_iter_loss: 0.008552884683012962
train_iter_loss: 0.007481864187866449
train_iter_loss: 0.023189622908830643
train_iter_loss: 0.009178806096315384
train_iter_loss: 0.007417262531816959
train_iter_loss: 0.009894032962620258
train_iter_loss: 0.006407704204320908
train_iter_loss: 0.02666904777288437
train_iter_loss: 0.01806645095348358
train_iter_loss: 0.021598493680357933
train_iter_loss: 0.011421984992921352
train_iter_loss: 0.014720280654728413
train_iter_loss: 0.030437054112553596
train_iter_loss: 0.02004973217844963
train_iter_loss: 0.050537701696157455
train_iter_loss: 0.02876988798379898
train_iter_loss: 0.0047395359724760056
train_iter_loss: 0.01669405959546566
train_iter_loss: 0.006554343272000551
train_iter_loss: 0.007610163185745478
train_iter_loss: 0.03248937055468559
train_iter_loss: 0.026271099224686623
train loss :0.0204
---------------------
Validation seg loss: 0.04568991236463365 at epoch 7
epoch =      8/  1000, exp = train
train_iter_loss: 0.0226186104118824
train_iter_loss: 0.029682163149118423
train_iter_loss: 0.022056790068745613
train_iter_loss: 0.008116276934742928
train_iter_loss: 0.032164208590984344
train_iter_loss: 0.022145899012684822
train_iter_loss: 0.05738168582320213
train_iter_loss: 0.04758438095450401
train_iter_loss: 0.012380086816847324
train_iter_loss: 0.02207212522625923
train_iter_loss: 0.02877836860716343
train_iter_loss: 0.030759863555431366
train_iter_loss: 0.015529345721006393
train_iter_loss: 0.015215507708489895
train_iter_loss: 0.018592171370983124
train_iter_loss: 0.0070514436811208725
train_iter_loss: 0.012164940126240253
train_iter_loss: 0.020602621138095856
train_iter_loss: 0.017280396074056625
train_iter_loss: 0.02320789359509945
train_iter_loss: 0.008285120129585266
train_iter_loss: 0.01893722265958786
train_iter_loss: 0.019456923007965088
train_iter_loss: 0.029414428398013115
train_iter_loss: 0.022866051644086838
train_iter_loss: 0.018108520656824112
train_iter_loss: 0.020618142560124397
train_iter_loss: 0.05060896649956703
train_iter_loss: 0.0092089232057333
train_iter_loss: 0.006677687633782625
train_iter_loss: 0.012668256647884846
train_iter_loss: 0.007524680811911821
train_iter_loss: 0.005944562144577503
train_iter_loss: 0.02376779168844223
train_iter_loss: 0.008416586555540562
train_iter_loss: 0.012260666117072105
train_iter_loss: 0.022893382236361504
train_iter_loss: 0.01976604200899601
train_iter_loss: 0.013144241645932198
train_iter_loss: 0.015896443277597427
train_iter_loss: 0.007613372057676315
train_iter_loss: 0.01340946089476347
train_iter_loss: 0.021728618070483208
train_iter_loss: 0.02589397132396698
train_iter_loss: 0.011978689581155777
train_iter_loss: 0.007590920198708773
train_iter_loss: 0.009178351610898972
train_iter_loss: 0.010971056297421455
train_iter_loss: 0.016402877867221832
train_iter_loss: 0.02044038474559784
train loss :0.0195
---------------------
Validation seg loss: 0.04868722413139383 at epoch 8
epoch =      9/  1000, exp = train
train_iter_loss: 0.043631743639707565
train_iter_loss: 0.05362694710493088
train_iter_loss: 0.033083152025938034
train_iter_loss: 0.029193215072155
train_iter_loss: 0.012072530575096607
train_iter_loss: 0.01721261814236641
train_iter_loss: 0.06898685544729233
train_iter_loss: 0.04528770223259926
train_iter_loss: 0.01815127022564411
train_iter_loss: 0.021936852484941483
train_iter_loss: 0.020494969561696053
train_iter_loss: 0.016753412783145905
train_iter_loss: 0.019318968057632446
train_iter_loss: 0.0133637310937047
train_iter_loss: 0.012585269287228584
train_iter_loss: 0.013288868591189384
train_iter_loss: 0.01186393667012453
train_iter_loss: 0.02315036952495575
train_iter_loss: 0.010270152240991592
train_iter_loss: 0.031039327383041382
train_iter_loss: 0.04327765107154846
train_iter_loss: 0.016242755576968193
train_iter_loss: 0.00788498017936945
train_iter_loss: 0.01074067410081625
train_iter_loss: 0.018821723759174347
train_iter_loss: 0.018095258623361588
train_iter_loss: 0.035125426948070526
train_iter_loss: 0.01895011216402054
train_iter_loss: 0.009237837977707386
train_iter_loss: 0.013613766059279442
train_iter_loss: 0.007181895896792412
train_iter_loss: 0.004915944300591946
train_iter_loss: 0.008096118457615376
train_iter_loss: 0.004482547752559185
train_iter_loss: 0.00658717006444931
train_iter_loss: 0.006373088341206312
train_iter_loss: 0.009034755639731884
train_iter_loss: 0.01552873570472002
train_iter_loss: 0.021547695621848106
train_iter_loss: 0.019692104309797287
train_iter_loss: 0.020750079303979874
train_iter_loss: 0.012114578858017921
train_iter_loss: 0.012569641694426537
train_iter_loss: 0.01667853631079197
train_iter_loss: 0.005519187543541193
train_iter_loss: 0.006143446080386639
train_iter_loss: 0.004780982621014118
train_iter_loss: 0.004538562148809433
train_iter_loss: 0.046215035021305084
train_iter_loss: 0.015279782004654408
train loss :0.0195
---------------------
Validation seg loss: 0.047783368953530025 at epoch 9
epoch =     10/  1000, exp = train
train_iter_loss: 0.013294738717377186
train_iter_loss: 0.04749758169054985
train_iter_loss: 0.043587032705545425
train_iter_loss: 0.007549820002168417
train_iter_loss: 0.016958260908722878
train_iter_loss: 0.019361596554517746
train_iter_loss: 0.009764480404555798
train_iter_loss: 0.034375518560409546
train_iter_loss: 0.03825990855693817
train_iter_loss: 0.011060722172260284
train_iter_loss: 0.033993594348430634
train_iter_loss: 0.028386428952217102
train_iter_loss: 0.024633679538965225
train_iter_loss: 0.006472900975495577
train_iter_loss: 0.010538502596318722
train_iter_loss: 0.00607953080907464
train_iter_loss: 0.024692000821232796
train_iter_loss: 0.023634571582078934
train_iter_loss: 0.031999606639146805
train_iter_loss: 0.021164795383810997
train_iter_loss: 0.010601839050650597
train_iter_loss: 0.015005886554718018
train_iter_loss: 0.010065964423120022
train_iter_loss: 0.007482948713004589
train_iter_loss: 0.04099366441369057
train_iter_loss: 0.014890392310917377
train_iter_loss: 0.028818611055612564
train_iter_loss: 0.021525179967284203
train_iter_loss: 0.010883450508117676
train_iter_loss: 0.02283618412911892
train_iter_loss: 0.008884684182703495
train_iter_loss: 0.008463345468044281
train_iter_loss: 0.007255452685058117
train_iter_loss: 0.010722911916673183
train_iter_loss: 0.0047632553614676
train_iter_loss: 0.013432282023131847
train_iter_loss: 0.009240896441042423
train_iter_loss: 0.030559182167053223
train_iter_loss: 0.014066220261156559
train_iter_loss: 0.021504370495676994
train_iter_loss: 0.031047238036990166
train_iter_loss: 0.02769232913851738
train_iter_loss: 0.020160596817731857
train_iter_loss: 0.05147615820169449
train_iter_loss: 0.007891161367297173
train_iter_loss: 0.005093385931104422
train_iter_loss: 0.005652846302837133
train_iter_loss: 0.006820918992161751
train_iter_loss: 0.02264079451560974
train_iter_loss: 0.023415803909301758
train loss :0.0197
---------------------
Validation seg loss: 0.04792617838654035 at epoch 10
epoch =     11/  1000, exp = train
train_iter_loss: 0.015691684558987617
train_iter_loss: 0.027083169668912888
train_iter_loss: 0.017403874546289444
train_iter_loss: 0.013403990305960178
train_iter_loss: 0.018919752910733223
train_iter_loss: 0.009430856443941593
train_iter_loss: 0.018103672191500664
train_iter_loss: 0.018920088186860085
train_iter_loss: 0.0182437002658844
train_iter_loss: 0.0379309207201004
train_iter_loss: 0.014066838659346104
train_iter_loss: 0.016295429319143295
train_iter_loss: 0.02193284034729004
train_iter_loss: 0.019281750544905663
train_iter_loss: 0.0321689136326313
train_iter_loss: 0.02304242178797722
train_iter_loss: 0.011738534085452557
train_iter_loss: 0.040226683020591736
train_iter_loss: 0.017675191164016724
train_iter_loss: 0.023258550092577934
train_iter_loss: 0.01131382491439581
train_iter_loss: 0.006646602880209684
train_iter_loss: 0.03534984588623047
train_iter_loss: 0.005958263762295246
train_iter_loss: 0.013975166715681553
train_iter_loss: 0.012202608399093151
train_iter_loss: 0.036071207374334335
train_iter_loss: 0.017711862921714783
train_iter_loss: 0.0057066152803599834
train_iter_loss: 0.008839569054543972
train_iter_loss: 0.0050939940847456455
train_iter_loss: 0.00998345110565424
train_iter_loss: 0.006775961257517338
train_iter_loss: 0.003969667945057154
train_iter_loss: 0.010975656099617481
train_iter_loss: 0.00908716395497322
train_iter_loss: 0.008930360898375511
train_iter_loss: 0.008257818408310413
train_iter_loss: 0.010955261997878551
train_iter_loss: 0.006306271068751812
train_iter_loss: 0.017294161021709442
train_iter_loss: 0.011308576911687851
train_iter_loss: 0.01681256853044033
train_iter_loss: 0.041672464460134506
train_iter_loss: 0.006792049389332533
train_iter_loss: 0.007997709326446056
train_iter_loss: 0.008714833296835423
train_iter_loss: 0.009907713159918785
train_iter_loss: 0.03245675936341286
train_iter_loss: 0.03067655861377716
train loss :0.0170
---------------------
Validation seg loss: 0.05555521015391931 at epoch 11
epoch =     12/  1000, exp = train
train_iter_loss: 0.02884439006447792
train_iter_loss: 0.02606876939535141
train_iter_loss: 0.010932231321930885
train_iter_loss: 0.010645614005625248
train_iter_loss: 0.013481774367392063
train_iter_loss: 0.010479201562702656
train_iter_loss: 0.026796575635671616
train_iter_loss: 0.02643505297601223
train_iter_loss: 0.014425872825086117
train_iter_loss: 0.02528471313416958
train_iter_loss: 0.02995893359184265
train_iter_loss: 0.03749225288629532
train_iter_loss: 0.014716065488755703
train_iter_loss: 0.011233203113079071
train_iter_loss: 0.009157939814031124
train_iter_loss: 0.009371032938361168
train_iter_loss: 0.006289365701377392
train_iter_loss: 0.023125261068344116
train_iter_loss: 0.02980147674679756
train_iter_loss: 0.014757916331291199
train_iter_loss: 0.016904639080166817
train_iter_loss: 0.006054005119949579
train_iter_loss: 0.004677558783441782
train_iter_loss: 0.020635146647691727
train_iter_loss: 0.00876197312027216
train_iter_loss: 0.023697126656770706
train_iter_loss: 0.013870998285710812
train_iter_loss: 0.0362967811524868
train_iter_loss: 0.007834140211343765
train_iter_loss: 0.005657383240759373
train_iter_loss: 0.010580846108496189
train_iter_loss: 0.017995573580265045
train_iter_loss: 0.004470075946301222
train_iter_loss: 0.002507520141080022
train_iter_loss: 0.00498851528391242
train_iter_loss: 0.003945761360228062
train_iter_loss: 0.04688774049282074
train_iter_loss: 0.012485582381486893
train_iter_loss: 0.031238006427884102
train_iter_loss: 0.009541843086481094
train_iter_loss: 0.013548213988542557
train_iter_loss: 0.011916407383978367
train_iter_loss: 0.028093568980693817
train_iter_loss: 0.018277570605278015
train_iter_loss: 0.010917174629867077
train_iter_loss: 0.005550069268792868
train_iter_loss: 0.004574982449412346
train_iter_loss: 0.0034570067655295134
train_iter_loss: 0.020638441666960716
train_iter_loss: 0.02079935371875763
train loss :0.0165
---------------------
Validation seg loss: 0.054722491747321876 at epoch 12
epoch =     13/  1000, exp = train
train_iter_loss: 0.023522701114416122
train_iter_loss: 0.03046574629843235
train_iter_loss: 0.0073092360980808735
train_iter_loss: 0.012436745688319206
train_iter_loss: 0.012004022486507893
train_iter_loss: 0.020781081169843674
train_iter_loss: 0.028605446219444275
train_iter_loss: 0.014928960241377354
train_iter_loss: 0.02377377636730671
train_iter_loss: 0.031910281628370285
train_iter_loss: 0.02750406414270401
train_iter_loss: 0.022855814546346664
train_iter_loss: 0.01040834840387106
train_iter_loss: 0.006394112482666969
train_iter_loss: 0.004886014852672815
train_iter_loss: 0.016882548108696938
train_iter_loss: 0.008051623590290546
train_iter_loss: 0.012550084851682186
train_iter_loss: 0.008289087563753128
train_iter_loss: 0.02090921252965927
train_iter_loss: 0.005429327487945557
train_iter_loss: 0.002664147410541773
train_iter_loss: 0.00806654803454876
train_iter_loss: 0.0029242606833577156
train_iter_loss: 0.036808330565690994
train_iter_loss: 0.02034512348473072
train_iter_loss: 0.010067303664982319
train_iter_loss: 0.015343724749982357
train_iter_loss: 0.007130049169063568
train_iter_loss: 0.024358004331588745
train_iter_loss: 0.006485086400061846
train_iter_loss: 0.029576517641544342
train_iter_loss: 0.008672921918332577
train_iter_loss: 0.010297288186848164
train_iter_loss: 0.008655310608446598
train_iter_loss: 0.005447380244731903
train_iter_loss: 0.015107328072190285
train_iter_loss: 0.04348483681678772
train_iter_loss: 0.010204717516899109
train_iter_loss: 0.021850531920790672
train_iter_loss: 0.013341574929654598
train_iter_loss: 0.017569107934832573
train_iter_loss: 0.014516436494886875
train_iter_loss: 0.016228608787059784
train_iter_loss: 0.0040092370472848415
train_iter_loss: 0.022802239283919334
train_iter_loss: 0.011437015607953072
train_iter_loss: 0.006694736424833536
train_iter_loss: 0.07070505619049072
train_iter_loss: 0.012837368994951248
train loss :0.0169
---------------------
Validation seg loss: 0.060771359589811905 at epoch 13
epoch =     14/  1000, exp = train
train_iter_loss: 0.011398429051041603
train_iter_loss: 0.02881731651723385
train_iter_loss: 0.013675197027623653
train_iter_loss: 0.025218339636921883
train_iter_loss: 0.019284237176179886
train_iter_loss: 0.04271082952618599
train_iter_loss: 0.06937092542648315
train_iter_loss: 0.02847769856452942
train_iter_loss: 0.04371191933751106
train_iter_loss: 0.020162547007203102
train_iter_loss: 0.028691114857792854
train_iter_loss: 0.013162530958652496
train_iter_loss: 0.007496786303818226
train_iter_loss: 0.011188830249011517
train_iter_loss: 0.007753351237624884
train_iter_loss: 0.013646048493683338
train_iter_loss: 0.02220684103667736
train_iter_loss: 0.015501142479479313
train_iter_loss: 0.021708400920033455
train_iter_loss: 0.02771623805165291
train_iter_loss: 0.045013342052698135
train_iter_loss: 0.007864781655371189
train_iter_loss: 0.006907825358211994
train_iter_loss: 0.005498117301613092
train_iter_loss: 0.042986910790205
train_iter_loss: 0.007476511877030134
train_iter_loss: 0.018105236813426018
train_iter_loss: 0.01979885809123516
train_iter_loss: 0.018565408885478973
train_iter_loss: 0.004940229468047619
train_iter_loss: 0.008719327859580517
train_iter_loss: 0.01973630301654339
train_iter_loss: 0.005363254342228174
train_iter_loss: 0.010322709567844868
train_iter_loss: 0.00566734978929162
train_iter_loss: 0.0032297102734446526
train_iter_loss: 0.01034513395279646
train_iter_loss: 0.02045925334095955
train_iter_loss: 0.01257279608398676
train_iter_loss: 0.008139836601912975
train_iter_loss: 0.014905630610883236
train_iter_loss: 0.012788907624781132
train_iter_loss: 0.007581801153719425
train_iter_loss: 0.009763835929334164
train_iter_loss: 0.00443706288933754
train_iter_loss: 0.013906442560255527
train_iter_loss: 0.011443421244621277
train_iter_loss: 0.005539277568459511
train_iter_loss: 0.013749969191849232
train_iter_loss: 0.02528402954339981
train loss :0.0178
---------------------
Validation seg loss: 0.060302304792578136 at epoch 14
epoch =     15/  1000, exp = train
train_iter_loss: 0.013499774038791656
train_iter_loss: 0.035836271941661835
train_iter_loss: 0.026860665529966354
train_iter_loss: 0.009477395564317703
train_iter_loss: 0.025738289579749107
train_iter_loss: 0.06808414310216904
train_iter_loss: 0.02362665720283985
train_iter_loss: 0.008412363938987255
train_iter_loss: 0.017165210098028183
train_iter_loss: 0.012109624221920967
train_iter_loss: 0.018731094896793365
train_iter_loss: 0.010158431716263294
train_iter_loss: 0.019531933590769768
train_iter_loss: 0.015254611149430275
train_iter_loss: 0.007578621618449688
train_iter_loss: 0.009499155916273594
train_iter_loss: 0.012676999904215336
train_iter_loss: 0.013190335594117641
train_iter_loss: 0.010723824612796307
train_iter_loss: 0.018786562606692314
train_iter_loss: 0.011083303019404411
train_iter_loss: 0.0077728754840791225
train_iter_loss: 0.0032159953843802214
train_iter_loss: 0.009191892109811306
train_iter_loss: 0.018634125590324402
train_iter_loss: 0.04555213451385498
train_iter_loss: 0.023005468770861626
train_iter_loss: 0.023350562900304794
train_iter_loss: 0.004274731036275625
train_iter_loss: 0.013401268981397152
train_iter_loss: 0.0059125726111233234
train_iter_loss: 0.007015151437371969
train_iter_loss: 0.00598978390917182
train_iter_loss: 0.005093421787023544
train_iter_loss: 0.006372309755533934
train_iter_loss: 0.008656821213662624
train_iter_loss: 0.012191485613584518
train_iter_loss: 0.01900247298181057
train_iter_loss: 0.009604888036847115
train_iter_loss: 0.028265202417969704
train_iter_loss: 0.017993947491049767
train_iter_loss: 0.02816055715084076
train_iter_loss: 0.014169740490615368
train_iter_loss: 0.017288915812969208
train_iter_loss: 0.006702483166009188
train_iter_loss: 0.010594135150313377
train_iter_loss: 0.007209321949630976
train_iter_loss: 0.005310296081006527
train_iter_loss: 0.022520139813423157
train_iter_loss: 0.01651587337255478
train loss :0.0162
---------------------
Validation seg loss: 0.05494381724044083 at epoch 15
epoch =     16/  1000, exp = train
train_iter_loss: 0.033278416842222214
train_iter_loss: 0.015109286643564701
train_iter_loss: 0.03811846673488617
train_iter_loss: 0.013220536522567272
train_iter_loss: 0.0654071643948555
train_iter_loss: 0.020713340491056442
train_iter_loss: 0.02250993810594082
train_iter_loss: 0.009161918424069881
train_iter_loss: 0.03143586963415146
train_iter_loss: 0.01058481726795435
train_iter_loss: 0.022101225331425667
train_iter_loss: 0.015402751043438911
train_iter_loss: 0.009569436311721802
train_iter_loss: 0.0050055296160280704
train_iter_loss: 0.008443757891654968
train_iter_loss: 0.020423883572220802
train_iter_loss: 0.025291206315159798
train_iter_loss: 0.009894011542201042
train_iter_loss: 0.011188122443854809
train_iter_loss: 0.03420765697956085
train_iter_loss: 0.013166805729269981
train_iter_loss: 0.0062003182247281075
train_iter_loss: 0.02222760021686554
train_iter_loss: 0.008824646472930908
train_iter_loss: 0.016012053936719894
train_iter_loss: 0.007410810794681311
train_iter_loss: 0.056113339960575104
train_iter_loss: 0.031142309308052063
train_iter_loss: 0.009767746552824974
train_iter_loss: 0.004918853286653757
train_iter_loss: 0.009374230168759823
train_iter_loss: 0.01128855999559164
train_iter_loss: 0.0057098837569355965
train_iter_loss: 0.009267346933484077
train_iter_loss: 0.004190792795270681
train_iter_loss: 0.007580066565424204
train_iter_loss: 0.014406006783246994
train_iter_loss: 0.010855324566364288
train_iter_loss: 0.018958793953061104
train_iter_loss: 0.020825615152716637
train_iter_loss: 0.014161127619445324
train_iter_loss: 0.006255089771002531
train_iter_loss: 0.02410123310983181
train_iter_loss: 0.011393350549042225
train_iter_loss: 0.004558987449854612
train_iter_loss: 0.004020423162728548
train_iter_loss: 0.008604772388935089
train_iter_loss: 0.0035237143747508526
train_iter_loss: 0.013125934638082981
train_iter_loss: 0.040119718760252
train loss :0.0171
---------------------
Validation seg loss: 0.05516017035016667 at epoch 16
epoch =     17/  1000, exp = train
train_iter_loss: 0.015924546867609024
train_iter_loss: 0.020413434132933617
train_iter_loss: 0.01773308403789997
train_iter_loss: 0.035817984491586685
train_iter_loss: 0.014236105605959892
train_iter_loss: 0.051462385803461075
train_iter_loss: 0.01058940775692463
train_iter_loss: 0.020000804215669632
train_iter_loss: 0.009520694613456726
train_iter_loss: 0.014373120851814747
train_iter_loss: 0.01851402036845684
train_iter_loss: 0.0189147237688303
train_iter_loss: 0.009640485048294067
train_iter_loss: 0.017828810960054398
train_iter_loss: 0.01332021877169609
train_iter_loss: 0.016051840037107468
train_iter_loss: 0.016071278601884842
train_iter_loss: 0.020088836550712585
train_iter_loss: 0.016767069697380066
train_iter_loss: 0.021528709679841995
train_iter_loss: 0.02507190592586994
train_iter_loss: 0.019163480028510094
train_iter_loss: 0.006041707005351782
train_iter_loss: 0.008608250878751278
train_iter_loss: 0.016726922243833542
train_iter_loss: 0.028389260172843933
train_iter_loss: 0.019750701263546944
train_iter_loss: 0.009494985453784466
train_iter_loss: 0.008540968410670757
train_iter_loss: 0.0026347460225224495
train_iter_loss: 0.015143828466534615
train_iter_loss: 0.006538670510053635
train_iter_loss: 0.014762775972485542
train_iter_loss: 0.0047373296692967415
train_iter_loss: 0.016483383253216743
train_iter_loss: 0.005214928183704615
train_iter_loss: 0.00953720510005951
train_iter_loss: 0.011480660177767277
train_iter_loss: 0.01745993085205555
train_iter_loss: 0.0054578655399382114
train_iter_loss: 0.019019143655896187
train_iter_loss: 0.01321769505739212
train_iter_loss: 0.010555194690823555
train_iter_loss: 0.012771766632795334
train_iter_loss: 0.003965652547776699
train_iter_loss: 0.004944480024278164
train_iter_loss: 0.008648679591715336
train_iter_loss: 0.0058817737735807896
train_iter_loss: 0.017293134704232216
train_iter_loss: 0.041722554713487625
train loss :0.0157
---------------------
Validation seg loss: 0.06015913932472204 at epoch 17
epoch =     18/  1000, exp = train
train_iter_loss: 0.009317830204963684
train_iter_loss: 0.005854244343936443
train_iter_loss: 0.028114300221204758
train_iter_loss: 0.006455174181610346
train_iter_loss: 0.024045266211032867
train_iter_loss: 0.006416135001927614
train_iter_loss: 0.017728686332702637
train_iter_loss: 0.03488277271389961
train_iter_loss: 0.010845889337360859
train_iter_loss: 0.04206926003098488
train_iter_loss: 0.011043254286050797
train_iter_loss: 0.01194311585277319
train_iter_loss: 0.010830492712557316
train_iter_loss: 0.014455759897828102
train_iter_loss: 0.015758978202939034
train_iter_loss: 0.0052860393188893795
train_iter_loss: 0.017584390938282013
train_iter_loss: 0.006071256007999182
train_iter_loss: 0.014824310317635536
train_iter_loss: 0.019251078367233276
train_iter_loss: 0.007504368666559458
train_iter_loss: 0.005438055843114853
train_iter_loss: 0.002490157727152109
train_iter_loss: 0.015517898835241795
train_iter_loss: 0.06197073683142662
train_iter_loss: 0.02680412493646145
train_iter_loss: 0.018420599400997162
train_iter_loss: 0.042095404118299484
train_iter_loss: 0.005472291726619005
train_iter_loss: 0.008587246760725975
train_iter_loss: 0.0031742434948682785
train_iter_loss: 0.019180024042725563
train_iter_loss: 0.0020186705514788628
train_iter_loss: 0.021140139549970627
train_iter_loss: 0.004005227237939835
train_iter_loss: 0.0025651478208601475
train_iter_loss: 0.019429795444011688
train_iter_loss: 0.00533043360337615
train_iter_loss: 0.026068897917866707
train_iter_loss: 0.007290012668818235
train_iter_loss: 0.014917876571416855
train_iter_loss: 0.029846008867025375
train_iter_loss: 0.01507512852549553
train_iter_loss: 0.006772495340555906
train_iter_loss: 0.007322319783270359
train_iter_loss: 0.0071833012625575066
train_iter_loss: 0.004095281008630991
train_iter_loss: 0.004632281139492989
train_iter_loss: 0.018131447955965996
train_iter_loss: 0.015889110043644905
train loss :0.0151
---------------------
Validation seg loss: 0.05819361786416266 at epoch 18
epoch =     19/  1000, exp = train
train_iter_loss: 0.019001567736268044
train_iter_loss: 0.012938104569911957
train_iter_loss: 0.029478829354047775
train_iter_loss: 0.06364449113607407
train_iter_loss: 0.04793739318847656
train_iter_loss: 0.005816114135086536
train_iter_loss: 0.010697749443352222
train_iter_loss: 0.03667274862527847
train_iter_loss: 0.01663004606962204
train_iter_loss: 0.023952439427375793
train_iter_loss: 0.014376380480825901
train_iter_loss: 0.011729291640222073
train_iter_loss: 0.007713721599429846
train_iter_loss: 0.007293899543583393
train_iter_loss: 0.007675105705857277
train_iter_loss: 0.0061233164742589
train_iter_loss: 0.011125796474516392
train_iter_loss: 0.006037572398781776
train_iter_loss: 0.020778875797986984
train_iter_loss: 0.043328218162059784
train_iter_loss: 0.00761301489546895
train_iter_loss: 0.018703017383813858
train_iter_loss: 0.010116370394825935
train_iter_loss: 0.01852342300117016
train_iter_loss: 0.01701745204627514
train_iter_loss: 0.027035759761929512
train_iter_loss: 0.07180451601743698
train_iter_loss: 0.00581234460696578
train_iter_loss: 0.012018284760415554
train_iter_loss: 0.0065883793868124485
train_iter_loss: 0.015726862475275993
train_iter_loss: 0.006039652042090893
train_iter_loss: 0.007723614107817411
train_iter_loss: 0.0048245335929095745
train_iter_loss: 0.009466484189033508
train_iter_loss: 0.012034573592245579
train_iter_loss: 0.03665108606219292
train_iter_loss: 0.012242414057254791
train_iter_loss: 0.00595081364735961
train_iter_loss: 0.004659801721572876
train_iter_loss: 0.057013656944036484
train_iter_loss: 0.012472066096961498
train_iter_loss: 0.028619740158319473
train_iter_loss: 0.015169691294431686
train_iter_loss: 0.019887981936335564
train_iter_loss: 0.014093464240431786
train_iter_loss: 0.00464064022526145
train_iter_loss: 0.004664381500333548
train_iter_loss: 0.01986861787736416
train_iter_loss: 0.03664351999759674
train loss :0.0188
---------------------
Validation seg loss: 0.053675103186627514 at epoch 19
epoch =     20/  1000, exp = train
train_iter_loss: 0.030250560492277145
train_iter_loss: 0.023868024349212646
train_iter_loss: 0.011502151377499104
train_iter_loss: 0.024052657186985016
train_iter_loss: 0.013026516884565353
train_iter_loss: 0.01881631277501583
train_iter_loss: 0.01804589293897152
train_iter_loss: 0.02918444573879242
train_iter_loss: 0.030563484877347946
train_iter_loss: 0.010068876668810844
train_iter_loss: 0.010167332366108894
train_iter_loss: 0.059077754616737366
train_iter_loss: 0.0050635263323783875
train_iter_loss: 0.03428855538368225
train_iter_loss: 0.01156427338719368
train_iter_loss: 0.01836390793323517
train_iter_loss: 0.005510042887181044
train_iter_loss: 0.02293688803911209
train_iter_loss: 0.01579081267118454
train_iter_loss: 0.015328538604080677
train_iter_loss: 0.024705084040760994
train_iter_loss: 0.017435457557439804
train_iter_loss: 0.002584872068837285
train_iter_loss: 0.021167028695344925
train_iter_loss: 0.007335652131587267
train_iter_loss: 0.014951210469007492
train_iter_loss: 0.018109023571014404
train_iter_loss: 0.03363288938999176
train_iter_loss: 0.0045564561150968075
train_iter_loss: 0.004045808222144842
train_iter_loss: 0.027148917317390442
train_iter_loss: 0.0038555737119168043
train_iter_loss: 0.007501474115997553
train_iter_loss: 0.00586357107385993
train_iter_loss: 0.006696104072034359
train_iter_loss: 0.004182879813015461
train_iter_loss: 0.011173438280820847
train_iter_loss: 0.0069916024804115295
train_iter_loss: 0.004792850464582443
train_iter_loss: 0.009001578204333782
train_iter_loss: 0.03519608825445175
train_iter_loss: 0.016522975638508797
train_iter_loss: 0.04098176956176758
train_iter_loss: 0.012316428124904633
train_iter_loss: 0.016006292775273323
train_iter_loss: 0.004170553293079138
train_iter_loss: 0.017080890014767647
train_iter_loss: 0.006660672836005688
train_iter_loss: 0.026429038494825363
train_iter_loss: 0.02061692252755165
train loss :0.0172
---------------------
Validation seg loss: 0.057066379768448826 at epoch 20
epoch =     21/  1000, exp = train
train_iter_loss: 0.011122750118374825
train_iter_loss: 0.036231737583875656
train_iter_loss: 0.02867978624999523
train_iter_loss: 0.02832890674471855
train_iter_loss: 0.028747474774718285
train_iter_loss: 0.03340592607855797
train_iter_loss: 0.028340687975287437
train_iter_loss: 0.029092278331518173
train_iter_loss: 0.009433095343410969
train_iter_loss: 0.007683600299060345
train_iter_loss: 0.031456366181373596
train_iter_loss: 0.016076166182756424
train_iter_loss: 0.013026803731918335
train_iter_loss: 0.01417350023984909
train_iter_loss: 0.010232103057205677
train_iter_loss: 0.014541978016495705
train_iter_loss: 0.009358846582472324
train_iter_loss: 0.0241546668112278
train_iter_loss: 0.020857276394963264
train_iter_loss: 0.04173660650849342
train_iter_loss: 0.02213915064930916
train_iter_loss: 0.00718448543921113
train_iter_loss: 0.009396961890161037
train_iter_loss: 0.024443194270133972
train_iter_loss: 0.005692849401384592
train_iter_loss: 0.013035439886152744
train_iter_loss: 0.017857372760772705
train_iter_loss: 0.02899276651442051
train_iter_loss: 0.005567853804677725
train_iter_loss: 0.01685589924454689
train_iter_loss: 0.003146679140627384
train_iter_loss: 0.004210964776575565
train_iter_loss: 0.004102888982743025
train_iter_loss: 0.002861540764570236
train_iter_loss: 0.022185716778039932
train_iter_loss: 0.007389842998236418
train_iter_loss: 0.01888270489871502
train_iter_loss: 0.012230600230395794
train_iter_loss: 0.022475166246294975
train_iter_loss: 0.012075078673660755
train_iter_loss: 0.004013993311673403
train_iter_loss: 0.008772837929427624
train_iter_loss: 0.012456688098609447
train_iter_loss: 0.028912857174873352
train_iter_loss: 0.013381856493651867
train_iter_loss: 0.002627401379868388
train_iter_loss: 0.0020298429299145937
train_iter_loss: 0.01245151273906231
train_iter_loss: 0.04689430072903633
train_iter_loss: 0.016189534217119217
train loss :0.0172
---------------------
Validation seg loss: 0.05682646710165328 at epoch 21
epoch =     22/  1000, exp = train
train_iter_loss: 0.00892317108809948
train_iter_loss: 0.023280415683984756
train_iter_loss: 0.028958147391676903
train_iter_loss: 0.03966229781508446
train_iter_loss: 0.05330898240208626
train_iter_loss: 0.019884897395968437
train_iter_loss: 0.015827421098947525
train_iter_loss: 0.04075067117810249
train_iter_loss: 0.02623869478702545
train_iter_loss: 0.01099812239408493
train_iter_loss: 0.011331277899444103
train_iter_loss: 0.009634215384721756
train_iter_loss: 0.0153002068400383
train_iter_loss: 0.004702990408986807
train_iter_loss: 0.024909354746341705
train_iter_loss: 0.008857074193656445
train_iter_loss: 0.013470222242176533
train_iter_loss: 0.009776272810995579
train_iter_loss: 0.012850791215896606
train_iter_loss: 0.01726420968770981
train_iter_loss: 0.005806594155728817
train_iter_loss: 0.0051677594892680645
train_iter_loss: 0.007246158551424742
train_iter_loss: 0.008035608567297459
train_iter_loss: 0.014270087704062462
train_iter_loss: 0.06540171802043915
train_iter_loss: 0.016697578132152557
train_iter_loss: 0.01085855346173048
train_iter_loss: 0.00663053710013628
train_iter_loss: 0.003476084442809224
train_iter_loss: 0.005479687359184027
train_iter_loss: 0.0050238813273608685
train_iter_loss: 0.002580162836238742
train_iter_loss: 0.007247347850352526
train_iter_loss: 0.00487275468185544
train_iter_loss: 0.02466162107884884
train_iter_loss: 0.059199944138526917
train_iter_loss: 0.01264581736177206
train_iter_loss: 0.012576826848089695
train_iter_loss: 0.008760581724345684
train_iter_loss: 0.048089977353811264
train_iter_loss: 0.03172130882740021
train_iter_loss: 0.007198241539299488
train_iter_loss: 0.022260185331106186
train_iter_loss: 0.015283974818885326
train_iter_loss: 0.002669725101441145
train_iter_loss: 0.004025818780064583
train_iter_loss: 0.00989486649632454
train_iter_loss: 0.01817975379526615
train_iter_loss: 0.014993909746408463
train loss :0.0175
---------------------
Validation seg loss: 0.06045821970927239 at epoch 22
epoch =     23/  1000, exp = train
train_iter_loss: 0.01324863638728857
train_iter_loss: 0.07599646598100662
train_iter_loss: 0.0052611930295825005
train_iter_loss: 0.05955427885055542
train_iter_loss: 0.03607287257909775
train_iter_loss: 0.017424311488866806
train_iter_loss: 0.03907884657382965
train_iter_loss: 0.048674218356609344
train_iter_loss: 0.019568296149373055
train_iter_loss: 0.022115280851721764
train_iter_loss: 0.008518378250300884
train_iter_loss: 0.041475046426057816
train_iter_loss: 0.007158155553042889
train_iter_loss: 0.029382437467575073
train_iter_loss: 0.023662535473704338
train_iter_loss: 0.016005290672183037
train_iter_loss: 0.019651949405670166
train_iter_loss: 0.007686837110668421
train_iter_loss: 0.019019484519958496
train_iter_loss: 0.02621724270284176
train_iter_loss: 0.0028776400722563267
train_iter_loss: 0.004850052762776613
train_iter_loss: 0.0037186886183917522
train_iter_loss: 0.004047214053571224
train_iter_loss: 0.06323150545358658
train_iter_loss: 0.06701339781284332
train_iter_loss: 0.012357544153928757
train_iter_loss: 0.023228829726576805
train_iter_loss: 0.00448824604973197
train_iter_loss: 0.007061288226395845
train_iter_loss: 0.0062678600661456585
train_iter_loss: 0.006156544666737318
train_iter_loss: 0.0018672257428988814
train_iter_loss: 0.013526076450943947
train_iter_loss: 0.009105170145630836
train_iter_loss: 0.0042705354280769825
train_iter_loss: 0.01025875099003315
train_iter_loss: 0.010592461563646793
train_iter_loss: 0.042255740612745285
train_iter_loss: 0.07283533364534378
train_iter_loss: 0.019665729254484177
train_iter_loss: 0.022712454199790955
train_iter_loss: 0.012313376180827618
train_iter_loss: 0.015440130606293678
train_iter_loss: 0.008277563378214836
train_iter_loss: 0.011531584896147251
train_iter_loss: 0.0028033475391566753
train_iter_loss: 0.005476121325045824
train_iter_loss: 0.015103252604603767
train_iter_loss: 0.012974049896001816
train loss :0.0210
---------------------
Validation seg loss: 0.05538171872838163 at epoch 23
epoch =     24/  1000, exp = train
train_iter_loss: 0.009735721163451672
train_iter_loss: 0.014343785122036934
train_iter_loss: 0.01569247432053089
train_iter_loss: 0.044203583151102066
train_iter_loss: 0.02050858736038208
train_iter_loss: 0.01996774412691593
train_iter_loss: 0.04592930153012276
train_iter_loss: 0.010194516740739346
train_iter_loss: 0.012777709402143955
train_iter_loss: 0.005619491450488567
train_iter_loss: 0.023383338004350662
train_iter_loss: 0.0583832785487175
train_iter_loss: 0.01133875735104084
train_iter_loss: 0.009589249268174171
train_iter_loss: 0.02522767148911953
train_iter_loss: 0.015812039375305176
train_iter_loss: 0.00650190282613039
train_iter_loss: 0.016190705820918083
train_iter_loss: 0.01467157807201147
train_iter_loss: 0.018147410824894905
train_iter_loss: 0.00782568659633398
train_iter_loss: 0.042555902153253555
train_iter_loss: 0.024252045899629593
train_iter_loss: 0.003760452615097165
train_iter_loss: 0.06283480674028397
train_iter_loss: 0.00940783228725195
train_iter_loss: 0.009740841574966908
train_iter_loss: 0.020254381000995636
train_iter_loss: 0.007811541203409433
train_iter_loss: 0.004916408099234104
train_iter_loss: 0.0075520481914281845
train_iter_loss: 0.0029999525286257267
train_iter_loss: 0.0026104578282684088
train_iter_loss: 0.003180079162120819
train_iter_loss: 0.002961639780551195
train_iter_loss: 0.001917663961648941
train_iter_loss: 0.031624723225831985
train_iter_loss: 0.012648854404687881
train_iter_loss: 0.02027011848986149
train_iter_loss: 0.008350455202162266
train_iter_loss: 0.047905948013067245
train_iter_loss: 0.01695910654962063
train_iter_loss: 0.017621463164687157
train_iter_loss: 0.022397324442863464
train_iter_loss: 0.010252530686557293
train_iter_loss: 0.009740222245454788
train_iter_loss: 0.003030474530532956
train_iter_loss: 0.0022513088770210743
train_iter_loss: 0.0227374080568552
train_iter_loss: 0.009285498410463333
train loss :0.0174
---------------------
Validation seg loss: 0.055381276981656895 at epoch 24
epoch =     25/  1000, exp = train
train_iter_loss: 0.015523804351687431
train_iter_loss: 0.0204724483191967
train_iter_loss: 0.011720933951437473
train_iter_loss: 0.01113405916839838
train_iter_loss: 0.029007188975811005
train_iter_loss: 0.03145080432295799
train_iter_loss: 0.0179449412971735
train_iter_loss: 0.009781954810023308
train_iter_loss: 0.018883008509874344
train_iter_loss: 0.010393844917416573
train_iter_loss: 0.011775147169828415
train_iter_loss: 0.019625622779130936
train_iter_loss: 0.007444411516189575
train_iter_loss: 0.011085589416325092
train_iter_loss: 0.012864172458648682
train_iter_loss: 0.004678591154515743
train_iter_loss: 0.01495650690048933
train_iter_loss: 0.016553491353988647
train_iter_loss: 0.014356506988406181
train_iter_loss: 0.011995854787528515
train_iter_loss: 0.008166421204805374
train_iter_loss: 0.009407889097929
train_iter_loss: 0.0019479542970657349
train_iter_loss: 0.018655331805348396
train_iter_loss: 0.026585496962070465
train_iter_loss: 0.02483353577554226
train_iter_loss: 0.013086363673210144
train_iter_loss: 0.03625456243753433
train_iter_loss: 0.010615452192723751
train_iter_loss: 0.005118813831359148
train_iter_loss: 0.005753070581704378
train_iter_loss: 0.004389997571706772
train_iter_loss: 0.00569524709135294
train_iter_loss: 0.012029126286506653
train_iter_loss: 0.005996041465550661
train_iter_loss: 0.0030980489682406187
train_iter_loss: 0.02113393135368824
train_iter_loss: 0.003026921534910798
train_iter_loss: 0.04808565601706505
train_iter_loss: 0.06647108495235443
train_iter_loss: 0.016813846305012703
train_iter_loss: 0.019487526267766953
train_iter_loss: 0.007467345800250769
train_iter_loss: 0.024249134585261345
train_iter_loss: 0.0029873226303607225
train_iter_loss: 0.004646604880690575
train_iter_loss: 0.004728967789560556
train_iter_loss: 0.004228278063237667
train_iter_loss: 0.04968973621726036
train_iter_loss: 0.019164839759469032
train loss :0.0161
---------------------
Validation seg loss: 0.053768681920735376 at epoch 25
epoch =     26/  1000, exp = train
train_iter_loss: 0.029876895248889923
train_iter_loss: 0.0162357185035944
train_iter_loss: 0.008440629579126835
train_iter_loss: 0.013824619352817535
train_iter_loss: 0.019562991335988045
train_iter_loss: 0.043346282094717026
train_iter_loss: 0.05725080892443657
train_iter_loss: 0.017900465056300163
train_iter_loss: 0.01958332769572735
train_iter_loss: 0.015470100566744804
train_iter_loss: 0.010212324559688568
train_iter_loss: 0.0133607042953372
train_iter_loss: 0.02714557759463787
train_iter_loss: 0.007270173169672489
train_iter_loss: 0.010967575944960117
train_iter_loss: 0.018662724643945694
train_iter_loss: 0.010810431092977524
train_iter_loss: 0.008417920209467411
train_iter_loss: 0.017810305580496788
train_iter_loss: 0.01714853011071682
train_iter_loss: 0.005815363954752684
train_iter_loss: 0.016632327809929848
train_iter_loss: 0.010559238493442535
train_iter_loss: 0.010402603074908257
train_iter_loss: 0.01572927087545395
train_iter_loss: 0.019222136586904526
train_iter_loss: 0.021986786276102066
train_iter_loss: 0.014997166581451893
train_iter_loss: 0.0050294287502765656
train_iter_loss: 0.0064039332792162895
train_iter_loss: 0.01306743174791336
train_iter_loss: 0.03732398897409439
train_iter_loss: 0.006597523577511311
train_iter_loss: 0.005442009773105383
train_iter_loss: 0.013926703482866287
train_iter_loss: 0.0036584115587174892
train_iter_loss: 0.012866362929344177
train_iter_loss: 0.012776928022503853
train_iter_loss: 0.027316709980368614
train_iter_loss: 0.008916031569242477
train_iter_loss: 0.037956077605485916
train_iter_loss: 0.039844200015068054
train_iter_loss: 0.011465851217508316
train_iter_loss: 0.005589228589087725
train_iter_loss: 0.0047499374486505985
train_iter_loss: 0.0167935062199831
train_iter_loss: 0.02156381867825985
train_iter_loss: 0.010889794677495956
train_iter_loss: 0.006225395482033491
train_iter_loss: 0.03379641845822334
train loss :0.0171
---------------------
Validation seg loss: 0.05427713430830374 at epoch 26
epoch =     27/  1000, exp = train
train_iter_loss: 0.015916822478175163
train_iter_loss: 0.043746113777160645
train_iter_loss: 0.031297873705625534
train_iter_loss: 0.025456644594669342
train_iter_loss: 0.014527461491525173
train_iter_loss: 0.028650492429733276
train_iter_loss: 0.017914123833179474
train_iter_loss: 0.008354857563972473
train_iter_loss: 0.011226278729736805
train_iter_loss: 0.011817599646747112
train_iter_loss: 0.009136390872299671
train_iter_loss: 0.006059457082301378
train_iter_loss: 0.006543026305735111
train_iter_loss: 0.006855987478047609
train_iter_loss: 0.0064221033826470375
train_iter_loss: 0.03609083220362663
train_iter_loss: 0.013822730630636215
train_iter_loss: 0.007358384784311056
train_iter_loss: 0.010468345135450363
train_iter_loss: 0.02554064802825451
train_iter_loss: 0.008244614116847515
train_iter_loss: 0.015693753957748413
train_iter_loss: 0.00250269309617579
train_iter_loss: 0.011257488280534744
train_iter_loss: 0.020730795338749886
train_iter_loss: 0.06382157653570175
train_iter_loss: 0.008599251508712769
train_iter_loss: 0.023241091519594193
train_iter_loss: 0.008775027468800545
train_iter_loss: 0.004802245646715164
train_iter_loss: 0.033492736518383026
train_iter_loss: 0.00567044410854578
train_iter_loss: 0.01065406296402216
train_iter_loss: 0.003659007837995887
train_iter_loss: 0.012790721841156483
train_iter_loss: 0.006615796126425266
train_iter_loss: 0.02358870767056942
train_iter_loss: 0.0042933025397360325
train_iter_loss: 0.013736140914261341
train_iter_loss: 0.016198450699448586
train_iter_loss: 0.01647990010678768
train_iter_loss: 0.01886432245373726
train_iter_loss: 0.014084664173424244
train_iter_loss: 0.02918127365410328
train_iter_loss: 0.011335321702063084
train_iter_loss: 0.01267068088054657
train_iter_loss: 0.0050088390707969666
train_iter_loss: 0.04064149037003517
train_iter_loss: 0.0235542394220829
train_iter_loss: 0.04242246598005295
train loss :0.0173
---------------------
Validation seg loss: 0.05846992817807301 at epoch 27
epoch =     28/  1000, exp = train
train_iter_loss: 0.04795468598604202
train_iter_loss: 0.017021989449858665
train_iter_loss: 0.010998662561178207
train_iter_loss: 0.010621593333780766
train_iter_loss: 0.016661593690514565
train_iter_loss: 0.07086842507123947
train_iter_loss: 0.07634840160608292
train_iter_loss: 0.011866510845720768
train_iter_loss: 0.02069547213613987
train_iter_loss: 0.01441272348165512
train_iter_loss: 0.010828717611730099
train_iter_loss: 0.005227946676313877
train_iter_loss: 0.005391268990933895
train_iter_loss: 0.006917722523212433
train_iter_loss: 0.023068755865097046
train_iter_loss: 0.013451209291815758
train_iter_loss: 0.00543347978964448
train_iter_loss: 0.014011126011610031
train_iter_loss: 0.04618008807301521
train_iter_loss: 0.015252125449478626
train_iter_loss: 0.010351459495723248
train_iter_loss: 0.005223574582487345
train_iter_loss: 0.014660364016890526
train_iter_loss: 0.012116174213588238
train_iter_loss: 0.004422888625413179
train_iter_loss: 0.00546553498134017
train_iter_loss: 0.00652272580191493
train_iter_loss: 0.02931796759366989
train_iter_loss: 0.013870692811906338
train_iter_loss: 0.00577247329056263
train_iter_loss: 0.0167381651699543
train_iter_loss: 0.012504620477557182
train_iter_loss: 0.004241417162120342
train_iter_loss: 0.008678111247718334
train_iter_loss: 0.008935270830988884
train_iter_loss: 0.002986421575769782
train_iter_loss: 0.016306143254041672
train_iter_loss: 0.006444596219807863
train_iter_loss: 0.00925916712731123
train_iter_loss: 0.01299932412803173
train_iter_loss: 0.010454187169671059
train_iter_loss: 0.012174854055047035
train_iter_loss: 0.01306212693452835
train_iter_loss: 0.010343355126678944
train_iter_loss: 0.007510026451200247
train_iter_loss: 0.004687882494181395
train_iter_loss: 0.008016939274966717
train_iter_loss: 0.008694485761225224
train_iter_loss: 0.013258994556963444
train_iter_loss: 0.01696077734231949
train loss :0.0155
---------------------
Validation seg loss: 0.056294850035864895 at epoch 28
epoch =     29/  1000, exp = train
train_iter_loss: 0.0042215012945234776
train_iter_loss: 0.0365581288933754
train_iter_loss: 0.005533295683562756
train_iter_loss: 0.008019361644983292
train_iter_loss: 0.06551273912191391
train_iter_loss: 0.03976066783070564
train_iter_loss: 0.020697930827736855
train_iter_loss: 0.019933732226490974
train_iter_loss: 0.011027120053768158
train_iter_loss: 0.051384590566158295
train_iter_loss: 0.010625801980495453
train_iter_loss: 0.013476907275617123
train_iter_loss: 0.013119717128574848
train_iter_loss: 0.008763061836361885
train_iter_loss: 0.010429158806800842
train_iter_loss: 0.0120627973228693
train_iter_loss: 0.011211791075766087
train_iter_loss: 0.02322653867304325
train_iter_loss: 0.030707191675901413
train_iter_loss: 0.00778683228418231
train_iter_loss: 0.010592350736260414
train_iter_loss: 0.004422365687787533
train_iter_loss: 0.0024543111212551594
train_iter_loss: 0.04238017275929451
train_iter_loss: 0.018655838444828987
train_iter_loss: 0.04555480182170868
train_iter_loss: 0.012023350223898888
train_iter_loss: 0.03783843293786049
train_iter_loss: 0.019125036895275116
train_iter_loss: 0.010500112548470497
train_iter_loss: 0.004006238654255867
train_iter_loss: 0.004661217797547579
train_iter_loss: 0.007697110064327717
train_iter_loss: 0.007748361211270094
train_iter_loss: 0.007867323234677315
train_iter_loss: 0.003987334668636322
train_iter_loss: 0.03147079423069954
train_iter_loss: 0.005949248559772968
train_iter_loss: 0.004876784980297089
train_iter_loss: 0.043617602437734604
train_iter_loss: 0.047026146203279495
train_iter_loss: 0.02907305769622326
train_iter_loss: 0.024201860651373863
train_iter_loss: 0.029683947563171387
train_iter_loss: 0.007993754930794239
train_iter_loss: 0.017213845625519753
train_iter_loss: 0.008656583726406097
train_iter_loss: 0.009840724058449268
train_iter_loss: 0.013023131527006626
train_iter_loss: 0.010655558668076992
train loss :0.0188
---------------------
Validation seg loss: 0.0534768369820909 at epoch 29
epoch =     30/  1000, exp = train
train_iter_loss: 0.021769337356090546
train_iter_loss: 0.014526988379657269
train_iter_loss: 0.006012748461216688
train_iter_loss: 0.015272153541445732
train_iter_loss: 0.02233755774796009
train_iter_loss: 0.012671168893575668
train_iter_loss: 0.012794533744454384
train_iter_loss: 0.00899928156286478
train_iter_loss: 0.011427974328398705
train_iter_loss: 0.012527171522378922
train_iter_loss: 0.006412534508854151
train_iter_loss: 0.0222086850553751
train_iter_loss: 0.013019184581935406
train_iter_loss: 0.006723636295646429
train_iter_loss: 0.02633078582584858
train_iter_loss: 0.010255933739244938
train_iter_loss: 0.005706986878067255
train_iter_loss: 0.010611547157168388
train_iter_loss: 0.014771892689168453
train_iter_loss: 0.006726334802806377
train_iter_loss: 0.031214002519845963
train_iter_loss: 0.02235228754580021
train_iter_loss: 0.006155419163405895
train_iter_loss: 0.01583602838218212
train_iter_loss: 0.0443720705807209
train_iter_loss: 0.005911410786211491
train_iter_loss: 0.05084940046072006
train_iter_loss: 0.002956379670649767
train_iter_loss: 0.010446893982589245
train_iter_loss: 0.012956347316503525
train_iter_loss: 0.0068758148699998856
train_iter_loss: 0.014693798497319221
train_iter_loss: 0.0034172653686255217
train_iter_loss: 0.014265547506511211
train_iter_loss: 0.01247665099799633
train_iter_loss: 0.0031016261782497168
train_iter_loss: 0.008700909093022346
train_iter_loss: 0.004446203820407391
train_iter_loss: 0.02373609133064747
train_iter_loss: 0.04559256136417389
train_iter_loss: 0.008776215836405754
train_iter_loss: 0.01068031508475542
train_iter_loss: 0.013215447776019573
train_iter_loss: 0.012984568253159523
train_iter_loss: 0.004434623755514622
train_iter_loss: 0.013022082857787609
train_iter_loss: 0.0017829012358561158
train_iter_loss: 0.016009239479899406
train_iter_loss: 0.03650299087166786
train_iter_loss: 0.13561204075813293
train loss :0.0175
---------------------
Validation seg loss: 0.0569419112377185 at epoch 30
epoch =     31/  1000, exp = train
train_iter_loss: 0.006586064118891954
train_iter_loss: 0.007882867939770222
train_iter_loss: 0.017787689343094826
train_iter_loss: 0.003961693495512009
train_iter_loss: 0.025533923879265785
train_iter_loss: 0.009562158957123756
train_iter_loss: 0.08216464519500732
train_iter_loss: 0.02012399397790432
train_iter_loss: 0.010103795677423477
train_iter_loss: 0.010592476464807987
train_iter_loss: 0.014942406676709652
train_iter_loss: 0.009816538542509079
train_iter_loss: 0.025184085592627525
train_iter_loss: 0.01038289349526167
train_iter_loss: 0.0067069013603031635
train_iter_loss: 0.007457696832716465
train_iter_loss: 0.0095441322773695
train_iter_loss: 0.019182872027158737
train_iter_loss: 0.012578064575791359
train_iter_loss: 0.014387428760528564
train_iter_loss: 0.006352177821099758
train_iter_loss: 0.0062402659095823765
train_iter_loss: 0.03234311565756798
train_iter_loss: 0.006884114351123571
train_iter_loss: 0.030889203771948814
train_iter_loss: 0.02233799360692501
train_iter_loss: 0.02349444292485714
train_iter_loss: 0.029584165662527084
train_iter_loss: 0.0028047943487763405
train_iter_loss: 0.008252840489149094
train_iter_loss: 0.006267247721552849
train_iter_loss: 0.020279686897993088
train_iter_loss: 0.010262886993587017
train_iter_loss: 0.007075037807226181
train_iter_loss: 0.012513501569628716
train_iter_loss: 0.0015667927218601108
train_iter_loss: 0.025718962773680687
train_iter_loss: 0.031653519719839096
train_iter_loss: 0.0022607394494116306
train_iter_loss: 0.019517192617058754
train_iter_loss: 0.011713877320289612
train_iter_loss: 0.0165992621332407
train_iter_loss: 0.016470525413751602
train_iter_loss: 0.021448172628879547
train_iter_loss: 0.004789115395396948
train_iter_loss: 0.0045502763241529465
train_iter_loss: 0.004453111905604601
train_iter_loss: 0.0033098773565143347
train_iter_loss: 0.01036074198782444
train_iter_loss: 0.009771467186510563
train loss :0.0150
---------------------
Validation seg loss: 0.05452809302478959 at epoch 31
epoch =     32/  1000, exp = train
train_iter_loss: 0.00516686774790287
train_iter_loss: 0.03887436166405678
train_iter_loss: 0.014562871307134628
train_iter_loss: 0.03070824034512043
train_iter_loss: 0.031696829944849014
train_iter_loss: 0.012095502577722073
train_iter_loss: 0.012724841013550758
train_iter_loss: 0.009804981760680676
train_iter_loss: 0.024329671636223793
train_iter_loss: 0.011330037377774715
train_iter_loss: 0.046115826815366745
train_iter_loss: 0.024907872080802917
train_iter_loss: 0.006833833642303944
train_iter_loss: 0.012440849095582962
train_iter_loss: 0.017803873866796494
train_iter_loss: 0.0031951069831848145
train_iter_loss: 0.015136385336518288
train_iter_loss: 0.007023152895271778
train_iter_loss: 0.010158520191907883
train_iter_loss: 0.018326932564377785
train_iter_loss: 0.005635242909193039
train_iter_loss: 0.00863184779882431
train_iter_loss: 0.0069124442525208
train_iter_loss: 0.014280740171670914
train_iter_loss: 0.0167810320854187
train_iter_loss: 0.009977891109883785
train_iter_loss: 0.012156481854617596
train_iter_loss: 0.05407043546438217
train_iter_loss: 0.004759753122925758
train_iter_loss: 0.007924167439341545
train_iter_loss: 0.006544685456901789
train_iter_loss: 0.0033197118900716305
train_iter_loss: 0.008049919269979
train_iter_loss: 0.0015410123160108924
train_iter_loss: 0.006665130145847797
train_iter_loss: 0.0020858454518020153
train_iter_loss: 0.005598791874945164
train_iter_loss: 0.03045901656150818
train_iter_loss: 0.010781197808682919
train_iter_loss: 0.012675154954195023
train_iter_loss: 0.019244980067014694
train_iter_loss: 0.06943695992231369
train_iter_loss: 0.010666225105524063
train_iter_loss: 0.006815364118665457
train_iter_loss: 0.004447340499609709
train_iter_loss: 0.004197001922875643
train_iter_loss: 0.010589958168566227
train_iter_loss: 0.003914952278137207
train_iter_loss: 0.01458137296140194
train_iter_loss: 0.010961377061903477
train loss :0.0150
---------------------
Validation seg loss: 0.05766275124558476 at epoch 32
epoch =     33/  1000, exp = train
train_iter_loss: 0.009542163461446762
train_iter_loss: 0.011973327025771141
train_iter_loss: 0.025337738916277885
train_iter_loss: 0.004257500171661377
train_iter_loss: 0.022414518520236015
train_iter_loss: 0.02999028190970421
train_iter_loss: 0.017116541042923927
train_iter_loss: 0.015106658451259136
train_iter_loss: 0.020175551995635033
train_iter_loss: 0.017570005729794502
train_iter_loss: 0.02795652486383915
train_iter_loss: 0.029551584273576736
train_iter_loss: 0.0072910054586827755
train_iter_loss: 0.012458452954888344
train_iter_loss: 0.02121080458164215
train_iter_loss: 0.009894054383039474
train_iter_loss: 0.018521534278988838
train_iter_loss: 0.02142282947897911
train_iter_loss: 0.009704982861876488
train_iter_loss: 0.007879934273660183
train_iter_loss: 0.00565672991797328
train_iter_loss: 0.010172784328460693
train_iter_loss: 0.0062299915589392185
train_iter_loss: 0.006263848394155502
train_iter_loss: 0.007878929376602173
train_iter_loss: 0.042127158492803574
train_iter_loss: 0.03706289827823639
train_iter_loss: 0.061127763241529465
train_iter_loss: 0.007562899496406317
train_iter_loss: 0.007244760170578957
train_iter_loss: 0.011309154331684113
train_iter_loss: 0.014785528182983398
train_iter_loss: 0.00572521798312664
train_iter_loss: 0.0029201614670455456
train_iter_loss: 0.0029966963920742273
train_iter_loss: 0.004433389753103256
train_iter_loss: 0.018393365666270256
train_iter_loss: 0.03552892059087753
train_iter_loss: 0.03917085379362106
train_iter_loss: 0.016329504549503326
train_iter_loss: 0.031198883429169655
train_iter_loss: 0.010339543223381042
train_iter_loss: 0.011492135003209114
train_iter_loss: 0.03285912796854973
train_iter_loss: 0.013953747227787971
train_iter_loss: 0.020209137350320816
train_iter_loss: 0.005863523576408625
train_iter_loss: 0.0199130829423666
train_iter_loss: 0.008561437018215656
train_iter_loss: 0.019825231283903122
train loss :0.0174
---------------------
Validation seg loss: 0.05347915976209443 at epoch 33
epoch =     34/  1000, exp = train
train_iter_loss: 0.01708996295928955
train_iter_loss: 0.04207174479961395
train_iter_loss: 0.022199660539627075
train_iter_loss: 0.013643487356603146
train_iter_loss: 0.05221526324748993
train_iter_loss: 0.006309447810053825
train_iter_loss: 0.011728908866643906
train_iter_loss: 0.021412765607237816
train_iter_loss: 0.007587881293147802
train_iter_loss: 0.006717287003993988
train_iter_loss: 0.01543853897601366
train_iter_loss: 0.011312445625662804
train_iter_loss: 0.014084728434681892
train_iter_loss: 0.003919138107448816
train_iter_loss: 0.024696771055459976
train_iter_loss: 0.006240305490791798
train_iter_loss: 0.027267416939139366
train_iter_loss: 0.01833723671734333
train_iter_loss: 0.021681055426597595
train_iter_loss: 0.01476849615573883
train_iter_loss: 0.014550517313182354
train_iter_loss: 0.014547443948686123
train_iter_loss: 0.005902275443077087
train_iter_loss: 0.009779976680874825
train_iter_loss: 0.011939575895667076
train_iter_loss: 0.02464701607823372
train_iter_loss: 0.07415015995502472
train_iter_loss: 0.007840903475880623
train_iter_loss: 0.006559044122695923
train_iter_loss: 0.016627585515379906
train_iter_loss: 0.006696873810142279
train_iter_loss: 0.008458234369754791
train_iter_loss: 0.0032861102372407913
train_iter_loss: 0.00694310711696744
train_iter_loss: 0.0035164272412657738
train_iter_loss: 0.006094146985560656
train_iter_loss: 0.026391832157969475
train_iter_loss: 0.01344397570937872
train_iter_loss: 0.013088474050164223
train_iter_loss: 0.010746387764811516
train_iter_loss: 0.026545362547039986
train_iter_loss: 0.03820484131574631
train_iter_loss: 0.03199572488665581
train_iter_loss: 0.014215256087481976
train_iter_loss: 0.0030670836567878723
train_iter_loss: 0.005345851182937622
train_iter_loss: 0.02813725173473358
train_iter_loss: 0.006788026541471481
train_iter_loss: 0.007937531918287277
train_iter_loss: 0.026571758091449738
train loss :0.0170
---------------------
Validation seg loss: 0.056809897830804264 at epoch 34
epoch =     35/  1000, exp = train
train_iter_loss: 0.00861192774027586
train_iter_loss: 0.022087544202804565
train_iter_loss: 0.012955183163285255
train_iter_loss: 0.016997234895825386
train_iter_loss: 0.01029221061617136
train_iter_loss: 0.037379760295152664
train_iter_loss: 0.014094894751906395
train_iter_loss: 0.03809564933180809
train_iter_loss: 0.02199440263211727
train_iter_loss: 0.03076362982392311
train_iter_loss: 0.02663741447031498
train_iter_loss: 0.01038437057286501
train_iter_loss: 0.005670615937560797
train_iter_loss: 0.009531335905194283
train_iter_loss: 0.012089051306247711
train_iter_loss: 0.01135422196239233
train_iter_loss: 0.020600255578756332
train_iter_loss: 0.04381515085697174
train_iter_loss: 0.01066440436989069
train_iter_loss: 0.007794538978487253
train_iter_loss: 0.008453970775008202
train_iter_loss: 0.01597210392355919
train_iter_loss: 0.008434126153588295
train_iter_loss: 0.008662370033562183
train_iter_loss: 0.015459904447197914
train_iter_loss: 0.016471441835165024
train_iter_loss: 0.01370572205632925
train_iter_loss: 0.04384980723261833
train_iter_loss: 0.00834835134446621
train_iter_loss: 0.014484208077192307
train_iter_loss: 0.020380821079015732
train_iter_loss: 0.006506027188152075
train_iter_loss: 0.01574542373418808
train_iter_loss: 0.014768430031836033
train_iter_loss: 0.01067489292472601
train_iter_loss: 0.004801639821380377
train_iter_loss: 0.029136469587683678
train_iter_loss: 0.0058263977989554405
train_iter_loss: 0.03054817207157612
train_iter_loss: 0.03401252627372742
train_iter_loss: 0.011060187593102455
train_iter_loss: 0.021617872640490532
train_iter_loss: 0.028024159371852875
train_iter_loss: 0.010930967517197132
train_iter_loss: 0.021501829847693443
train_iter_loss: 0.010102778673171997
train_iter_loss: 0.0024062080774456263
train_iter_loss: 0.013726561330258846
train_iter_loss: 0.05062102526426315
train_iter_loss: 0.013407504186034203
train loss :0.0180
---------------------
Validation seg loss: 0.05988247266104049 at epoch 35
epoch =     36/  1000, exp = train
train_iter_loss: 0.01719001680612564
train_iter_loss: 0.012872309423983097
train_iter_loss: 0.02302861586213112
train_iter_loss: 0.009941842406988144
train_iter_loss: 0.012378251180052757
train_iter_loss: 0.009014648385345936
train_iter_loss: 0.019375715404748917
train_iter_loss: 0.00941894855350256
train_iter_loss: 0.016116196289658546
train_iter_loss: 0.010831117630004883
train_iter_loss: 0.024322593584656715
train_iter_loss: 0.017441345378756523
train_iter_loss: 0.00814277958124876
train_iter_loss: 0.017674734815955162
train_iter_loss: 0.015917060896754265
train_iter_loss: 0.004307930823415518
train_iter_loss: 0.027715159580111504
train_iter_loss: 0.011869453825056553
train_iter_loss: 0.017313586547970772
train_iter_loss: 0.01571195386350155
train_iter_loss: 0.02707402966916561
train_iter_loss: 0.009086805395781994
train_iter_loss: 0.010804714635014534
train_iter_loss: 0.018338939175009727
train_iter_loss: 0.023920005187392235
train_iter_loss: 0.011642754077911377
train_iter_loss: 0.01284857839345932
train_iter_loss: 0.009915287606418133
train_iter_loss: 0.03334123268723488
train_iter_loss: 0.009530487470328808
train_iter_loss: 0.007730347570031881
train_iter_loss: 0.003569534048438072
train_iter_loss: 0.003989711869508028
train_iter_loss: 0.003160362131893635
train_iter_loss: 0.016423312947154045
train_iter_loss: 0.0030306167900562286
train_iter_loss: 0.004394525196403265
train_iter_loss: 0.02545434981584549
train_iter_loss: 0.029731385409832
train_iter_loss: 0.02555525116622448
train_iter_loss: 0.009966575540602207
train_iter_loss: 0.02824760414659977
train_iter_loss: 0.004871886223554611
train_iter_loss: 0.038945574313402176
train_iter_loss: 0.013745763339102268
train_iter_loss: 0.007937650196254253
train_iter_loss: 0.005208246875554323
train_iter_loss: 0.002474518958479166
train_iter_loss: 0.025249827653169632
train_iter_loss: 0.02373638190329075
train loss :0.0154
---------------------
Validation seg loss: 0.05723878523507287 at epoch 36
epoch =     37/  1000, exp = train
train_iter_loss: 0.022305691614747047
train_iter_loss: 0.016221676021814346
train_iter_loss: 0.025143304839730263
train_iter_loss: 0.011987680569291115
train_iter_loss: 0.03842579200863838
train_iter_loss: 0.0461852066218853
train_iter_loss: 0.04321134835481644
train_iter_loss: 0.03325597196817398
train_iter_loss: 0.041700009256601334
train_iter_loss: 0.019518796354532242
train_iter_loss: 0.021008772775530815
train_iter_loss: 0.011793398298323154
train_iter_loss: 0.00830517616122961
train_iter_loss: 0.008335305377840996
train_iter_loss: 0.010365655645728111
train_iter_loss: 0.00630513159558177
train_iter_loss: 0.02204580418765545
train_iter_loss: 0.008705771528184414
train_iter_loss: 0.013513733632862568
train_iter_loss: 0.017644399777054787
train_iter_loss: 0.002171556930989027
train_iter_loss: 0.0543031245470047
train_iter_loss: 0.009529992006719112
train_iter_loss: 0.02230891026556492
train_iter_loss: 0.015692567452788353
train_iter_loss: 0.03220200911164284
train_iter_loss: 0.019899049773812294
train_iter_loss: 0.03026343509554863
train_iter_loss: 0.0019358221907168627
train_iter_loss: 0.0014882624382153153
train_iter_loss: 0.004287855699658394
train_iter_loss: 0.009501030668616295
train_iter_loss: 0.002492540283128619
train_iter_loss: 0.002123898360878229
train_iter_loss: 0.005870681256055832
train_iter_loss: 0.007289425004273653
train_iter_loss: 0.019421331584453583
train_iter_loss: 0.011890686117112637
train_iter_loss: 0.00954480841755867
train_iter_loss: 0.006925161927938461
train_iter_loss: 0.015159474685788155
train_iter_loss: 0.020212192088365555
train_iter_loss: 0.024065840989351273
train_iter_loss: 0.00916158128529787
train_iter_loss: 0.0075415452010929585
train_iter_loss: 0.01459320168942213
train_iter_loss: 0.00633668340742588
train_iter_loss: 0.010397667065262794
train_iter_loss: 0.025072962045669556
train_iter_loss: 0.03377436101436615
train loss :0.0175
---------------------
Validation seg loss: 0.05607530837060383 at epoch 37
epoch =     38/  1000, exp = train
train_iter_loss: 0.011372530832886696
train_iter_loss: 0.0252735186368227
train_iter_loss: 0.011683517135679722
train_iter_loss: 0.024006208404898643
train_iter_loss: 0.011534512974321842
train_iter_loss: 0.1052883118391037
train_iter_loss: 0.07082569599151611
train_iter_loss: 0.03507135063409805
train_iter_loss: 0.012337560765445232
train_iter_loss: 0.018704300746321678
train_iter_loss: 0.024783659726381302
train_iter_loss: 0.0346597395837307
train_iter_loss: 0.0051980288699269295
train_iter_loss: 0.007327171973884106
train_iter_loss: 0.011269967071712017
train_iter_loss: 0.006525109522044659
train_iter_loss: 0.012440778315067291
train_iter_loss: 0.04490397498011589
train_iter_loss: 0.00838584452867508
train_iter_loss: 0.012979095801711082
train_iter_loss: 0.0075376322492957115
train_iter_loss: 0.03316077962517738
train_iter_loss: 0.008184663020074368
train_iter_loss: 0.007225397974252701
train_iter_loss: 0.023780662566423416
train_iter_loss: 0.020589059218764305
train_iter_loss: 0.013669120147824287
train_iter_loss: 0.00867094099521637
train_iter_loss: 0.0033996906131505966
train_iter_loss: 0.0031520125921815634
train_iter_loss: 0.00548722967505455
train_iter_loss: 0.0029502043034881353
train_iter_loss: 0.007792285177856684
train_iter_loss: 0.013173739425837994
train_iter_loss: 0.0010542823001742363
train_iter_loss: 0.004602563101798296
train_iter_loss: 0.005396230146288872
train_iter_loss: 0.0072941770777106285
train_iter_loss: 0.007755085360258818
train_iter_loss: 0.012239329516887665
train_iter_loss: 0.0217134952545166
train_iter_loss: 0.006003549322485924
train_iter_loss: 0.01376171875745058
train_iter_loss: 0.025182947516441345
train_iter_loss: 0.010019849985837936
train_iter_loss: 0.015582961961627007
train_iter_loss: 0.024310419335961342
train_iter_loss: 0.0030654841102659702
train_iter_loss: 0.021682942286133766
train_iter_loss: 0.02580314874649048
train loss :0.0175
---------------------
Validation seg loss: 0.05862556396102761 at epoch 38
epoch =     39/  1000, exp = train
train_iter_loss: 0.012093056924641132
train_iter_loss: 0.03807114437222481
train_iter_loss: 0.008562863804399967
train_iter_loss: 0.06251850724220276
train_iter_loss: 0.07125435024499893
train_iter_loss: 0.06162090227007866
train_iter_loss: 0.010234016925096512
train_iter_loss: 0.030898379161953926
train_iter_loss: 0.051931802183389664
train_iter_loss: 0.014487792737782001
train_iter_loss: 0.013908449560403824
train_iter_loss: 0.05989868938922882
train_iter_loss: 0.04249495640397072
train_iter_loss: 0.007311995141208172
train_iter_loss: 0.004267328418791294
train_iter_loss: 0.0021988381631672382
train_iter_loss: 0.017226899042725563
train_iter_loss: 0.005570877809077501
train_iter_loss: 0.02071642503142357
train_iter_loss: 0.013436369597911835
train_iter_loss: 0.011083467863500118
train_iter_loss: 0.03706570714712143
train_iter_loss: 0.005775731988251209
train_iter_loss: 0.007065570447593927
train_iter_loss: 0.006450558081269264
train_iter_loss: 0.02042580395936966
train_iter_loss: 0.0066474308259785175
train_iter_loss: 0.031598787754774094
train_iter_loss: 0.017483441159129143
train_iter_loss: 0.010654098354279995
train_iter_loss: 0.004154939204454422
train_iter_loss: 0.0056959474459290504
train_iter_loss: 0.003976787906140089
train_iter_loss: 0.013423683121800423
train_iter_loss: 0.0048919180408120155
train_iter_loss: 0.008256490342319012
train_iter_loss: 0.010686984285712242
train_iter_loss: 0.009054671972990036
train_iter_loss: 0.031591977924108505
train_iter_loss: 0.026575569063425064
train_iter_loss: 0.02532334066927433
train_iter_loss: 0.008132493123412132
train_iter_loss: 0.03195803612470627
train_iter_loss: 0.016852108761668205
train_iter_loss: 0.002401558682322502
train_iter_loss: 0.02739766426384449
train_iter_loss: 0.03580193966627121
train_iter_loss: 0.03027755208313465
train_iter_loss: 0.018203409388661385
train_iter_loss: 0.021766696125268936
train loss :0.0211
---------------------
Validation seg loss: 0.05745536768051163 at epoch 39
epoch =     40/  1000, exp = train
train_iter_loss: 0.012755397707223892
train_iter_loss: 0.01131894439458847
train_iter_loss: 0.0046375286765396595
train_iter_loss: 0.022184519097208977
train_iter_loss: 0.040293317288160324
train_iter_loss: 0.023139867931604385
train_iter_loss: 0.012493801303207874
train_iter_loss: 0.037444937974214554
train_iter_loss: 0.024259792640805244
train_iter_loss: 0.014974855817854404
train_iter_loss: 0.029265234246850014
train_iter_loss: 0.01527841854840517
train_iter_loss: 0.010202358476817608
train_iter_loss: 0.020429620519280434
train_iter_loss: 0.01695999875664711
train_iter_loss: 0.00967416726052761
train_iter_loss: 0.03605612739920616
train_iter_loss: 0.018537623807787895
train_iter_loss: 0.016180118545889854
train_iter_loss: 0.01815936155617237
train_iter_loss: 0.00953865610063076
train_iter_loss: 0.02166828326880932
train_iter_loss: 0.02658971957862377
train_iter_loss: 0.002836488652974367
train_iter_loss: 0.00790508184581995
train_iter_loss: 0.01814904808998108
train_iter_loss: 0.01383956428617239
train_iter_loss: 0.06186394393444061
train_iter_loss: 0.005600209813565016
train_iter_loss: 0.004504542797803879
train_iter_loss: 0.003655392676591873
train_iter_loss: 0.004116705618798733
train_iter_loss: 0.007233976386487484
train_iter_loss: 0.0068228705786168575
train_iter_loss: 0.007637552451342344
train_iter_loss: 0.007354194298386574
train_iter_loss: 0.010405328124761581
train_iter_loss: 0.014195673167705536
train_iter_loss: 0.011766890995204449
train_iter_loss: 0.011982936412096024
train_iter_loss: 0.01662958413362503
train_iter_loss: 0.01699424535036087
train_iter_loss: 0.007245802320539951
train_iter_loss: 0.00871416088193655
train_iter_loss: 0.0046738628298044205
train_iter_loss: 0.006254987791180611
train_iter_loss: 0.009447463788092136
train_iter_loss: 0.009476353414356709
train_iter_loss: 0.014461731538176537
train_iter_loss: 0.010086311027407646
train loss :0.0155
---------------------
Validation seg loss: 0.05550829607708915 at epoch 40
epoch =     41/  1000, exp = train
train_iter_loss: 0.008179405704140663
train_iter_loss: 0.03240644186735153
train_iter_loss: 0.018534280359745026
train_iter_loss: 0.03274593874812126
train_iter_loss: 0.012539594434201717
train_iter_loss: 0.008937062695622444
train_iter_loss: 0.012055816128849983
train_iter_loss: 0.01882239431142807
train_iter_loss: 0.018790025264024734
train_iter_loss: 0.011280223727226257
train_iter_loss: 0.01892339251935482
train_iter_loss: 0.010673824697732925
train_iter_loss: 0.012005924247205257
train_iter_loss: 0.019068578258156776
train_iter_loss: 0.00889913272112608
train_iter_loss: 0.017810188233852386
train_iter_loss: 0.023128097876906395
train_iter_loss: 0.013856052421033382
train_iter_loss: 0.009600639343261719
train_iter_loss: 0.012384387664496899
train_iter_loss: 0.009775296784937382
train_iter_loss: 0.02258453518152237
train_iter_loss: 0.011365796439349651
train_iter_loss: 0.007416213396936655
train_iter_loss: 0.014715501107275486
train_iter_loss: 0.011547854170203209
train_iter_loss: 0.0070879459381103516
train_iter_loss: 0.06855183094739914
train_iter_loss: 0.003062701318413019
train_iter_loss: 0.005625093821436167
train_iter_loss: 0.0025551507715135813
train_iter_loss: 0.004005075432360172
train_iter_loss: 0.008816930465400219
train_iter_loss: 0.0029741718899458647
train_iter_loss: 0.0028128251433372498
train_iter_loss: 0.00507241440936923
train_iter_loss: 0.013318526558578014
train_iter_loss: 0.012506816536188126
train_iter_loss: 0.016230667009949684
train_iter_loss: 0.006256471388041973
train_iter_loss: 0.03280758857727051
train_iter_loss: 0.019610784947872162
train_iter_loss: 0.014866824261844158
train_iter_loss: 0.012668292969465256
train_iter_loss: 0.012545342557132244
train_iter_loss: 0.01780364103615284
train_iter_loss: 0.010527482256293297
train_iter_loss: 0.015706157311797142
train_iter_loss: 0.058890752494335175
train_iter_loss: 0.017226239666342735
train loss :0.0157
---------------------
Validation seg loss: nan at epoch 41
epoch =     42/  1000, exp = train
train_iter_loss: 0.027079252526164055
train_iter_loss: 0.00547975255176425
train_iter_loss: 0.009017410688102245
train_iter_loss: 0.017488598823547363
train_iter_loss: 0.020142704248428345
train_iter_loss: 0.023617515340447426
train_iter_loss: 0.005007322411984205
train_iter_loss: 0.012981291860342026
train_iter_loss: 0.014319229871034622
train_iter_loss: 0.017008155584335327
train_iter_loss: 0.02326422929763794
train_iter_loss: 0.026930544525384903
train_iter_loss: 0.0038686927873641253
train_iter_loss: 0.017202170565724373
train_iter_loss: 0.013189923949539661
train_iter_loss: 0.016457611694931984
train_iter_loss: 0.009162969887256622
train_iter_loss: 0.01635117083787918
train_iter_loss: 0.013548258692026138
train_iter_loss: 0.007201163563877344
train_iter_loss: 0.01097873318940401
train_iter_loss: 0.017936790362000465
train_iter_loss: 0.00828015897423029
train_iter_loss: 0.022544628009200096
train_iter_loss: 0.045968905091285706
train_iter_loss: 0.02390887588262558
train_iter_loss: 0.020786423236131668
train_iter_loss: 0.029902849346399307
train_iter_loss: 0.005796590354293585
train_iter_loss: 0.003946985118091106
train_iter_loss: 0.0036584516055881977
train_iter_loss: 0.011665861122310162
train_iter_loss: 0.00872931256890297
train_iter_loss: 0.004764950834214687
train_iter_loss: 0.010139725171029568
train_iter_loss: 0.0039492095820605755
train_iter_loss: 0.01593158021569252
train_iter_loss: 0.023832136765122414
train_iter_loss: 0.013064306229352951
train_iter_loss: 0.011684524826705456
train_iter_loss: 0.01794004812836647
train_iter_loss: 0.019299602136015892
train_iter_loss: 0.023442618548870087
train_iter_loss: 0.009765567258000374
train_iter_loss: 0.004821333102881908
train_iter_loss: 0.0028818657156080008
train_iter_loss: 0.0059171332977712154
train_iter_loss: 0.012820521369576454
train_iter_loss: 0.016216494143009186
train_iter_loss: 0.00693306140601635
train loss :0.0147
---------------------
Validation seg loss: 0.05626178611995749 at epoch 42
epoch =     43/  1000, exp = train
train_iter_loss: 0.01777430810034275
train_iter_loss: 0.020936964079737663
train_iter_loss: 0.011305482126772404
train_iter_loss: 0.005650036036968231
train_iter_loss: 0.017136991024017334
train_iter_loss: 0.021122585982084274
train_iter_loss: 0.008932316675782204
train_iter_loss: 0.010753946378827095
train_iter_loss: 0.011000675149261951
train_iter_loss: 0.017316758632659912
train_iter_loss: 0.04139656946063042
train_iter_loss: 0.016308141872286797
train_iter_loss: 0.007496953010559082
train_iter_loss: 0.004011155106127262
train_iter_loss: 0.00897660106420517
train_iter_loss: 0.007935822010040283
train_iter_loss: 0.011721567250788212
train_iter_loss: 0.03185562789440155
train_iter_loss: 0.011422443203628063
train_iter_loss: 0.02072799950838089
train_iter_loss: 0.002414701273664832
train_iter_loss: 0.019546283408999443
train_iter_loss: 0.00985032133758068
train_iter_loss: 0.06915658712387085
train_iter_loss: 0.01050649769604206
train_iter_loss: 0.046084702014923096
train_iter_loss: 0.02180640771985054
train_iter_loss: 0.02349673956632614
train_iter_loss: 0.016747405752539635
train_iter_loss: 0.01672990247607231
train_iter_loss: 0.008415114134550095
train_iter_loss: 0.01047689188271761
train_iter_loss: 0.00422089034691453
train_iter_loss: 0.00510864844545722
train_iter_loss: 0.0019122884841635823
train_iter_loss: 0.004388893023133278
train_iter_loss: 0.02473139762878418
train_iter_loss: 0.017817657440900803
train_iter_loss: 0.021596236154437065
train_iter_loss: 0.02226743847131729
train_iter_loss: 0.01413502637296915
train_iter_loss: 0.010186327621340752
train_iter_loss: 0.020014319568872452
train_iter_loss: 0.02332347072660923
train_iter_loss: 0.005761399399489164
train_iter_loss: 0.004140118602663279
train_iter_loss: 0.016058970242738724
train_iter_loss: 0.008103122003376484
train_iter_loss: 0.02041214518249035
train_iter_loss: 0.034033484756946564
train loss :0.0166
---------------------
Validation seg loss: 0.059386461784976384 at epoch 43
epoch =     44/  1000, exp = train
train_iter_loss: 0.013210424222052097
train_iter_loss: 0.012874904088675976
train_iter_loss: 0.008936304599046707
train_iter_loss: 0.004228539764881134
train_iter_loss: 0.07345026731491089
train_iter_loss: 0.008459916338324547
train_iter_loss: 0.028994983062148094
train_iter_loss: 0.02456034906208515
train_iter_loss: 0.012532448396086693
train_iter_loss: 0.02257489040493965
train_iter_loss: 0.018121156841516495
train_iter_loss: 0.009790235199034214
train_iter_loss: 0.00784891378134489
train_iter_loss: 0.008881204761564732
train_iter_loss: 0.014549040235579014
train_iter_loss: 0.013032926246523857
train_iter_loss: 0.01678575947880745
train_iter_loss: 0.0264532882720232
train_iter_loss: 0.026151705533266068
train_iter_loss: 0.011284712702035904
train_iter_loss: 0.012767679058015347
train_iter_loss: 0.029959730803966522
train_iter_loss: 0.005822080187499523
train_iter_loss: 0.01893025077879429
train_iter_loss: 0.008302687667310238
train_iter_loss: 0.018115242943167686
train_iter_loss: 0.01554715633392334
train_iter_loss: 0.03282345458865166
train_iter_loss: 0.02664768509566784
train_iter_loss: 0.003753598080947995
train_iter_loss: 0.005556637421250343
train_iter_loss: 0.003738054074347019
train_iter_loss: 0.001969830831512809
train_iter_loss: 0.003799624042585492
train_iter_loss: 0.003262891201302409
train_iter_loss: 0.0015799521934241056
train_iter_loss: 0.006406411528587341
train_iter_loss: 0.012005343101918697
train_iter_loss: 0.05916544049978256
train_iter_loss: 0.011593707837164402
train_iter_loss: 0.012059163302183151
train_iter_loss: 0.009297405369579792
train_iter_loss: 0.021143602207303047
train_iter_loss: 0.010176473297178745
train_iter_loss: 0.009273981675505638
train_iter_loss: 0.013337014243006706
train_iter_loss: 0.011337012983858585
train_iter_loss: 0.006072472780942917
train_iter_loss: 0.013465275056660175
train_iter_loss: 0.03396335244178772
train loss :0.0160
---------------------
Validation seg loss: 0.053133362714741554 at epoch 44
epoch =     45/  1000, exp = train
train_iter_loss: 0.00885383877903223
train_iter_loss: 0.010180572047829628
train_iter_loss: 0.010498153045773506
train_iter_loss: 0.009526177309453487
train_iter_loss: 0.051438335329294205
train_iter_loss: 0.05540367215871811
train_iter_loss: 0.013914373703300953
train_iter_loss: 0.024401558563113213
train_iter_loss: 0.00989549607038498
train_iter_loss: 0.01929771527647972
train_iter_loss: 0.03324408084154129
train_iter_loss: 0.018683314323425293
train_iter_loss: 0.016651084646582603
train_iter_loss: 0.005006232298910618
train_iter_loss: 0.0032430558931082487
train_iter_loss: 0.008280007168650627
train_iter_loss: 0.03175180032849312
train_iter_loss: 0.009618831798434258
train_iter_loss: 0.03077474609017372
train_iter_loss: 0.010450165718793869
train_iter_loss: 0.0055784257128834724
train_iter_loss: 0.004054259043186903
train_iter_loss: 0.012576086446642876
train_iter_loss: 0.0029581966809928417
train_iter_loss: 0.011701042763888836
train_iter_loss: 0.009437531232833862
train_iter_loss: 0.020978283137083054
train_iter_loss: 0.01727074384689331
train_iter_loss: 0.00620068097487092
train_iter_loss: 0.001870059291832149
train_iter_loss: 0.00957363098859787
train_iter_loss: 0.020619135349988937
train_iter_loss: 0.003636505687609315
train_iter_loss: 0.00458528334274888
train_iter_loss: 0.0032048197463154793
train_iter_loss: 0.0035490388981997967
train_iter_loss: 0.017005160450935364
train_iter_loss: 0.005900212097913027
train_iter_loss: 0.011892870999872684
train_iter_loss: 0.03194092586636543
train_iter_loss: 0.030610710382461548
train_iter_loss: 0.026378601789474487
train_iter_loss: 0.013680736534297466
train_iter_loss: 0.015999088063836098
train_iter_loss: 0.0043876562267541885
train_iter_loss: 0.042189545929431915
train_iter_loss: 0.014133191667497158
train_iter_loss: 0.010196234099566936
train_iter_loss: 0.017651161178946495
train_iter_loss: 0.009738360531628132
train loss :0.0157
---------------------
Validation seg loss: 0.054013808262819984 at epoch 45
epoch =     46/  1000, exp = train
train_iter_loss: 0.01704264059662819
train_iter_loss: 0.04742807149887085
train_iter_loss: 0.007429209537804127
train_iter_loss: 0.00769687769934535
train_iter_loss: 0.03608618304133415
train_iter_loss: 0.020199067890644073
train_iter_loss: 0.02957374043762684
train_iter_loss: 0.01948094740509987
train_iter_loss: 0.02212599292397499
train_iter_loss: 0.007665624842047691
train_iter_loss: 0.027338514104485512
train_iter_loss: 0.010551372542977333
train_iter_loss: 0.0032779609318822622
train_iter_loss: 0.010483543388545513
train_iter_loss: 0.007078107912093401
train_iter_loss: 0.006687077693641186
train_iter_loss: 0.017366154119372368
train_iter_loss: 0.014858533628284931
train_iter_loss: 0.0037871773820370436
train_iter_loss: 0.01154104433953762
train_iter_loss: 0.0036963282618671656
train_iter_loss: 0.055701881647109985
train_iter_loss: 0.020750008523464203
train_iter_loss: 0.010314060375094414
train_iter_loss: 0.051684409379959106
train_iter_loss: 0.06490234285593033
train_iter_loss: 0.023703482002019882
train_iter_loss: 0.027678348124027252
train_iter_loss: 0.002560193184763193
train_iter_loss: 0.006912747863680124
train_iter_loss: 0.005572678055614233
train_iter_loss: 0.004250186029821634
train_iter_loss: 0.009771151468157768
train_iter_loss: 0.004061833489686251
train_iter_loss: 0.014524110592901707
train_iter_loss: 0.020031211897730827
train_iter_loss: 0.0057449787855148315
train_iter_loss: 0.021381856873631477
train_iter_loss: 0.003199515398591757
train_iter_loss: 0.008313207887113094
train_iter_loss: 0.0359247662127018
train_iter_loss: 0.008301068097352982
train_iter_loss: 0.07521891593933105
train_iter_loss: 0.009361418895423412
train_iter_loss: 0.015805011615157127
train_iter_loss: 0.0064315455965697765
train_iter_loss: 0.015295530669391155
train_iter_loss: 0.008616634644567966
train_iter_loss: 0.017142442986369133
train_iter_loss: 0.010013618506491184
train loss :0.0182
---------------------
Validation seg loss: 0.05643595862537315 at epoch 46
epoch =     47/  1000, exp = train
train_iter_loss: 0.013369465246796608
train_iter_loss: 0.025291694328188896
train_iter_loss: 0.012493661604821682
train_iter_loss: 0.030436191707849503
train_iter_loss: 0.012296591885387897
train_iter_loss: 0.019116265699267387
train_iter_loss: 0.03299715742468834
train_iter_loss: 0.02710612490773201
train_iter_loss: 0.007310966029763222
train_iter_loss: 0.026789657771587372
train_iter_loss: 0.04315131530165672
train_iter_loss: 0.04433630406856537
train_iter_loss: 0.04434451460838318
train_iter_loss: 0.02051209844648838
train_iter_loss: 0.05702275410294533
train_iter_loss: 0.012011289596557617
train_iter_loss: 0.015032082796096802
train_iter_loss: 0.011194020509719849
train_iter_loss: 0.00791556853801012
train_iter_loss: 0.01943182200193405
train_iter_loss: 0.018254823982715607
train_iter_loss: 0.024305742233991623
train_iter_loss: 0.013956756331026554
train_iter_loss: 0.004944485612213612
train_iter_loss: 0.01309514045715332
train_iter_loss: 0.023212647065520287
train_iter_loss: 0.01830112934112549
train_iter_loss: 0.01596168242394924
train_iter_loss: 0.007627699989825487
train_iter_loss: 0.0025351806543767452
train_iter_loss: 0.00207612756639719
train_iter_loss: 0.0036016444209963083
train_iter_loss: 0.009541312232613564
train_iter_loss: 0.0033422824926674366
train_iter_loss: 0.006092191208153963
train_iter_loss: 0.0015450422652065754
train_iter_loss: 0.017710328102111816
train_iter_loss: 0.017229586839675903
train_iter_loss: 0.007113840896636248
train_iter_loss: 0.03323476016521454
train_iter_loss: 0.005136612802743912
train_iter_loss: 0.012472517788410187
train_iter_loss: 0.01602502167224884
train_iter_loss: 0.012152774259448051
train_iter_loss: 0.024803277105093002
train_iter_loss: 0.0050756013952195644
train_iter_loss: 0.015291390009224415
train_iter_loss: 0.005109818186610937
train_iter_loss: 0.007250182330608368
train_iter_loss: 0.005914886482059956
train loss :0.0171
---------------------
Validation seg loss: 0.05269298394458294 at epoch 47
epoch =     48/  1000, exp = train
train_iter_loss: 0.011194499209523201
train_iter_loss: 0.025422073900699615
train_iter_loss: 0.011232658289372921
train_iter_loss: 0.005566765088587999
train_iter_loss: 0.02865748479962349
train_iter_loss: 0.04983162134885788
train_iter_loss: 0.020568545907735825
train_iter_loss: 0.03410503640770912
train_iter_loss: 0.014077277854084969
train_iter_loss: 0.015467305667698383
train_iter_loss: 0.009882086887955666
train_iter_loss: 0.008165974169969559
train_iter_loss: 0.009352627210319042
train_iter_loss: 0.004182316828519106
train_iter_loss: 0.0037186602130532265
train_iter_loss: 0.005275648087263107
train_iter_loss: 0.0219286996871233
train_iter_loss: 0.026515448465943336
train_iter_loss: 0.030351007357239723
train_iter_loss: 0.015599320642650127
train_iter_loss: 0.045330360531806946
train_iter_loss: 0.002188856713473797
train_iter_loss: 0.004557668697088957
train_iter_loss: 0.01621319353580475
train_iter_loss: 0.015061870217323303
train_iter_loss: 0.012375067919492722
train_iter_loss: 0.006287834141403437
train_iter_loss: 0.01032433845102787
train_iter_loss: 0.005712134763598442
train_iter_loss: 0.009413055144250393
train_iter_loss: 0.00627090921625495
train_iter_loss: 0.015089832246303558
train_iter_loss: 0.00635263929143548
train_iter_loss: 0.009368674829602242
train_iter_loss: 0.009704994037747383
train_iter_loss: 0.006212675012648106
train_iter_loss: 0.01289838831871748
train_iter_loss: 0.04669376090168953
train_iter_loss: 0.003683488117530942
train_iter_loss: 0.014198529534041882
train_iter_loss: 0.02110208198428154
train_iter_loss: 0.008053792640566826
train_iter_loss: 0.018299425020813942
train_iter_loss: 0.01660796068608761
train_iter_loss: 0.00775772612541914
train_iter_loss: 0.021767621859908104
train_iter_loss: 0.013404084369540215
train_iter_loss: 0.0017852421151474118
train_iter_loss: 0.008609237149357796
train_iter_loss: 0.024236947298049927
train loss :0.0154
---------------------
Validation seg loss: 0.056767367949365544 at epoch 48
epoch =     49/  1000, exp = train
train_iter_loss: 0.008714466355741024
train_iter_loss: 0.013936501927673817
train_iter_loss: 0.00769418990239501
train_iter_loss: 0.012919708155095577
train_iter_loss: 0.028596865013241768
train_iter_loss: 0.03170815110206604
train_iter_loss: 0.021874230355024338
train_iter_loss: 0.036383818835020065
train_iter_loss: 0.030796444043517113
train_iter_loss: 0.023946985602378845
train_iter_loss: 0.05848922207951546
train_iter_loss: 0.011621628887951374
train_iter_loss: 0.022022735327482224
train_iter_loss: 0.002787162782624364
train_iter_loss: 0.005307602230459452
train_iter_loss: 0.013691470958292484
train_iter_loss: 0.007214799057692289
train_iter_loss: 0.01562744379043579
train_iter_loss: 0.01142997294664383
train_iter_loss: 0.03765461593866348
train_iter_loss: 0.013733488507568836
train_iter_loss: 0.003966482821851969
train_iter_loss: 0.009969420731067657
train_iter_loss: 0.004583889618515968
train_iter_loss: 0.01632353849709034
train_iter_loss: 0.013988925144076347
train_iter_loss: 0.022779034450650215
train_iter_loss: 0.04017525911331177
train_iter_loss: 0.007331064436584711
train_iter_loss: 0.005435593891888857
train_iter_loss: 0.00515384878963232
train_iter_loss: 0.011752252466976643
train_iter_loss: 0.007018222473561764
train_iter_loss: 0.005598310846835375
train_iter_loss: 0.0038744229823350906
train_iter_loss: 0.0021240191999822855
train_iter_loss: 0.013150276616215706
train_iter_loss: 0.01816702075302601
train_iter_loss: 0.029133198782801628
train_iter_loss: 0.015051494352519512
train_iter_loss: 0.038236360996961594
train_iter_loss: 0.011403711512684822
train_iter_loss: 0.023627184331417084
train_iter_loss: 0.007815292105078697
train_iter_loss: 0.013094189576804638
train_iter_loss: 0.013150813989341259
train_iter_loss: 0.00819380022585392
train_iter_loss: 0.008220167830586433
train_iter_loss: 0.010653791017830372
train_iter_loss: 0.02089407667517662
train loss :0.0164
---------------------
Validation seg loss: 0.05259518087569751 at epoch 49
epoch =     50/  1000, exp = train
train_iter_loss: 0.015042711980640888
train_iter_loss: 0.07358279824256897
train_iter_loss: 0.009193476289510727
train_iter_loss: 0.03002660907804966
train_iter_loss: 0.02185957320034504
train_iter_loss: 0.021390914916992188
train_iter_loss: 0.03741414472460747
train_iter_loss: 0.013380996882915497
train_iter_loss: 0.01344765443354845
train_iter_loss: 0.0084678390994668
train_iter_loss: 0.01448300201445818
train_iter_loss: 0.04836311936378479
train_iter_loss: 0.00934554636478424
train_iter_loss: 0.0050648474134504795
train_iter_loss: 0.012656861916184425
train_iter_loss: 0.006048941984772682
train_iter_loss: 0.014970160089433193
train_iter_loss: 0.02278728224337101
train_iter_loss: 0.007634223438799381
train_iter_loss: 0.010047880932688713
train_iter_loss: 0.07967481762170792
train_iter_loss: 0.0049748411402106285
train_iter_loss: 0.004811619408428669
train_iter_loss: 0.004801505710929632
train_iter_loss: 0.006249629892408848
train_iter_loss: 0.009165997616946697
train_iter_loss: 0.019310960546135902
train_iter_loss: 0.06736288219690323
train_iter_loss: 0.006539882160723209
train_iter_loss: 0.0024467301554977894
train_iter_loss: 0.003993641585111618
train_iter_loss: 0.004812912084162235
train_iter_loss: 0.004317089449614286
train_iter_loss: 0.002792513696476817
train_iter_loss: 0.007556859869509935
train_iter_loss: 0.0021962772589176893
train_iter_loss: 0.004638285376131535
train_iter_loss: 0.02908199280500412
train_iter_loss: 0.018330542370676994
train_iter_loss: 0.00896913930773735
train_iter_loss: 0.04754796624183655
train_iter_loss: 0.05589626356959343
train_iter_loss: 0.018226521089673042
train_iter_loss: 0.015727944672107697
train_iter_loss: 0.01187126524746418
train_iter_loss: 0.008628912270069122
train_iter_loss: 0.012738017365336418
train_iter_loss: 0.02120188996195793
train_iter_loss: 0.032013218849897385
train_iter_loss: 0.011072609573602676
train loss :0.0188
---------------------
Validation seg loss: 0.052727714124248794 at epoch 50
epoch =     51/  1000, exp = train
train_iter_loss: 0.08456439524888992
train_iter_loss: 0.027476279065012932
train_iter_loss: 0.011767522431910038
train_iter_loss: 0.044266823679208755
train_iter_loss: 0.020594798028469086
train_iter_loss: 0.035698533058166504
train_iter_loss: 0.010210465639829636
train_iter_loss: 0.01063481718301773
train_iter_loss: 0.05546174570918083
train_iter_loss: 0.017589740455150604
train_iter_loss: 0.0423181988298893
train_iter_loss: 0.03069012425839901
train_iter_loss: 0.04372246935963631
train_iter_loss: 0.0092792809009552
train_iter_loss: 0.008733702823519707
train_iter_loss: 0.0032410977873951197
train_iter_loss: 0.020843079313635826
train_iter_loss: 0.01879015378654003
train_iter_loss: 0.007059444673359394
train_iter_loss: 0.019231541082262993
train_iter_loss: 0.005630091298371553
train_iter_loss: 0.014991650357842445
train_iter_loss: 0.0037470576353371143
train_iter_loss: 0.008180679753422737
train_iter_loss: 0.03435022383928299
train_iter_loss: 0.038102082908153534
train_iter_loss: 0.032022662460803986
train_iter_loss: 0.019681358709931374
train_iter_loss: 0.006689052563160658
train_iter_loss: 0.015120238065719604
train_iter_loss: 0.002741887466982007
train_iter_loss: 0.00436380784958601
train_iter_loss: 0.002832606667652726
train_iter_loss: 0.0018838837277144194
train_iter_loss: 0.0011212769895792007
train_iter_loss: 0.011492901481688023
train_iter_loss: 0.010937645100057125
train_iter_loss: 0.01917164772748947
train_iter_loss: 0.0064850677736103535
train_iter_loss: 0.00741648068651557
train_iter_loss: 0.010238164104521275
train_iter_loss: 0.011121926829218864
train_iter_loss: 0.02518714778125286
train_iter_loss: 0.021551527082920074
train_iter_loss: 0.008977026678621769
train_iter_loss: 0.0068739354610443115
train_iter_loss: 0.0018271558219566941
train_iter_loss: 0.006116796750575304
train_iter_loss: 0.018187392503023148
train_iter_loss: 0.014692881144583225
train loss :0.0183
---------------------
Validation seg loss: 0.051200052531367994 at epoch 51
epoch =     52/  1000, exp = train
train_iter_loss: 0.02615330182015896
train_iter_loss: 0.008341866545379162
train_iter_loss: 0.01127514149993658
train_iter_loss: 0.01684335432946682
train_iter_loss: 0.023999951779842377
train_iter_loss: 0.007767359726130962
train_iter_loss: 0.029910068958997726
train_iter_loss: 0.0747581422328949
train_iter_loss: 0.010147666558623314
train_iter_loss: 0.027226053178310394
train_iter_loss: 0.015446720644831657
train_iter_loss: 0.02555249258875847
train_iter_loss: 0.009314220398664474
train_iter_loss: 0.007046830840408802
train_iter_loss: 0.019854556769132614
train_iter_loss: 0.005658547859638929
train_iter_loss: 0.0164568480104208
train_iter_loss: 0.017237283289432526
train_iter_loss: 0.03222757205367088
train_iter_loss: 0.008053598925471306
train_iter_loss: 0.004769728984683752
train_iter_loss: 0.019523274153470993
train_iter_loss: 0.007611870765686035
train_iter_loss: 0.002070370363071561
train_iter_loss: 0.05206143856048584
train_iter_loss: 0.012653728947043419
train_iter_loss: 0.021019810810685158
train_iter_loss: 0.015163116157054901
train_iter_loss: 0.008337026461958885
train_iter_loss: 0.011476673185825348
train_iter_loss: 0.011977627873420715
train_iter_loss: 0.005144895054399967
train_iter_loss: 0.004135636612772942
train_iter_loss: 0.004384045954793692
train_iter_loss: 0.0035048448480665684
train_iter_loss: 0.005283222068101168
train_iter_loss: 0.009555053897202015
train_iter_loss: 0.01598522625863552
train_iter_loss: 0.039320968091487885
train_iter_loss: 0.005670716054737568
train_iter_loss: 0.008752874098718166
train_iter_loss: 0.022182555869221687
train_iter_loss: 0.013518871739506721
train_iter_loss: 0.027944447472691536
train_iter_loss: 0.0022183360997587442
train_iter_loss: 0.0016924215015023947
train_iter_loss: 0.0035786451771855354
train_iter_loss: 0.0019615143537521362
train_iter_loss: 0.02613126114010811
train_iter_loss: 0.031595852226018906
train loss :0.0162
---------------------
Validation seg loss: 0.05415864930587561 at epoch 52
epoch =     53/  1000, exp = train
train_iter_loss: 0.013963808305561543
train_iter_loss: 0.02365608513355255
train_iter_loss: 0.02209085412323475
train_iter_loss: 0.014368920587003231
train_iter_loss: 0.011677942238748074
train_iter_loss: 0.05299237370491028
train_iter_loss: 0.018776217475533485
train_iter_loss: 0.012836528941988945
train_iter_loss: 0.010281396098434925
train_iter_loss: 0.02178160846233368
train_iter_loss: 0.012680753134191036
train_iter_loss: 0.007706701289862394
train_iter_loss: 0.026886697858572006
train_iter_loss: 0.007109269965440035
train_iter_loss: 0.011666994541883469
train_iter_loss: 0.012329678051173687
train_iter_loss: 0.013198450207710266
train_iter_loss: 0.05083621293306351
train_iter_loss: 0.010146284475922585
train_iter_loss: 0.006663320120424032
train_iter_loss: 0.0019264302682131529
train_iter_loss: 0.009115280583500862
train_iter_loss: 0.0034799145068973303
train_iter_loss: 0.007495644968003035
train_iter_loss: 0.00836765207350254
train_iter_loss: 0.05334316939115524
train_iter_loss: 0.028499644249677658
train_iter_loss: 0.004540341440588236
train_iter_loss: 0.007517544087022543
train_iter_loss: 0.003574145259335637
train_iter_loss: 0.00248192367143929
train_iter_loss: 0.004735979251563549
train_iter_loss: 0.005568171851336956
train_iter_loss: 0.008259473368525505
train_iter_loss: 0.0035588396713137627
train_iter_loss: 0.0056073288433253765
train_iter_loss: 0.007391652557998896
train_iter_loss: 0.012355209328234196
train_iter_loss: 0.009468894451856613
train_iter_loss: 0.02453524060547352
train_iter_loss: 0.020655447617173195
train_iter_loss: 0.019777998328208923
train_iter_loss: 0.01710638776421547
train_iter_loss: 0.02896098792552948
train_iter_loss: 0.004177459981292486
train_iter_loss: 0.004230143036693335
train_iter_loss: 0.0027765147387981415
train_iter_loss: 0.00987470243126154
train_iter_loss: 0.030583135783672333
train_iter_loss: 0.01063753105700016
train loss :0.0148
---------------------
Validation seg loss: 0.05507271695703066 at epoch 53
epoch =     54/  1000, exp = train
train_iter_loss: 0.004460248630493879
train_iter_loss: 0.003545578569173813
train_iter_loss: 0.015699757263064384
train_iter_loss: 0.047620151191949844
train_iter_loss: 0.06247852370142937
train_iter_loss: 0.08510645478963852
train_iter_loss: 0.036790698766708374
train_iter_loss: 0.05917312204837799
train_iter_loss: 0.005602030549198389
train_iter_loss: 0.028410548344254494
train_iter_loss: 0.02326558716595173
train_iter_loss: 0.026400920003652573
train_iter_loss: 0.006042151711881161
train_iter_loss: 0.00888481643050909
train_iter_loss: 0.02143995091319084
train_iter_loss: 0.005890495143830776
train_iter_loss: 0.040382128208875656
train_iter_loss: 0.0047387415543198586
train_iter_loss: 0.025369124487042427
train_iter_loss: 0.01195816695690155
train_iter_loss: 0.006885927636176348
train_iter_loss: 0.011042528785765171
train_iter_loss: 0.0035676194820553064
train_iter_loss: 0.0022571587469428778
train_iter_loss: 0.03737381100654602
train_iter_loss: 0.07708844542503357
train_iter_loss: 0.04027381166815758
train_iter_loss: 0.025313353165984154
train_iter_loss: 0.008568229153752327
train_iter_loss: 0.00444780383259058
train_iter_loss: 0.011282121762633324
train_iter_loss: 0.005901529919356108
train_iter_loss: 0.031244290992617607
train_iter_loss: 0.006109416950494051
train_iter_loss: 0.007881013676524162
train_iter_loss: 0.004258510656654835
train_iter_loss: 0.004452149849385023
train_iter_loss: 0.009533069096505642
train_iter_loss: 0.004962189123034477
train_iter_loss: 0.04647018760442734
train_iter_loss: 0.016873350366950035
train_iter_loss: 0.014973020181059837
train_iter_loss: 0.012729664333164692
train_iter_loss: 0.018920954316854477
train_iter_loss: 0.012275447137653828
train_iter_loss: 0.002171010011807084
train_iter_loss: 0.005750984884798527
train_iter_loss: 0.003724960144609213
train_iter_loss: 0.0095021678134799
train_iter_loss: 0.017405789345502853
train loss :0.0200
---------------------
Validation seg loss: 0.052287260935870265 at epoch 54
epoch =     55/  1000, exp = train
train_iter_loss: 0.020996512845158577
train_iter_loss: 0.04963657259941101
train_iter_loss: 0.015598801895976067
train_iter_loss: 0.022674748674035072
train_iter_loss: 0.057623278349637985
train_iter_loss: 0.011467568576335907
train_iter_loss: 0.007355342619121075
train_iter_loss: 0.02824089117348194
train_iter_loss: 0.01836010068655014
train_iter_loss: 0.013139483518898487
train_iter_loss: 0.017810016870498657
train_iter_loss: 0.01625053957104683
train_iter_loss: 0.008593333885073662
train_iter_loss: 0.02222898043692112
train_iter_loss: 0.007071566302329302
train_iter_loss: 0.016424862667918205
train_iter_loss: 0.008532343432307243
train_iter_loss: 0.01120491698384285
train_iter_loss: 0.015208162367343903
train_iter_loss: 0.023954013362526894
train_iter_loss: 0.007794643752276897
train_iter_loss: 0.006167505867779255
train_iter_loss: 0.0019199864473193884
train_iter_loss: 0.008685067296028137
train_iter_loss: 0.014473982155323029
train_iter_loss: 0.021873649209737778
train_iter_loss: 0.004308200441300869
train_iter_loss: 0.022370392456650734
train_iter_loss: 0.002526565920561552
train_iter_loss: 0.01407558098435402
train_iter_loss: 0.006747561506927013
train_iter_loss: 0.004385446198284626
train_iter_loss: 0.002692488022148609
train_iter_loss: 0.01613815687596798
train_iter_loss: 0.0034230246674269438
train_iter_loss: 0.003350678365677595
train_iter_loss: 0.037241335958242416
train_iter_loss: 0.00533882062882185
train_iter_loss: 0.009585672058165073
train_iter_loss: 0.008562500588595867
train_iter_loss: 0.02152988314628601
train_iter_loss: 0.01343459915369749
train_iter_loss: 0.014866294339299202
train_iter_loss: 0.007116003893315792
train_iter_loss: 0.003315246431156993
train_iter_loss: 0.003441076958552003
train_iter_loss: 0.00952704343944788
train_iter_loss: 0.008971544913947582
train_iter_loss: 0.019298851490020752
train_iter_loss: 0.024047600105404854
train loss :0.0148
---------------------
Validation seg loss: 0.05720893985548997 at epoch 55
epoch =     56/  1000, exp = train
train_iter_loss: 0.011876721866428852
train_iter_loss: 0.010751227848231792
train_iter_loss: 0.01199527457356453
train_iter_loss: 0.023774977773427963
train_iter_loss: 0.02638799510896206
train_iter_loss: 0.09272868186235428
train_iter_loss: 0.035330601036548615
train_iter_loss: 0.026977963745594025
train_iter_loss: 0.0075171650387346745
train_iter_loss: 0.009405731223523617
train_iter_loss: 0.015244865790009499
train_iter_loss: 0.017308592796325684
train_iter_loss: 0.006570488214492798
train_iter_loss: 0.004151541274040937
train_iter_loss: 0.004691025707870722
train_iter_loss: 0.010073937475681305
train_iter_loss: 0.03810291737318039
train_iter_loss: 0.008849273435771465
train_iter_loss: 0.008242873474955559
train_iter_loss: 0.017093149945139885
train_iter_loss: 0.05519329383969307
train_iter_loss: 0.019132647663354874
train_iter_loss: 0.009067971259355545
train_iter_loss: 0.01053515076637268
train_iter_loss: 0.007874964736402035
train_iter_loss: 0.014258689247071743
train_iter_loss: 0.01706121116876602
train_iter_loss: 0.009082911536097527
train_iter_loss: 0.006121402606368065
train_iter_loss: 0.006349385716021061
train_iter_loss: 0.009162935428321362
train_iter_loss: 0.005966457538306713
train_iter_loss: 0.009331419132649899
train_iter_loss: 0.0020430677104741335
train_iter_loss: 0.003908654674887657
train_iter_loss: 0.0028877570293843746
train_iter_loss: 0.011152233928442001
train_iter_loss: 0.007780803833156824
train_iter_loss: 0.0267525352537632
train_iter_loss: 0.014216254465281963
train_iter_loss: 0.010812980122864246
train_iter_loss: 0.019750064238905907
train_iter_loss: 0.019422870129346848
train_iter_loss: 0.01382964476943016
train_iter_loss: 0.018879370763897896
train_iter_loss: 0.012724384665489197
train_iter_loss: 0.003443073481321335
train_iter_loss: 0.01138908602297306
train_iter_loss: 0.005729673895984888
train_iter_loss: 0.013917526230216026
train loss :0.0156
---------------------
Validation seg loss: nan at epoch 56
epoch =     57/  1000, exp = train
train_iter_loss: 0.014771434478461742
train_iter_loss: 0.009738682769238949
train_iter_loss: 0.015382117591798306
train_iter_loss: 0.011440493166446686
train_iter_loss: 0.031848251819610596
train_iter_loss: 0.011799568310379982
train_iter_loss: 0.023554354906082153
train_iter_loss: 0.06160552799701691
train_iter_loss: 0.007218803744763136
train_iter_loss: 0.02087128721177578
train_iter_loss: 0.007149748038500547
train_iter_loss: 0.01695742830634117
train_iter_loss: 0.007892175577580929
train_iter_loss: 0.007394852116703987
train_iter_loss: 0.009647220373153687
train_iter_loss: 0.00521621759980917
train_iter_loss: 0.028610290959477425
train_iter_loss: 0.019965553656220436
train_iter_loss: 0.010183868929743767
train_iter_loss: 0.007380128372460604
train_iter_loss: 0.013015546835958958
train_iter_loss: 0.017435722053050995
train_iter_loss: 0.013911574147641659
train_iter_loss: 0.012676387093961239
train_iter_loss: 0.060482509434223175
train_iter_loss: 0.007165476679801941
train_iter_loss: 0.011894267983734608
train_iter_loss: 0.02929513342678547
train_iter_loss: 0.003656306304037571
train_iter_loss: 0.01814325340092182
train_iter_loss: 0.006665763910859823
train_iter_loss: 0.004752641078084707
train_iter_loss: 0.00446287402883172
train_iter_loss: 0.006250017788261175
train_iter_loss: 0.0025444484781473875
train_iter_loss: 0.005018433090299368
train_iter_loss: 0.020395392552018166
train_iter_loss: 0.013583687134087086
train_iter_loss: 0.024737080559134483
train_iter_loss: 0.0035744253545999527
train_iter_loss: 0.035961877554655075
train_iter_loss: 0.014001578092575073
train_iter_loss: 0.010987636633217335
train_iter_loss: 0.015063216909766197
train_iter_loss: 0.004868865944445133
train_iter_loss: 0.007691832259297371
train_iter_loss: 0.011910119093954563
train_iter_loss: 0.0063557070679962635
train_iter_loss: 0.011339422315359116
train_iter_loss: 0.013284309767186642
train loss :0.0151
---------------------
Validation seg loss: 0.05753566551569713 at epoch 57
epoch =     58/  1000, exp = train
train_iter_loss: 0.02255367301404476
train_iter_loss: 0.021468792110681534
train_iter_loss: 0.005464567337185144
train_iter_loss: 0.024646250531077385
train_iter_loss: 0.017687533050775528
train_iter_loss: 0.12796680629253387
train_iter_loss: 0.067259781062603
train_iter_loss: 0.008354535326361656
train_iter_loss: 0.008475221693515778
train_iter_loss: 0.0071540880016982555
train_iter_loss: 0.021965408697724342
train_iter_loss: 0.02011394314467907
train_iter_loss: 0.007012995891273022
train_iter_loss: 0.013239610940217972
train_iter_loss: 0.009365490637719631
train_iter_loss: 0.004523403476923704
train_iter_loss: 0.011068868450820446
train_iter_loss: 0.026664353907108307
train_iter_loss: 0.019635774195194244
train_iter_loss: 0.011698588728904724
train_iter_loss: 0.015512704849243164
train_iter_loss: 0.003946925047785044
train_iter_loss: 0.01378589402884245
train_iter_loss: 0.03465583920478821
train_iter_loss: 0.004815196618437767
train_iter_loss: 0.011240233667194843
train_iter_loss: 0.011353597044944763
train_iter_loss: 0.018586907535791397
train_iter_loss: 0.0028834412805736065
train_iter_loss: 0.0564810149371624
train_iter_loss: 0.006619570776820183
train_iter_loss: 0.007612348534166813
train_iter_loss: 0.004851188976317644
train_iter_loss: 0.002641427330672741
train_iter_loss: 0.0017539268592372537
train_iter_loss: 0.034438423812389374
train_iter_loss: 0.005513176321983337
train_iter_loss: 0.017377933487296104
train_iter_loss: 0.0118380356580019
train_iter_loss: 0.019126730039715767
train_iter_loss: 0.036557603627443314
train_iter_loss: 0.00818602740764618
train_iter_loss: 0.026502089574933052
train_iter_loss: 0.00979401171207428
train_iter_loss: 0.008684808388352394
train_iter_loss: 0.014628673903644085
train_iter_loss: 0.015697956085205078
train_iter_loss: 0.010373096913099289
train_iter_loss: 0.00934489443898201
train_iter_loss: 0.008692553266882896
train loss :0.0181
---------------------
Validation seg loss: 0.05093144303910382 at epoch 58
epoch =     59/  1000, exp = train
train_iter_loss: 0.01789763756096363
train_iter_loss: 0.015725210309028625
train_iter_loss: 0.010288669727742672
train_iter_loss: 0.020943069830536842
train_iter_loss: 0.010286533273756504
train_iter_loss: 0.011061317287385464
train_iter_loss: 0.013813520781695843
train_iter_loss: 0.11331132054328918
train_iter_loss: 0.021568870171904564
train_iter_loss: 0.03459698334336281
train_iter_loss: 0.01935560815036297
train_iter_loss: 0.01515237521380186
train_iter_loss: 0.007060498930513859
train_iter_loss: 0.0232041385024786
train_iter_loss: 0.00536400405690074
train_iter_loss: 0.01320149190723896
train_iter_loss: 0.03530995920300484
train_iter_loss: 0.020870201289653778
train_iter_loss: 0.013954222202301025
train_iter_loss: 0.028242051601409912
train_iter_loss: 0.004398053046315908
train_iter_loss: 0.009331104345619678
train_iter_loss: 0.0032444591633975506
train_iter_loss: 0.0035860876087099314
train_iter_loss: 0.012306349352002144
train_iter_loss: 0.05864730849862099
train_iter_loss: 0.027638830244541168
train_iter_loss: 0.04145742952823639
train_iter_loss: 0.0034338629338890314
train_iter_loss: 0.00439755292609334
train_iter_loss: 0.01238290499895811
train_iter_loss: 0.0035657472908496857
train_iter_loss: 0.0019351396476849914
train_iter_loss: 0.011923574842512608
train_iter_loss: 0.005651663523167372
train_iter_loss: 0.012615873478353024
train_iter_loss: 0.010272542014718056
train_iter_loss: 0.00441437354311347
train_iter_loss: 0.009568382054567337
train_iter_loss: 0.016667792573571205
train_iter_loss: 0.033054765313863754
train_iter_loss: 0.03027195669710636
train_iter_loss: 0.03972262144088745
train_iter_loss: 0.025792744010686874
train_iter_loss: 0.007954039610922337
train_iter_loss: 0.004507147707045078
train_iter_loss: 0.002986973151564598
train_iter_loss: 0.00862024910748005
train_iter_loss: 0.0443088598549366
train_iter_loss: 0.010311651974916458
train loss :0.0187
---------------------
Validation seg loss: 0.06302927712770398 at epoch 59
epoch =     60/  1000, exp = train
train_iter_loss: 0.011379299685359001
train_iter_loss: 0.014577578753232956
train_iter_loss: 0.005633469205349684
train_iter_loss: 0.012094090692698956
train_iter_loss: 0.027370374649763107
train_iter_loss: 0.091043621301651
train_iter_loss: 0.013827739283442497
train_iter_loss: 0.01841661147773266
train_iter_loss: 0.010191005654633045
train_iter_loss: 0.02706078626215458
train_iter_loss: 0.010210138745605946
train_iter_loss: 0.060244761407375336
train_iter_loss: 0.01961776800453663
train_iter_loss: 0.0035028529819101095
train_iter_loss: 0.004178584553301334
train_iter_loss: 0.007923059165477753
train_iter_loss: 0.020209316164255142
train_iter_loss: 0.024121128022670746
train_iter_loss: 0.006258070468902588
train_iter_loss: 0.007667395286262035
train_iter_loss: 0.009928430430591106
train_iter_loss: 0.006122339982539415
train_iter_loss: 0.035509563982486725
train_iter_loss: 0.04174133017659187
train_iter_loss: 0.03492385521531105
train_iter_loss: 0.03383396938443184
train_iter_loss: 0.007008671760559082
train_iter_loss: 0.013075779192149639
train_iter_loss: 0.017945850268006325
train_iter_loss: 0.0021514403633773327
train_iter_loss: 0.0035536475479602814
train_iter_loss: 0.002508288947865367
train_iter_loss: 0.002230730839073658
train_iter_loss: 0.0047320653684437275
train_iter_loss: 0.0027399335522204638
train_iter_loss: 0.014922038652002811
train_iter_loss: 0.021255474537611008
train_iter_loss: 0.0037631532177329063
train_iter_loss: 0.05869570001959801
train_iter_loss: 0.01922483555972576
train_iter_loss: 0.022646799683570862
train_iter_loss: 0.013865236192941666
train_iter_loss: 0.04861384257674217
train_iter_loss: 0.004928844049572945
train_iter_loss: 0.010071185417473316
train_iter_loss: 0.010663761757314205
train_iter_loss: 0.013782117515802383
train_iter_loss: 0.01723610609769821
train_iter_loss: 0.028880544006824493
train_iter_loss: 0.010720069520175457
train loss :0.0186
---------------------
Validation seg loss: 0.04979487901862671 at epoch 60
epoch =     61/  1000, exp = train
train_iter_loss: 0.010066981427371502
train_iter_loss: 0.014590633101761341
train_iter_loss: 0.022425422444939613
train_iter_loss: 0.026950452476739883
train_iter_loss: 0.04382354021072388
train_iter_loss: 0.05252321809530258
train_iter_loss: 0.06140175089240074
train_iter_loss: 0.07643070071935654
train_iter_loss: 0.011555464006960392
train_iter_loss: 0.05598036199808121
train_iter_loss: 0.015779197216033936
train_iter_loss: 0.022459104657173157
train_iter_loss: 0.008817292749881744
train_iter_loss: 0.004310188349336386
train_iter_loss: 0.017240023240447044
train_iter_loss: 0.0045502991415560246
train_iter_loss: 0.008269745856523514
train_iter_loss: 0.02507098577916622
train_iter_loss: 0.020793285220861435
train_iter_loss: 0.01583210751414299
train_iter_loss: 0.003675228450447321
train_iter_loss: 0.006217702757567167
train_iter_loss: 0.013623150065541267
train_iter_loss: 0.014822720550000668
train_iter_loss: 0.021564878523349762
train_iter_loss: 0.02399216964840889
train_iter_loss: 0.031896501779556274
train_iter_loss: 0.0073713199235498905
train_iter_loss: 0.026671739295125008
train_iter_loss: 0.0021712295711040497
train_iter_loss: 0.01322308462113142
train_iter_loss: 0.0032464952673763037
train_iter_loss: 0.0012753931805491447
train_iter_loss: 0.002490442246198654
train_iter_loss: 0.0034806872718036175
train_iter_loss: 0.006629305426031351
train_iter_loss: 0.00922428723424673
train_iter_loss: 0.006707994267344475
train_iter_loss: 0.006933185271918774
train_iter_loss: 0.038442179560661316
train_iter_loss: 0.012788001447916031
train_iter_loss: 0.012790779583156109
train_iter_loss: 0.012188899330794811
train_iter_loss: 0.014537991024553776
train_iter_loss: 0.004201706498861313
train_iter_loss: 0.004756079521030188
train_iter_loss: 0.0024457494728267193
train_iter_loss: 0.010176011361181736
train_iter_loss: 0.0130610391497612
train_iter_loss: 0.025460250675678253
train loss :0.0179
---------------------
Validation seg loss: 0.05512791541078291 at epoch 61
epoch =     62/  1000, exp = train
train_iter_loss: 0.021935829892754555
train_iter_loss: 0.01792430505156517
train_iter_loss: 0.02922469563782215
train_iter_loss: 0.00819108821451664
train_iter_loss: 0.033692121505737305
train_iter_loss: 0.02192794717848301
train_iter_loss: 0.024768883362412453
train_iter_loss: 0.040564946830272675
train_iter_loss: 0.022212743759155273
train_iter_loss: 0.010710412636399269
train_iter_loss: 0.019926825538277626
train_iter_loss: 0.011171716265380383
train_iter_loss: 0.015634991228580475
train_iter_loss: 0.007921096868813038
train_iter_loss: 0.0032618653494864702
train_iter_loss: 0.0034914955031126738
train_iter_loss: 0.009539126418530941
train_iter_loss: 0.0057371435686945915
train_iter_loss: 0.010544810444116592
train_iter_loss: 0.01549852080643177
train_iter_loss: 0.03721807524561882
train_iter_loss: 0.002461310476064682
train_iter_loss: 0.0022345108445733786
train_iter_loss: 0.012735484167933464
train_iter_loss: 0.011622322723269463
train_iter_loss: 0.00516533711925149
train_iter_loss: 0.01507512852549553
train_iter_loss: 0.009287583641707897
train_iter_loss: 0.006562505383044481
train_iter_loss: 0.007844150997698307
train_iter_loss: 0.005002919118851423
train_iter_loss: 0.006452356465160847
train_iter_loss: 0.0013366176281124353
train_iter_loss: 0.0016080710338428617
train_iter_loss: 0.006315224338322878
train_iter_loss: 0.011455602012574673
train_iter_loss: 0.012293674983084202
train_iter_loss: 0.01643657125532627
train_iter_loss: 0.013203497044742107
train_iter_loss: 0.007094867527484894
train_iter_loss: 0.011166756972670555
train_iter_loss: 0.01323707029223442
train_iter_loss: 0.04164702072739601
train_iter_loss: 0.005079126451164484
train_iter_loss: 0.0029454019386321306
train_iter_loss: 0.016555676236748695
train_iter_loss: 0.008158009499311447
train_iter_loss: 0.014287876896560192
train_iter_loss: 0.025873756036162376
train_iter_loss: 0.025205668061971664
train loss :0.0141
---------------------
Validation seg loss: 0.06062179382721331 at epoch 62
epoch =     63/  1000, exp = train
train_iter_loss: 0.027155732735991478
train_iter_loss: 0.012655057944357395
train_iter_loss: 0.00666776904836297
train_iter_loss: 0.010030938312411308
train_iter_loss: 0.030955146998167038
train_iter_loss: 0.06235528364777565
train_iter_loss: 0.008042561821639538
train_iter_loss: 0.03699519485235214
train_iter_loss: 0.019216155633330345
train_iter_loss: 0.025281883776187897
train_iter_loss: 0.007527184206992388
train_iter_loss: 0.026404062286019325
train_iter_loss: 0.027050575241446495
train_iter_loss: 0.004106743261218071
train_iter_loss: 0.026471421122550964
train_iter_loss: 0.008489440195262432
train_iter_loss: 0.006373820826411247
train_iter_loss: 0.01456568855792284
train_iter_loss: 0.018184255808591843
train_iter_loss: 0.009683202020823956
train_iter_loss: 0.002331323688849807
train_iter_loss: 0.005918353796005249
train_iter_loss: 0.003031326225027442
train_iter_loss: 0.0022047352977097034
train_iter_loss: 0.06584423035383224
train_iter_loss: 0.026693610474467278
train_iter_loss: 0.027106596156954765
train_iter_loss: 0.026213837787508965
train_iter_loss: 0.0030447065364569426
train_iter_loss: 0.003457500832155347
train_iter_loss: 0.0055702063255012035
train_iter_loss: 0.004886021837592125
train_iter_loss: 0.0026535128708928823
train_iter_loss: 0.007150247227400541
train_iter_loss: 0.005026255268603563
train_iter_loss: 0.022278688848018646
train_iter_loss: 0.009939607232809067
train_iter_loss: 0.01656191609799862
train_iter_loss: 0.005026350729167461
train_iter_loss: 0.01756029762327671
train_iter_loss: 0.024348339065909386
train_iter_loss: 0.023523643612861633
train_iter_loss: 0.020549871027469635
train_iter_loss: 0.0170819703489542
train_iter_loss: 0.003980288282036781
train_iter_loss: 0.007080742623656988
train_iter_loss: 0.0068228580057621
train_iter_loss: 0.002685676794499159
train_iter_loss: 0.051481667906045914
train_iter_loss: 0.006261621136218309
train loss :0.0166
---------------------
Validation seg loss: 0.05568469106823751 at epoch 63
epoch =     64/  1000, exp = train
train_iter_loss: 0.009217148646712303
train_iter_loss: 0.025701291859149933
train_iter_loss: 0.027888793498277664
train_iter_loss: 0.007362674456089735
train_iter_loss: 0.0160982608795166
train_iter_loss: 0.012181567959487438
train_iter_loss: 0.03350777551531792
train_iter_loss: 0.01124885305762291
train_iter_loss: 0.008954067714512348
train_iter_loss: 0.01430766936391592
train_iter_loss: 0.026191025972366333
train_iter_loss: 0.021697144955396652
train_iter_loss: 0.018904345110058784
train_iter_loss: 0.007896758615970612
train_iter_loss: 0.008607970550656319
train_iter_loss: 0.010714208707213402
train_iter_loss: 0.013093315996229649
train_iter_loss: 0.006964727770537138
train_iter_loss: 0.007253556977957487
train_iter_loss: 0.010718859732151031
train_iter_loss: 0.009618191979825497
train_iter_loss: 0.015762561932206154
train_iter_loss: 0.0035796386655420065
train_iter_loss: 0.010000367648899555
train_iter_loss: 0.05684999004006386
train_iter_loss: 0.03693205490708351
train_iter_loss: 0.029234066605567932
train_iter_loss: 0.007703348528593779
train_iter_loss: 0.007408583536744118
train_iter_loss: 0.010475433431565762
train_iter_loss: 0.005542568396776915
train_iter_loss: 0.010145977139472961
train_iter_loss: 0.010053823702037334
train_iter_loss: 0.007552398834377527
train_iter_loss: 0.00425433786585927
train_iter_loss: 0.0022502264473587275
train_iter_loss: 0.008460239507257938
train_iter_loss: 0.03341159224510193
train_iter_loss: 0.01882263645529747
train_iter_loss: 0.02134428359568119
train_iter_loss: 0.011015674099326134
train_iter_loss: 0.032288260757923126
train_iter_loss: 0.004748574923723936
train_iter_loss: 0.007715639658272266
train_iter_loss: 0.008586034178733826
train_iter_loss: 0.00569513626396656
train_iter_loss: 0.017288202419877052
train_iter_loss: 0.00569528341293335
train_iter_loss: 0.017865221947431564
train_iter_loss: 0.031615328043699265
train loss :0.0153
---------------------
Validation seg loss: 0.05577741508764206 at epoch 64
epoch =     65/  1000, exp = train
train_iter_loss: 0.01205816213041544
train_iter_loss: 0.016569677740335464
train_iter_loss: 0.016882924363017082
train_iter_loss: 0.007930613122880459
train_iter_loss: 0.007432526908814907
train_iter_loss: 0.010995784774422646
train_iter_loss: 0.0323532372713089
train_iter_loss: 0.036401644349098206
train_iter_loss: 0.01421594712883234
train_iter_loss: 0.016856927424669266
train_iter_loss: 0.009841062128543854
train_iter_loss: 0.01052483543753624
train_iter_loss: 0.005071242805570364
train_iter_loss: 0.005395389162003994
train_iter_loss: 0.02381734736263752
train_iter_loss: 0.005151357501745224
train_iter_loss: 0.01404137909412384
train_iter_loss: 0.006054411642253399
train_iter_loss: 0.024655573070049286
train_iter_loss: 0.007919041439890862
train_iter_loss: 0.005093161948025227
train_iter_loss: 0.01517697423696518
train_iter_loss: 0.013355359435081482
train_iter_loss: 0.04209313169121742
train_iter_loss: 0.005841728299856186
train_iter_loss: 0.013529747724533081
train_iter_loss: 0.012158474884927273
train_iter_loss: 0.009213811717927456
train_iter_loss: 0.005267357919365168
train_iter_loss: 0.0034058953169733286
train_iter_loss: 0.005101819057017565
train_iter_loss: 0.01412143837660551
train_iter_loss: 0.012380566447973251
train_iter_loss: 0.0031779499258846045
train_iter_loss: 0.005887174513190985
train_iter_loss: 0.004632080439478159
train_iter_loss: 0.028994383290410042
train_iter_loss: 0.017308278009295464
train_iter_loss: 0.0074232895858585835
train_iter_loss: 0.024032780900597572
train_iter_loss: 0.01148864533752203
train_iter_loss: 0.007032611407339573
train_iter_loss: 0.010055004619061947
train_iter_loss: 0.0073814429342746735
train_iter_loss: 0.004517092369496822
train_iter_loss: 0.0026873659808188677
train_iter_loss: 0.004944965709000826
train_iter_loss: 0.010913413017988205
train_iter_loss: 0.01235433854162693
train_iter_loss: 0.01900426857173443
train loss :0.0128
---------------------
Validation seg loss: 0.057221174441642604 at epoch 65
epoch =     66/  1000, exp = train
train_iter_loss: 0.017073310911655426
train_iter_loss: 0.010980661027133465
train_iter_loss: 0.023095853626728058
train_iter_loss: 0.007155511528253555
train_iter_loss: 0.06194015219807625
train_iter_loss: 0.04942653700709343
train_iter_loss: 0.02811741828918457
train_iter_loss: 0.01850169524550438
train_iter_loss: 0.020236752927303314
train_iter_loss: 0.016868002712726593
train_iter_loss: 0.008805619552731514
train_iter_loss: 0.024504227563738823
train_iter_loss: 0.006331988610327244
train_iter_loss: 0.009043961763381958
train_iter_loss: 0.00652062613517046
train_iter_loss: 0.018594540655612946
train_iter_loss: 0.0069276741705834866
train_iter_loss: 0.012698029167950153
train_iter_loss: 0.008425838313996792
train_iter_loss: 0.016437362879514694
train_iter_loss: 0.004258216358721256
train_iter_loss: 0.005330716725438833
train_iter_loss: 0.008983476087450981
train_iter_loss: 0.0014353579608723521
train_iter_loss: 0.01323035079985857
train_iter_loss: 0.03387729451060295
train_iter_loss: 0.04540657252073288
train_iter_loss: 0.017705027014017105
train_iter_loss: 0.004842129535973072
train_iter_loss: 0.01755405403673649
train_iter_loss: 0.005481990519911051
train_iter_loss: 0.015790952369570732
train_iter_loss: 0.003073828760534525
train_iter_loss: 0.013639593496918678
train_iter_loss: 0.0011324853403493762
train_iter_loss: 0.00727448146790266
train_iter_loss: 0.01419742126017809
train_iter_loss: 0.012131654657423496
train_iter_loss: 0.055268336087465286
train_iter_loss: 0.00633851857855916
train_iter_loss: 0.008763208985328674
train_iter_loss: 0.007239651866257191
train_iter_loss: 0.02599196508526802
train_iter_loss: 0.0364929623901844
train_iter_loss: 0.020605579018592834
train_iter_loss: 0.010223365388810635
train_iter_loss: 0.0031678425148129463
train_iter_loss: 0.020071297883987427
train_iter_loss: 0.0189655888825655
train_iter_loss: 0.03049948252737522
train loss :0.0171
---------------------
Validation seg loss: 0.05059782688435659 at epoch 66
epoch =     67/  1000, exp = train
train_iter_loss: 0.00823774840682745
train_iter_loss: 0.017886830493807793
train_iter_loss: 0.01641874387860298
train_iter_loss: 0.011861186474561691
train_iter_loss: 0.0037889715749770403
train_iter_loss: 0.009009492583572865
train_iter_loss: 0.010123088024556637
train_iter_loss: 0.016358492895960808
train_iter_loss: 0.022222798317670822
train_iter_loss: 0.01722146011888981
train_iter_loss: 0.0033738892525434494
train_iter_loss: 0.01941467449069023
train_iter_loss: 0.008141819387674332
train_iter_loss: 0.003427700139582157
train_iter_loss: 0.0053479946218431
train_iter_loss: 0.014977909624576569
train_iter_loss: 0.0387122817337513
train_iter_loss: 0.012985418550670147
train_iter_loss: 0.016590295359492302
train_iter_loss: 0.008140007965266705
train_iter_loss: 0.008241440169513226
train_iter_loss: 0.009684865362942219
train_iter_loss: 0.02297615073621273
train_iter_loss: 0.004666234832257032
train_iter_loss: 0.05721276253461838
train_iter_loss: 0.011714293621480465
train_iter_loss: 0.010075317695736885
train_iter_loss: 0.05516275390982628
train_iter_loss: 0.003407773096114397
train_iter_loss: 0.011443286202847958
train_iter_loss: 0.005075516644865274
train_iter_loss: 0.0024193564895540476
train_iter_loss: 0.007035683374851942
train_iter_loss: 0.01446467824280262
train_iter_loss: 0.006447623483836651
train_iter_loss: 0.011367051862180233
train_iter_loss: 0.011814824305474758
train_iter_loss: 0.009472458623349667
train_iter_loss: 0.006501428317278624
train_iter_loss: 0.007843835279345512
train_iter_loss: 0.021961774677038193
train_iter_loss: 0.02428661845624447
train_iter_loss: 0.01938793808221817
train_iter_loss: 0.01513102650642395
train_iter_loss: 0.00811831746250391
train_iter_loss: 0.008061224594712257
train_iter_loss: 0.002487373538315296
train_iter_loss: 0.005541977472603321
train_iter_loss: 0.02065252512693405
train_iter_loss: 0.055418960750103
train loss :0.0148
---------------------
Validation seg loss: 0.05116160921650864 at epoch 67
epoch =     68/  1000, exp = train
train_iter_loss: 0.007546494714915752
train_iter_loss: 0.02504044584929943
train_iter_loss: 0.00955252256244421
train_iter_loss: 0.030626734718680382
train_iter_loss: 0.028664685785770416
train_iter_loss: 0.02983470819890499
train_iter_loss: 0.0212808046489954
train_iter_loss: 0.025745827704668045
train_iter_loss: 0.04555089399218559
train_iter_loss: 0.006134476978331804
train_iter_loss: 0.005540921818464994
train_iter_loss: 0.02420729398727417
train_iter_loss: 0.004694399889558554
train_iter_loss: 0.00760861998423934
train_iter_loss: 0.005708224140107632
train_iter_loss: 0.012447734363377094
train_iter_loss: 0.011753969825804234
train_iter_loss: 0.009903538040816784
train_iter_loss: 0.02376161329448223
train_iter_loss: 0.020732318982481956
train_iter_loss: 0.011578301899135113
train_iter_loss: 0.0048987106420099735
train_iter_loss: 0.011742634698748589
train_iter_loss: 0.005406778305768967
train_iter_loss: 0.02881511114537716
train_iter_loss: 0.011548027396202087
train_iter_loss: 0.008198249153792858
train_iter_loss: 0.01032893918454647
train_iter_loss: 0.0031880238093435764
train_iter_loss: 0.0026714312843978405
train_iter_loss: 0.012547322548925877
train_iter_loss: 0.007272309623658657
train_iter_loss: 0.025866037234663963
train_iter_loss: 0.01862187311053276
train_iter_loss: 0.004519416950643063
train_iter_loss: 0.004439753480255604
train_iter_loss: 0.028899718075990677
train_iter_loss: 0.00668907817453146
train_iter_loss: 0.014038740657269955
train_iter_loss: 0.008122684434056282
train_iter_loss: 0.023244859650731087
train_iter_loss: 0.007356648333370686
train_iter_loss: 0.01818513125181198
train_iter_loss: 0.028061527758836746
train_iter_loss: 0.002997287316247821
train_iter_loss: 0.017886493355035782
train_iter_loss: 0.010401228442788124
train_iter_loss: 0.020109873265028
train_iter_loss: 0.014903128147125244
train_iter_loss: 0.046162787824869156
train loss :0.0158
---------------------
Validation seg loss: 0.05748640191422793 at epoch 68
epoch =     69/  1000, exp = train
train_iter_loss: 0.020787449553608894
train_iter_loss: 0.006794292479753494
train_iter_loss: 0.03156709671020508
train_iter_loss: 0.011046366766095161
train_iter_loss: 0.016667168587446213
train_iter_loss: 0.030504386872053146
train_iter_loss: 0.06137092038989067
train_iter_loss: 0.014921571128070354
train_iter_loss: 0.026439867913722992
train_iter_loss: 0.010746662504971027
train_iter_loss: 0.00697645777836442
train_iter_loss: 0.01381018664687872
train_iter_loss: 0.0019547550473362207
train_iter_loss: 0.01779472827911377
train_iter_loss: 0.00882193073630333
train_iter_loss: 0.008460036478936672
train_iter_loss: 0.01851857639849186
train_iter_loss: 0.016577214002609253
train_iter_loss: 0.007034953683614731
train_iter_loss: 0.007172029465436935
train_iter_loss: 0.015101788565516472
train_iter_loss: 0.0028183565009385347
train_iter_loss: 0.013559547252953053
train_iter_loss: 0.010482395999133587
train_iter_loss: 0.043793439865112305
train_iter_loss: 0.014372805133461952
train_iter_loss: 0.0054847244173288345
train_iter_loss: 0.006215258967131376
train_iter_loss: 0.003156596329063177
train_iter_loss: 0.0048424010165035725
train_iter_loss: 0.004971151240170002
train_iter_loss: 0.006566380150616169
train_iter_loss: 0.0063413577154278755
train_iter_loss: 0.00851942878216505
train_iter_loss: 0.0074761961586773396
train_iter_loss: 0.027565857395529747
train_iter_loss: 0.011199436150491238
train_iter_loss: 0.013639676384627819
train_iter_loss: 0.053818363696336746
train_iter_loss: 0.007562380284070969
train_iter_loss: 0.02132229693233967
train_iter_loss: 0.0511833094060421
train_iter_loss: 0.028606228530406952
train_iter_loss: 0.028572699055075645
train_iter_loss: 0.0053581856191158295
train_iter_loss: 0.007213396951556206
train_iter_loss: 0.01874670572578907
train_iter_loss: 0.0038930277805775404
train_iter_loss: 0.011019542813301086
train_iter_loss: 0.020154166966676712
train loss :0.0163
---------------------
Validation seg loss: 0.057622038862527404 at epoch 69
epoch =     70/  1000, exp = train
train_iter_loss: 0.002068856032565236
train_iter_loss: 0.010151979513466358
train_iter_loss: 0.0036438715178519487
train_iter_loss: 0.014141734689474106
train_iter_loss: 0.024606000632047653
train_iter_loss: 0.028658295050263405
train_iter_loss: 0.017696533352136612
train_iter_loss: 0.033609259873628616
train_iter_loss: 0.01251404732465744
train_iter_loss: 0.006695830263197422
train_iter_loss: 0.009380090050399303
train_iter_loss: 0.03742072358727455
train_iter_loss: 0.020311305299401283
train_iter_loss: 0.008041531778872013
train_iter_loss: 0.008954460732638836
train_iter_loss: 0.005152795929461718
train_iter_loss: 0.012180463410913944
train_iter_loss: 0.014288372360169888
train_iter_loss: 0.01070405263453722
train_iter_loss: 0.007537573575973511
train_iter_loss: 0.010103689506649971
train_iter_loss: 0.005419016350060701
train_iter_loss: 0.004948045592755079
train_iter_loss: 0.01493756752461195
train_iter_loss: 0.019304728135466576
train_iter_loss: 0.01685991883277893
train_iter_loss: 0.019351346418261528
train_iter_loss: 0.036641675978899
train_iter_loss: 0.005177083890885115
train_iter_loss: 0.004941880237311125
train_iter_loss: 0.003931035753339529
train_iter_loss: 0.00632324256002903
train_iter_loss: 0.028909729793667793
train_iter_loss: 0.0046308161690831184
train_iter_loss: 0.002256611594930291
train_iter_loss: 0.0030102285090833902
train_iter_loss: 0.01556389033794403
train_iter_loss: 0.006303213071078062
train_iter_loss: 0.014771334826946259
train_iter_loss: 0.004197414498776197
train_iter_loss: 0.007367302197962999
train_iter_loss: 0.04399404674768448
train_iter_loss: 0.009734190069139004
train_iter_loss: 0.030881429091095924
train_iter_loss: 0.01616508886218071
train_iter_loss: 0.008023051545023918
train_iter_loss: 0.00341338780708611
train_iter_loss: 0.006527142133563757
train_iter_loss: 0.01226256787776947
train_iter_loss: 0.01615736447274685
train loss :0.0137
---------------------
Validation seg loss: 0.06076366916070429 at epoch 70
epoch =     71/  1000, exp = train
train_iter_loss: 0.006624020170420408
train_iter_loss: 0.024844856932759285
train_iter_loss: 0.02285015396773815
train_iter_loss: 0.015338554978370667
train_iter_loss: 0.026583831757307053
train_iter_loss: 0.015535654500126839
train_iter_loss: 0.024118764325976372
train_iter_loss: 0.018441542983055115
train_iter_loss: 0.018170589581131935
train_iter_loss: 0.010999040678143501
train_iter_loss: 0.020289991050958633
train_iter_loss: 0.00956872571259737
train_iter_loss: 0.014735798351466656
train_iter_loss: 0.004809862934052944
train_iter_loss: 0.004946340341120958
train_iter_loss: 0.014165553264319897
train_iter_loss: 0.014306618832051754
train_iter_loss: 0.01489565335214138
train_iter_loss: 0.03344688192009926
train_iter_loss: 0.005448844749480486
train_iter_loss: 0.0028170435689389706
train_iter_loss: 0.016517722979187965
train_iter_loss: 0.04149223491549492
train_iter_loss: 0.005636064801365137
train_iter_loss: 0.023443439975380898
train_iter_loss: 0.04106828197836876
train_iter_loss: 0.015113674104213715
train_iter_loss: 0.01886068657040596
train_iter_loss: 0.00275628175586462
train_iter_loss: 0.0079730823636055
train_iter_loss: 0.005235813558101654
train_iter_loss: 0.015711169689893723
train_iter_loss: 0.003725379938259721
train_iter_loss: 0.0018030247883871198
train_iter_loss: 0.026646021753549576
train_iter_loss: 0.003050862578675151
train_iter_loss: 0.006639157887548208
train_iter_loss: 0.007159005384892225
train_iter_loss: 0.010637368075549603
train_iter_loss: 0.005457588005810976
train_iter_loss: 0.020349228754639626
train_iter_loss: 0.020665986463427544
train_iter_loss: 0.03307007625699043
train_iter_loss: 0.00865783542394638
train_iter_loss: 0.0032358283642679453
train_iter_loss: 0.012060054577887058
train_iter_loss: 0.010010801255702972
train_iter_loss: 0.007709995377808809
train_iter_loss: 0.04094929248094559
train_iter_loss: 0.045083776116371155
train loss :0.0159
---------------------
Validation seg loss: 0.054106785134107035 at epoch 71
epoch =     72/  1000, exp = train
train_iter_loss: 0.016623128205537796
train_iter_loss: 0.01853295788168907
train_iter_loss: 0.010321218520402908
train_iter_loss: 0.0075241620652377605
train_iter_loss: 0.04963306337594986
train_iter_loss: 0.012372777797281742
train_iter_loss: 0.020400049164891243
train_iter_loss: 0.014412458054721355
train_iter_loss: 0.016559194773435593
train_iter_loss: 0.02743818238377571
train_iter_loss: 0.02346854656934738
train_iter_loss: 0.011853630654513836
train_iter_loss: 0.005468045827001333
train_iter_loss: 0.03796002268791199
train_iter_loss: 0.0075397007167339325
train_iter_loss: 0.011968952603638172
train_iter_loss: 0.012351563200354576
train_iter_loss: 0.016613706946372986
train_iter_loss: 0.01695302315056324
train_iter_loss: 0.015373069792985916
train_iter_loss: 0.004440619610249996
train_iter_loss: 0.033215656876564026
train_iter_loss: 0.0189987663179636
train_iter_loss: 0.004964587278664112
train_iter_loss: 0.005247068591415882
train_iter_loss: 0.007566538639366627
train_iter_loss: 0.01629624329507351
train_iter_loss: 0.018286745995283127
train_iter_loss: 0.003159452462568879
train_iter_loss: 0.0016473300056532025
train_iter_loss: 0.00529883336275816
train_iter_loss: 0.005036472342908382
train_iter_loss: 0.004887592978775501
train_iter_loss: 0.0023634068202227354
train_iter_loss: 0.002434615744277835
train_iter_loss: 0.012503411620855331
train_iter_loss: 0.00555804930627346
train_iter_loss: 0.016673991456627846
train_iter_loss: 0.016153626143932343
train_iter_loss: 0.003087107790634036
train_iter_loss: 0.01703239418566227
train_iter_loss: 0.016817975789308548
train_iter_loss: 0.01341345813125372
train_iter_loss: 0.013271243311464787
train_iter_loss: 0.0032710391096770763
train_iter_loss: 0.007442837115377188
train_iter_loss: 0.00984107330441475
train_iter_loss: 0.02986437827348709
train_iter_loss: 0.023831894621253014
train_iter_loss: 0.02559712342917919
train loss :0.0144
---------------------
Validation seg loss: 0.05754836819179681 at epoch 72
epoch =     73/  1000, exp = train
train_iter_loss: 0.038433823734521866
train_iter_loss: 0.012713050469756126
train_iter_loss: 0.034787148237228394
train_iter_loss: 0.027470052242279053
train_iter_loss: 0.023582588881254196
train_iter_loss: 0.019766170531511307
train_iter_loss: 0.014116880483925343
train_iter_loss: 0.07422755658626556
train_iter_loss: 0.013417357578873634
train_iter_loss: 0.009782977402210236
train_iter_loss: 0.019226117059588432
train_iter_loss: 0.015017927624285221
train_iter_loss: 0.006190833169966936
train_iter_loss: 0.011565947905182838
train_iter_loss: 0.022605547681450844
train_iter_loss: 0.01439864095300436
train_iter_loss: 0.01725253090262413
train_iter_loss: 0.009870754554867744
train_iter_loss: 0.007132049184292555
train_iter_loss: 0.02433515526354313
train_iter_loss: 0.004482056479901075
train_iter_loss: 0.0080553088337183
train_iter_loss: 0.01594441942870617
train_iter_loss: 0.013464795425534248
train_iter_loss: 0.007942510768771172
train_iter_loss: 0.031115079298615456
train_iter_loss: 0.017562706023454666
train_iter_loss: 0.024561377242207527
train_iter_loss: 0.005269228480756283
train_iter_loss: 0.005886721424758434
train_iter_loss: 0.001919192261993885
train_iter_loss: 0.002806000877171755
train_iter_loss: 0.004625976551324129
train_iter_loss: 0.004208679776638746
train_iter_loss: 0.00877309124916792
train_iter_loss: 0.003983617760241032
train_iter_loss: 0.03135748207569122
train_iter_loss: 0.01481833029538393
train_iter_loss: 0.006996077951043844
train_iter_loss: 0.047103602439165115
train_iter_loss: 0.011224551126360893
train_iter_loss: 0.012935694307088852
train_iter_loss: 0.03312074765563011
train_iter_loss: 0.006143958307802677
train_iter_loss: 0.00473809614777565
train_iter_loss: 0.003221511607989669
train_iter_loss: 0.005335644818842411
train_iter_loss: 0.010496006347239017
train_iter_loss: 0.012214587070047855
train_iter_loss: 0.013608535751700401
train loss :0.0161
---------------------
Validation seg loss: 0.05295347604932997 at epoch 73
epoch =     74/  1000, exp = train
train_iter_loss: 0.013458367437124252
train_iter_loss: 0.012270300649106503
train_iter_loss: 0.030514288693666458
train_iter_loss: 0.011961952783167362
train_iter_loss: 0.06139795854687691
train_iter_loss: 0.02068094164133072
train_iter_loss: 0.014216595329344273
train_iter_loss: 0.030841050669550896
train_iter_loss: 0.02312971092760563
train_iter_loss: 0.022308075800538063
train_iter_loss: 0.004383462015539408
train_iter_loss: 0.029805373400449753
train_iter_loss: 0.00894972961395979
train_iter_loss: 0.003225089516490698
train_iter_loss: 0.00894781481474638
train_iter_loss: 0.011625041253864765
train_iter_loss: 0.031840965151786804
train_iter_loss: 0.01335880160331726
train_iter_loss: 0.014508264139294624
train_iter_loss: 0.008787022903561592
train_iter_loss: 0.012027907185256481
train_iter_loss: 0.006407418288290501
train_iter_loss: 0.002621822990477085
train_iter_loss: 0.0295095257461071
train_iter_loss: 0.0407949835062027
train_iter_loss: 0.07799319177865982
train_iter_loss: 0.04957178607583046
train_iter_loss: 0.048627931624650955
train_iter_loss: 0.0029242357704788446
train_iter_loss: 0.0039035731460899115
train_iter_loss: 0.00499678123742342
train_iter_loss: 0.0038572640623897314
train_iter_loss: 0.005322593729943037
train_iter_loss: 0.0037825244944542646
train_iter_loss: 0.0034682166296988726
train_iter_loss: 0.0035764602944254875
train_iter_loss: 0.005879489239305258
train_iter_loss: 0.030920416116714478
train_iter_loss: 0.015923291444778442
train_iter_loss: 0.0046418197453022
train_iter_loss: 0.023315588012337685
train_iter_loss: 0.023472696542739868
train_iter_loss: 0.008121473714709282
train_iter_loss: 0.0118526266887784
train_iter_loss: 0.008325385861098766
train_iter_loss: 0.007105943746864796
train_iter_loss: 0.01409146934747696
train_iter_loss: 0.014542861841619015
train_iter_loss: 0.014338800683617592
train_iter_loss: 0.006797625217586756
train loss :0.0176
---------------------
Validation seg loss: 0.050281622492513875 at epoch 74
epoch =     75/  1000, exp = train
train_iter_loss: 0.06105415150523186
train_iter_loss: 0.04043241962790489
train_iter_loss: 0.016445184126496315
train_iter_loss: 0.013295217417180538
train_iter_loss: 0.026789210736751556
train_iter_loss: 0.008340379223227501
train_iter_loss: 0.025348946452140808
train_iter_loss: 0.012993678450584412
train_iter_loss: 0.02893979288637638
train_iter_loss: 0.009634207002818584
train_iter_loss: 0.03482827544212341
train_iter_loss: 0.06508779525756836
train_iter_loss: 0.0066959671676158905
train_iter_loss: 0.006626551039516926
train_iter_loss: 0.004080257378518581
train_iter_loss: 0.013398033566772938
train_iter_loss: 0.009796996600925922
train_iter_loss: 0.005922249983996153
train_iter_loss: 0.009121527895331383
train_iter_loss: 0.0076911975629627705
train_iter_loss: 0.0041885883547365665
train_iter_loss: 0.00224168598651886
train_iter_loss: 0.008598673157393932
train_iter_loss: 0.010937714949250221
train_iter_loss: 0.027244826778769493
train_iter_loss: 0.005627546459436417
train_iter_loss: 0.006439944729208946
train_iter_loss: 0.03245191276073456
train_iter_loss: 0.004069374408572912
train_iter_loss: 0.005397184286266565
train_iter_loss: 0.0028115373570472
train_iter_loss: 0.009902683086693287
train_iter_loss: 0.0026941478718072176
train_iter_loss: 0.007232499308884144
train_iter_loss: 0.022599633783102036
train_iter_loss: 0.0020289900712668896
train_iter_loss: 0.00637409370392561
train_iter_loss: 0.015120563097298145
train_iter_loss: 0.021937642246484756
train_iter_loss: 0.008356955833733082
train_iter_loss: 0.007416747510433197
train_iter_loss: 0.026791930198669434
train_iter_loss: 0.04239198938012123
train_iter_loss: 0.021685713902115822
train_iter_loss: 0.00771064730361104
train_iter_loss: 0.005243581719696522
train_iter_loss: 0.001693077152594924
train_iter_loss: 0.010352627374231815
train_iter_loss: 0.013143550604581833
train_iter_loss: 0.01369711384177208
train loss :0.0156
---------------------
Validation seg loss: 0.056698627943334495 at epoch 75
epoch =     76/  1000, exp = train
train_iter_loss: 0.0167811568826437
train_iter_loss: 0.01854485273361206
train_iter_loss: 0.033819202333688736
train_iter_loss: 0.009508864022791386
train_iter_loss: 0.014223644509911537
train_iter_loss: 0.04842055216431618
train_iter_loss: 0.00887357909232378
train_iter_loss: 0.02213307097554207
train_iter_loss: 0.019567478448152542
train_iter_loss: 0.020448049530386925
train_iter_loss: 0.0260730292648077
train_iter_loss: 0.006270944606512785
train_iter_loss: 0.02016732096672058
train_iter_loss: 0.003916719928383827
train_iter_loss: 0.013400759547948837
train_iter_loss: 0.011437812820076942
train_iter_loss: 0.016174841672182083
train_iter_loss: 0.030114496126770973
train_iter_loss: 0.01525170262902975
train_iter_loss: 0.013571028597652912
train_iter_loss: 0.012456382624804974
train_iter_loss: 0.0031060983892530203
train_iter_loss: 0.0027613507118076086
train_iter_loss: 0.007294041104614735
train_iter_loss: 0.017596693709492683
train_iter_loss: 0.011429967358708382
train_iter_loss: 0.030716465786099434
train_iter_loss: 0.019998598843812943
train_iter_loss: 0.0064941225573420525
train_iter_loss: 0.003942898940294981
train_iter_loss: 0.0017921134131029248
train_iter_loss: 0.0032062530517578125
train_iter_loss: 0.011862356215715408
train_iter_loss: 0.0203053317964077
train_iter_loss: 0.0034381619188934565
train_iter_loss: 0.004897234495729208
train_iter_loss: 0.03574426844716072
train_iter_loss: 0.012472077272832394
train_iter_loss: 0.014797481708228588
train_iter_loss: 0.021460117772221565
train_iter_loss: 0.0286228209733963
train_iter_loss: 0.019839121028780937
train_iter_loss: 0.008890405297279358
train_iter_loss: 0.008263996802270412
train_iter_loss: 0.005626400001347065
train_iter_loss: 0.0019962203223258257
train_iter_loss: 0.014343885704874992
train_iter_loss: 0.013787977397441864
train_iter_loss: 0.015782207250595093
train_iter_loss: 0.05937130004167557
train loss :0.0161
---------------------
Validation seg loss: 0.0510854044651013 at epoch 76
epoch =     77/  1000, exp = train
train_iter_loss: 0.03242996707558632
train_iter_loss: 0.020983587950468063
train_iter_loss: 0.03284022584557533
train_iter_loss: 0.01056170929223299
train_iter_loss: 0.05638537555932999
train_iter_loss: 0.006883468013256788
train_iter_loss: 0.019465558230876923
train_iter_loss: 0.00935455597937107
train_iter_loss: 0.02651900239288807
train_iter_loss: 0.011286817491054535
train_iter_loss: 0.022328265011310577
train_iter_loss: 0.009510312229394913
train_iter_loss: 0.007501067593693733
train_iter_loss: 0.0034185233525931835
train_iter_loss: 0.020977048203349113
train_iter_loss: 0.006706441752612591
train_iter_loss: 0.03923334926366806
train_iter_loss: 0.007497746963053942
train_iter_loss: 0.01940212957561016
train_iter_loss: 0.008633511140942574
train_iter_loss: 0.00810985453426838
train_iter_loss: 0.0029819279443472624
train_iter_loss: 0.004029739648103714
train_iter_loss: 0.011107866652309895
train_iter_loss: 0.04707512632012367
train_iter_loss: 0.030534658581018448
train_iter_loss: 0.04635266214609146
train_iter_loss: 0.006516390014439821
train_iter_loss: 0.004924598149955273
train_iter_loss: 0.004213085863739252
train_iter_loss: 0.00702996551990509
train_iter_loss: 0.0013682047137990594
train_iter_loss: 0.0256551131606102
train_iter_loss: 0.003932225983589888
train_iter_loss: 0.007593248039484024
train_iter_loss: 0.006966272369027138
train_iter_loss: 0.02493417263031006
train_iter_loss: 0.0075440192595124245
train_iter_loss: 0.00920620933175087
train_iter_loss: 0.006871921010315418
train_iter_loss: 0.023638717830181122
train_iter_loss: 0.018724650144577026
train_iter_loss: 0.01923498511314392
train_iter_loss: 0.022398805245757103
train_iter_loss: 0.004185377154499292
train_iter_loss: 0.00155829475261271
train_iter_loss: 0.003020073752850294
train_iter_loss: 0.0033996140118688345
train_iter_loss: 0.05125138536095619
train_iter_loss: 0.02932676300406456
train loss :0.0166
---------------------
Validation seg loss: 0.05142945040773517 at epoch 77
epoch =     78/  1000, exp = train
train_iter_loss: 0.0070312172174453735
train_iter_loss: 0.01754724606871605
train_iter_loss: 0.013523909263312817
train_iter_loss: 0.008484156802296638
train_iter_loss: 0.011452085338532925
train_iter_loss: 0.03725189343094826
train_iter_loss: 0.04391511157155037
train_iter_loss: 0.028303399682044983
train_iter_loss: 0.011984647251665592
train_iter_loss: 0.039325982332229614
train_iter_loss: 0.006448024418205023
train_iter_loss: 0.01795065402984619
train_iter_loss: 0.013321531005203724
train_iter_loss: 0.011525685898959637
train_iter_loss: 0.014583676122128963
train_iter_loss: 0.014180213212966919
train_iter_loss: 0.021677648648619652
train_iter_loss: 0.009112675674259663
train_iter_loss: 0.014836210757493973
train_iter_loss: 0.01640581525862217
train_iter_loss: 0.033937547355890274
train_iter_loss: 0.03419170528650284
train_iter_loss: 0.010085572488605976
train_iter_loss: 0.002168049570173025
train_iter_loss: 0.027560362592339516
train_iter_loss: 0.012363893911242485
train_iter_loss: 0.04388798028230667
train_iter_loss: 0.01732991263270378
train_iter_loss: 0.004264481831341982
train_iter_loss: 0.01635756902396679
train_iter_loss: 0.009926650673151016
train_iter_loss: 0.01697268895804882
train_iter_loss: 0.0035796251613646746
train_iter_loss: 0.0022738734260201454
train_iter_loss: 0.0029669231735169888
train_iter_loss: 0.006228102371096611
train_iter_loss: 0.014637626707553864
train_iter_loss: 0.014711604453623295
train_iter_loss: 0.023930393159389496
train_iter_loss: 0.010302928276360035
train_iter_loss: 0.0386485792696476
train_iter_loss: 0.011243524961173534
train_iter_loss: 0.02280496619641781
train_iter_loss: 0.023691631853580475
train_iter_loss: 0.011722984723746777
train_iter_loss: 0.005956833250820637
train_iter_loss: 0.0017898045480251312
train_iter_loss: 0.0033166413195431232
train_iter_loss: 0.013009816408157349
train_iter_loss: 0.008374129422008991
train loss :0.0165
---------------------
Validation seg loss: 0.05178459856029323 at epoch 78
epoch =     79/  1000, exp = train
train_iter_loss: 0.016760433092713356
train_iter_loss: 0.0469387024641037
train_iter_loss: 0.009159606881439686
train_iter_loss: 0.02021445892751217
train_iter_loss: 0.032628487795591354
train_iter_loss: 0.032724957913160324
train_iter_loss: 0.049738142639398575
train_iter_loss: 0.04088405892252922
train_iter_loss: 0.015945537015795708
train_iter_loss: 0.01103849709033966
train_iter_loss: 0.012773644179105759
train_iter_loss: 0.04823552444577217
train_iter_loss: 0.006445538252592087
train_iter_loss: 0.0055815610103309155
train_iter_loss: 0.0064031085930764675
train_iter_loss: 0.009227797389030457
train_iter_loss: 0.0051356032490730286
train_iter_loss: 0.006201065145432949
train_iter_loss: 0.018435290083289146
train_iter_loss: 0.027503136545419693
train_iter_loss: 0.008474619127810001
train_iter_loss: 0.005822134669870138
train_iter_loss: 0.008059368468821049
train_iter_loss: 0.006412826478481293
train_iter_loss: 0.013172526843845844
train_iter_loss: 0.021751632913947105
train_iter_loss: 0.07251614332199097
train_iter_loss: 0.01606699265539646
train_iter_loss: 0.01742449402809143
train_iter_loss: 0.01078849658370018
train_iter_loss: 0.002252464182674885
train_iter_loss: 0.008480533957481384
train_iter_loss: 0.007183672860264778
train_iter_loss: 0.00285361148416996
train_iter_loss: 0.002796486020088196
train_iter_loss: 0.005120425019413233
train_iter_loss: 0.0038626447785645723
train_iter_loss: 0.014046714641153812
train_iter_loss: 0.004085225518792868
train_iter_loss: 0.008452379144728184
train_iter_loss: 0.025384308770298958
train_iter_loss: 0.01833021081984043
train_iter_loss: 0.016535060480237007
train_iter_loss: 0.018883878365159035
train_iter_loss: 0.015702130272984505
train_iter_loss: 0.003156560705974698
train_iter_loss: 0.004705699626356363
train_iter_loss: 0.005067440681159496
train_iter_loss: 0.010908680036664009
train_iter_loss: 0.00586791941896081
train loss :0.0161
---------------------
Validation seg loss: 0.049731565745495795 at epoch 79
epoch =     80/  1000, exp = train
train_iter_loss: 0.017400594428181648
train_iter_loss: 0.016509782522916794
train_iter_loss: 0.01529308408498764
train_iter_loss: 0.015299326740205288
train_iter_loss: 0.012911648489534855
train_iter_loss: 0.009548275731503963
train_iter_loss: 0.014629737474024296
train_iter_loss: 0.018750347197055817
train_iter_loss: 0.014236249029636383
train_iter_loss: 0.02461269311606884
train_iter_loss: 0.013927810825407505
train_iter_loss: 0.011667597107589245
train_iter_loss: 0.0038639912381768227
train_iter_loss: 0.02268623560667038
train_iter_loss: 0.004233673680573702
train_iter_loss: 0.005530145019292831
train_iter_loss: 0.016136135905981064
train_iter_loss: 0.012878911569714546
train_iter_loss: 0.008554200641810894
train_iter_loss: 0.009600706398487091
train_iter_loss: 0.026316044852137566
train_iter_loss: 0.01673221029341221
train_iter_loss: 0.007583524566143751
train_iter_loss: 0.0019390673842281103
train_iter_loss: 0.0095242690294981
train_iter_loss: 0.038855064660310745
train_iter_loss: 0.013363594189286232
train_iter_loss: 0.015763919800519943
train_iter_loss: 0.002583115128800273
train_iter_loss: 0.0038053966127336025
train_iter_loss: 0.0031145811080932617
train_iter_loss: 0.016982577741146088
train_iter_loss: 0.0028791173826903105
train_iter_loss: 0.005058396141976118
train_iter_loss: 0.027593009173870087
train_iter_loss: 0.0030960163567215204
train_iter_loss: 0.027172444388270378
train_iter_loss: 0.0069165779277682304
train_iter_loss: 0.005323970690369606
train_iter_loss: 0.0039320639334619045
train_iter_loss: 0.02084987983107567
train_iter_loss: 0.021400222554802895
train_iter_loss: 0.026455948129296303
train_iter_loss: 0.013935690745711327
train_iter_loss: 0.009831445291638374
train_iter_loss: 0.009620308876037598
train_iter_loss: 0.0026834902819246054
train_iter_loss: 0.01892838254570961
train_iter_loss: 0.007484029978513718
train_iter_loss: 0.015217886306345463
train loss :0.0134
---------------------
Validation seg loss: 0.053856558107962076 at epoch 80
epoch =     81/  1000, exp = train
train_iter_loss: 0.007262327242642641
train_iter_loss: 0.04442284628748894
train_iter_loss: 0.006371196359395981
train_iter_loss: 0.005611301865428686
train_iter_loss: 0.028201458975672722
train_iter_loss: 0.009381631389260292
train_iter_loss: 0.02702273800969124
train_iter_loss: 0.021297212690114975
train_iter_loss: 0.025066036731004715
train_iter_loss: 0.026130421087145805
train_iter_loss: 0.030292170122265816
train_iter_loss: 0.0038890040013939142
train_iter_loss: 0.00905863381922245
train_iter_loss: 0.012063542380928993
train_iter_loss: 0.01914389058947563
train_iter_loss: 0.021369777619838715
train_iter_loss: 0.010466200299561024
train_iter_loss: 0.0054953740909695625
train_iter_loss: 0.016706600785255432
train_iter_loss: 0.011600644327700138
train_iter_loss: 0.018850594758987427
train_iter_loss: 0.00874718464910984
train_iter_loss: 0.016726551577448845
train_iter_loss: 0.010134323500096798
train_iter_loss: 0.011341731064021587
train_iter_loss: 0.013295995071530342
train_iter_loss: 0.017999807372689247
train_iter_loss: 0.005131610203534365
train_iter_loss: 0.003979104571044445
train_iter_loss: 0.018106648698449135
train_iter_loss: 0.00292548188008368
train_iter_loss: 0.005965430289506912
train_iter_loss: 0.004715367220342159
train_iter_loss: 0.004510446451604366
train_iter_loss: 0.0008818823844194412
train_iter_loss: 0.024449186399579048
train_iter_loss: 0.00835355930030346
train_iter_loss: 0.012720515951514244
train_iter_loss: 0.024540722370147705
train_iter_loss: 0.006122906226664782
train_iter_loss: 0.01166395004838705
train_iter_loss: 0.03812665119767189
train_iter_loss: 0.005832613445818424
train_iter_loss: 0.01471343357115984
train_iter_loss: 0.003708349773660302
train_iter_loss: 0.01630443148314953
train_iter_loss: 0.004379523452371359
train_iter_loss: 0.008094546385109425
train_iter_loss: 0.01061262097209692
train_iter_loss: 0.008517342619597912
train loss :0.0139
---------------------
Validation seg loss: 0.05674533393368002 at epoch 81
epoch =     82/  1000, exp = train
train_iter_loss: 0.010317967273294926
train_iter_loss: 0.025946570560336113
train_iter_loss: 0.004420147743076086
train_iter_loss: 0.02616284228861332
train_iter_loss: 0.011990353465080261
train_iter_loss: 0.014060590416193008
train_iter_loss: 0.025605345144867897
train_iter_loss: 0.018487565219402313
train_iter_loss: 0.00443456694483757
train_iter_loss: 0.013365344144403934
train_iter_loss: 0.02052650973200798
train_iter_loss: 0.0062459432519972324
train_iter_loss: 0.0043322183191776276
train_iter_loss: 0.006883763242512941
train_iter_loss: 0.008387730456888676
train_iter_loss: 0.014681171625852585
train_iter_loss: 0.011203236877918243
train_iter_loss: 0.007657456211745739
train_iter_loss: 0.022911174222826958
train_iter_loss: 0.006453708745539188
train_iter_loss: 0.012265943922102451
train_iter_loss: 0.012598803266882896
train_iter_loss: 0.0038602747954428196
train_iter_loss: 0.004648680333048105
train_iter_loss: 0.014939038082957268
train_iter_loss: 0.0313967689871788
train_iter_loss: 0.012044908478856087
train_iter_loss: 0.020246630534529686
train_iter_loss: 0.01490319799631834
train_iter_loss: 0.006302630994468927
train_iter_loss: 0.0034912312403321266
train_iter_loss: 0.005895528942346573
train_iter_loss: 0.020326388999819756
train_iter_loss: 0.001848777406848967
train_iter_loss: 0.003481559921056032
train_iter_loss: 0.0024891498032957315
train_iter_loss: 0.012632564641535282
train_iter_loss: 0.02743440680205822
train_iter_loss: 0.008120791055262089
train_iter_loss: 0.007310183718800545
train_iter_loss: 0.01278218999505043
train_iter_loss: 0.019717909395694733
train_iter_loss: 0.012472579255700111
train_iter_loss: 0.013198287226259708
train_iter_loss: 0.0023081996478140354
train_iter_loss: 0.005790166091173887
train_iter_loss: 0.003229044144973159
train_iter_loss: 0.011791998520493507
train_iter_loss: 0.013566939160227776
train_iter_loss: 0.013354917988181114
train loss :0.0122
---------------------
Validation seg loss: 0.059045189063290995 at epoch 82
epoch =     83/  1000, exp = train
train_iter_loss: 0.011598230339586735
train_iter_loss: 0.026785582304000854
train_iter_loss: 0.020486053079366684
train_iter_loss: 0.006241835653781891
train_iter_loss: 0.00843276921659708
train_iter_loss: 0.017768017947673798
train_iter_loss: 0.017280180007219315
train_iter_loss: 0.060754649341106415
train_iter_loss: 0.011883215047419071
train_iter_loss: 0.0194903202354908
train_iter_loss: 0.011237885802984238
train_iter_loss: 0.006488219369202852
train_iter_loss: 0.00343997566960752
train_iter_loss: 0.0027766029816120863
train_iter_loss: 0.018929345533251762
train_iter_loss: 0.006118787918239832
train_iter_loss: 0.009733468294143677
train_iter_loss: 0.01622909866273403
train_iter_loss: 0.013109852559864521
train_iter_loss: 0.016726749017834663
train_iter_loss: 0.005519981496036053
train_iter_loss: 0.0021999068558216095
train_iter_loss: 0.006754310801625252
train_iter_loss: 0.011447044089436531
train_iter_loss: 0.013648456893861294
train_iter_loss: 0.022076962515711784
train_iter_loss: 0.028414886444807053
train_iter_loss: 0.01734497770667076
train_iter_loss: 0.008329806849360466
train_iter_loss: 0.007599026430398226
train_iter_loss: 0.004275522660464048
train_iter_loss: 0.0061476826667785645
train_iter_loss: 0.019042974337935448
train_iter_loss: 0.009762476198375225
train_iter_loss: 0.0035191162023693323
train_iter_loss: 0.0016859779134392738
train_iter_loss: 0.014639491215348244
train_iter_loss: 0.0073697264306247234
train_iter_loss: 0.06373860687017441
train_iter_loss: 0.022557208314538002
train_iter_loss: 0.022991672158241272
train_iter_loss: 0.01718018390238285
train_iter_loss: 0.0232390183955431
train_iter_loss: 0.04665552079677582
train_iter_loss: 0.005181142129004002
train_iter_loss: 0.011089375242590904
train_iter_loss: 0.0033443444408476353
train_iter_loss: 0.005231346935033798
train_iter_loss: 0.011163284070789814
train_iter_loss: 0.025042720139026642
train loss :0.0153
---------------------
Validation seg loss: 0.05635567402639009 at epoch 83
epoch =     84/  1000, exp = train
train_iter_loss: 0.06491916626691818
train_iter_loss: 0.01641964539885521
train_iter_loss: 0.008217516355216503
train_iter_loss: 0.012576855719089508
train_iter_loss: 0.025648804381489754
train_iter_loss: 0.028627494350075722
train_iter_loss: 0.0730815902352333
train_iter_loss: 0.02714712731540203
train_iter_loss: 0.019267043098807335
train_iter_loss: 0.004381163511425257
train_iter_loss: 0.020545275881886482
train_iter_loss: 0.020227570086717606
train_iter_loss: 0.005093178246170282
train_iter_loss: 0.01235118880867958
train_iter_loss: 0.013004285283386707
train_iter_loss: 0.011963319033384323
train_iter_loss: 0.011503692716360092
train_iter_loss: 0.027271434664726257
train_iter_loss: 0.005500202067196369
train_iter_loss: 0.013250044547021389
train_iter_loss: 0.009455625899136066
train_iter_loss: 0.017962833866477013
train_iter_loss: 0.004988686181604862
train_iter_loss: 0.010503147728741169
train_iter_loss: 0.0576138012111187
train_iter_loss: 0.043342359364032745
train_iter_loss: 0.011360595934092999
train_iter_loss: 0.005036789458245039
train_iter_loss: 0.004879259504377842
train_iter_loss: 0.006931228097528219
train_iter_loss: 0.009518287144601345
train_iter_loss: 0.007223144639283419
train_iter_loss: 0.009908231906592846
train_iter_loss: 0.0033180497121065855
train_iter_loss: 0.0021642318461090326
train_iter_loss: 0.006347013637423515
train_iter_loss: 0.026863349601626396
train_iter_loss: 0.010228374972939491
train_iter_loss: 0.014460830949246883
train_iter_loss: 0.010713974945247173
train_iter_loss: 0.03747730329632759
train_iter_loss: 0.005890857893973589
train_iter_loss: 0.028996843844652176
train_iter_loss: 0.02303224615752697
train_iter_loss: 0.003750240197405219
train_iter_loss: 0.010509413667023182
train_iter_loss: 0.02678108774125576
train_iter_loss: 0.006003838498145342
train_iter_loss: 0.04173439368605614
train_iter_loss: 0.00980345532298088
train loss :0.0181
---------------------
Validation seg loss: 0.05639821718837341 at epoch 84
epoch =     85/  1000, exp = train
train_iter_loss: 0.027427634224295616
train_iter_loss: 0.01717206835746765
train_iter_loss: 0.031022431328892708
train_iter_loss: 0.001573041663505137
train_iter_loss: 0.007287028711289167
train_iter_loss: 0.013166884891688824
train_iter_loss: 0.03159650042653084
train_iter_loss: 0.015138380229473114
train_iter_loss: 0.024174563586711884
train_iter_loss: 0.03411034867167473
train_iter_loss: 0.024958621710538864
train_iter_loss: 0.011424055323004723
train_iter_loss: 0.013020357117056847
train_iter_loss: 0.0038059684447944164
train_iter_loss: 0.004412621725350618
train_iter_loss: 0.006949601694941521
train_iter_loss: 0.007737473584711552
train_iter_loss: 0.01867251843214035
train_iter_loss: 0.034472186118364334
train_iter_loss: 0.0417829267680645
train_iter_loss: 0.0028609377332031727
train_iter_loss: 0.011441458016633987
train_iter_loss: 0.02450018934905529
train_iter_loss: 0.0027469091583043337
train_iter_loss: 0.015475748106837273
train_iter_loss: 0.014053513295948505
train_iter_loss: 0.052288640290498734
train_iter_loss: 0.011433451436460018
train_iter_loss: 0.0019277886021882296
train_iter_loss: 0.01106460951268673
train_iter_loss: 0.00559271452948451
train_iter_loss: 0.005322771146893501
train_iter_loss: 0.010710903443396091
train_iter_loss: 0.015682877972722054
train_iter_loss: 0.0029965974390506744
train_iter_loss: 0.004986362997442484
train_iter_loss: 0.022731700912117958
train_iter_loss: 0.012211586348712444
train_iter_loss: 0.008449438028037548
train_iter_loss: 0.006484529934823513
train_iter_loss: 0.023601336404681206
train_iter_loss: 0.016155263409018517
train_iter_loss: 0.01003256905823946
train_iter_loss: 0.005637684371322393
train_iter_loss: 0.006892251782119274
train_iter_loss: 0.00314348959363997
train_iter_loss: 0.011653533205389977
train_iter_loss: 0.002806401578709483
train_iter_loss: 0.008651156909763813
train_iter_loss: 0.050130054354667664
train loss :0.0154
---------------------
Validation seg loss: 0.05461530311155036 at epoch 85
epoch =     86/  1000, exp = train
train_iter_loss: 0.016580313444137573
train_iter_loss: 0.03809742256999016
train_iter_loss: 0.018797824159264565
train_iter_loss: 0.00766123877838254
train_iter_loss: 0.01993793621659279
train_iter_loss: 0.041803184896707535
train_iter_loss: 0.011704751290380955
train_iter_loss: 0.040243275463581085
train_iter_loss: 0.016797982156276703
train_iter_loss: 0.01934751868247986
train_iter_loss: 0.012005132623016834
train_iter_loss: 0.005548628978431225
train_iter_loss: 0.0035515562631189823
train_iter_loss: 0.010209326632320881
train_iter_loss: 0.015107397921383381
train_iter_loss: 0.004950102884322405
train_iter_loss: 0.012891274876892567
train_iter_loss: 0.016706056892871857
train_iter_loss: 0.008581439033150673
train_iter_loss: 0.048418983817100525
train_iter_loss: 0.00276729348115623
train_iter_loss: 0.01295258104801178
train_iter_loss: 0.03220365196466446
train_iter_loss: 0.0038275665137916803
train_iter_loss: 0.022378752008080482
train_iter_loss: 0.01009144727140665
train_iter_loss: 0.02753189206123352
train_iter_loss: 0.012115716002881527
train_iter_loss: 0.0018228208646178246
train_iter_loss: 0.0036794417537748814
train_iter_loss: 0.002010335447266698
train_iter_loss: 0.0123354597017169
train_iter_loss: 0.007922455668449402
train_iter_loss: 0.007661633193492889
train_iter_loss: 0.00735624460503459
train_iter_loss: 0.0020621195435523987
train_iter_loss: 0.015614002011716366
train_iter_loss: 0.005999090615659952
train_iter_loss: 0.02099757269024849
train_iter_loss: 0.019649360328912735
train_iter_loss: 0.01244488824158907
train_iter_loss: 0.035801567137241364
train_iter_loss: 0.013997508212924004
train_iter_loss: 0.010965687222778797
train_iter_loss: 0.010007619857788086
train_iter_loss: 0.008191619999706745
train_iter_loss: 0.04054051637649536
train_iter_loss: 0.018153058364987373
train_iter_loss: 0.016798892989754677
train_iter_loss: 0.010226299054920673
train loss :0.0158
---------------------
Validation seg loss: 0.05082233213981007 at epoch 86
epoch =     87/  1000, exp = train
train_iter_loss: 0.0156764704734087
train_iter_loss: 0.025644224137067795
train_iter_loss: 0.0054937670938670635
train_iter_loss: 0.03826698288321495
train_iter_loss: 0.05761832743883133
train_iter_loss: 0.018949156627058983
train_iter_loss: 0.005672171711921692
train_iter_loss: 0.01574508287012577
train_iter_loss: 0.019419891759753227
train_iter_loss: 0.01962294429540634
train_iter_loss: 0.01013802457600832
train_iter_loss: 0.04321851208806038
train_iter_loss: 0.012869903817772865
train_iter_loss: 0.005769797600805759
train_iter_loss: 0.029595673084259033
train_iter_loss: 0.0023342452477663755
train_iter_loss: 0.009237715974450111
train_iter_loss: 0.011258882470428944
train_iter_loss: 0.019669722765684128
train_iter_loss: 0.022914161905646324
train_iter_loss: 0.007520930841565132
train_iter_loss: 0.007304776459932327
train_iter_loss: 0.024355938658118248
train_iter_loss: 0.00855975691229105
train_iter_loss: 0.016147466376423836
train_iter_loss: 0.02402016706764698
train_iter_loss: 0.00493102939799428
train_iter_loss: 0.09204699844121933
train_iter_loss: 0.003835023147985339
train_iter_loss: 0.004617547616362572
train_iter_loss: 0.019808350130915642
train_iter_loss: 0.013434655964374542
train_iter_loss: 0.0028290667105466127
train_iter_loss: 0.0010179613018408418
train_iter_loss: 0.008067877031862736
train_iter_loss: 0.002917290199548006
train_iter_loss: 0.05312332883477211
train_iter_loss: 0.008254102431237698
train_iter_loss: 0.004696191288530827
train_iter_loss: 0.014029926620423794
train_iter_loss: 0.012415207922458649
train_iter_loss: 0.014363810420036316
train_iter_loss: 0.023646583780646324
train_iter_loss: 0.008223448880016804
train_iter_loss: 0.009754007682204247
train_iter_loss: 0.003500098828226328
train_iter_loss: 0.014852763153612614
train_iter_loss: 0.0029345655348151922
train_iter_loss: 0.00795399397611618
train_iter_loss: 0.0179554745554924
train loss :0.0168
---------------------
Validation seg loss: nan at epoch 87
epoch =     88/  1000, exp = train
train_iter_loss: 0.011277932673692703
train_iter_loss: 0.02467978745698929
train_iter_loss: 0.01874135434627533
train_iter_loss: 0.008661321364343166
train_iter_loss: 0.034268297255039215
train_iter_loss: 0.042417123913764954
train_iter_loss: 0.0670672133564949
train_iter_loss: 0.012123492546379566
train_iter_loss: 0.03164300322532654
train_iter_loss: 0.015348426066339016
train_iter_loss: 0.01118980161845684
train_iter_loss: 0.005684760399162769
train_iter_loss: 0.012300043366849422
train_iter_loss: 0.013092339038848877
train_iter_loss: 0.008473867550492287
train_iter_loss: 0.007268836721777916
train_iter_loss: 0.03323596343398094
train_iter_loss: 0.007816294208168983
train_iter_loss: 0.012651436030864716
train_iter_loss: 0.02915937267243862
train_iter_loss: 0.017415817826986313
train_iter_loss: 0.0057629006914794445
train_iter_loss: 0.007080204784870148
train_iter_loss: 0.047705575823783875
train_iter_loss: 0.013671609573066235
train_iter_loss: 0.018205976113677025
train_iter_loss: 0.013293763622641563
train_iter_loss: 0.03441895171999931
train_iter_loss: 0.007922655902802944
train_iter_loss: 0.005322540644556284
train_iter_loss: 0.008670805022120476
train_iter_loss: 0.0030909187626093626
train_iter_loss: 0.01386395376175642
train_iter_loss: 0.005620550364255905
train_iter_loss: 0.004319778177887201
train_iter_loss: 0.005532195791602135
train_iter_loss: 0.005003347527235746
train_iter_loss: 0.0051816790364682674
train_iter_loss: 0.020818199962377548
train_iter_loss: 0.020222298800945282
train_iter_loss: 0.01447100006043911
train_iter_loss: 0.015270031057298183
train_iter_loss: 0.011743762530386448
train_iter_loss: 0.015431211329996586
train_iter_loss: 0.0027065412141382694
train_iter_loss: 0.014373560436069965
train_iter_loss: 0.008101135492324829
train_iter_loss: 0.012700486928224564
train_iter_loss: 0.039914801716804504
train_iter_loss: 0.035858411341905594
train loss :0.0172
---------------------
Validation seg loss: 0.05456777926993486 at epoch 88
epoch =     89/  1000, exp = train
train_iter_loss: 0.007297594100236893
train_iter_loss: 0.010712646879255772
train_iter_loss: 0.027040205895900726
train_iter_loss: 0.015988687053322792
train_iter_loss: 0.012047222815454006
train_iter_loss: 0.03430481627583504
train_iter_loss: 0.03407057002186775
train_iter_loss: 0.02604489028453827
train_iter_loss: 0.0101185142993927
train_iter_loss: 0.009054576978087425
train_iter_loss: 0.006424535531550646
train_iter_loss: 0.005435503087937832
train_iter_loss: 0.005170920863747597
train_iter_loss: 0.004641422536224127
train_iter_loss: 0.021748196333646774
train_iter_loss: 0.01306270994246006
train_iter_loss: 0.0071740783751010895
train_iter_loss: 0.02412719838321209
train_iter_loss: 0.01868836022913456
train_iter_loss: 0.010933440178632736
train_iter_loss: 0.021127929911017418
train_iter_loss: 0.009002899751067162
train_iter_loss: 0.006855235435068607
train_iter_loss: 0.010910763405263424
train_iter_loss: 0.016062285751104355
train_iter_loss: 0.011573148891329765
train_iter_loss: 0.015710892155766487
train_iter_loss: 0.006276649422943592
train_iter_loss: 0.002049302449449897
train_iter_loss: 0.007116069085896015
train_iter_loss: 0.013153919950127602
train_iter_loss: 0.004176139831542969
train_iter_loss: 0.008506644517183304
train_iter_loss: 0.0026788287796080112
train_iter_loss: 0.005132825113832951
train_iter_loss: 0.012320902198553085
train_iter_loss: 0.01356534007936716
train_iter_loss: 0.006299098953604698
train_iter_loss: 0.00797633919864893
train_iter_loss: 0.0108930179849267
train_iter_loss: 0.01994594931602478
train_iter_loss: 0.023242685943841934
train_iter_loss: 0.009671514853835106
train_iter_loss: 0.006542179733514786
train_iter_loss: 0.01290301326662302
train_iter_loss: 0.008586444891989231
train_iter_loss: 0.006144257728010416
train_iter_loss: 0.0028334453236311674
train_iter_loss: 0.02851281501352787
train_iter_loss: 0.02426934242248535
train loss :0.0131
---------------------
Validation seg loss: 0.0509338153119557 at epoch 89
epoch =     90/  1000, exp = train
train_iter_loss: 0.013140697963535786
train_iter_loss: 0.004277120344340801
train_iter_loss: 0.01561945490539074
train_iter_loss: 0.030959779396653175
train_iter_loss: 0.007231678813695908
train_iter_loss: 0.016376694664359093
train_iter_loss: 0.01974041759967804
train_iter_loss: 0.03320224955677986
train_iter_loss: 0.019387520849704742
train_iter_loss: 0.016443990170955658
train_iter_loss: 0.007021024823188782
train_iter_loss: 0.015529380179941654
train_iter_loss: 0.021585071459412575
train_iter_loss: 0.009122399613261223
train_iter_loss: 0.03523769602179527
train_iter_loss: 0.008397741243243217
train_iter_loss: 0.01499512605369091
train_iter_loss: 0.031061887741088867
train_iter_loss: 0.007023176643997431
train_iter_loss: 0.011415520682930946
train_iter_loss: 0.037452470511198044
train_iter_loss: 0.012008892372250557
train_iter_loss: 0.006589050870388746
train_iter_loss: 0.02105848863720894
train_iter_loss: 0.010651526041328907
train_iter_loss: 0.03747949004173279
train_iter_loss: 0.013850954361259937
train_iter_loss: 0.03547145426273346
train_iter_loss: 0.0048581077717244625
train_iter_loss: 0.010531632229685783
train_iter_loss: 0.006131259724497795
train_iter_loss: 0.0030078315176069736
train_iter_loss: 0.014012349769473076
train_iter_loss: 0.011591672897338867
train_iter_loss: 0.007673653308302164
train_iter_loss: 0.013647538609802723
train_iter_loss: 0.006598635111004114
train_iter_loss: 0.0039214761927723885
train_iter_loss: 0.005857826676219702
train_iter_loss: 0.013391776941716671
train_iter_loss: 0.03641773387789726
train_iter_loss: 0.0255559291690588
train_iter_loss: 0.022677257657051086
train_iter_loss: 0.011008668690919876
train_iter_loss: 0.01658325083553791
train_iter_loss: 0.0028345000464469194
train_iter_loss: 0.03383121266961098
train_iter_loss: 0.009828317910432816
train_iter_loss: 0.037957482039928436
train_iter_loss: 0.009146765805780888
train loss :0.0167
---------------------
Validation seg loss: 0.050195459311170164 at epoch 90
epoch =     91/  1000, exp = train
train_iter_loss: 0.015946030616760254
train_iter_loss: 0.008116227574646473
train_iter_loss: 0.023858150467276573
train_iter_loss: 0.023684319108724594
train_iter_loss: 0.027998728677630424
train_iter_loss: 0.018973255529999733
train_iter_loss: 0.008007536642253399
train_iter_loss: 0.04834068939089775
train_iter_loss: 0.02516077645123005
train_iter_loss: 0.015403012745082378
train_iter_loss: 0.01853138767182827
train_iter_loss: 0.036384325474500656
train_iter_loss: 0.003202575957402587
train_iter_loss: 0.004416762851178646
train_iter_loss: 0.02152899093925953
train_iter_loss: 0.007191813085228205
train_iter_loss: 0.010165234096348286
train_iter_loss: 0.020138852298259735
train_iter_loss: 0.014146898873150349
train_iter_loss: 0.009329922497272491
train_iter_loss: 0.00450210040435195
train_iter_loss: 0.005177890416234732
train_iter_loss: 0.002044226974248886
train_iter_loss: 0.0036038458347320557
train_iter_loss: 0.03556840121746063
train_iter_loss: 0.008899304084479809
train_iter_loss: 0.007951759733259678
train_iter_loss: 0.03596768155694008
train_iter_loss: 0.0029985150322318077
train_iter_loss: 0.007301016245037317
train_iter_loss: 0.003944528289139271
train_iter_loss: 0.004729161038994789
train_iter_loss: 0.024832110852003098
train_iter_loss: 0.0044995625503361225
train_iter_loss: 0.001421900698915124
train_iter_loss: 0.013027668930590153
train_iter_loss: 0.0038377726450562477
train_iter_loss: 0.02381976693868637
train_iter_loss: 0.02728589065372944
train_iter_loss: 0.028294047340750694
train_iter_loss: 0.013424260541796684
train_iter_loss: 0.02091088332235813
train_iter_loss: 0.014297348447144032
train_iter_loss: 0.020075762644410133
train_iter_loss: 0.003752472111955285
train_iter_loss: 0.003463279688730836
train_iter_loss: 0.01758022978901863
train_iter_loss: 0.002626873552799225
train_iter_loss: 0.013829277828335762
train_iter_loss: 0.022481948137283325
train loss :0.0152
---------------------
Validation seg loss: 0.049698810942195366 at epoch 91
epoch =     92/  1000, exp = train
train_iter_loss: 0.0035069393925368786
train_iter_loss: 0.014822275377810001
train_iter_loss: 0.006532005965709686
train_iter_loss: 0.029033975675702095
train_iter_loss: 0.022062787786126137
train_iter_loss: 0.012221081182360649
train_iter_loss: 0.00895259715616703
train_iter_loss: 0.016250096261501312
train_iter_loss: 0.020742671564221382
train_iter_loss: 0.010696747340261936
train_iter_loss: 0.008098467253148556
train_iter_loss: 0.022224489599466324
train_iter_loss: 0.028078123927116394
train_iter_loss: 0.0029134785290807486
train_iter_loss: 0.001573370536789298
train_iter_loss: 0.012210623361170292
train_iter_loss: 0.010569651611149311
train_iter_loss: 0.014683921821415424
train_iter_loss: 0.014038139022886753
train_iter_loss: 0.016691790893673897
train_iter_loss: 0.011464561335742474
train_iter_loss: 0.004641242325305939
train_iter_loss: 0.04945654422044754
train_iter_loss: 0.03372451290488243
train_iter_loss: 0.00791216641664505
train_iter_loss: 0.054568812251091
train_iter_loss: 0.02082456834614277
train_iter_loss: 0.023931730538606644
train_iter_loss: 0.004315824247896671
train_iter_loss: 0.01066652499139309
train_iter_loss: 0.007078665774315596
train_iter_loss: 0.009191597811877728
train_iter_loss: 0.0023922063410282135
train_iter_loss: 0.010956970043480396
train_iter_loss: 0.004029017873108387
train_iter_loss: 0.009312025271356106
train_iter_loss: 0.010833372361958027
train_iter_loss: 0.023218922317028046
train_iter_loss: 0.015605870634317398
train_iter_loss: 0.020379304885864258
train_iter_loss: 0.027251577004790306
train_iter_loss: 0.005025411956012249
train_iter_loss: 0.008159500546753407
train_iter_loss: 0.00897871982306242
train_iter_loss: 0.0031647158320993185
train_iter_loss: 0.004426199477165937
train_iter_loss: 0.0018144251080229878
train_iter_loss: 0.005749779287725687
train_iter_loss: 0.06225963309407234
train_iter_loss: 0.023492740467190742
train loss :0.0155
---------------------
Validation seg loss: 0.05024989337683985 at epoch 92
epoch =     93/  1000, exp = train
train_iter_loss: 0.016701653599739075
train_iter_loss: 0.027766458690166473
train_iter_loss: 0.028853336349129677
train_iter_loss: 0.020496752113103867
train_iter_loss: 0.015025479719042778
train_iter_loss: 0.013158116489648819
train_iter_loss: 0.0589122399687767
train_iter_loss: 0.023488324135541916
train_iter_loss: 0.037533074617385864
train_iter_loss: 0.01565433107316494
train_iter_loss: 0.1251109093427658
train_iter_loss: 0.00886442605406046
train_iter_loss: 0.006379992701113224
train_iter_loss: 0.01781025342643261
train_iter_loss: 0.02132974937558174
train_iter_loss: 0.009001304395496845
train_iter_loss: 0.004449697211384773
train_iter_loss: 0.003096445696428418
train_iter_loss: 0.011484743095934391
train_iter_loss: 0.010012299753725529
train_iter_loss: 0.007200588006526232
train_iter_loss: 0.004260271787643433
train_iter_loss: 0.0025684060528874397
train_iter_loss: 0.008267667144536972
train_iter_loss: 0.0191678274422884
train_iter_loss: 0.027758538722991943
train_iter_loss: 0.039783116430044174
train_iter_loss: 0.008801473304629326
train_iter_loss: 0.007399588357657194
train_iter_loss: 0.009943225421011448
train_iter_loss: 0.00772880157455802
train_iter_loss: 0.006685030180960894
train_iter_loss: 0.02109055407345295
train_iter_loss: 0.0057921758852899075
train_iter_loss: 0.007790380157530308
train_iter_loss: 0.010247143916785717
train_iter_loss: 0.02546171471476555
train_iter_loss: 0.016374869272112846
train_iter_loss: 0.011383907869458199
train_iter_loss: 0.03571290522813797
train_iter_loss: 0.005435251165181398
train_iter_loss: 0.014862011186778545
train_iter_loss: 0.004100587218999863
train_iter_loss: 0.010736058466136456
train_iter_loss: 0.0021376663353294134
train_iter_loss: 0.01807858794927597
train_iter_loss: 0.006038193590939045
train_iter_loss: 0.0032650460489094257
train_iter_loss: 0.028726210817694664
train_iter_loss: 0.02249353937804699
train loss :0.0178
---------------------
Validation seg loss: 0.05577698643009051 at epoch 93
epoch =     94/  1000, exp = train
train_iter_loss: 0.02602100372314453
train_iter_loss: 0.007110945414751768
train_iter_loss: 0.011424930766224861
train_iter_loss: 0.029203834012150764
train_iter_loss: 0.015337205491960049
train_iter_loss: 0.07268395274877548
train_iter_loss: 0.00806909054517746
train_iter_loss: 0.02559075690805912
train_iter_loss: 0.01159761380404234
train_iter_loss: 0.011000489816069603
train_iter_loss: 0.011153727769851685
train_iter_loss: 0.007791492156684399
train_iter_loss: 0.006998810917139053
train_iter_loss: 0.007453230209648609
train_iter_loss: 0.0046916380524635315
train_iter_loss: 0.004174954257905483
train_iter_loss: 0.01618228293955326
train_iter_loss: 0.014826005324721336
train_iter_loss: 0.026066135615110397
train_iter_loss: 0.02032497338950634
train_iter_loss: 0.009348912164568901
train_iter_loss: 0.0017570232739672065
train_iter_loss: 0.009517776779830456
train_iter_loss: 0.011213058605790138
train_iter_loss: 0.0527598038315773
train_iter_loss: 0.01271610613912344
train_iter_loss: 0.009343123063445091
train_iter_loss: 0.017990630120038986
train_iter_loss: 0.005585578735917807
train_iter_loss: 0.006744536571204662
train_iter_loss: 0.0029213186353445053
train_iter_loss: 0.004457796923816204
train_iter_loss: 0.017371905967593193
train_iter_loss: 0.002555087674409151
train_iter_loss: 0.008190024644136429
train_iter_loss: 0.0018072181846946478
train_iter_loss: 0.027588997036218643
train_iter_loss: 0.013768787495791912
train_iter_loss: 0.029939331114292145
train_iter_loss: 0.008288748562335968
train_iter_loss: 0.009026371873915195
train_iter_loss: 0.009934842586517334
train_iter_loss: 0.0346623994410038
train_iter_loss: 0.018221130594611168
train_iter_loss: 0.0040277959778904915
train_iter_loss: 0.0022331825457513332
train_iter_loss: 0.009353350847959518
train_iter_loss: 0.028902046382427216
train_iter_loss: 0.01145766768604517
train_iter_loss: 0.013314185664057732
train loss :0.0150
---------------------
Validation seg loss: nan at epoch 94
epoch =     95/  1000, exp = train
train_iter_loss: 0.01953255943953991
train_iter_loss: 0.01541807409375906
train_iter_loss: 0.007380330935120583
train_iter_loss: 0.01106295082718134
train_iter_loss: 0.011456559412181377
train_iter_loss: 0.025982901453971863
train_iter_loss: 0.02756255306303501
train_iter_loss: 0.01801159232854843
train_iter_loss: 0.010319792665541172
train_iter_loss: 0.03902679309248924
train_iter_loss: 0.02655843272805214
train_iter_loss: 0.012483554892241955
train_iter_loss: 0.004852329380810261
train_iter_loss: 0.009332421235740185
train_iter_loss: 0.0044438946060836315
train_iter_loss: 0.0036434598732739687
train_iter_loss: 0.0032270136289298534
train_iter_loss: 0.015384663827717304
train_iter_loss: 0.0045634545385837555
train_iter_loss: 0.010527157224714756
train_iter_loss: 0.003379153786227107
train_iter_loss: 0.015453467145562172
train_iter_loss: 0.003018016694113612
train_iter_loss: 0.004521968308836222
train_iter_loss: 0.046058010309934616
train_iter_loss: 0.010037782602012157
train_iter_loss: 0.00952906720340252
train_iter_loss: 0.012335825711488724
train_iter_loss: 0.014292309992015362
train_iter_loss: 0.012201203964650631
train_iter_loss: 0.01628103107213974
train_iter_loss: 0.0019775431137531996
train_iter_loss: 0.008597454987466335
train_iter_loss: 0.0020613691303879023
train_iter_loss: 0.0035492172464728355
train_iter_loss: 0.009185018949210644
train_iter_loss: 0.010179438628256321
train_iter_loss: 0.006064478307962418
train_iter_loss: 0.013094739988446236
train_iter_loss: 0.010438895784318447
train_iter_loss: 0.019103439524769783
train_iter_loss: 0.0073189749382436275
train_iter_loss: 0.02033345215022564
train_iter_loss: 0.008551139384508133
train_iter_loss: 0.0015744187403470278
train_iter_loss: 0.012578765861690044
train_iter_loss: 0.00135261588729918
train_iter_loss: 0.002545389346778393
train_iter_loss: 0.033351216465234756
train_iter_loss: 0.03178635239601135
train loss :0.0129
---------------------
Validation seg loss: 0.051454901679052166 at epoch 95
epoch =     96/  1000, exp = train
train_iter_loss: 0.012990114279091358
train_iter_loss: 0.00517862755805254
train_iter_loss: 0.019445648416876793
train_iter_loss: 0.013427562080323696
train_iter_loss: 0.04677748307585716
train_iter_loss: 0.013907335698604584
train_iter_loss: 0.022114219143986702
train_iter_loss: 0.013094672001898289
train_iter_loss: 0.02056185156106949
train_iter_loss: 0.03089512139558792
train_iter_loss: 0.02321610040962696
train_iter_loss: 0.01735992170870304
train_iter_loss: 0.005240133963525295
train_iter_loss: 0.020791171118617058
train_iter_loss: 0.004875927232205868
train_iter_loss: 0.012036485597491264
train_iter_loss: 0.02249140851199627
train_iter_loss: 0.009871890768408775
train_iter_loss: 0.009745482355356216
train_iter_loss: 0.013468582183122635
train_iter_loss: 0.03150254860520363
train_iter_loss: 0.008733540773391724
train_iter_loss: 0.010330396704375744
train_iter_loss: 0.005304967053234577
train_iter_loss: 0.019409213215112686
train_iter_loss: 0.01008681207895279
train_iter_loss: 0.00422528525814414
train_iter_loss: 0.03198796510696411
train_iter_loss: 0.00793328508734703
train_iter_loss: 0.01596330851316452
train_iter_loss: 0.010059505701065063
train_iter_loss: 0.002282343339174986
train_iter_loss: 0.009045540355145931
train_iter_loss: 0.0019315705867484212
train_iter_loss: 0.005155839491635561
train_iter_loss: 0.0047966474667191505
train_iter_loss: 0.016849033534526825
train_iter_loss: 0.02287318930029869
train_iter_loss: 0.014645655639469624
train_iter_loss: 0.01060548797249794
train_iter_loss: 0.025210440158843994
train_iter_loss: 0.02405676804482937
train_iter_loss: 0.010356158018112183
train_iter_loss: 0.005937631241977215
train_iter_loss: 0.009039991535246372
train_iter_loss: 0.003912295214831829
train_iter_loss: 0.012162726372480392
train_iter_loss: 0.012917222455143929
train_iter_loss: 0.019922440871596336
train_iter_loss: 0.011731656268239021
train loss :0.0146
---------------------
Validation seg loss: 0.050985736914779686 at epoch 96
epoch =     97/  1000, exp = train
train_iter_loss: 0.013218133710324764
train_iter_loss: 0.014285823330283165
train_iter_loss: 0.008515330962836742
train_iter_loss: 0.009527035988867283
train_iter_loss: 0.02650083787739277
train_iter_loss: 0.02635236270725727
train_iter_loss: 0.02363169752061367
train_iter_loss: 0.01444424968212843
train_iter_loss: 0.018449589610099792
train_iter_loss: 0.026069408282637596
train_iter_loss: 0.010633246041834354
train_iter_loss: 0.0035708611831068993
train_iter_loss: 0.010277132503688335
train_iter_loss: 0.011340911500155926
train_iter_loss: 0.016787191852927208
train_iter_loss: 0.009050635620951653
train_iter_loss: 0.006425878964364529
train_iter_loss: 0.02282201685011387
train_iter_loss: 0.014721967279911041
train_iter_loss: 0.027237262576818466
train_iter_loss: 0.008309906348586082
train_iter_loss: 0.008944946341216564
train_iter_loss: 0.007339577656239271
train_iter_loss: 0.003865587990731001
train_iter_loss: 0.005853889510035515
train_iter_loss: 0.06092396751046181
train_iter_loss: 0.02041442133486271
train_iter_loss: 0.012541386298835278
train_iter_loss: 0.002958822064101696
train_iter_loss: 0.012189915403723717
train_iter_loss: 0.012876703403890133
train_iter_loss: 0.005536033771932125
train_iter_loss: 0.0022576495539397
train_iter_loss: 0.002336160046979785
train_iter_loss: 0.00968383252620697
train_iter_loss: 0.007872441783547401
train_iter_loss: 0.017755739390850067
train_iter_loss: 0.010728251188993454
train_iter_loss: 0.011048370972275734
train_iter_loss: 0.013759678229689598
train_iter_loss: 0.021114161238074303
train_iter_loss: 0.00912453979253769
train_iter_loss: 0.011840982362627983
train_iter_loss: 0.015437536872923374
train_iter_loss: 0.009749984368681908
train_iter_loss: 0.003997967578470707
train_iter_loss: 0.0018148114904761314
train_iter_loss: 0.0037423560861498117
train_iter_loss: 0.02445220947265625
train_iter_loss: 0.034599419683218
train loss :0.0140
---------------------
Validation seg loss: 0.051931517948105466 at epoch 97
epoch =     98/  1000, exp = train
train_iter_loss: 0.01210184395313263
train_iter_loss: 0.007870197296142578
train_iter_loss: 0.023978466168045998
train_iter_loss: 0.011619454249739647
train_iter_loss: 0.018463194370269775
train_iter_loss: 0.023223377764225006
train_iter_loss: 0.01858074963092804
train_iter_loss: 0.031328070908784866
train_iter_loss: 0.010814512148499489
train_iter_loss: 0.017523735761642456
train_iter_loss: 0.016413284465670586
train_iter_loss: 0.0067166052758693695
train_iter_loss: 0.006891094148159027
train_iter_loss: 0.002616075100377202
train_iter_loss: 0.00965513102710247
train_iter_loss: 0.010332902893424034
train_iter_loss: 0.010289712809026241
train_iter_loss: 0.005623155273497105
train_iter_loss: 0.024538086727261543
train_iter_loss: 0.008111557923257351
train_iter_loss: 0.0029413418378680944
train_iter_loss: 0.006158678326755762
train_iter_loss: 0.032332390546798706
train_iter_loss: 0.007223860360682011
train_iter_loss: 0.09158527851104736
train_iter_loss: 0.01046396791934967
train_iter_loss: 0.006776223424822092
train_iter_loss: 0.026509277522563934
train_iter_loss: 0.007622880395501852
train_iter_loss: 0.0031577134504914284
train_iter_loss: 0.01364835910499096
train_iter_loss: 0.010037156753242016
train_iter_loss: 0.002518497873097658
train_iter_loss: 0.005474545527249575
train_iter_loss: 0.007873238995671272
train_iter_loss: 0.0021267912816256285
train_iter_loss: 0.01162263099104166
train_iter_loss: 0.019398832693696022
train_iter_loss: 0.010250935330986977
train_iter_loss: 0.010296517983078957
train_iter_loss: 0.007092328742146492
train_iter_loss: 0.016174383461475372
train_iter_loss: 0.0166828203946352
train_iter_loss: 0.04515258967876434
train_iter_loss: 0.011310177855193615
train_iter_loss: 0.010956008918583393
train_iter_loss: 0.0035617726389318705
train_iter_loss: 0.0071616400964558125
train_iter_loss: 0.013112237676978111
train_iter_loss: 0.017448168247938156
train loss :0.0145
---------------------
Validation seg loss: 0.050592834747424965 at epoch 98
epoch =     99/  1000, exp = train
train_iter_loss: 0.005806450266391039
train_iter_loss: 0.022844763472676277
train_iter_loss: 0.038647402077913284
train_iter_loss: 0.013609819114208221
train_iter_loss: 0.01452388521283865
train_iter_loss: 0.023646386340260506
train_iter_loss: 0.019992617890238762
train_iter_loss: 0.02751350961625576
train_iter_loss: 0.012501015327870846
train_iter_loss: 0.012845076620578766
train_iter_loss: 0.017639482393860817
train_iter_loss: 0.019757654517889023
train_iter_loss: 0.003010121174156666
train_iter_loss: 0.004482635296881199
train_iter_loss: 0.0034993430599570274
train_iter_loss: 0.03900838643312454
train_iter_loss: 0.02417764998972416
train_iter_loss: 0.005799311678856611
train_iter_loss: 0.01122627966105938
train_iter_loss: 0.03337414190173149
train_iter_loss: 0.00602360675111413
train_iter_loss: 0.004334823228418827
train_iter_loss: 0.044142186641693115
train_iter_loss: 0.01344352401793003
train_iter_loss: 0.06158681586384773
train_iter_loss: 0.027684921398758888
train_iter_loss: 0.010137044824659824
train_iter_loss: 0.008928460069000721
train_iter_loss: 0.0034177645575255156
train_iter_loss: 0.004418640397489071
train_iter_loss: 0.008234193548560143
train_iter_loss: 0.004971555899828672
train_iter_loss: 0.006290771532803774
train_iter_loss: 0.007828682661056519
train_iter_loss: 0.0040041133761405945
train_iter_loss: 0.020774543285369873
train_iter_loss: 0.011696192435920238
train_iter_loss: 0.012178038246929646
train_iter_loss: 0.02258680947124958
train_iter_loss: 0.026353051885962486
train_iter_loss: 0.0038189745973795652
train_iter_loss: 0.017020074650645256
train_iter_loss: 0.023957766592502594
train_iter_loss: 0.020031919702887535
train_iter_loss: 0.0038498216308653355
train_iter_loss: 0.011557303369045258
train_iter_loss: 0.005524004809558392
train_iter_loss: 0.0013939577620476484
train_iter_loss: 0.030831240117549896
train_iter_loss: 0.0060380068607628345
train loss :0.0160
---------------------
Validation seg loss: 0.05582312207466117 at epoch 99
epoch =    100/  1000, exp = train
train_iter_loss: 0.01101916003972292
train_iter_loss: 0.02485564351081848
train_iter_loss: 0.007799994200468063
train_iter_loss: 0.005986630450934172
train_iter_loss: 0.013876896351575851
train_iter_loss: 0.03649742156267166
train_iter_loss: 0.025277314707636833
train_iter_loss: 0.009100671857595444
train_iter_loss: 0.04113588482141495
train_iter_loss: 0.017002949491143227
train_iter_loss: 0.019871290773153305
train_iter_loss: 0.020249713212251663
train_iter_loss: 0.0029736266005784273
train_iter_loss: 0.014610670506954193
train_iter_loss: 0.014706204645335674
train_iter_loss: 0.013450946658849716
train_iter_loss: 0.012314306572079659
train_iter_loss: 0.02661227062344551
train_iter_loss: 0.024942317977547646
train_iter_loss: 0.006107981316745281
train_iter_loss: 0.006538036745041609
train_iter_loss: 0.025643296539783478
train_iter_loss: 0.004235489293932915
train_iter_loss: 0.012223237194120884
train_iter_loss: 0.02174225077033043
train_iter_loss: 0.013653095811605453
train_iter_loss: 0.03269089758396149
train_iter_loss: 0.006968403700739145
train_iter_loss: 0.0039016634691506624
train_iter_loss: 0.01495770737528801
train_iter_loss: 0.0032795476727187634
train_iter_loss: 0.018758663907647133
train_iter_loss: 0.002129222499206662
train_iter_loss: 0.003874776652082801
train_iter_loss: 0.005417570937424898
train_iter_loss: 0.007983210496604443
train_iter_loss: 0.013658479787409306
train_iter_loss: 0.010065190494060516
train_iter_loss: 0.03306379169225693
train_iter_loss: 0.005583972204476595
train_iter_loss: 0.014094987884163857
train_iter_loss: 0.006264692172408104
train_iter_loss: 0.011711790226399899
train_iter_loss: 0.021132808178663254
train_iter_loss: 0.005908788647502661
train_iter_loss: 0.008158225566148758
train_iter_loss: 0.005091503728181124
train_iter_loss: 0.007467171642929316
train_iter_loss: 0.006150171160697937
train_iter_loss: 0.012036196887493134
train loss :0.0142
---------------------
Validation seg loss: 0.05075110882988259 at epoch 100
epoch =    101/  1000, exp = train
train_iter_loss: 0.017955902963876724
train_iter_loss: 0.00644854037091136
train_iter_loss: 0.005600597243756056
train_iter_loss: 0.01187252625823021
train_iter_loss: 0.12574051320552826
train_iter_loss: 0.020841658115386963
train_iter_loss: 0.07878516614437103
train_iter_loss: 0.012794474139809608
train_iter_loss: 0.030623681843280792
train_iter_loss: 0.010322296060621738
train_iter_loss: 0.024336449801921844
train_iter_loss: 0.009221475571393967
train_iter_loss: 0.00571463443338871
train_iter_loss: 0.00748489098623395
train_iter_loss: 0.006025465205311775
train_iter_loss: 0.021240966394543648
train_iter_loss: 0.013655897229909897
train_iter_loss: 0.007770638447254896
train_iter_loss: 0.020570561289787292
train_iter_loss: 0.009258083067834377
train_iter_loss: 0.013630799017846584
train_iter_loss: 0.021930327638983727
train_iter_loss: 0.024726232513785362
train_iter_loss: 0.0018071940867230296
train_iter_loss: 0.004945453256368637
train_iter_loss: 0.03823021054267883
train_iter_loss: 0.014003890566527843
train_iter_loss: 0.03350161761045456
train_iter_loss: 0.004675436299294233
train_iter_loss: 0.006045859307050705
train_iter_loss: 0.012518255971372128
train_iter_loss: 0.003959154710173607
train_iter_loss: 0.005059950519353151
train_iter_loss: 0.015167978592216969
train_iter_loss: 0.008684942498803139
train_iter_loss: 0.006013551261276007
train_iter_loss: 0.028316080570220947
train_iter_loss: 0.013695993460714817
train_iter_loss: 0.0158295426517725
train_iter_loss: 0.010387284681200981
train_iter_loss: 0.007142691407352686
train_iter_loss: 0.019002443179488182
train_iter_loss: 0.0047172661870718
train_iter_loss: 0.010647548362612724
train_iter_loss: 0.0033263436052948236
train_iter_loss: 0.013346013613045216
train_iter_loss: 0.01082763820886612
train_iter_loss: 0.005676347762346268
train_iter_loss: 0.0378488190472126
train_iter_loss: 0.021321283653378487
train loss :0.0175
---------------------
Validation seg loss: 0.050332262715528486 at epoch 101
epoch =    102/  1000, exp = train
train_iter_loss: 0.01917196251451969
train_iter_loss: 0.015113042667508125
train_iter_loss: 0.01070273108780384
train_iter_loss: 0.042541928589344025
train_iter_loss: 0.03168118745088577
train_iter_loss: 0.034170493483543396
train_iter_loss: 0.03521241992712021
train_iter_loss: 0.027472328394651413
train_iter_loss: 0.013517717830836773
train_iter_loss: 0.007747180759906769
train_iter_loss: 0.014099542051553726
train_iter_loss: 0.026775473728775978
train_iter_loss: 0.007272187154740095
train_iter_loss: 0.006283642258495092
train_iter_loss: 0.0046685123816132545
train_iter_loss: 0.02015516348183155
train_iter_loss: 0.034422602504491806
train_iter_loss: 0.017899850383400917
train_iter_loss: 0.008061015978455544
train_iter_loss: 0.007817049510776997
train_iter_loss: 0.00658456003293395
train_iter_loss: 0.002018967643380165
train_iter_loss: 0.004263399634510279
train_iter_loss: 0.017040057107806206
train_iter_loss: 0.021711833775043488
train_iter_loss: 0.017688652500510216
train_iter_loss: 0.007758354768157005
train_iter_loss: 0.09185079485177994
train_iter_loss: 0.0065249367617070675
train_iter_loss: 0.019862843677401543
train_iter_loss: 0.009050576016306877
train_iter_loss: 0.0026126925367861986
train_iter_loss: 0.006892789620906115
train_iter_loss: 0.0022300323471426964
train_iter_loss: 0.0035909635480493307
train_iter_loss: 0.011621391400694847
train_iter_loss: 0.012684168294072151
train_iter_loss: 0.03322329744696617
train_iter_loss: 0.008864417672157288
train_iter_loss: 0.02162829041481018
train_iter_loss: 0.008273915387690067
train_iter_loss: 0.006894290912896395
train_iter_loss: 0.008487173356115818
train_iter_loss: 0.008724365383386612
train_iter_loss: 0.017094695940613747
train_iter_loss: 0.0024052311200648546
train_iter_loss: 0.006782690994441509
train_iter_loss: 0.010531372390687466
train_iter_loss: 0.011704361997544765
train_iter_loss: 0.01317672897130251
train loss :0.0161
---------------------
Validation seg loss: 0.05629766424997042 at epoch 102
epoch =    103/  1000, exp = train
train_iter_loss: 0.04595581069588661
train_iter_loss: 0.005747154820710421
train_iter_loss: 0.011297949589788914
train_iter_loss: 0.012590274214744568
train_iter_loss: 0.016791386529803276
train_iter_loss: 0.02981746383011341
train_iter_loss: 0.038280799984931946
train_iter_loss: 0.008301389403641224
train_iter_loss: 0.026698065921664238
train_iter_loss: 0.012908984906971455
train_iter_loss: 0.01647958904504776
train_iter_loss: 0.01754463091492653
train_iter_loss: 0.01329230796545744
train_iter_loss: 0.007664516102522612
train_iter_loss: 0.020084569230675697
train_iter_loss: 0.0038561723195016384
train_iter_loss: 0.005633845925331116
train_iter_loss: 0.013989570550620556
train_iter_loss: 0.02727768011391163
train_iter_loss: 0.013458157889544964
train_iter_loss: 0.004387036897242069
train_iter_loss: 0.0061398218385875225
train_iter_loss: 0.003021216718479991
train_iter_loss: 0.02572884038090706
train_iter_loss: 0.007327702362090349
train_iter_loss: 0.0036765357945114374
train_iter_loss: 0.023617619648575783
train_iter_loss: 0.01659270189702511
train_iter_loss: 0.0039322711527347565
train_iter_loss: 0.0014002354582771659
train_iter_loss: 0.0023216072004288435
train_iter_loss: 0.003720069071277976
train_iter_loss: 0.005797326564788818
train_iter_loss: 0.007556546945124865
train_iter_loss: 0.006580809596925974
train_iter_loss: 0.007769211661070585
train_iter_loss: 0.01574263907968998
train_iter_loss: 0.010012912563979626
train_iter_loss: 0.0054643782787024975
train_iter_loss: 0.029156146571040154
train_iter_loss: 0.01823974959552288
train_iter_loss: 0.015038265846669674
train_iter_loss: 0.0325816385447979
train_iter_loss: 0.01973196677863598
train_iter_loss: 0.003865271108224988
train_iter_loss: 0.02562178485095501
train_iter_loss: 0.004158795345574617
train_iter_loss: 0.006392645183950663
train_iter_loss: 0.03866950049996376
train_iter_loss: 0.01818016730248928
train loss :0.0147
---------------------
Validation seg loss: 0.0514039286218868 at epoch 103
epoch =    104/  1000, exp = train
train_iter_loss: 0.011234438978135586
train_iter_loss: 0.005885528400540352
train_iter_loss: 0.011463024653494358
train_iter_loss: 0.02944471314549446
train_iter_loss: 0.01903323456645012
train_iter_loss: 0.0202003363519907
train_iter_loss: 0.04809410870075226
train_iter_loss: 0.01685970649123192
train_iter_loss: 0.009575231932103634
train_iter_loss: 0.01917511411011219
train_iter_loss: 0.006268272642046213
train_iter_loss: 0.01048872247338295
train_iter_loss: 0.014978709630668163
train_iter_loss: 0.026184337213635445
train_iter_loss: 0.008441710844635963
train_iter_loss: 0.009262727573513985
train_iter_loss: 0.009424467571079731
train_iter_loss: 0.03009159117937088
train_iter_loss: 0.00860318262130022
train_iter_loss: 0.007982118986546993
train_iter_loss: 0.0019385823979973793
train_iter_loss: 0.010167740285396576
train_iter_loss: 0.004298370331525803
train_iter_loss: 0.010606048628687859
train_iter_loss: 0.00794894341379404
train_iter_loss: 0.017731405794620514
train_iter_loss: 0.01646954007446766
train_iter_loss: 0.02328009344637394
train_iter_loss: 0.006926647387444973
train_iter_loss: 0.01003781333565712
train_iter_loss: 0.013808061368763447
train_iter_loss: 0.01037533488124609
train_iter_loss: 0.012167409993708134
train_iter_loss: 0.008400341495871544
train_iter_loss: 0.0029521258547902107
train_iter_loss: 0.004025047644972801
train_iter_loss: 0.03262966498732567
train_iter_loss: 0.012277895584702492
train_iter_loss: 0.008305300027132034
train_iter_loss: 0.017240799963474274
train_iter_loss: 0.005518170073628426
train_iter_loss: 0.03161787986755371
train_iter_loss: 0.006912106182426214
train_iter_loss: 0.009634522721171379
train_iter_loss: 0.023945849388837814
train_iter_loss: 0.00984949991106987
train_iter_loss: 0.010849972255527973
train_iter_loss: 0.004154140129685402
train_iter_loss: 0.012576458044350147
train_iter_loss: 0.012322396971285343
train loss :0.0139
---------------------
Validation seg loss: 0.05085167172509037 at epoch 104
epoch =    105/  1000, exp = train
train_iter_loss: 0.023870155215263367
train_iter_loss: 0.014289051294326782
train_iter_loss: 0.009565497748553753
train_iter_loss: 0.004983946215361357
train_iter_loss: 0.011521455831825733
train_iter_loss: 0.03949049115180969
train_iter_loss: 0.028730088844895363
train_iter_loss: 0.031949661672115326
train_iter_loss: 0.011051135137677193
train_iter_loss: 0.007385562639683485
train_iter_loss: 0.003639647038653493
train_iter_loss: 0.014648405835032463
train_iter_loss: 0.009300472214818
train_iter_loss: 0.0033463353756815195
train_iter_loss: 0.003410270204767585
train_iter_loss: 0.005685486365109682
train_iter_loss: 0.018524369224905968
train_iter_loss: 0.02998146042227745
train_iter_loss: 0.009195839986205101
train_iter_loss: 0.00721756974235177
train_iter_loss: 0.0021222832147032022
train_iter_loss: 0.009476465173065662
train_iter_loss: 0.0039056772366166115
train_iter_loss: 0.05241146683692932
train_iter_loss: 0.07122528553009033
train_iter_loss: 0.02688639797270298
train_iter_loss: 0.011330649256706238
train_iter_loss: 0.05320177227258682
train_iter_loss: 0.002142711076885462
train_iter_loss: 0.0035689305514097214
train_iter_loss: 0.003705758834257722
train_iter_loss: 0.0018520747544243932
train_iter_loss: 0.0022776026744395494
train_iter_loss: 0.006022063083946705
train_iter_loss: 0.005268390290439129
train_iter_loss: 0.015063413418829441
train_iter_loss: 0.007058495189994574
train_iter_loss: 0.007817503996193409
train_iter_loss: 0.02814645506441593
train_iter_loss: 0.006364334374666214
train_iter_loss: 0.010636616498231888
train_iter_loss: 0.02125329151749611
train_iter_loss: 0.0366673618555069
train_iter_loss: 0.013569492846727371
train_iter_loss: 0.008036619052290916
train_iter_loss: 0.01580848917365074
train_iter_loss: 0.005153891164809465
train_iter_loss: 0.0050703492015600204
train_iter_loss: 0.012434585951268673
train_iter_loss: 0.009833313524723053
train loss :0.0152
---------------------
Validation seg loss: 0.05966722711069314 at epoch 105
epoch =    106/  1000, exp = train
train_iter_loss: 0.03101738914847374
train_iter_loss: 0.018397094681859016
train_iter_loss: 0.025144118815660477
train_iter_loss: 0.010245456360280514
train_iter_loss: 0.04023095220327377
train_iter_loss: 0.01357593946158886
train_iter_loss: 0.023710260167717934
train_iter_loss: 0.015115818940103054
train_iter_loss: 0.007539760787039995
train_iter_loss: 0.009703910909593105
train_iter_loss: 0.020545566454529762
train_iter_loss: 0.04794013127684593
train_iter_loss: 0.008384075947105885
train_iter_loss: 0.004829108715057373
train_iter_loss: 0.004727466031908989
train_iter_loss: 0.006012597121298313
train_iter_loss: 0.009389752522110939
train_iter_loss: 0.02435101754963398
train_iter_loss: 0.009676234796643257
train_iter_loss: 0.012798056937754154
train_iter_loss: 0.010998251847922802
train_iter_loss: 0.005892463028430939
train_iter_loss: 0.002541913650929928
train_iter_loss: 0.011152200400829315
train_iter_loss: 0.007394172251224518
train_iter_loss: 0.008823869749903679
train_iter_loss: 0.017710821703076363
train_iter_loss: 0.015713069587945938
train_iter_loss: 0.004709846340119839
train_iter_loss: 0.0060181692242622375
train_iter_loss: 0.0017701300093904138
train_iter_loss: 0.0044693248346447945
train_iter_loss: 0.013895193114876747
train_iter_loss: 0.0027637125458568335
train_iter_loss: 0.006309660151600838
train_iter_loss: 0.0030273571610450745
train_iter_loss: 0.005403648596256971
train_iter_loss: 0.010191875509917736
train_iter_loss: 0.009020255878567696
train_iter_loss: 0.026938408613204956
train_iter_loss: 0.046533748507499695
train_iter_loss: 0.034492477774620056
train_iter_loss: 0.037950508296489716
train_iter_loss: 0.017927225679159164
train_iter_loss: 0.004736907780170441
train_iter_loss: 0.02939145639538765
train_iter_loss: 0.006050604861229658
train_iter_loss: 0.0023310231044888496
train_iter_loss: 0.04811173677444458
train_iter_loss: 0.010282527655363083
train loss :0.0154
---------------------
Validation seg loss: 0.050731600414264735 at epoch 106
epoch =    107/  1000, exp = train
train_iter_loss: 0.014782602898776531
train_iter_loss: 0.008141804486513138
train_iter_loss: 0.002424820326268673
train_iter_loss: 0.008884545415639877
train_iter_loss: 0.02719816192984581
train_iter_loss: 0.034751590341329575
train_iter_loss: 0.0673903375864029
train_iter_loss: 0.0076805767603218555
train_iter_loss: 0.011743593961000443
train_iter_loss: 0.009608718566596508
train_iter_loss: 0.010210070759057999
train_iter_loss: 0.00664324127137661
train_iter_loss: 0.02328225038945675
train_iter_loss: 0.005448964890092611
train_iter_loss: 0.027294669300317764
train_iter_loss: 0.014196312054991722
train_iter_loss: 0.01300888229161501
train_iter_loss: 0.016596592962741852
train_iter_loss: 0.005277460906654596
train_iter_loss: 0.014210512861609459
train_iter_loss: 0.013995880261063576
train_iter_loss: 0.006916581653058529
train_iter_loss: 0.01930108852684498
train_iter_loss: 0.032554060220718384
train_iter_loss: 0.006195292808115482
train_iter_loss: 0.03524674475193024
train_iter_loss: 0.006151926703751087
train_iter_loss: 0.0182177796959877
train_iter_loss: 0.00875094998627901
train_iter_loss: 0.01353662833571434
train_iter_loss: 0.005848005414009094
train_iter_loss: 0.0041930899024009705
train_iter_loss: 0.0021121164318174124
train_iter_loss: 0.0061613391153514385
train_iter_loss: 0.0031822321470826864
train_iter_loss: 0.0021683413069695234
train_iter_loss: 0.012945866212248802
train_iter_loss: 0.016992351040244102
train_iter_loss: 0.016884973272681236
train_iter_loss: 0.010709780268371105
train_iter_loss: 0.011973338201642036
train_iter_loss: 0.009676346555352211
train_iter_loss: 0.01819985918700695
train_iter_loss: 0.031009487807750702
train_iter_loss: 0.0030995921697467566
train_iter_loss: 0.0018171973060816526
train_iter_loss: 0.009066838771104813
train_iter_loss: 0.00950595922768116
train_iter_loss: 0.010548162274062634
train_iter_loss: 0.025864282622933388
train loss :0.0143
---------------------
Validation seg loss: 0.059142210105593854 at epoch 107
epoch =    108/  1000, exp = train
train_iter_loss: 0.03371438756585121
train_iter_loss: 0.018796201795339584
train_iter_loss: 0.01224822923541069
train_iter_loss: 0.006748318672180176
train_iter_loss: 0.01906079798936844
train_iter_loss: 0.024598080664873123
train_iter_loss: 0.027326233685016632
train_iter_loss: 0.021021995693445206
train_iter_loss: 0.02879614382982254
train_iter_loss: 0.020872430875897408
train_iter_loss: 0.017031829804182053
train_iter_loss: 0.023793872445821762
train_iter_loss: 0.011498784646391869
train_iter_loss: 0.005838283337652683
train_iter_loss: 0.007583375088870525
train_iter_loss: 0.005415786989033222
train_iter_loss: 0.006178736686706543
train_iter_loss: 0.017865115776658058
train_iter_loss: 0.01407943107187748
train_iter_loss: 0.01979919523000717
train_iter_loss: 0.003963628318160772
train_iter_loss: 0.037443455308675766
train_iter_loss: 0.023567091673612595
train_iter_loss: 0.004120582714676857
train_iter_loss: 0.02552778273820877
train_iter_loss: 0.05234460160136223
train_iter_loss: 0.014384657144546509
train_iter_loss: 0.029882995411753654
train_iter_loss: 0.005194081924855709
train_iter_loss: 0.007559394929558039
train_iter_loss: 0.00348650012165308
train_iter_loss: 0.007578844204545021
train_iter_loss: 0.00651028985157609
train_iter_loss: 0.0016555942129343748
train_iter_loss: 0.006603491026908159
train_iter_loss: 0.002454480854794383
train_iter_loss: 0.017330491915345192
train_iter_loss: 0.014027019031345844
train_iter_loss: 0.02510332688689232
train_iter_loss: 0.008231407962739468
train_iter_loss: 0.08307510614395142
train_iter_loss: 0.0325201191008091
train_iter_loss: 0.00688436022028327
train_iter_loss: 0.04060458764433861
train_iter_loss: 0.0017326571978628635
train_iter_loss: 0.0030377476941794157
train_iter_loss: 0.00528897438198328
train_iter_loss: 0.0036919189151376486
train_iter_loss: 0.012179800309240818
train_iter_loss: 0.04393981769680977
train loss :0.0177
---------------------
Validation seg loss: 0.04887611345818512 at epoch 108
epoch =    109/  1000, exp = train
train_iter_loss: 0.013841216452419758
train_iter_loss: 0.02638571336865425
train_iter_loss: 0.03659584000706673
train_iter_loss: 0.016799965873360634
train_iter_loss: 0.021390574052929878
train_iter_loss: 0.0949816033244133
train_iter_loss: 0.03689452260732651
train_iter_loss: 0.030713168904185295
train_iter_loss: 0.027976639568805695
train_iter_loss: 0.021743500605225563
train_iter_loss: 0.014212395995855331
train_iter_loss: 0.078793466091156
train_iter_loss: 0.008135668933391571
train_iter_loss: 0.020327994599938393
train_iter_loss: 0.015298029407858849
train_iter_loss: 0.0057021877728402615
train_iter_loss: 0.018248731270432472
train_iter_loss: 0.01738060638308525
train_iter_loss: 0.02985524572432041
train_iter_loss: 0.011844736523926258
train_iter_loss: 0.009858428500592709
train_iter_loss: 0.0021742559038102627
train_iter_loss: 0.00460120290517807
train_iter_loss: 0.01575027033686638
train_iter_loss: 0.043554823845624924
train_iter_loss: 0.008541742339730263
train_iter_loss: 0.026673607528209686
train_iter_loss: 0.024391187354922295
train_iter_loss: 0.005733349360525608
train_iter_loss: 0.00563267944380641
train_iter_loss: 0.010976863093674183
train_iter_loss: 0.004000621847808361
train_iter_loss: 0.010933937504887581
train_iter_loss: 0.002457793802022934
train_iter_loss: 0.011554871685802937
train_iter_loss: 0.005228836555033922
train_iter_loss: 0.016367333009839058
train_iter_loss: 0.014298432506620884
train_iter_loss: 0.01784970611333847
train_iter_loss: 0.017501145601272583
train_iter_loss: 0.015083365142345428
train_iter_loss: 0.03251441940665245
train_iter_loss: 0.009898324497044086
train_iter_loss: 0.009379618801176548
train_iter_loss: 0.020198166370391846
train_iter_loss: 0.006381409242749214
train_iter_loss: 0.00971146672964096
train_iter_loss: 0.002807182725518942
train_iter_loss: 0.009742466732859612
train_iter_loss: 0.017822973430156708
train loss :0.0191
---------------------
Validation seg loss: 0.04962723861782886 at epoch 109
epoch =    110/  1000, exp = train
train_iter_loss: 0.013864937238395214
train_iter_loss: 0.022600864991545677
train_iter_loss: 0.006156307179480791
train_iter_loss: 0.008783042430877686
train_iter_loss: 0.05119825899600983
train_iter_loss: 0.012225805781781673
train_iter_loss: 0.04259001463651657
train_iter_loss: 0.05846400186419487
train_iter_loss: 0.010132972151041031
train_iter_loss: 0.0054365238174796104
train_iter_loss: 0.016798822209239006
train_iter_loss: 0.023652663454413414
train_iter_loss: 0.005840422585606575
train_iter_loss: 0.010103890672326088
train_iter_loss: 0.01881873607635498
train_iter_loss: 0.004359992686659098
train_iter_loss: 0.03878416493535042
train_iter_loss: 0.005324812605977058
train_iter_loss: 0.023142263293266296
train_iter_loss: 0.014856160618364811
train_iter_loss: 0.006194865796715021
train_iter_loss: 0.0036294045858085155
train_iter_loss: 0.006844007410109043
train_iter_loss: 0.0068196384236216545
train_iter_loss: 0.030849361792206764
train_iter_loss: 0.03801979869604111
train_iter_loss: 0.025878742337226868
train_iter_loss: 0.04781077429652214
train_iter_loss: 0.006217779126018286
train_iter_loss: 0.018873164430260658
train_iter_loss: 0.004625089932233095
train_iter_loss: 0.0027456521056592464
train_iter_loss: 0.0027711184229701757
train_iter_loss: 0.003908815328031778
train_iter_loss: 0.006684207823127508
train_iter_loss: 0.026034172624349594
train_iter_loss: 0.02486138418316841
train_iter_loss: 0.00920527707785368
train_iter_loss: 0.004923082888126373
train_iter_loss: 0.010397273115813732
train_iter_loss: 0.01130206324160099
train_iter_loss: 0.019749566912651062
train_iter_loss: 0.0059379516169428825
train_iter_loss: 0.02454284578561783
train_iter_loss: 0.011308192275464535
train_iter_loss: 0.005232306197285652
train_iter_loss: 0.0031322988215833902
train_iter_loss: 0.004168172366917133
train_iter_loss: 0.01362351793795824
train_iter_loss: 0.011366802267730236
train loss :0.0162
---------------------
Validation seg loss: 0.05200869317305437 at epoch 110
epoch =    111/  1000, exp = train
train_iter_loss: 0.033717330545186996
train_iter_loss: 0.00947530660778284
train_iter_loss: 0.01941850781440735
train_iter_loss: 0.015232962556183338
train_iter_loss: 0.03683743253350258
train_iter_loss: 0.0160482507199049
train_iter_loss: 0.0726003348827362
train_iter_loss: 0.045586634427309036
train_iter_loss: 0.004337556194514036
train_iter_loss: 0.006474675145000219
train_iter_loss: 0.01817844621837139
train_iter_loss: 0.013236531987786293
train_iter_loss: 0.006361870560795069
train_iter_loss: 0.002877039136365056
train_iter_loss: 0.0025682158302515745
train_iter_loss: 0.007030730601400137
train_iter_loss: 0.008887778967618942
train_iter_loss: 0.005277440417557955
train_iter_loss: 0.004239035304635763
train_iter_loss: 0.005611863452941179
train_iter_loss: 0.008128134533762932
train_iter_loss: 0.026019174605607986
train_iter_loss: 0.008369137533009052
train_iter_loss: 0.01130739226937294
train_iter_loss: 0.012237000279128551
train_iter_loss: 0.02046959288418293
train_iter_loss: 0.024111175909638405
train_iter_loss: 0.07050732523202896
train_iter_loss: 0.01234256848692894
train_iter_loss: 0.0016564317047595978
train_iter_loss: 0.0063864802941679955
train_iter_loss: 0.004398027900606394
train_iter_loss: 0.0012975047575309873
train_iter_loss: 0.00889486912637949
train_iter_loss: 0.00775974802672863
train_iter_loss: 0.00646715983748436
train_iter_loss: 0.02721359394490719
train_iter_loss: 0.01058509573340416
train_iter_loss: 0.007455090060830116
train_iter_loss: 0.011992041021585464
train_iter_loss: 0.012307818047702312
train_iter_loss: 0.007030158303678036
train_iter_loss: 0.013236362487077713
train_iter_loss: 0.01086660660803318
train_iter_loss: 0.004711618181318045
train_iter_loss: 0.006172458175569773
train_iter_loss: 0.004970494657754898
train_iter_loss: 0.008872204460203648
train_iter_loss: 0.011898950673639774
train_iter_loss: 0.009383264929056168
train loss :0.0145
---------------------
Validation seg loss: 0.05403003492118035 at epoch 111
epoch =    112/  1000, exp = train
train_iter_loss: 0.010092264041304588
train_iter_loss: 0.049593694508075714
train_iter_loss: 0.02129279635846615
train_iter_loss: 0.008930563926696777
train_iter_loss: 0.02458428032696247
train_iter_loss: 0.012863334268331528
train_iter_loss: 0.025182906538248062
train_iter_loss: 0.045986440032720566
train_iter_loss: 0.0062302784062922
train_iter_loss: 0.013879284262657166
train_iter_loss: 0.012332972139120102
train_iter_loss: 0.007176029030233622
train_iter_loss: 0.011031048372387886
train_iter_loss: 0.015660664066672325
train_iter_loss: 0.01680987887084484
train_iter_loss: 0.003734666621312499
train_iter_loss: 0.011430656537413597
train_iter_loss: 0.024018719792366028
train_iter_loss: 0.03342540189623833
train_iter_loss: 0.023238396272063255
train_iter_loss: 0.021680545061826706
train_iter_loss: 0.019724871963262558
train_iter_loss: 0.00685558607801795
train_iter_loss: 0.03862760215997696
train_iter_loss: 0.030787795782089233
train_iter_loss: 0.0319686196744442
train_iter_loss: 0.027403725311160088
train_iter_loss: 0.021672489121556282
train_iter_loss: 0.007986730895936489
train_iter_loss: 0.0017530537443235517
train_iter_loss: 0.006902668625116348
train_iter_loss: 0.005032213404774666
train_iter_loss: 0.006402813363820314
train_iter_loss: 0.00503803975880146
train_iter_loss: 0.0036086859181523323
train_iter_loss: 0.0010876827873289585
train_iter_loss: 0.004134890157729387
train_iter_loss: 0.013218785636126995
train_iter_loss: 0.008632964454591274
train_iter_loss: 0.030280733481049538
train_iter_loss: 0.026794515550136566
train_iter_loss: 0.020920125767588615
train_iter_loss: 0.011535963974893093
train_iter_loss: 0.03727234527468681
train_iter_loss: 0.003757396014407277
train_iter_loss: 0.006135882344096899
train_iter_loss: 0.009044687263667583
train_iter_loss: 0.013041242957115173
train_iter_loss: 0.018574681133031845
train_iter_loss: 0.009531931020319462
train loss :0.0168
---------------------
Validation seg loss: 0.04829210720111765 at epoch 112
epoch =    113/  1000, exp = train

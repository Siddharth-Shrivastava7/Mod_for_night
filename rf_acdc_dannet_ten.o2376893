===============================
2376893.pbshpc
vsky009.hpc.iitd.ac.in
===============================
/home/cse/phd/anz208849/Mod_for_night
wait
['so_run_btad_2.py']
Snapshot stored in: ../scratch/saved_models/acdc/dannet/train
                     note : train          
                    model : deeplab        
                    train : 1              
                 multigpu : 0              
                    fixbn : 0              
                 fix_seed : 1              
            learning_rate : 7.5e-05        
                num_steps : 5000           
                   epochs : 1000           
             weight_decay : 0.0005         
                 momentum : 0.9            
                    power : 0.9            
                    round : 6              
               print_freq : 372            
                save_freq : 372            
              tensorboard : 1              
                  neptune : 0              
                   screen : 1              
                      val : 1              
                 val_freq : 5              
                   source : acdc_train_rf_tensor
                   target : acdc_val_rf_tensor
                   worker : 4              
               batch_size : 2              
              num_classes : 2              
                input_src : 720            
                input_tgt : 720            
                 crop_src : 600            
                 crop_tgt : 600            
                   mirror : 1              
                scale_min : 0.5            
                scale_max : 1.5            
                      rec : 0              
              init_weight : ./save/model410_city_deeplabv2.pth
             restore_from : None           
                 snapshot : ../scratch/saved_models/acdc/dannet/train
                   result : ./miou_result/ 
                      log : ./log/         
                   plabel : ./plabel       
                       tb : ./log/train    

Mode --> Train
Lets ride...
epoch =      0/  1000, exp = train
train_iter_loss: 0.7891377806663513
train_iter_loss: 0.7710544466972351
train_iter_loss: 0.7434272170066833
train_iter_loss: 0.7830803990364075
train_iter_loss: 0.7533856630325317
train_iter_loss: 0.7647235989570618
train_iter_loss: 0.7269695401191711
train_iter_loss: 0.7370830178260803
train_iter_loss: 0.7663946151733398
train_iter_loss: 0.7739381194114685
train_iter_loss: 0.7433757781982422
train_iter_loss: 0.6974069476127625
train_iter_loss: 0.7307256460189819
train_iter_loss: 0.7005720138549805
train_iter_loss: 0.7076200842857361
train_iter_loss: 0.6851050853729248
train_iter_loss: 0.719805121421814
train_iter_loss: 0.6709028482437134
train_iter_loss: 0.7080504298210144
train_iter_loss: 0.7093616127967834
train_iter_loss: 0.682666540145874
train_iter_loss: 0.6429831981658936
train_iter_loss: 0.6492220759391785
train_iter_loss: 0.683724045753479
train_iter_loss: 0.7012643814086914
train_iter_loss: 0.6678435206413269
train_iter_loss: 0.6189623475074768
train_iter_loss: 0.7185155153274536
train_iter_loss: 0.6861247420310974
train_iter_loss: 0.710379421710968
train_iter_loss: 0.6237457394599915
train_iter_loss: 0.6596927046775818
train_iter_loss: 0.6452205777168274
train_iter_loss: 0.6471046805381775
train_iter_loss: 0.6645433306694031
train_iter_loss: 0.6800805926322937
train_iter_loss: 0.6926548480987549
train_iter_loss: 0.5942675471305847
train_iter_loss: 0.608245849609375
train_iter_loss: 0.6027271747589111
train_iter_loss: 0.5724011063575745
train_iter_loss: 0.6553471088409424
train_iter_loss: 0.6652076840400696
train_iter_loss: 0.7227064967155457
train_iter_loss: 0.5396127104759216
train_iter_loss: 0.6860776543617249
train_iter_loss: 0.7037680149078369
train_iter_loss: 0.7190098762512207
train_iter_loss: 0.6508646607398987
train_iter_loss: 0.6806129813194275
train_iter_loss: 0.6218745708465576
train_iter_loss: 0.6898081302642822
train_iter_loss: 0.6648104786872864
train_iter_loss: 0.7141156196594238
train_iter_loss: 0.6616340279579163
train_iter_loss: 0.643215000629425
train_iter_loss: 0.6345054507255554
train_iter_loss: 0.6635540127754211
train_iter_loss: 0.6802759170532227
train_iter_loss: 0.6997935771942139
train_iter_loss: 0.6339688897132874
train_iter_loss: 0.6859594583511353
train_iter_loss: 0.6280211210250854
train_iter_loss: 0.5913406014442444
train_iter_loss: 0.6306756734848022
train_iter_loss: 0.6220790147781372
train_iter_loss: 0.7016578912734985
train_iter_loss: 0.6355026364326477
train_iter_loss: 0.6277801394462585
train_iter_loss: 0.6436104774475098
train_iter_loss: 0.6143394708633423
train_iter_loss: 0.6728267669677734
train_iter_loss: 0.5870620608329773
train_iter_loss: 0.6076335906982422
train_iter_loss: 0.6467733979225159
train_iter_loss: 0.6715782880783081
train_iter_loss: 0.5924621820449829
train_iter_loss: 0.5860205292701721
train_iter_loss: 0.6596748232841492
train_iter_loss: 0.6534350514411926
train_iter_loss: 0.5607712268829346
train_iter_loss: 0.6095226407051086
train_iter_loss: 0.6575927734375
train_iter_loss: 0.6340251564979553
train_iter_loss: 0.5575104355812073
train_iter_loss: 0.6612110137939453
train_iter_loss: 0.5974321365356445
train_iter_loss: 0.6243160367012024
train_iter_loss: 0.6440996527671814
train_iter_loss: 0.6077760457992554
train_iter_loss: 0.6438203454017639
train_iter_loss: 0.5817103385925293
train_iter_loss: 0.6008382439613342
train_iter_loss: 0.6740309596061707
train_iter_loss: 0.6170794367790222
train_iter_loss: 0.6141438484191895
train_iter_loss: 0.5155543088912964
train_iter_loss: 0.5418702960014343
train_iter_loss: 0.5834543704986572
train_iter_loss: 0.5790122151374817
train_iter_loss: 0.7126557230949402
train_iter_loss: 0.6743993759155273
train_iter_loss: 0.6456155776977539
train_iter_loss: 0.6530106663703918
train_iter_loss: 0.6513620018959045
train_iter_loss: 0.5925623774528503
train_iter_loss: 0.5649354457855225
train_iter_loss: 0.5444352626800537
train_iter_loss: 0.697401225566864
train_iter_loss: 0.5981169939041138
train_iter_loss: 0.6440320014953613
train_iter_loss: 0.5513675212860107
train_iter_loss: 0.6928759813308716
train_iter_loss: 0.6981958746910095
train_iter_loss: 0.5955230593681335
train_iter_loss: 0.6004355549812317
train_iter_loss: 0.6423863172531128
train_iter_loss: 0.6925399899482727
train_iter_loss: 0.6106386780738831
train_iter_loss: 0.6418889164924622
train_iter_loss: 0.7002370357513428
train_iter_loss: 0.5971177220344543
train_iter_loss: 0.5487571954727173
train_iter_loss: 0.5632823705673218
train_iter_loss: 0.5553827285766602
train_iter_loss: 0.6263668537139893
train_iter_loss: 0.6155492663383484
train_iter_loss: 0.5856900811195374
train_iter_loss: 0.6239703893661499
train_iter_loss: 0.5819582939147949
train_iter_loss: 0.5648514628410339
train_iter_loss: 0.6203559041023254
train_iter_loss: 0.6363601088523865
train_iter_loss: 0.5863081812858582
train_iter_loss: 0.5972460508346558
train_iter_loss: 0.6492430567741394
train_iter_loss: 0.6194981932640076
train_iter_loss: 0.6336345672607422
train_iter_loss: 0.592354416847229
train_iter_loss: 0.6624891757965088
train_iter_loss: 0.6291831135749817
train_iter_loss: 0.6239035129547119
train_iter_loss: 0.6873059868812561
train_iter_loss: 0.5721157193183899
train_iter_loss: 0.6194292902946472
train_iter_loss: 0.6924742460250854
train_iter_loss: 0.5330852270126343
train_iter_loss: 0.5135930180549622
train_iter_loss: 0.5829508304595947
train_iter_loss: 0.5328987240791321
train_iter_loss: 0.6247841715812683
train_iter_loss: 0.558551013469696
train_iter_loss: 0.6591207981109619
train_iter_loss: 0.552920401096344
train_iter_loss: 0.6622589230537415
train_iter_loss: 0.57296222448349
train_iter_loss: 0.5465715527534485
train_iter_loss: 0.5864837765693665
train_iter_loss: 0.5363190770149231
train_iter_loss: 0.5965113639831543
train_iter_loss: 0.655205488204956
train_iter_loss: 0.599227249622345
train_iter_loss: 0.6168637275695801
train_iter_loss: 0.6196007132530212
train_iter_loss: 0.5929628014564514
train_iter_loss: 0.5754473209381104
train_iter_loss: 0.5881582498550415
train_iter_loss: 0.6337496638298035
train_iter_loss: 0.6439502835273743
train_iter_loss: 0.5614302754402161
train_iter_loss: 0.593962550163269
train_iter_loss: 0.6507906317710876
train_iter_loss: 0.5653362274169922
train_iter_loss: 0.6151260137557983
train_iter_loss: 0.6210075616836548
train_iter_loss: 0.5948950052261353
train_iter_loss: 0.6052822470664978
train_iter_loss: 0.6254613399505615
train_iter_loss: 0.6422386765480042
train_iter_loss: 0.6467852592468262
train_iter_loss: 0.6067068576812744
train_iter_loss: 0.7084055542945862
train_iter_loss: 0.5642955899238586
train_iter_loss: 0.5720967054367065
train_iter_loss: 0.6349806785583496
train_iter_loss: 0.5743563175201416
train_iter_loss: 0.6035217642784119
train_iter_loss: 0.6226484775543213
train_iter_loss: 0.5983028411865234
train_iter_loss: 0.6162843704223633
train_iter_loss: 0.6218669414520264
train_iter_loss: 0.570503830909729
train_iter_loss: 0.6194101572036743
train_iter_loss: 0.615272581577301
train_iter_loss: 0.5693612098693848
train_iter_loss: 0.5829878449440002
train_iter_loss: 0.5809770226478577
train_iter_loss: 0.5682042837142944
train_iter_loss: 0.6225041151046753
train_iter_loss: 0.5060924887657166
train loss :0.6344
---------------------
Validation seg loss: 0.6104424165667228 at epoch 0
********************
best_val_epoch_loss:  0.6104424165667228
MODEL UPDATED
epoch =      1/  1000, exp = train
train_iter_loss: 0.49915915727615356
train_iter_loss: 0.5755258798599243
train_iter_loss: 0.5684743523597717
train_iter_loss: 0.6170495748519897
train_iter_loss: 0.5527051091194153
train_iter_loss: 0.6174588799476624
train_iter_loss: 0.629814624786377
train_iter_loss: 0.574317216873169
train_iter_loss: 0.5462508201599121
train_iter_loss: 0.651107907295227
train_iter_loss: 0.5633699893951416
train_iter_loss: 0.5521504282951355
train_iter_loss: 0.5760486721992493
train_iter_loss: 0.6253111958503723
train_iter_loss: 0.6157483458518982
train_iter_loss: 0.6286262273788452
train_iter_loss: 0.5632379651069641
train_iter_loss: 0.578559160232544
train_iter_loss: 0.6390472650527954
train_iter_loss: 0.5774381160736084
train_iter_loss: 0.554123044013977
train_iter_loss: 0.567248523235321
train_iter_loss: 0.5485827922821045
train_iter_loss: 0.5271689891815186
train_iter_loss: 0.5900788903236389
train_iter_loss: 0.5831574201583862
train_iter_loss: 0.5055622458457947
train_iter_loss: 0.5267727971076965
train_iter_loss: 0.5181731581687927
train_iter_loss: 0.4892890155315399
train_iter_loss: 0.5631944537162781
train_iter_loss: 0.6437406539916992
train_iter_loss: 0.6191117167472839
train_iter_loss: 0.572205126285553
train_iter_loss: 0.6337860226631165
train_iter_loss: 0.6255842447280884
train_iter_loss: 0.5982624292373657
train_iter_loss: 0.5701708793640137
train_iter_loss: 0.586520791053772
train_iter_loss: 0.5851894021034241
train_iter_loss: 0.5631434321403503
train_iter_loss: 0.570064127445221
train_iter_loss: 0.5709637403488159
train_iter_loss: 0.5534068942070007
train_iter_loss: 0.5202891230583191
train_iter_loss: 0.6368700265884399
train_iter_loss: 0.48626911640167236
train_iter_loss: 0.5219235420227051
train_iter_loss: 0.6044237613677979
train_iter_loss: 0.5448884963989258
train_iter_loss: 0.585638701915741
train_iter_loss: 0.5547110438346863
train_iter_loss: 0.5387372374534607
train_iter_loss: 0.5824041962623596
train_iter_loss: 0.5635919570922852
train_iter_loss: 0.6460595726966858
train_iter_loss: 0.6066858768463135
train_iter_loss: 0.6656522154808044
train_iter_loss: 0.6046233177185059
train_iter_loss: 0.5761080980300903
train_iter_loss: 0.5423220992088318
train_iter_loss: 0.5467490553855896
train_iter_loss: 0.6035056710243225
train_iter_loss: 0.590226948261261
train_iter_loss: 0.6145961284637451
train_iter_loss: 0.560001790523529
train_iter_loss: 0.5954037308692932
train_iter_loss: 0.5663967132568359
train_iter_loss: 0.5751452445983887
train_iter_loss: 0.5908529758453369
train_iter_loss: 0.5876318216323853
train_iter_loss: 0.5398206114768982
train_iter_loss: 0.5812774300575256
train_iter_loss: 0.5126299262046814
train_iter_loss: 0.6370083093643188
train_iter_loss: 0.5742784738540649
train_iter_loss: 0.5904321074485779
train_iter_loss: 0.5953147411346436
train_iter_loss: 0.5981630682945251
train_iter_loss: 0.557040274143219
train_iter_loss: 0.5173973441123962
train_iter_loss: 0.6029388904571533
train_iter_loss: 0.6359256505966187
train_iter_loss: 0.5942385196685791
train_iter_loss: 0.5651463270187378
train_iter_loss: 0.5597309470176697
train_iter_loss: 0.5401380062103271
train_iter_loss: 0.6139869689941406
train_iter_loss: 0.6119557619094849
train_iter_loss: 0.6310171484947205
train_iter_loss: 0.5860114693641663
train_iter_loss: 0.5862075686454773
train_iter_loss: 0.664717435836792
train_iter_loss: 0.5493589043617249
train_iter_loss: 0.5337153077125549
train_iter_loss: 0.5960931181907654
train_iter_loss: 0.5545278191566467
train_iter_loss: 0.5498324632644653
train_iter_loss: 0.532622218132019
train_iter_loss: 0.48550087213516235
train_iter_loss: 0.6583141684532166
train_iter_loss: 0.5978479981422424
train_iter_loss: 0.5539023876190186
train_iter_loss: 0.5978190898895264
train_iter_loss: 0.478659451007843
train_iter_loss: 0.6338949203491211
train_iter_loss: 0.5160712599754333
train_iter_loss: 0.5349525213241577
train_iter_loss: 0.5968539714813232
train_iter_loss: 0.6089334487915039
train_iter_loss: 0.4946564733982086
train_iter_loss: 0.5892158150672913
train_iter_loss: 0.5624602437019348
train_iter_loss: 0.5019239187240601
train_iter_loss: 0.5585513114929199
train_iter_loss: 0.5887749195098877
train_iter_loss: 0.5748934745788574
train_iter_loss: 0.5122510194778442
train_iter_loss: 0.4826379716396332
train_iter_loss: 0.6019342541694641
train_iter_loss: 0.5923669338226318
train_iter_loss: 0.5263470411300659
train_iter_loss: 0.6173253655433655
train_iter_loss: 0.5973562598228455
train_iter_loss: 0.5565135478973389
train_iter_loss: 0.5639309287071228
train_iter_loss: 0.5821138024330139
train_iter_loss: 0.48455098271369934
train_iter_loss: 0.49992164969444275
train_iter_loss: 0.5323566198348999
train_iter_loss: 0.5395553708076477
train_iter_loss: 0.5794901251792908
train_iter_loss: 0.6197639107704163
train_iter_loss: 0.5313665270805359
train_iter_loss: 0.5230486989021301
train_iter_loss: 0.6155549883842468
train_iter_loss: 0.6246882081031799
train_iter_loss: 0.4723011553287506
train_iter_loss: 0.5509048104286194
train_iter_loss: 0.5014370083808899
train_iter_loss: 0.5667027831077576
train_iter_loss: 0.5207380652427673
train_iter_loss: 0.5933260321617126
train_iter_loss: 0.5351836085319519
train_iter_loss: 0.551099956035614
train_iter_loss: 0.545135498046875
train_iter_loss: 0.6078301668167114
train_iter_loss: 0.5744053721427917
train_iter_loss: 0.5625911951065063
train_iter_loss: 0.5947378277778625
train_iter_loss: 0.533455491065979
train_iter_loss: 0.5208205580711365
train_iter_loss: 0.5549783110618591
train_iter_loss: 0.5511096715927124
train_iter_loss: 0.4744294285774231
train_iter_loss: 0.547390341758728
train_iter_loss: 0.5382470488548279
train_iter_loss: 0.6000679731369019
train_iter_loss: 0.584018886089325
train_iter_loss: 0.5195095539093018
train_iter_loss: 0.6247224807739258
train_iter_loss: 0.5772626399993896
train_iter_loss: 0.5940418839454651
train_iter_loss: 0.565992534160614
train_iter_loss: 0.6128636598587036
train_iter_loss: 0.5387678742408752
train_iter_loss: 0.5330158472061157
train_iter_loss: 0.5148544907569885
train_iter_loss: 0.5944772958755493
train_iter_loss: 0.5145425796508789
train_iter_loss: 0.49630025029182434
train_iter_loss: 0.590603232383728
train_iter_loss: 0.5705108642578125
train_iter_loss: 0.5819993019104004
train_iter_loss: 0.49677178263664246
train_iter_loss: 0.5194748044013977
train_iter_loss: 0.5509786009788513
train_iter_loss: 0.5543064475059509
train_iter_loss: 0.5500748157501221
train_iter_loss: 0.5778180360794067
train_iter_loss: 0.5465726852416992
train_iter_loss: 0.5254992246627808
train_iter_loss: 0.5451729893684387
train_iter_loss: 0.535584032535553
train_iter_loss: 0.5392846465110779
train_iter_loss: 0.4998636841773987
train_iter_loss: 0.5358490943908691
train_iter_loss: 0.5379744172096252
train_iter_loss: 0.5402135252952576
train_iter_loss: 0.5748830437660217
train_iter_loss: 0.539798378944397
train_iter_loss: 0.5749497413635254
train_iter_loss: 0.6235718131065369
train_iter_loss: 0.5738303661346436
train_iter_loss: 0.4558221697807312
train_iter_loss: 0.5677862167358398
train_iter_loss: 0.5478963255882263
train_iter_loss: 0.5817251205444336
train_iter_loss: 0.5644307732582092
train_iter_loss: 0.5465489029884338
train loss :0.5695
---------------------
Validation seg loss: 0.5637947287199632 at epoch 1
********************
best_val_epoch_loss:  0.5637947287199632
MODEL UPDATED
epoch =      2/  1000, exp = train
train_iter_loss: 0.5516772270202637
train_iter_loss: 0.6137903928756714
train_iter_loss: 0.5755231976509094
train_iter_loss: 0.5466445088386536
train_iter_loss: 0.612078070640564
train_iter_loss: 0.5439555048942566
train_iter_loss: 0.5044100880622864
train_iter_loss: 0.5101388096809387
train_iter_loss: 0.5341556072235107
train_iter_loss: 0.5742523670196533
train_iter_loss: 0.4700528681278229
train_iter_loss: 0.5693494081497192
train_iter_loss: 0.535793125629425
train_iter_loss: 0.5774692893028259
train_iter_loss: 0.5555673837661743
train_iter_loss: 0.6195380687713623
train_iter_loss: 0.5286611914634705
train_iter_loss: 0.46718382835388184
train_iter_loss: 0.6102270483970642
train_iter_loss: 0.5484922528266907
train_iter_loss: 0.5547621846199036
train_iter_loss: 0.5236555933952332
train_iter_loss: 0.4653838574886322
train_iter_loss: 0.5519319176673889
train_iter_loss: 0.5725535154342651
train_iter_loss: 0.5739130973815918
train_iter_loss: 0.5848443508148193
train_iter_loss: 0.5697875618934631
train_iter_loss: 0.5584784746170044
train_iter_loss: 0.49760469794273376
train_iter_loss: 0.4896330237388611
train_iter_loss: 0.583137571811676
train_iter_loss: 0.5367157459259033
train_iter_loss: 0.524674654006958
train_iter_loss: 0.44266995787620544
train_iter_loss: 0.5493623614311218
train_iter_loss: 0.4890587031841278
train_iter_loss: 0.5728992819786072
train_iter_loss: 0.5297906398773193
train_iter_loss: 0.5386475920677185
train_iter_loss: 0.5014163255691528
train_iter_loss: 0.5348993539810181
train_iter_loss: 0.5588696599006653
train_iter_loss: 0.5179270505905151
train_iter_loss: 0.5698398947715759
train_iter_loss: 0.5356739163398743
train_iter_loss: 0.49514511227607727
train_iter_loss: 0.5840463638305664
train_iter_loss: 0.5282292366027832
train_iter_loss: 0.4878596067428589
train_iter_loss: 0.5501702427864075
train_iter_loss: 0.534084141254425
train_iter_loss: 0.4981183409690857
train_iter_loss: 0.5843744277954102
train_iter_loss: 0.5890278816223145
train_iter_loss: 0.5481864213943481
train_iter_loss: 0.567410945892334
train_iter_loss: 0.5413748025894165
train_iter_loss: 0.5075010061264038
train_iter_loss: 0.5526825189590454
train_iter_loss: 0.5026068091392517
train_iter_loss: 0.5693881511688232
train_iter_loss: 0.524448573589325
train_iter_loss: 0.5549291968345642
train_iter_loss: 0.5973336696624756
train_iter_loss: 0.564281165599823
train_iter_loss: 0.5444217920303345
train_iter_loss: 0.527300238609314
train_iter_loss: 0.5550900101661682
train_iter_loss: 0.5568299889564514
train_iter_loss: 0.4942810833454132
train_iter_loss: 0.51567542552948
train_iter_loss: 0.5662552714347839
train_iter_loss: 0.5262248516082764
train_iter_loss: 0.4907125234603882
train_iter_loss: 0.5615018010139465
train_iter_loss: 0.48859402537345886
train_iter_loss: 0.5691540241241455
train_iter_loss: 0.5155673623085022
train_iter_loss: 0.4914725422859192
train_iter_loss: 0.45658203959465027
train_iter_loss: 0.5134211182594299
train_iter_loss: 0.4773806929588318
train_iter_loss: 0.5252782702445984
train_iter_loss: 0.5146617889404297
train_iter_loss: 0.5958451628684998
train_iter_loss: 0.557756781578064
train_iter_loss: 0.5402204394340515
train_iter_loss: 0.5408100485801697
train_iter_loss: 0.5605947971343994
train_iter_loss: 0.5502879023551941
train_iter_loss: 0.438286691904068
train_iter_loss: 0.49077722430229187
train_iter_loss: 0.40989619493484497
train_iter_loss: 0.5680570602416992
train_iter_loss: 0.5379458665847778
train_iter_loss: 0.5647100210189819
train_iter_loss: 0.5586039423942566
train_iter_loss: 0.594703733921051
train_iter_loss: 0.5614763498306274
train_iter_loss: 0.4714071750640869
train_iter_loss: 0.5307483673095703
train_iter_loss: 0.5142883658409119
train_iter_loss: 0.5340431928634644
train_iter_loss: 0.5234870314598083
train_iter_loss: 0.5660061836242676
train_iter_loss: 0.5083879232406616
train_iter_loss: 0.5134215354919434
train_iter_loss: 0.5434600710868835
train_iter_loss: 0.5422113537788391
train_iter_loss: 0.5422771573066711
train_iter_loss: 0.4520103931427002
train_iter_loss: 0.5502721667289734
train_iter_loss: 0.5423638224601746
train_iter_loss: 0.47921913862228394
train_iter_loss: 0.49411922693252563
train_iter_loss: 0.5682252645492554
train_iter_loss: 0.5584858059883118
train_iter_loss: 0.5054447054862976
train_iter_loss: 0.519504189491272
train_iter_loss: 0.582347571849823
train_iter_loss: 0.4991634488105774
train_iter_loss: 0.46732938289642334
train_iter_loss: 0.5067662000656128
train_iter_loss: 0.5014544129371643
train_iter_loss: 0.5656271576881409
train_iter_loss: 0.5449463725090027
train_iter_loss: 0.49210694432258606
train_iter_loss: 0.5516994595527649
train_iter_loss: 0.5058801770210266
train_iter_loss: 0.5201297402381897
train_iter_loss: 0.4994586408138275
train_iter_loss: 0.4997728765010834
train_iter_loss: 0.5044727325439453
train_iter_loss: 0.5692598819732666
train_iter_loss: 0.5060056447982788
train_iter_loss: 0.539770781993866
train_iter_loss: 0.5241946578025818
train_iter_loss: 0.5315229296684265
train_iter_loss: 0.5715777277946472
train_iter_loss: 0.5343887805938721
train_iter_loss: 0.4842659533023834
train_iter_loss: 0.5529127717018127
train_iter_loss: 0.5390772819519043
train_iter_loss: 0.47464483976364136
train_iter_loss: 0.5528358817100525
train_iter_loss: 0.506412923336029
train_iter_loss: 0.5460377335548401
train_iter_loss: 0.47699055075645447
train_iter_loss: 0.569758951663971
train_iter_loss: 0.47635218501091003
train_iter_loss: 0.4712975323200226
train_iter_loss: 0.4699641764163971
train_iter_loss: 0.539326548576355
train_iter_loss: 0.5458033680915833
train_iter_loss: 0.5421005487442017
train_iter_loss: 0.5354279279708862
train_iter_loss: 0.5332943201065063
train_iter_loss: 0.5056338906288147
train_iter_loss: 0.43405571579933167
train_iter_loss: 0.5254742503166199
train_iter_loss: 0.43916574120521545
train_iter_loss: 0.5195684432983398
train_iter_loss: 0.5201635360717773
train_iter_loss: 0.49746260046958923
train_iter_loss: 0.49093762040138245
train_iter_loss: 0.5134069919586182
train_iter_loss: 0.538058340549469
train_iter_loss: 0.52793949842453
train_iter_loss: 0.5005371570587158
train_iter_loss: 0.48582059144973755
train_iter_loss: 0.5056635737419128
train_iter_loss: 0.6107202768325806
train_iter_loss: 0.4541061222553253
train_iter_loss: 0.5226506590843201
train_iter_loss: 0.4947584867477417
train_iter_loss: 0.5071097016334534
train_iter_loss: 0.5497321486473083
train_iter_loss: 0.48134154081344604
train_iter_loss: 0.5035499930381775
train_iter_loss: 0.5251510739326477
train_iter_loss: 0.5152024626731873
train_iter_loss: 0.4891258776187897
train_iter_loss: 0.41994789242744446
train_iter_loss: 0.5044912099838257
train_iter_loss: 0.5007166862487793
train_iter_loss: 0.45058730244636536
train_iter_loss: 0.5365025997161865
train_iter_loss: 0.547302782535553
train_iter_loss: 0.42079663276672363
train_iter_loss: 0.5772420763969421
train_iter_loss: 0.5190744996070862
train_iter_loss: 0.45139551162719727
train_iter_loss: 0.46631473302841187
train_iter_loss: 0.5752149224281311
train_iter_loss: 0.5055862069129944
train_iter_loss: 0.4633640944957733
train_iter_loss: 0.45003676414489746
train_iter_loss: 0.4737008810043335
train_iter_loss: 0.4916444420814514
train loss :0.5285
---------------------
Validation seg loss: 0.5221758878455972 at epoch 2
********************
best_val_epoch_loss:  0.5221758878455972
MODEL UPDATED
epoch =      3/  1000, exp = train
train_iter_loss: 0.523986279964447
train_iter_loss: 0.46987006068229675
train_iter_loss: 0.561617910861969
train_iter_loss: 0.5267292857170105
train_iter_loss: 0.48337289690971375
train_iter_loss: 0.49166181683540344
train_iter_loss: 0.5199403762817383
train_iter_loss: 0.6193587779998779
train_iter_loss: 0.4901066720485687
train_iter_loss: 0.5004161596298218
train_iter_loss: 0.5574216842651367
train_iter_loss: 0.49785637855529785
train_iter_loss: 0.49906060099601746
train_iter_loss: 0.5289958119392395
train_iter_loss: 0.5080207586288452
train_iter_loss: 0.49362340569496155
train_iter_loss: 0.4908844530582428
train_iter_loss: 0.5054611563682556
train_iter_loss: 0.4593254029750824
train_iter_loss: 0.49336162209510803
train_iter_loss: 0.5283348560333252
train_iter_loss: 0.45226913690567017
train_iter_loss: 0.5124136209487915
train_iter_loss: 0.528978705406189
train_iter_loss: 0.5327765345573425
train_iter_loss: 0.5421410202980042
train_iter_loss: 0.46480435132980347
train_iter_loss: 0.5275679230690002
train_iter_loss: 0.49870532751083374
train_iter_loss: 0.5002581477165222
train_iter_loss: 0.4379732608795166
train_iter_loss: 0.4906398355960846
train_iter_loss: 0.45330697298049927
train_iter_loss: 0.47770166397094727
train_iter_loss: 0.4813293218612671
train_iter_loss: 0.5146855115890503
train_iter_loss: 0.4886939227581024
train_iter_loss: 0.49165141582489014
train_iter_loss: 0.48378875851631165
train_iter_loss: 0.5222446322441101
train_iter_loss: 0.4697880148887634
train_iter_loss: 0.5119439959526062
train_iter_loss: 0.501552164554596
train_iter_loss: 0.47097888588905334
train_iter_loss: 0.5059877634048462
train_iter_loss: 0.43088892102241516
train_iter_loss: 0.44186559319496155
train_iter_loss: 0.5034944415092468
train_iter_loss: 0.5208653211593628
train_iter_loss: 0.4477251172065735
train_iter_loss: 0.5107719302177429
train_iter_loss: 0.5608636736869812
train_iter_loss: 0.5434906482696533
train_iter_loss: 0.504747748374939
train_iter_loss: 0.5047577023506165
train_iter_loss: 0.46919795870780945
train_iter_loss: 0.5266270041465759
train_iter_loss: 0.4328450858592987
train_iter_loss: 0.4591785669326782
train_iter_loss: 0.4451915919780731
train_iter_loss: 0.5201008915901184
train_iter_loss: 0.4585200548171997
train_iter_loss: 0.4232780933380127
train_iter_loss: 0.4562353193759918
train_iter_loss: 0.48809686303138733
train_iter_loss: 0.4974890947341919
train_iter_loss: 0.44890543818473816
train_iter_loss: 0.469696968793869
train_iter_loss: 0.5155479311943054
train_iter_loss: 0.47257399559020996
train_iter_loss: 0.5155821442604065
train_iter_loss: 0.4284663796424866
train_iter_loss: 0.49464720487594604
train_iter_loss: 0.575045645236969
train_iter_loss: 0.4620054364204407
train_iter_loss: 0.49290353059768677
train_iter_loss: 0.5151193737983704
train_iter_loss: 0.6314934492111206
train_iter_loss: 0.5113971829414368
train_iter_loss: 0.5029125809669495
train_iter_loss: 0.49696847796440125
train_iter_loss: 0.422575443983078
train_iter_loss: 0.5637745261192322
train_iter_loss: 0.5134004950523376
train_iter_loss: 0.5252882242202759
train_iter_loss: 0.5166066288948059
train_iter_loss: 0.5117352604866028
train_iter_loss: 0.4973290264606476
train_iter_loss: 0.4938155710697174
train_iter_loss: 0.5000091791152954
train_iter_loss: 0.4328940808773041
train_iter_loss: 0.5051512122154236
train_iter_loss: 0.5155901908874512
train_iter_loss: 0.5105106830596924
train_iter_loss: 0.457713782787323
train_iter_loss: 0.519324779510498
train_iter_loss: 0.5215902924537659
train_iter_loss: 0.5346047878265381
train_iter_loss: 0.4834451377391815
train_iter_loss: 0.4422009289264679
train_iter_loss: 0.4751170873641968
train_iter_loss: 0.5692286491394043
train_iter_loss: 0.47099822759628296
train_iter_loss: 0.5092835426330566
train_iter_loss: 0.3922254741191864
train_iter_loss: 0.5383884906768799
train_iter_loss: 0.43991991877555847
train_iter_loss: 0.467481791973114
train_iter_loss: 0.4667235314846039
train_iter_loss: 0.4759540855884552
train_iter_loss: 0.49192073941230774
train_iter_loss: 0.5230790972709656
train_iter_loss: 0.50074702501297
train_iter_loss: 0.5141059756278992
train_iter_loss: 0.43956664204597473
train_iter_loss: 0.49990782141685486
train_iter_loss: 0.4809815585613251
train_iter_loss: 0.4602896571159363
train_iter_loss: 0.5178389549255371
train_iter_loss: 0.5320125818252563
train_iter_loss: 0.4811917543411255
train_iter_loss: 0.47596275806427
train_iter_loss: 0.46170106530189514
train_iter_loss: 0.5167771577835083
train_iter_loss: 0.461849570274353
train_iter_loss: 0.5271217823028564
train_iter_loss: 0.44246238470077515
train_iter_loss: 0.5539413094520569
train_iter_loss: 0.5092089176177979
train_iter_loss: 0.4995926320552826
train_iter_loss: 0.5363977551460266
train_iter_loss: 0.5205262899398804
train_iter_loss: 0.4892605245113373
train_iter_loss: 0.4649515450000763
train_iter_loss: 0.5255739688873291
train_iter_loss: 0.47640934586524963
train_iter_loss: 0.5387912392616272
train_iter_loss: 0.5064086318016052
train_iter_loss: 0.4721734821796417
train_iter_loss: 0.4518784284591675
train_iter_loss: 0.5428221225738525
train_iter_loss: 0.4461928904056549
train_iter_loss: 0.4646114110946655
train_iter_loss: 0.4922108054161072
train_iter_loss: 0.46731793880462646
train_iter_loss: 0.4780198633670807
train_iter_loss: 0.4436565041542053
train_iter_loss: 0.4702690839767456
train_iter_loss: 0.4206826090812683
train_iter_loss: 0.4890006184577942
train_iter_loss: 0.550827145576477
train_iter_loss: 0.5034617185592651
train_iter_loss: 0.5123536586761475
train_iter_loss: 0.49450165033340454
train_iter_loss: 0.43549326062202454
train_iter_loss: 0.5109848976135254
train_iter_loss: 0.48147210478782654
train_iter_loss: 0.4650130569934845
train_iter_loss: 0.5330055356025696
train_iter_loss: 0.5199451446533203
train_iter_loss: 0.47808149456977844
train_iter_loss: 0.500086784362793
train_iter_loss: 0.4822015166282654
train_iter_loss: 0.4761732220649719
train_iter_loss: 0.5278598666191101
train_iter_loss: 0.46274280548095703
train_iter_loss: 0.4386822581291199
train_iter_loss: 0.44979679584503174
train_iter_loss: 0.47095778584480286
train_iter_loss: 0.46427613496780396
train_iter_loss: 0.49910634756088257
train_iter_loss: 0.47105297446250916
train_iter_loss: 0.4769991636276245
train_iter_loss: 0.49550744891166687
train_iter_loss: 0.48355790972709656
train_iter_loss: 0.5043827295303345
train_iter_loss: 0.45841503143310547
train_iter_loss: 0.49655601382255554
train_iter_loss: 0.4922296702861786
train_iter_loss: 0.47659358382225037
train_iter_loss: 0.4652749001979828
train_iter_loss: 0.4989634156227112
train_iter_loss: 0.4898408055305481
train_iter_loss: 0.4300929009914398
train_iter_loss: 0.5099741816520691
train_iter_loss: 0.45701834559440613
train_iter_loss: 0.49371054768562317
train_iter_loss: 0.5270124077796936
train_iter_loss: 0.5094640851020813
train_iter_loss: 0.49828460812568665
train_iter_loss: 0.39420026540756226
train_iter_loss: 0.4548577666282654
train_iter_loss: 0.514434278011322
train_iter_loss: 0.5003272891044617
train_iter_loss: 0.4893357753753662
train_iter_loss: 0.5020250678062439
train_iter_loss: 0.42937642335891724
train_iter_loss: 0.49884647130966187
train_iter_loss: 0.5200474262237549
train_iter_loss: 0.4964667856693268
train loss :0.4949
---------------------
Validation seg loss: 0.5190735985085649 at epoch 3
********************
best_val_epoch_loss:  0.5190735985085649
MODEL UPDATED
epoch =      4/  1000, exp = train
train_iter_loss: 0.47953274846076965
train_iter_loss: 0.47814539074897766
train_iter_loss: 0.5251741409301758
train_iter_loss: 0.4544590413570404
train_iter_loss: 0.4665033519268036
train_iter_loss: 0.49132317304611206
train_iter_loss: 0.5444851517677307
train_iter_loss: 0.4559255838394165
train_iter_loss: 0.5024157762527466
train_iter_loss: 0.4356538653373718
train_iter_loss: 0.4581848382949829
train_iter_loss: 0.47480443120002747
train_iter_loss: 0.452644407749176
train_iter_loss: 0.43815210461616516
train_iter_loss: 0.3666621148586273
train_iter_loss: 0.4345410168170929
train_iter_loss: 0.460803359746933
train_iter_loss: 0.47801485657691956
train_iter_loss: 0.4476795196533203
train_iter_loss: 0.4941501021385193
train_iter_loss: 0.4303663969039917
train_iter_loss: 0.48656779527664185
train_iter_loss: 0.4748409390449524
train_iter_loss: 0.43008723855018616
train_iter_loss: 0.5071097016334534
train_iter_loss: 0.5201930999755859
train_iter_loss: 0.5232138633728027
train_iter_loss: 0.4989643692970276
train_iter_loss: 0.4549662172794342
train_iter_loss: 0.42824289202690125
train_iter_loss: 0.5231047868728638
train_iter_loss: 0.5148360729217529
train_iter_loss: 0.5092859864234924
train_iter_loss: 0.4699191153049469
train_iter_loss: 0.43338361382484436
train_iter_loss: 0.4914916753768921
train_iter_loss: 0.45572027564048767
train_iter_loss: 0.4743834435939789
train_iter_loss: 0.4658842086791992
train_iter_loss: 0.4975432753562927
train_iter_loss: 0.4480445086956024
train_iter_loss: 0.46669450402259827
train_iter_loss: 0.46460017561912537
train_iter_loss: 0.4890630841255188
train_iter_loss: 0.45741838216781616
train_iter_loss: 0.45874300599098206
train_iter_loss: 0.4818838834762573
train_iter_loss: 0.5058574676513672
train_iter_loss: 0.4476141929626465
train_iter_loss: 0.4778476655483246
train_iter_loss: 0.46638980507850647
train_iter_loss: 0.453843891620636
train_iter_loss: 0.47281500697135925
train_iter_loss: 0.46102461218833923
train_iter_loss: 0.4391065239906311
train_iter_loss: 0.4360608756542206
train_iter_loss: 0.4590657651424408
train_iter_loss: 0.5161034464836121
train_iter_loss: 0.4667523503303528
train_iter_loss: 0.48034441471099854
train_iter_loss: 0.4924532473087311
train_iter_loss: 0.5308064222335815
train_iter_loss: 0.46916964650154114
train_iter_loss: 0.4919997751712799
train_iter_loss: 0.42798081040382385
train_iter_loss: 0.4712899327278137
train_iter_loss: 0.46052902936935425
train_iter_loss: 0.44453078508377075
train_iter_loss: 0.5001178979873657
train_iter_loss: 0.4514933228492737
train_iter_loss: 0.4132368564605713
train_iter_loss: 0.4899563491344452
train_iter_loss: 0.4638720154762268
train_iter_loss: 0.45334166288375854
train_iter_loss: 0.47773414850234985
train_iter_loss: 0.46627405285835266
train_iter_loss: 0.47463664412498474
train_iter_loss: 0.4521418511867523
train_iter_loss: 0.40112540125846863
train_iter_loss: 0.47380298376083374
train_iter_loss: 0.4673106372356415
train_iter_loss: 0.48011016845703125
train_iter_loss: 0.452950656414032
train_iter_loss: 0.4533762037754059
train_iter_loss: 0.5090819001197815
train_iter_loss: 0.4260128140449524
train_iter_loss: 0.43261539936065674
train_iter_loss: 0.4737783670425415
train_iter_loss: 0.46692556142807007
train_iter_loss: 0.45349815487861633
train_iter_loss: 0.43320730328559875
train_iter_loss: 0.4968370497226715
train_iter_loss: 0.45506197214126587
train_iter_loss: 0.4799621105194092
train_iter_loss: 0.3620865046977997
train_iter_loss: 0.47818663716316223
train_iter_loss: 0.4872346818447113
train_iter_loss: 0.5102629661560059
train_iter_loss: 0.45871222019195557
train_iter_loss: 0.5201497077941895
train_iter_loss: 0.49448850750923157
train_iter_loss: 0.41516634821891785
train_iter_loss: 0.457694947719574
train_iter_loss: 0.47930851578712463
train_iter_loss: 0.48196303844451904
train_iter_loss: 0.44440940022468567
train_iter_loss: 0.4795309603214264
train_iter_loss: 0.4995613694190979
train_iter_loss: 0.4657244384288788
train_iter_loss: 0.5212641954421997
train_iter_loss: 0.49621662497520447
train_iter_loss: 0.421087384223938
train_iter_loss: 0.4291595220565796
train_iter_loss: 0.43950870633125305
train_iter_loss: 0.5156571865081787
train_iter_loss: 0.3814699947834015
train_iter_loss: 0.5102468132972717
train_iter_loss: 0.48362213373184204
train_iter_loss: 0.42279931902885437
train_iter_loss: 0.46575555205345154
train_iter_loss: 0.4769270420074463
train_iter_loss: 0.5085163116455078
train_iter_loss: 0.3963228464126587
train_iter_loss: 0.47400930523872375
train_iter_loss: 0.4642139673233032
train_iter_loss: 0.4395322799682617
train_iter_loss: 0.45443597435951233
train_iter_loss: 0.4841753840446472
train_iter_loss: 0.4236195385456085
train_iter_loss: 0.42922842502593994
train_iter_loss: 0.41935035586357117
train_iter_loss: 0.4080353081226349
train_iter_loss: 0.4461890459060669
train_iter_loss: 0.4746852219104767
train_iter_loss: 0.45164334774017334
train_iter_loss: 0.51878821849823
train_iter_loss: 0.4575386047363281
train_iter_loss: 0.4337772727012634
train_iter_loss: 0.40100154280662537
train_iter_loss: 0.44227391481399536
train_iter_loss: 0.47424444556236267
train_iter_loss: 0.4751715064048767
train_iter_loss: 0.4924872815608978
train_iter_loss: 0.5082478523254395
train_iter_loss: 0.44263672828674316
train_iter_loss: 0.4785979092121124
train_iter_loss: 0.402850478887558
train_iter_loss: 0.4680953621864319
train_iter_loss: 0.575355052947998
train_iter_loss: 0.4714154303073883
train_iter_loss: 0.4301891028881073
train_iter_loss: 0.4410058557987213
train_iter_loss: 0.4760344922542572
train_iter_loss: 0.4968368113040924
train_iter_loss: 0.43269890546798706
train_iter_loss: 0.4428033232688904
train_iter_loss: 0.4360138177871704
train_iter_loss: 0.46431079506874084
train_iter_loss: 0.44647887349128723
train_iter_loss: 0.46990966796875
train_iter_loss: 0.43349602818489075
train_iter_loss: 0.4659581482410431
train_iter_loss: 0.48772215843200684
train_iter_loss: 0.4663965702056885
train_iter_loss: 0.45465487241744995
train_iter_loss: 0.42401182651519775
train_iter_loss: 0.45488253235816956
train_iter_loss: 0.4527789056301117
train_iter_loss: 0.4046633243560791
train_iter_loss: 0.4096039831638336
train_iter_loss: 0.41098594665527344
train_iter_loss: 0.5001333951950073
train_iter_loss: 0.48979130387306213
train_iter_loss: 0.469095915555954
train_iter_loss: 0.44706740975379944
train_iter_loss: 0.4268178939819336
train_iter_loss: 0.43363097310066223
train_iter_loss: 0.4577910602092743
train_iter_loss: 0.4799574911594391
train_iter_loss: 0.4394536018371582
train_iter_loss: 0.4950493276119232
train_iter_loss: 0.4358954131603241
train_iter_loss: 0.5163827538490295
train_iter_loss: 0.5021785497665405
train_iter_loss: 0.4509328305721283
train_iter_loss: 0.4575177729129791
train_iter_loss: 0.44710150361061096
train_iter_loss: 0.45385193824768066
train_iter_loss: 0.47462648153305054
train_iter_loss: 0.43968310952186584
train_iter_loss: 0.5690165758132935
train_iter_loss: 0.46472039818763733
train_iter_loss: 0.420400470495224
train_iter_loss: 0.4022238850593567
train_iter_loss: 0.5013771653175354
train_iter_loss: 0.49932998418807983
train_iter_loss: 0.4489871859550476
train_iter_loss: 0.4113030433654785
train_iter_loss: 0.47516483068466187
train_iter_loss: 0.4612724781036377
train loss :0.4667
---------------------
Validation seg loss: 0.48310189989377866 at epoch 4
********************
best_val_epoch_loss:  0.48310189989377866
MODEL UPDATED
epoch =      5/  1000, exp = train
train_iter_loss: 0.4250343143939972
train_iter_loss: 0.4797668755054474
train_iter_loss: 0.47802215814590454
train_iter_loss: 0.46909815073013306
train_iter_loss: 0.42500898241996765
train_iter_loss: 0.48394766449928284
train_iter_loss: 0.5086849331855774
train_iter_loss: 0.4645099639892578
train_iter_loss: 0.43313249945640564
train_iter_loss: 0.4461973011493683
train_iter_loss: 0.43067216873168945
train_iter_loss: 0.44398564100265503
train_iter_loss: 0.4285745322704315
train_iter_loss: 0.40696609020233154
train_iter_loss: 0.48533597588539124
train_iter_loss: 0.4384964108467102
train_iter_loss: 0.434334933757782
train_iter_loss: 0.43693193793296814
train_iter_loss: 0.4716935157775879
train_iter_loss: 0.4828961193561554
train_iter_loss: 0.5272589921951294
train_iter_loss: 0.4832374155521393
train_iter_loss: 0.4462878406047821
train_iter_loss: 0.39613673090934753
train_iter_loss: 0.4796939194202423
train_iter_loss: 0.44126802682876587
train_iter_loss: 0.4536788761615753
train_iter_loss: 0.4449697434902191
train_iter_loss: 0.3974386751651764
train_iter_loss: 0.46419334411621094
train_iter_loss: 0.4136180281639099
train_iter_loss: 0.43851765990257263
train_iter_loss: 0.4643357992172241
train_iter_loss: 0.45688825845718384
train_iter_loss: 0.4445720314979553
train_iter_loss: 0.4882284104824066
train_iter_loss: 0.5020092725753784
train_iter_loss: 0.44195377826690674
train_iter_loss: 0.4813310205936432
train_iter_loss: 0.43355387449264526
train_iter_loss: 0.428266704082489
train_iter_loss: 0.4461095929145813
train_iter_loss: 0.44120296835899353
train_iter_loss: 0.4286501705646515
train_iter_loss: 0.3780174255371094
train_iter_loss: 0.4565770626068115
train_iter_loss: 0.44857439398765564
train_iter_loss: 0.4918414354324341
train_iter_loss: 0.4482690989971161
train_iter_loss: 0.41959407925605774
train_iter_loss: 0.40116098523139954
train_iter_loss: 0.4705697298049927
train_iter_loss: 0.44468361139297485
train_iter_loss: 0.41552311182022095
train_iter_loss: 0.4637109935283661
train_iter_loss: 0.42367982864379883
train_iter_loss: 0.42278608679771423
train_iter_loss: 0.47292810678482056
train_iter_loss: 0.4419777989387512
train_iter_loss: 0.4889337420463562
train_iter_loss: 0.45527130365371704
train_iter_loss: 0.448781281709671
train_iter_loss: 0.44516220688819885
train_iter_loss: 0.4208546280860901
train_iter_loss: 0.4350150227546692
train_iter_loss: 0.43928825855255127
train_iter_loss: 0.4357675015926361
train_iter_loss: 0.4493371248245239
train_iter_loss: 0.4786326587200165
train_iter_loss: 0.41033104062080383
train_iter_loss: 0.38661107420921326
train_iter_loss: 0.49463924765586853
train_iter_loss: 0.43773317337036133
train_iter_loss: 0.4345906376838684
train_iter_loss: 0.4599705636501312
train_iter_loss: 0.43951666355133057
train_iter_loss: 0.45706281065940857
train_iter_loss: 0.4546065032482147
train_iter_loss: 0.4531043767929077
train_iter_loss: 0.4466475546360016
train_iter_loss: 0.3832109272480011
train_iter_loss: 0.3980541527271271
train_iter_loss: 0.43163833022117615
train_iter_loss: 0.39197972416877747
train_iter_loss: 0.4478304088115692
train_iter_loss: 0.4638344645500183
train_iter_loss: 0.44798681139945984
train_iter_loss: 0.41498783230781555
train_iter_loss: 0.46189579367637634
train_iter_loss: 0.4419133961200714
train_iter_loss: 0.39001888036727905
train_iter_loss: 0.4012749493122101
train_iter_loss: 0.4241381287574768
train_iter_loss: 0.4409758746623993
train_iter_loss: 0.4244980216026306
train_iter_loss: 0.4376487731933594
train_iter_loss: 0.4248339831829071
train_iter_loss: 0.4350533187389374
train_iter_loss: 0.42133158445358276
train_iter_loss: 0.44176244735717773
train_iter_loss: 0.46449369192123413
train_iter_loss: 0.4354384243488312
train_iter_loss: 0.44158026576042175
train_iter_loss: 0.41117650270462036
train_iter_loss: 0.40336886048316956
train_iter_loss: 0.3785564601421356
train_iter_loss: 0.4204122722148895
train_iter_loss: 0.46286532282829285
train_iter_loss: 0.4683423936367035
train_iter_loss: 0.4413183331489563
train_iter_loss: 0.4144076704978943
train_iter_loss: 0.42263171076774597
train_iter_loss: 0.4209716320037842
train_iter_loss: 0.4361538887023926
train_iter_loss: 0.4069775938987732
train_iter_loss: 0.4463760256767273
train_iter_loss: 0.37939542531967163
train_iter_loss: 0.467422217130661
train_iter_loss: 0.45494574308395386
train_iter_loss: 0.4354502558708191
train_iter_loss: 0.4543081223964691
train_iter_loss: 0.4246055781841278
train_iter_loss: 0.445412278175354
train_iter_loss: 0.5065276026725769
train_iter_loss: 0.48773548007011414
train_iter_loss: 0.42183372378349304
train_iter_loss: 0.44768592715263367
train_iter_loss: 0.4120182991027832
train_iter_loss: 0.451181560754776
train_iter_loss: 0.44841641187667847
train_iter_loss: 0.42759495973587036
train_iter_loss: 0.41134539246559143
train_iter_loss: 0.44764024019241333
train_iter_loss: 0.49599871039390564
train_iter_loss: 0.4637323319911957
train_iter_loss: 0.39642783999443054
train_iter_loss: 0.4532204866409302
train_iter_loss: 0.43691104650497437
train_iter_loss: 0.48431214690208435
train_iter_loss: 0.4408690929412842
train_iter_loss: 0.43264609575271606
train_iter_loss: 0.4506714344024658
train_iter_loss: 0.43624821305274963
train_iter_loss: 0.44543638825416565
train_iter_loss: 0.366351842880249
train_iter_loss: 0.3995491862297058
train_iter_loss: 0.4005756676197052
train_iter_loss: 0.4870273172855377
train_iter_loss: 0.4124458134174347
train_iter_loss: 0.42186591029167175
train_iter_loss: 0.5101510882377625
train_iter_loss: 0.43991619348526
train_iter_loss: 0.43985238671302795
train_iter_loss: 0.3853677809238434
train_iter_loss: 0.4226755201816559
train_iter_loss: 0.46564775705337524
train_iter_loss: 0.4410693943500519
train_iter_loss: 0.3861193060874939
train_iter_loss: 0.3989063501358032
train_iter_loss: 0.4335840344429016
train_iter_loss: 0.4111727774143219
train_iter_loss: 0.4413413405418396
train_iter_loss: 0.43840235471725464
train_iter_loss: 0.41649994254112244
train_iter_loss: 0.4335947036743164
train_iter_loss: 0.45756128430366516
train_iter_loss: 0.43010079860687256
train_iter_loss: 0.40839552879333496
train_iter_loss: 0.42032867670059204
train_iter_loss: 0.4102299213409424
train_iter_loss: 0.48927557468414307
train_iter_loss: 0.4512576758861542
train_iter_loss: 0.4426894187927246
train_iter_loss: 0.4491933286190033
train_iter_loss: 0.3854662775993347
train_iter_loss: 0.49932861328125
train_iter_loss: 0.3648717999458313
train_iter_loss: 0.4173460304737091
train_iter_loss: 0.38763198256492615
train_iter_loss: 0.41737931966781616
train_iter_loss: 0.39184728264808655
train_iter_loss: 0.48866012692451477
train_iter_loss: 0.4394129812717438
train_iter_loss: 0.42110878229141235
train_iter_loss: 0.4554729163646698
train_iter_loss: 0.4565780460834503
train_iter_loss: 0.3673926293849945
train_iter_loss: 0.4373324513435364
train_iter_loss: 0.479200154542923
train_iter_loss: 0.4084254205226898
train_iter_loss: 0.5164058208465576
train_iter_loss: 0.5112646222114563
train_iter_loss: 0.4420328736305237
train_iter_loss: 0.4443998634815216
train_iter_loss: 0.4196929931640625
train_iter_loss: 0.4523198902606964
train_iter_loss: 0.43880486488342285
train_iter_loss: 0.4530414044857025
train_iter_loss: 0.44754356145858765
train_iter_loss: 0.47314876317977905
train loss :0.4427
---------------------
Validation seg loss: 0.47502917866661865 at epoch 5
********************
best_val_epoch_loss:  0.47502917866661865
MODEL UPDATED
epoch =      6/  1000, exp = train
train_iter_loss: 0.4346666932106018
train_iter_loss: 0.4539876878261566
train_iter_loss: 0.3849094808101654
train_iter_loss: 0.447126179933548
train_iter_loss: 0.3964924216270447
train_iter_loss: 0.4577525556087494
train_iter_loss: 0.4367176294326782
train_iter_loss: 0.4011434018611908
train_iter_loss: 0.44177937507629395
train_iter_loss: 0.43573763966560364
train_iter_loss: 0.3938858211040497
train_iter_loss: 0.49448490142822266
train_iter_loss: 0.4199620485305786
train_iter_loss: 0.41152891516685486
train_iter_loss: 0.44911330938339233
train_iter_loss: 0.39330828189849854
train_iter_loss: 0.4413944482803345
train_iter_loss: 0.4304984509944916
train_iter_loss: 0.46158114075660706
train_iter_loss: 0.42202138900756836
train_iter_loss: 0.41961345076560974
train_iter_loss: 0.45181602239608765
train_iter_loss: 0.46093884110450745
train_iter_loss: 0.3012147843837738
train_iter_loss: 0.4205416738986969
train_iter_loss: 0.4101157784461975
train_iter_loss: 0.43899914622306824
train_iter_loss: 0.41883939504623413
train_iter_loss: 0.42501941323280334
train_iter_loss: 0.4777964651584625
train_iter_loss: 0.41748183965682983
train_iter_loss: 0.42510709166526794
train_iter_loss: 0.42552438378334045
train_iter_loss: 0.477438747882843
train_iter_loss: 0.41000014543533325
train_iter_loss: 0.4441032111644745
train_iter_loss: 0.4874158501625061
train_iter_loss: 0.44173240661621094
train_iter_loss: 0.40693187713623047
train_iter_loss: 0.4154270887374878
train_iter_loss: 0.38466259837150574
train_iter_loss: 0.42450690269470215
train_iter_loss: 0.38238656520843506
train_iter_loss: 0.4323387145996094
train_iter_loss: 0.4482121169567108
train_iter_loss: 0.3840152621269226
train_iter_loss: 0.49691540002822876
train_iter_loss: 0.4182431995868683
train_iter_loss: 0.3965299427509308
train_iter_loss: 0.39446672797203064
train_iter_loss: 0.4230394661426544
train_iter_loss: 0.44195014238357544
train_iter_loss: 0.44367748498916626
train_iter_loss: 0.4576905369758606
train_iter_loss: 0.4596407115459442
train_iter_loss: 0.42921245098114014
train_iter_loss: 0.41255176067352295
train_iter_loss: 0.42044663429260254
train_iter_loss: 0.4424899220466614
train_iter_loss: 0.46641626954078674
train_iter_loss: 0.4588526785373688
train_iter_loss: 0.44130370020866394
train_iter_loss: 0.46902599930763245
train_iter_loss: 0.3490103781223297
train_iter_loss: 0.42037540674209595
train_iter_loss: 0.43752720952033997
train_iter_loss: 0.4435403347015381
train_iter_loss: 0.4037487506866455
train_iter_loss: 0.41557788848876953
train_iter_loss: 0.4143003821372986
train_iter_loss: 0.3995051980018616
train_iter_loss: 0.45261526107788086
train_iter_loss: 0.4071253538131714
train_iter_loss: 0.5082720518112183
train_iter_loss: 0.4130077660083771
train_iter_loss: 0.4262891113758087
train_iter_loss: 0.35525718331336975
train_iter_loss: 0.44589143991470337
train_iter_loss: 0.43926841020584106
train_iter_loss: 0.44784125685691833
train_iter_loss: 0.4172985553741455
train_iter_loss: 0.4246654510498047
train_iter_loss: 0.3972482681274414
train_iter_loss: 0.3608398139476776
train_iter_loss: 0.40048134326934814
train_iter_loss: 0.4220445156097412
train_iter_loss: 0.4084794819355011
train_iter_loss: 0.4160648584365845
train_iter_loss: 0.4147438108921051
train_iter_loss: 0.4205375611782074
train_iter_loss: 0.4100986123085022
train_iter_loss: 0.43450093269348145
train_iter_loss: 0.40007108449935913
train_iter_loss: 0.38915902376174927
train_iter_loss: 0.410586953163147
train_iter_loss: 0.43037644028663635
train_iter_loss: 0.4327755272388458
train_iter_loss: 0.3734850287437439
train_iter_loss: 0.4033057987689972
train_iter_loss: 0.42454302310943604
train_iter_loss: 0.34999820590019226
train_iter_loss: 0.40592873096466064
train_iter_loss: 0.42402613162994385
train_iter_loss: 0.404257208108902
train_iter_loss: 0.379456490278244
train_iter_loss: 0.42135345935821533
train_iter_loss: 0.40276530385017395
train_iter_loss: 0.4590899348258972
train_iter_loss: 0.4027833640575409
train_iter_loss: 0.4350534677505493
train_iter_loss: 0.4118404984474182
train_iter_loss: 0.44423991441726685
train_iter_loss: 0.4788978397846222
train_iter_loss: 0.4742352068424225
train_iter_loss: 0.4679717421531677
train_iter_loss: 0.4899708926677704
train_iter_loss: 0.3919752836227417
train_iter_loss: 0.4614717662334442
train_iter_loss: 0.42693138122558594
train_iter_loss: 0.3689383566379547
train_iter_loss: 0.45566752552986145
train_iter_loss: 0.4108622968196869
train_iter_loss: 0.40788936614990234
train_iter_loss: 0.40986958146095276
train_iter_loss: 0.4148954153060913
train_iter_loss: 0.4315989911556244
train_iter_loss: 0.44548362493515015
train_iter_loss: 0.41499391198158264
train_iter_loss: 0.49903032183647156
train_iter_loss: 0.3975500464439392
train_iter_loss: 0.3978893458843231
train_iter_loss: 0.39980968832969666
train_iter_loss: 0.4016689360141754
train_iter_loss: 0.4465040862560272
train_iter_loss: 0.4196746349334717
train_iter_loss: 0.42824089527130127
train_iter_loss: 0.4258255958557129
train_iter_loss: 0.47807398438453674
train_iter_loss: 0.42993512749671936
train_iter_loss: 0.44598445296287537
train_iter_loss: 0.3956528306007385
train_iter_loss: 0.455206960439682
train_iter_loss: 0.4075651168823242
train_iter_loss: 0.43142375349998474
train_iter_loss: 0.38093024492263794
train_iter_loss: 0.3951566219329834
train_iter_loss: 0.42798036336898804
train_iter_loss: 0.40088266134262085
train_iter_loss: 0.47522398829460144
train_iter_loss: 0.4165128171443939
train_iter_loss: 0.416486918926239
train_iter_loss: 0.40004411339759827
train_iter_loss: 0.43006613850593567
train_iter_loss: 0.41153645515441895
train_iter_loss: 0.36179402470588684
train_iter_loss: 0.4338063597679138
train_iter_loss: 0.40819913148880005
train_iter_loss: 0.4325929284095764
train_iter_loss: 0.3931892216205597
train_iter_loss: 0.40902000665664673
train_iter_loss: 0.37028422951698303
train_iter_loss: 0.44339945912361145
train_iter_loss: 0.5001686215400696
train_iter_loss: 0.3999623954296112
train_iter_loss: 0.41148144006729126
train_iter_loss: 0.40467604994773865
train_iter_loss: 0.43621137738227844
train_iter_loss: 0.41235777735710144
train_iter_loss: 0.38866126537323
train_iter_loss: 0.3824710249900818
train_iter_loss: 0.4085247218608856
train_iter_loss: 0.44582420587539673
train_iter_loss: 0.4078409969806671
train_iter_loss: 0.40104061365127563
train_iter_loss: 0.41995546221733093
train_iter_loss: 0.47363924980163574
train_iter_loss: 0.3886590600013733
train_iter_loss: 0.3741503357887268
train_iter_loss: 0.35293617844581604
train_iter_loss: 0.4315020740032196
train_iter_loss: 0.46649548411369324
train_iter_loss: 0.4282311201095581
train_iter_loss: 0.4005257189273834
train_iter_loss: 0.42819082736968994
train_iter_loss: 0.3844129741191864
train_iter_loss: 0.3982730805873871
train_iter_loss: 0.398944616317749
train_iter_loss: 0.3843082785606384
train_iter_loss: 0.3868355453014374
train_iter_loss: 0.3647211492061615
train_iter_loss: 0.42584991455078125
train_iter_loss: 0.38694363832473755
train_iter_loss: 0.39493393898010254
train_iter_loss: 0.42215824127197266
train_iter_loss: 0.3950268030166626
train_iter_loss: 0.38309556245803833
train_iter_loss: 0.42376160621643066
train_iter_loss: 0.3712383806705475
train_iter_loss: 0.46026191115379333
train_iter_loss: 0.3542221784591675
train loss :0.4229
---------------------
Validation seg loss: 0.4373539568118329 at epoch 6
********************
best_val_epoch_loss:  0.4373539568118329
MODEL UPDATED
epoch =      7/  1000, exp = train
train_iter_loss: 0.45084822177886963
train_iter_loss: 0.4012792110443115
train_iter_loss: 0.3758343458175659
train_iter_loss: 0.42278632521629333
train_iter_loss: 0.42116183042526245
train_iter_loss: 0.38610732555389404
train_iter_loss: 0.4168148338794708
train_iter_loss: 0.43624383211135864
train_iter_loss: 0.4117967188358307
train_iter_loss: 0.3993814289569855
train_iter_loss: 0.39506810903549194
train_iter_loss: 0.4732344448566437
train_iter_loss: 0.37645265460014343
train_iter_loss: 0.4356597363948822
train_iter_loss: 0.3892977237701416
train_iter_loss: 0.4433714747428894
train_iter_loss: 0.39749598503112793
train_iter_loss: 0.4215324819087982
train_iter_loss: 0.39157119393348694
train_iter_loss: 0.43279263377189636
train_iter_loss: 0.4221965968608856
train_iter_loss: 0.4052000045776367
train_iter_loss: 0.4779509902000427
train_iter_loss: 0.4005984663963318
train_iter_loss: 0.37611955404281616
train_iter_loss: 0.4120417535305023
train_iter_loss: 0.3770015835762024
train_iter_loss: 0.43596625328063965
train_iter_loss: 0.38292911648750305
train_iter_loss: 0.4041319191455841
train_iter_loss: 0.4126555025577545
train_iter_loss: 0.39625313878059387
train_iter_loss: 0.37766194343566895
train_iter_loss: 0.42093655467033386
train_iter_loss: 0.3983847498893738
train_iter_loss: 0.41878142952919006
train_iter_loss: 0.4319126605987549
train_iter_loss: 0.3775143325328827
train_iter_loss: 0.4184776842594147
train_iter_loss: 0.3942951261997223
train_iter_loss: 0.4028926491737366
train_iter_loss: 0.4054737687110901
train_iter_loss: 0.39854758977890015
train_iter_loss: 0.40245217084884644
train_iter_loss: 0.4628511965274811
train_iter_loss: 0.3663673400878906
train_iter_loss: 0.4233701825141907
train_iter_loss: 0.38668960332870483
train_iter_loss: 0.39784735441207886
train_iter_loss: 0.416996568441391
train_iter_loss: 0.4328247308731079
train_iter_loss: 0.3928684592247009
train_iter_loss: 0.3852832317352295
train_iter_loss: 0.41892245411872864
train_iter_loss: 0.4386884868144989
train_iter_loss: 0.45403507351875305
train_iter_loss: 0.38567841053009033
train_iter_loss: 0.43039578199386597
train_iter_loss: 0.3809043765068054
train_iter_loss: 0.3782599866390228
train_iter_loss: 0.4787176847457886
train_iter_loss: 0.40485283732414246
train_iter_loss: 0.4214200973510742
train_iter_loss: 0.40007877349853516
train_iter_loss: 0.37042492628097534
train_iter_loss: 0.44749176502227783
train_iter_loss: 0.43711718916893005
train_iter_loss: 0.43105778098106384
train_iter_loss: 0.3895733654499054
train_iter_loss: 0.4105703830718994
train_iter_loss: 0.37561798095703125
train_iter_loss: 0.3805142045021057
train_iter_loss: 0.40662920475006104
train_iter_loss: 0.4212326407432556
train_iter_loss: 0.4094262719154358
train_iter_loss: 0.4603363573551178
train_iter_loss: 0.4065251052379608
train_iter_loss: 0.45135384798049927
train_iter_loss: 0.41252216696739197
train_iter_loss: 0.4165876805782318
train_iter_loss: 0.47697049379348755
train_iter_loss: 0.42932382225990295
train_iter_loss: 0.37565848231315613
train_iter_loss: 0.39078289270401
train_iter_loss: 0.4022254943847656
train_iter_loss: 0.3846672773361206
train_iter_loss: 0.4047768712043762
train_iter_loss: 0.3858424723148346
train_iter_loss: 0.4111475348472595
train_iter_loss: 0.43651247024536133
train_iter_loss: 0.406263142824173
train_iter_loss: 0.3823409676551819
train_iter_loss: 0.3641829788684845
train_iter_loss: 0.38481882214546204
train_iter_loss: 0.2967362701892853
train_iter_loss: 0.4497821033000946
train_iter_loss: 0.337407648563385
train_iter_loss: 0.391909658908844
train_iter_loss: 0.3620712161064148
train_iter_loss: 0.3939802050590515
train_iter_loss: 0.4278905689716339
train_iter_loss: 0.36882686614990234
train_iter_loss: 0.3631325364112854
train_iter_loss: 0.3890158534049988
train_iter_loss: 0.401276171207428
train_iter_loss: 0.4163120985031128
train_iter_loss: 0.42972126603126526
train_iter_loss: 0.3948326110839844
train_iter_loss: 0.3390769064426422
train_iter_loss: 0.3879398703575134
train_iter_loss: 0.3802824914455414
train_iter_loss: 0.38316670060157776
train_iter_loss: 0.4260641634464264
train_iter_loss: 0.4587436020374298
train_iter_loss: 0.36833637952804565
train_iter_loss: 0.40352609753608704
train_iter_loss: 0.42801082134246826
train_iter_loss: 0.41108107566833496
train_iter_loss: 0.4019429385662079
train_iter_loss: 0.4103112816810608
train_iter_loss: 0.4023418426513672
train_iter_loss: 0.42899036407470703
train_iter_loss: 0.4129326343536377
train_iter_loss: 0.3891420066356659
train_iter_loss: 0.4042254090309143
train_iter_loss: 0.3904827833175659
train_iter_loss: 0.42751479148864746
train_iter_loss: 0.4376371502876282
train_iter_loss: 0.47397381067276
train_iter_loss: 0.3798905909061432
train_iter_loss: 0.43082085251808167
train_iter_loss: 0.42418166995048523
train_iter_loss: 0.4111776053905487
train_iter_loss: 0.40178215503692627
train_iter_loss: 0.38984182476997375
train_iter_loss: 0.4488733410835266
train_iter_loss: 0.3787268102169037
train_iter_loss: 0.3994159698486328
train_iter_loss: 0.4249059855937958
train_iter_loss: 0.3752349615097046
train_iter_loss: 0.3617827892303467
train_iter_loss: 0.3769344985485077
train_iter_loss: 0.396468847990036
train_iter_loss: 0.38091421127319336
train_iter_loss: 0.36903414130210876
train_iter_loss: 0.367534339427948
train_iter_loss: 0.39000123739242554
train_iter_loss: 0.3920149505138397
train_iter_loss: 0.4281812906265259
train_iter_loss: 0.39001375436782837
train_iter_loss: 0.4168906509876251
train_iter_loss: 0.37433934211730957
train_iter_loss: 0.4248362183570862
train_iter_loss: 0.3958762586116791
train_iter_loss: 0.3254467844963074
train_iter_loss: 0.4019194543361664
train_iter_loss: 0.40320536494255066
train_iter_loss: 0.4356449246406555
train_iter_loss: 0.40231937170028687
train_iter_loss: 0.39443671703338623
train_iter_loss: 0.42894676327705383
train_iter_loss: 0.42031919956207275
train_iter_loss: 0.3903447389602661
train_iter_loss: 0.40847915410995483
train_iter_loss: 0.4688626527786255
train_iter_loss: 0.4012267589569092
train_iter_loss: 0.4207395613193512
train_iter_loss: 0.4144727885723114
train_iter_loss: 0.3676331639289856
train_iter_loss: 0.393371045589447
train_iter_loss: 0.38605988025665283
train_iter_loss: 0.38736847043037415
train_iter_loss: 0.4185672402381897
train_iter_loss: 0.3949326276779175
train_iter_loss: 0.38158881664276123
train_iter_loss: 0.38180485367774963
train_iter_loss: 0.3481479287147522
train_iter_loss: 0.393288254737854
train_iter_loss: 0.4028562605381012
train_iter_loss: 0.379098504781723
train_iter_loss: 0.3015744686126709
train_iter_loss: 0.3024410903453827
train_iter_loss: 0.4152510166168213
train_iter_loss: 0.45845842361450195
train_iter_loss: 0.36661574244499207
train_iter_loss: 0.38889995217323303
train_iter_loss: 0.38776639103889465
train_iter_loss: 0.39448070526123047
train_iter_loss: 0.3852545917034149
train_iter_loss: 0.3765237033367157
train_iter_loss: 0.417940616607666
train_iter_loss: 0.3942244350910187
train_iter_loss: 0.4561002552509308
train_iter_loss: 0.40337488055229187
train_iter_loss: 0.3724692165851593
train_iter_loss: 0.40566185116767883
train_iter_loss: 0.3728931248188019
train_iter_loss: 0.37843531370162964
train_iter_loss: 0.4068155288696289
train_iter_loss: 0.44896644353866577
train loss :0.4054
---------------------
Validation seg loss: 0.41558964044417973 at epoch 7
********************
best_val_epoch_loss:  0.41558964044417973
MODEL UPDATED
epoch =      8/  1000, exp = train
train_iter_loss: 0.4005547761917114
train_iter_loss: 0.43839380145072937
train_iter_loss: 0.41223183274269104
train_iter_loss: 0.37661901116371155
train_iter_loss: 0.41172146797180176
train_iter_loss: 0.3756006062030792
train_iter_loss: 0.41718557476997375
train_iter_loss: 0.3815836012363434
train_iter_loss: 0.39773643016815186
train_iter_loss: 0.3405117392539978
train_iter_loss: 0.4005470871925354
train_iter_loss: 0.4091370403766632
train_iter_loss: 0.34838834404945374
train_iter_loss: 0.402252197265625
train_iter_loss: 0.37652164697647095
train_iter_loss: 0.31978508830070496
train_iter_loss: 0.3566960096359253
train_iter_loss: 0.41748034954071045
train_iter_loss: 0.39654406905174255
train_iter_loss: 0.35028964281082153
train_iter_loss: 0.412356972694397
train_iter_loss: 0.41653013229370117
train_iter_loss: 0.42365747690200806
train_iter_loss: 0.39754146337509155
train_iter_loss: 0.35628703236579895
train_iter_loss: 0.37051528692245483
train_iter_loss: 0.4092235565185547
train_iter_loss: 0.38835567235946655
train_iter_loss: 0.3913334310054779
train_iter_loss: 0.38126420974731445
train_iter_loss: 0.3449954390525818
train_iter_loss: 0.3754199743270874
train_iter_loss: 0.40704843401908875
train_iter_loss: 0.3605702519416809
train_iter_loss: 0.34568825364112854
train_iter_loss: 0.42330649495124817
train_iter_loss: 0.3699522018432617
train_iter_loss: 0.42300644516944885
train_iter_loss: 0.384662389755249
train_iter_loss: 0.4055447578430176
train_iter_loss: 0.37302911281585693
train_iter_loss: 0.3440593481063843
train_iter_loss: 0.35396960377693176
train_iter_loss: 0.3729369640350342
train_iter_loss: 0.3434608578681946
train_iter_loss: 0.37900903820991516
train_iter_loss: 0.4048440456390381
train_iter_loss: 0.42816653847694397
train_iter_loss: 0.41153958439826965
train_iter_loss: 0.3836710751056671
train_iter_loss: 0.42521774768829346
train_iter_loss: 0.3755638003349304
train_iter_loss: 0.39255377650260925
train_iter_loss: 0.37460246682167053
train_iter_loss: 0.3859078884124756
train_iter_loss: 0.3371659219264984
train_iter_loss: 0.4215697944164276
train_iter_loss: 0.3716734051704407
train_iter_loss: 0.3633626401424408
train_iter_loss: 0.3905234634876251
train_iter_loss: 0.42260342836380005
train_iter_loss: 0.396712064743042
train_iter_loss: 0.42205432057380676
train_iter_loss: 0.38432976603507996
train_iter_loss: 0.356784462928772
train_iter_loss: 0.4050467908382416
train_iter_loss: 0.3975772261619568
train_iter_loss: 0.39507871866226196
train_iter_loss: 0.43472087383270264
train_iter_loss: 0.3269535005092621
train_iter_loss: 0.39005064964294434
train_iter_loss: 0.36522647738456726
train_iter_loss: 0.3922705352306366
train_iter_loss: 0.38172802329063416
train_iter_loss: 0.42471569776535034
train_iter_loss: 0.3637741804122925
train_iter_loss: 0.3669886887073517
train_iter_loss: 0.41928738355636597
train_iter_loss: 0.3994150161743164
train_iter_loss: 0.37902429699897766
train_iter_loss: 0.37856194376945496
train_iter_loss: 0.4228307008743286
train_iter_loss: 0.3897445499897003
train_iter_loss: 0.3744632601737976
train_iter_loss: 0.4067687392234802
train_iter_loss: 0.37995409965515137
train_iter_loss: 0.42186105251312256
train_iter_loss: 0.37643176317214966
train_iter_loss: 0.38152629137039185
train_iter_loss: 0.3746539354324341
train_iter_loss: 0.36167651414871216
train_iter_loss: 0.39601776003837585
train_iter_loss: 0.4068078398704529
train_iter_loss: 0.4368997812271118
train_iter_loss: 0.3968169093132019
train_iter_loss: 0.34293079376220703
train_iter_loss: 0.3812464773654938
train_iter_loss: 0.38319888710975647
train_iter_loss: 0.3762807548046112
train_iter_loss: 0.48189669847488403
train_iter_loss: 0.4247710108757019
train_iter_loss: 0.37440162897109985
train_iter_loss: 0.4365021586418152
train_iter_loss: 0.4274648129940033
train_iter_loss: 0.42015817761421204
train_iter_loss: 0.3914608359336853
train_iter_loss: 0.40010127425193787
train_iter_loss: 0.3822093904018402
train_iter_loss: 0.391357958316803
train_iter_loss: 0.4081505537033081
train_iter_loss: 0.38320261240005493
train_iter_loss: 0.3478395640850067
train_iter_loss: 0.35463401675224304
train_iter_loss: 0.38343295454978943
train_iter_loss: 0.3545598089694977
train_iter_loss: 0.3855108916759491
train_iter_loss: 0.38972964882850647
train_iter_loss: 0.4039856791496277
train_iter_loss: 0.4128974676132202
train_iter_loss: 0.36449721455574036
train_iter_loss: 0.37767162919044495
train_iter_loss: 0.37387847900390625
train_iter_loss: 0.3722588121891022
train_iter_loss: 0.3645986318588257
train_iter_loss: 0.3514224886894226
train_iter_loss: 0.4238992929458618
train_iter_loss: 0.3897002935409546
train_iter_loss: 0.4360658526420593
train_iter_loss: 0.3863934576511383
train_iter_loss: 0.42013731598854065
train_iter_loss: 0.44099190831184387
train_iter_loss: 0.41470181941986084
train_iter_loss: 0.4013429582118988
train_iter_loss: 0.3728692829608917
train_iter_loss: 0.38297489285469055
train_iter_loss: 0.36155644059181213
train_iter_loss: 0.3727559447288513
train_iter_loss: 0.38051462173461914
train_iter_loss: 0.40738922357559204
train_iter_loss: 0.34592950344085693
train_iter_loss: 0.3889414370059967
train_iter_loss: 0.396955281496048
train_iter_loss: 0.34009850025177
train_iter_loss: 0.37508559226989746
train_iter_loss: 0.4658687114715576
train_iter_loss: 0.3797302544116974
train_iter_loss: 0.3719326853752136
train_iter_loss: 0.35041046142578125
train_iter_loss: 0.36867520213127136
train_iter_loss: 0.3880055248737335
train_iter_loss: 0.3518349528312683
train_iter_loss: 0.4352739453315735
train_iter_loss: 0.36084631085395813
train_iter_loss: 0.3637208342552185
train_iter_loss: 0.3882073760032654
train_iter_loss: 0.4211414158344269
train_iter_loss: 0.32284459471702576
train_iter_loss: 0.3893527388572693
train_iter_loss: 0.38118186593055725
train_iter_loss: 0.35820886492729187
train_iter_loss: 0.36188867688179016
train_iter_loss: 0.38455715775489807
train_iter_loss: 0.36500802636146545
train_iter_loss: 0.3707364797592163
train_iter_loss: 0.36601975560188293
train_iter_loss: 0.3728097379207611
train_iter_loss: 0.3732588589191437
train_iter_loss: 0.47860756516456604
train_iter_loss: 0.40826454758644104
train_iter_loss: 0.37826380133628845
train_iter_loss: 0.4234296977519989
train_iter_loss: 0.35391995310783386
train_iter_loss: 0.3806155323982239
train_iter_loss: 0.3703667223453522
train_iter_loss: 0.357802152633667
train_iter_loss: 0.37902745604515076
train_iter_loss: 0.38473808765411377
train_iter_loss: 0.3943406641483307
train_iter_loss: 0.3761409819126129
train_iter_loss: 0.350496768951416
train_iter_loss: 0.37276166677474976
train_iter_loss: 0.4183274805545807
train_iter_loss: 0.3670629560947418
train_iter_loss: 0.40044400095939636
train_iter_loss: 0.3764704465866089
train_iter_loss: 0.39521342515945435
train_iter_loss: 0.4013656973838806
train_iter_loss: 0.43909022212028503
train_iter_loss: 0.3627167344093323
train_iter_loss: 0.3550131618976593
train_iter_loss: 0.35325175523757935
train_iter_loss: 0.3712628185749054
train_iter_loss: 0.3943087160587311
train_iter_loss: 0.3823997676372528
train_iter_loss: 0.4099363684654236
train_iter_loss: 0.4240177273750305
train_iter_loss: 0.3843713402748108
train_iter_loss: 0.36713576316833496
train_iter_loss: 0.387384831905365
train_iter_loss: 0.3609376847743988
train loss :0.3891
---------------------
Validation seg loss: 0.40733278837968717 at epoch 8
********************
best_val_epoch_loss:  0.40733278837968717
MODEL UPDATED
epoch =      9/  1000, exp = train
train_iter_loss: 0.36846309900283813
train_iter_loss: 0.32196807861328125
train_iter_loss: 0.3955675959587097
train_iter_loss: 0.330963671207428
train_iter_loss: 0.4596465528011322
train_iter_loss: 0.36423325538635254
train_iter_loss: 0.3568987250328064
train_iter_loss: 0.3106340169906616
train_iter_loss: 0.3793223798274994
train_iter_loss: 0.2994389832019806
train_iter_loss: 0.3437580466270447
train_iter_loss: 0.3902408182621002
train_iter_loss: 0.49127858877182007
train_iter_loss: 0.3719654679298401
train_iter_loss: 0.4173378646373749
train_iter_loss: 0.43205443024635315
train_iter_loss: 0.3617820143699646
train_iter_loss: 0.39684751629829407
train_iter_loss: 0.3293514549732208
train_iter_loss: 0.40584859251976013
train_iter_loss: 0.3925970494747162
train_iter_loss: 0.3970493972301483
train_iter_loss: 0.37082451581954956
train_iter_loss: 0.36082208156585693
train_iter_loss: 0.3332931101322174
train_iter_loss: 0.4321489930152893
train_iter_loss: 0.36867713928222656
train_iter_loss: 0.3777967393398285
train_iter_loss: 0.3796313405036926
train_iter_loss: 0.36926060914993286
train_iter_loss: 0.34292685985565186
train_iter_loss: 0.3638390004634857
train_iter_loss: 0.365609347820282
train_iter_loss: 0.3267579674720764
train_iter_loss: 0.3886364698410034
train_iter_loss: 0.3654012680053711
train_iter_loss: 0.4132827818393707
train_iter_loss: 0.420611709356308
train_iter_loss: 0.4220510423183441
train_iter_loss: 0.3810538947582245
train_iter_loss: 0.3790561258792877
train_iter_loss: 0.34957239031791687
train_iter_loss: 0.37579697370529175
train_iter_loss: 0.3616626560688019
train_iter_loss: 0.36935344338417053
train_iter_loss: 0.38411945104599
train_iter_loss: 0.363411545753479
train_iter_loss: 0.3748337924480438
train_iter_loss: 0.3520364463329315
train_iter_loss: 0.3700038492679596
train_iter_loss: 0.3729889392852783
train_iter_loss: 0.3933143615722656
train_iter_loss: 0.416409432888031
train_iter_loss: 0.4192321300506592
train_iter_loss: 0.36589932441711426
train_iter_loss: 0.376010537147522
train_iter_loss: 0.3659152686595917
train_iter_loss: 0.36681118607521057
train_iter_loss: 0.37533509731292725
train_iter_loss: 0.3742799460887909
train_iter_loss: 0.3626924455165863
train_iter_loss: 0.3681809902191162
train_iter_loss: 0.36074918508529663
train_iter_loss: 0.385991632938385
train_iter_loss: 0.333300918340683
train_iter_loss: 0.3838863670825958
train_iter_loss: 0.36167359352111816
train_iter_loss: 0.4060567021369934
train_iter_loss: 0.41238531470298767
train_iter_loss: 0.3335145115852356
train_iter_loss: 0.3529675304889679
train_iter_loss: 0.3880665898323059
train_iter_loss: 0.3512423038482666
train_iter_loss: 0.34054356813430786
train_iter_loss: 0.3308763802051544
train_iter_loss: 0.3779582977294922
train_iter_loss: 0.32428479194641113
train_iter_loss: 0.3434563875198364
train_iter_loss: 0.3421982526779175
train_iter_loss: 0.39346861839294434
train_iter_loss: 0.36887070536613464
train_iter_loss: 0.34755179286003113
train_iter_loss: 0.3355545997619629
train_iter_loss: 0.3657338321208954
train_iter_loss: 0.3738274574279785
train_iter_loss: 0.38065484166145325
train_iter_loss: 0.38687312602996826
train_iter_loss: 0.36673033237457275
train_iter_loss: 0.3958679437637329
train_iter_loss: 0.40406477451324463
train_iter_loss: 0.4141160547733307
train_iter_loss: 0.42319539189338684
train_iter_loss: 0.3991723358631134
train_iter_loss: 0.34542056918144226
train_iter_loss: 0.36815181374549866
train_iter_loss: 0.43892842531204224
train_iter_loss: 0.41461244225502014
train_iter_loss: 0.39497727155685425
train_iter_loss: 0.3389951288700104
train_iter_loss: 0.38908445835113525
train_iter_loss: 0.4115924835205078
train_iter_loss: 0.35800403356552124
train_iter_loss: 0.34073132276535034
train_iter_loss: 0.3326752781867981
train_iter_loss: 0.408136248588562
train_iter_loss: 0.3509189188480377
train_iter_loss: 0.4614633619785309
train_iter_loss: 0.4663091003894806
train_iter_loss: 0.3517075777053833
train_iter_loss: 0.33159002661705017
train_iter_loss: 0.3576560616493225
train_iter_loss: 0.3899571895599365
train_iter_loss: 0.3604922890663147
train_iter_loss: 0.4284657835960388
train_iter_loss: 0.4298792779445648
train_iter_loss: 0.4785080850124359
train_iter_loss: 0.3341214954853058
train_iter_loss: 0.383845716714859
train_iter_loss: 0.38159239292144775
train_iter_loss: 0.3620520830154419
train_iter_loss: 0.3743133842945099
train_iter_loss: 0.37814903259277344
train_iter_loss: 0.3605552017688751
train_iter_loss: 0.37052613496780396
train_iter_loss: 0.3346601724624634
train_iter_loss: 0.4113040268421173
train_iter_loss: 0.3035135567188263
train_iter_loss: 0.3280986249446869
train_iter_loss: 0.40139240026474
train_iter_loss: 0.359261155128479
train_iter_loss: 0.34476396441459656
train_iter_loss: 0.36474499106407166
train_iter_loss: 0.37220877408981323
train_iter_loss: 0.39341825246810913
train_iter_loss: 0.397919237613678
train_iter_loss: 0.35564330220222473
train_iter_loss: 0.41271018981933594
train_iter_loss: 0.3989742696285248
train_iter_loss: 0.37696602940559387
train_iter_loss: 0.34240198135375977
train_iter_loss: 0.35206377506256104
train_iter_loss: 0.3398641049861908
train_iter_loss: 0.4424161911010742
train_iter_loss: 0.38471299409866333
train_iter_loss: 0.34763815999031067
train_iter_loss: 0.3880681097507477
train_iter_loss: 0.3452482521533966
train_iter_loss: 0.39571085572242737
train_iter_loss: 0.37002840638160706
train_iter_loss: 0.3575647175312042
train_iter_loss: 0.3940833508968353
train_iter_loss: 0.3587585389614105
train_iter_loss: 0.352389931678772
train_iter_loss: 0.31475207209587097
train_iter_loss: 0.3452911376953125
train_iter_loss: 0.35940057039260864
train_iter_loss: 0.2819187343120575
train_iter_loss: 0.3661366105079651
train_iter_loss: 0.3337918221950531
train_iter_loss: 0.3915306031703949
train_iter_loss: 0.35796990990638733
train_iter_loss: 0.36616963148117065
train_iter_loss: 0.3760645389556885
train_iter_loss: 0.4025290906429291
train_iter_loss: 0.35558944940567017
train_iter_loss: 0.3771381974220276
train_iter_loss: 0.3023292124271393
train_iter_loss: 0.4005073010921478
train_iter_loss: 0.3856344521045685
train_iter_loss: 0.3483370840549469
train_iter_loss: 0.34159770607948303
train_iter_loss: 0.34356269240379333
train_iter_loss: 0.36906009912490845
train_iter_loss: 0.377946138381958
train_iter_loss: 0.4487326741218567
train_iter_loss: 0.45951753854751587
train_iter_loss: 0.3597922921180725
train_iter_loss: 0.42547664046287537
train_iter_loss: 0.40033459663391113
train_iter_loss: 0.3866048753261566
train_iter_loss: 0.38010159134864807
train_iter_loss: 0.38514599204063416
train_iter_loss: 0.3588899075984955
train_iter_loss: 0.3819569945335388
train_iter_loss: 0.32154783606529236
train_iter_loss: 0.3751503825187683
train_iter_loss: 0.34209543466567993
train_iter_loss: 0.3656741678714752
train_iter_loss: 0.38025861978530884
train_iter_loss: 0.36754655838012695
train_iter_loss: 0.3785870373249054
train_iter_loss: 0.35785776376724243
train_iter_loss: 0.38179007172584534
train_iter_loss: 0.342681348323822
train_iter_loss: 0.3495529890060425
train_iter_loss: 0.38404202461242676
train_iter_loss: 0.3578645586967468
train_iter_loss: 0.33966904878616333
train_iter_loss: 0.40565720200538635
train_iter_loss: 0.3210952579975128
train loss :0.3754
---------------------
Validation seg loss: 0.3939066886339547 at epoch 9
********************
best_val_epoch_loss:  0.3939066886339547
MODEL UPDATED
epoch =     10/  1000, exp = train
train_iter_loss: 0.39524999260902405
train_iter_loss: 0.3242207169532776
train_iter_loss: 0.4063881039619446
train_iter_loss: 0.3504330515861511
train_iter_loss: 0.3568790555000305
train_iter_loss: 0.3348281681537628
train_iter_loss: 0.3505163788795471
train_iter_loss: 0.3797861337661743
train_iter_loss: 0.3620631694793701
train_iter_loss: 0.33883097767829895
train_iter_loss: 0.40130749344825745
train_iter_loss: 0.3763715624809265
train_iter_loss: 0.3602139353752136
train_iter_loss: 0.3676667809486389
train_iter_loss: 0.38212475180625916
train_iter_loss: 0.40521228313446045
train_iter_loss: 0.3884154260158539
train_iter_loss: 0.38309746980667114
train_iter_loss: 0.3196147382259369
train_iter_loss: 0.37498024106025696
train_iter_loss: 0.37147587537765503
train_iter_loss: 0.3543035686016083
train_iter_loss: 0.35565635561943054
train_iter_loss: 0.3105756640434265
train_iter_loss: 0.39108407497406006
train_iter_loss: 0.3793705701828003
train_iter_loss: 0.40033337473869324
train_iter_loss: 0.37327513098716736
train_iter_loss: 0.3582136631011963
train_iter_loss: 0.3915591239929199
train_iter_loss: 0.35247352719306946
train_iter_loss: 0.3664170801639557
train_iter_loss: 0.39739230275154114
train_iter_loss: 0.3392745852470398
train_iter_loss: 0.30992603302001953
train_iter_loss: 0.3984709680080414
train_iter_loss: 0.34032732248306274
train_iter_loss: 0.4104531705379486
train_iter_loss: 0.3250264525413513
train_iter_loss: 0.4290117621421814
train_iter_loss: 0.32880836725234985
train_iter_loss: 0.3398592472076416
train_iter_loss: 0.3483664393424988
train_iter_loss: 0.38978394865989685
train_iter_loss: 0.33538374304771423
train_iter_loss: 0.417408287525177
train_iter_loss: 0.38553735613822937
train_iter_loss: 0.3804931938648224
train_iter_loss: 0.3232737183570862
train_iter_loss: 0.32291141152381897
train_iter_loss: 0.3462643325328827
train_iter_loss: 0.3753393292427063
train_iter_loss: 0.3894715905189514
train_iter_loss: 0.36108240485191345
train_iter_loss: 0.3762219250202179
train_iter_loss: 0.34213143587112427
train_iter_loss: 0.3670834004878998
train_iter_loss: 0.3618539571762085
train_iter_loss: 0.36170175671577454
train_iter_loss: 0.37718746066093445
train_iter_loss: 0.4295266270637512
train_iter_loss: 0.3630234897136688
train_iter_loss: 0.3482434153556824
train_iter_loss: 0.3511638641357422
train_iter_loss: 0.33293387293815613
train_iter_loss: 0.38999298214912415
train_iter_loss: 0.2979990243911743
train_iter_loss: 0.3578214645385742
train_iter_loss: 0.4249235987663269
train_iter_loss: 0.31354737281799316
train_iter_loss: 0.3538852035999298
train_iter_loss: 0.37752142548561096
train_iter_loss: 0.32553115487098694
train_iter_loss: 0.3696550130844116
train_iter_loss: 0.32724061608314514
train_iter_loss: 0.35794979333877563
train_iter_loss: 0.4262787699699402
train_iter_loss: 0.43245387077331543
train_iter_loss: 0.45656654238700867
train_iter_loss: 0.37740445137023926
train_iter_loss: 0.3973821997642517
train_iter_loss: 0.343549519777298
train_iter_loss: 0.4073299467563629
train_iter_loss: 0.3271719217300415
train_iter_loss: 0.3537251651287079
train_iter_loss: 0.4455077648162842
train_iter_loss: 0.39399299025535583
train_iter_loss: 0.37234970927238464
train_iter_loss: 0.3851642310619354
train_iter_loss: 0.3637215197086334
train_iter_loss: 0.38663727045059204
train_iter_loss: 0.332853764295578
train_iter_loss: 0.36349189281463623
train_iter_loss: 0.34279975295066833
train_iter_loss: 0.3361319899559021
train_iter_loss: 0.35344672203063965
train_iter_loss: 0.33890974521636963
train_iter_loss: 0.4319832921028137
train_iter_loss: 0.34089723229408264
train_iter_loss: 0.36419710516929626
train_iter_loss: 0.335837185382843
train_iter_loss: 0.40355488657951355
train_iter_loss: 0.3868366777896881
train_iter_loss: 0.38417741656303406
train_iter_loss: 0.3667939603328705
train_iter_loss: 0.35098451375961304
train_iter_loss: 0.3408592641353607
train_iter_loss: 0.3669528663158417
train_iter_loss: 0.339352011680603
train_iter_loss: 0.3660756051540375
train_iter_loss: 0.34760966897010803
train_iter_loss: 0.340566486120224
train_iter_loss: 0.33911263942718506
train_iter_loss: 0.42252403497695923
train_iter_loss: 0.37739330530166626
train_iter_loss: 0.3586464822292328
train_iter_loss: 0.3477465510368347
train_iter_loss: 0.40464749932289124
train_iter_loss: 0.322467565536499
train_iter_loss: 0.3451122045516968
train_iter_loss: 0.3185367286205292
train_iter_loss: 0.3522515892982483
train_iter_loss: 0.38407406210899353
train_iter_loss: 0.4107372462749481
train_iter_loss: 0.3823913633823395
train_iter_loss: 0.33976396918296814
train_iter_loss: 0.3657587766647339
train_iter_loss: 0.3310544788837433
train_iter_loss: 0.34815075993537903
train_iter_loss: 0.3699911832809448
train_iter_loss: 0.36269721388816833
train_iter_loss: 0.36948421597480774
train_iter_loss: 0.36847221851348877
train_iter_loss: 0.3555484414100647
train_iter_loss: 0.39283645153045654
train_iter_loss: 0.3319132328033447
train_iter_loss: 0.35869649052619934
train_iter_loss: 0.3027089834213257
train_iter_loss: 0.36403030157089233
train_iter_loss: 0.3495349586009979
train_iter_loss: 0.35602715611457825
train_iter_loss: 0.33421993255615234
train_iter_loss: 0.3372904360294342
train_iter_loss: 0.38880300521850586
train_iter_loss: 0.3889557123184204
train_iter_loss: 0.339568555355072
train_iter_loss: 0.3683398365974426
train_iter_loss: 0.35834017395973206
train_iter_loss: 0.40309521555900574
train_iter_loss: 0.33246171474456787
train_iter_loss: 0.3852325677871704
train_iter_loss: 0.400580495595932
train_iter_loss: 0.3374820351600647
train_iter_loss: 0.37920206785202026
train_iter_loss: 0.3434430956840515
train_iter_loss: 0.3904927670955658
train_iter_loss: 0.34212902188301086
train_iter_loss: 0.3469783067703247
train_iter_loss: 0.3541813790798187
train_iter_loss: 0.3382607102394104
train_iter_loss: 0.3431893289089203
train_iter_loss: 0.33093905448913574
train_iter_loss: 0.3534655272960663
train_iter_loss: 0.3714102506637573
train_iter_loss: 0.4040481448173523
train_iter_loss: 0.3380887806415558
train_iter_loss: 0.34486284852027893
train_iter_loss: 0.3615330755710602
train_iter_loss: 0.38303956389427185
train_iter_loss: 0.32166165113449097
train_iter_loss: 0.3322116434574127
train_iter_loss: 0.3255678117275238
train_iter_loss: 0.3266392648220062
train_iter_loss: 0.33248409628868103
train_iter_loss: 0.3443235456943512
train_iter_loss: 0.33906009793281555
train_iter_loss: 0.35032036900520325
train_iter_loss: 0.3016071021556854
train_iter_loss: 0.3434872329235077
train_iter_loss: 0.4917624294757843
train_iter_loss: 0.3984549343585968
train_iter_loss: 0.31573739647865295
train_iter_loss: 0.39458128809928894
train_iter_loss: 0.34711915254592896
train_iter_loss: 0.2959294021129608
train_iter_loss: 0.3575703501701355
train_iter_loss: 0.3312854766845703
train_iter_loss: 0.34403038024902344
train_iter_loss: 0.3673694431781769
train_iter_loss: 0.3578817546367645
train_iter_loss: 0.3445291817188263
train_iter_loss: 0.3190576136112213
train_iter_loss: 0.3558111786842346
train_iter_loss: 0.34545084834098816
train_iter_loss: 0.32811665534973145
train_iter_loss: 0.3308441936969757
train_iter_loss: 0.3797314763069153
train_iter_loss: 0.3714219629764557
train_iter_loss: 0.3235929608345032
train_iter_loss: 0.3431761562824249
train loss :0.3637
---------------------
Validation seg loss: 0.3993103433892412 at epoch 10
epoch =     11/  1000, exp = train
train_iter_loss: 0.38287225365638733
train_iter_loss: 0.33754977583885193
train_iter_loss: 0.3357781767845154
train_iter_loss: 0.3953017592430115
train_iter_loss: 0.35292720794677734
train_iter_loss: 0.4288104176521301
train_iter_loss: 0.3491138815879822
train_iter_loss: 0.37609684467315674
train_iter_loss: 0.4349506199359894
train_iter_loss: 0.36788642406463623
train_iter_loss: 0.3686574399471283
train_iter_loss: 0.3349159359931946
train_iter_loss: 0.36819371581077576
train_iter_loss: 0.3296908140182495
train_iter_loss: 0.3710213005542755
train_iter_loss: 0.38739585876464844
train_iter_loss: 0.3475041091442108
train_iter_loss: 0.3362917900085449
train_iter_loss: 0.33957597613334656
train_iter_loss: 0.3506094515323639
train_iter_loss: 0.31192708015441895
train_iter_loss: 0.3349297046661377
train_iter_loss: 0.3517378568649292
train_iter_loss: 0.32903552055358887
train_iter_loss: 0.3896790146827698
train_iter_loss: 0.36838456988334656
train_iter_loss: 0.36627835035324097
train_iter_loss: 0.30552151799201965
train_iter_loss: 0.3936200439929962
train_iter_loss: 0.3712570071220398
train_iter_loss: 0.3408247232437134
train_iter_loss: 0.31387993693351746
train_iter_loss: 0.32020530104637146
train_iter_loss: 0.30636611580848694
train_iter_loss: 0.34944406151771545
train_iter_loss: 0.33951953053474426
train_iter_loss: 0.3235573470592499
train_iter_loss: 0.3517495393753052
train_iter_loss: 0.30362072587013245
train_iter_loss: 0.3235810697078705
train_iter_loss: 0.39050185680389404
train_iter_loss: 0.44236841797828674
train_iter_loss: 0.3654700517654419
train_iter_loss: 0.3348087966442108
train_iter_loss: 0.4106694757938385
train_iter_loss: 0.33455318212509155
train_iter_loss: 0.3511000871658325
train_iter_loss: 0.34444376826286316
train_iter_loss: 0.35792645812034607
train_iter_loss: 0.3361653685569763
train_iter_loss: 0.38081327080726624
train_iter_loss: 0.3604205548763275
train_iter_loss: 0.4269803762435913
train_iter_loss: 0.34400102496147156
train_iter_loss: 0.34123536944389343
train_iter_loss: 0.32763129472732544
train_iter_loss: 0.36968669295310974
train_iter_loss: 0.33582016825675964
train_iter_loss: 0.36356672644615173
train_iter_loss: 0.36385804414749146
train_iter_loss: 0.33263710141181946
train_iter_loss: 0.33778199553489685
train_iter_loss: 0.3218623995780945
train_iter_loss: 0.3349277675151825
train_iter_loss: 0.33026543259620667
train_iter_loss: 0.2754639983177185
train_iter_loss: 0.3626385033130646
train_iter_loss: 0.33751797676086426
train_iter_loss: 0.43919527530670166
train_iter_loss: 0.3814193606376648
train_iter_loss: 0.3626788854598999
train_iter_loss: 0.3403933048248291
train_iter_loss: 0.2908326983451843
train_iter_loss: 0.39100030064582825
train_iter_loss: 0.35919511318206787
train_iter_loss: 0.33316585421562195
train_iter_loss: 0.33744025230407715
train_iter_loss: 0.40971311926841736
train_iter_loss: 0.3630276322364807
train_iter_loss: 0.3210836350917816
train_iter_loss: 0.33896881341934204
train_iter_loss: 0.2972494065761566
train_iter_loss: 0.40832194685935974
train_iter_loss: 0.33790621161460876
train_iter_loss: 0.3366992473602295
train_iter_loss: 0.34650707244873047
train_iter_loss: 0.369344562292099
train_iter_loss: 0.3874998092651367
train_iter_loss: 0.3274356722831726
train_iter_loss: 0.38651132583618164
train_iter_loss: 0.3159177601337433
train_iter_loss: 0.33896470069885254
train_iter_loss: 0.34724971652030945
train_iter_loss: 0.3531293570995331
train_iter_loss: 0.3273731470108032
train_iter_loss: 0.3426072895526886
train_iter_loss: 0.3735121488571167
train_iter_loss: 0.3592349588871002
train_iter_loss: 0.27218374609947205
train_iter_loss: 0.28847989439964294
train_iter_loss: 0.37069377303123474
train_iter_loss: 0.3502257466316223
train_iter_loss: 0.3795113265514374
train_iter_loss: 0.4233255982398987
train_iter_loss: 0.3353043794631958
train_iter_loss: 0.35937589406967163
train_iter_loss: 0.3483026325702667
train_iter_loss: 0.3333192765712738
train_iter_loss: 0.3210398554801941
train_iter_loss: 0.36981338262557983
train_iter_loss: 0.370694100856781
train_iter_loss: 0.30840742588043213
train_iter_loss: 0.32034438848495483
train_iter_loss: 0.31355929374694824
train_iter_loss: 0.36099520325660706
train_iter_loss: 0.32206055521965027
train_iter_loss: 0.36999568343162537
train_iter_loss: 0.34052225947380066
train_iter_loss: 0.33374837040901184
train_iter_loss: 0.29041779041290283
train_iter_loss: 0.37798836827278137
train_iter_loss: 0.3499109447002411
train_iter_loss: 0.331197053194046
train_iter_loss: 0.31445544958114624
train_iter_loss: 0.34081047773361206
train_iter_loss: 0.3378671705722809
train_iter_loss: 0.38891586661338806
train_iter_loss: 0.34185197949409485
train_iter_loss: 0.3663126528263092
train_iter_loss: 0.33072179555892944
train_iter_loss: 0.3771526515483856
train_iter_loss: 0.32739317417144775
train_iter_loss: 0.3168053925037384
train_iter_loss: 0.3319428563117981
train_iter_loss: 0.34132251143455505
train_iter_loss: 0.36368176341056824
train_iter_loss: 0.39615151286125183
train_iter_loss: 0.34902405738830566
train_iter_loss: 0.3008982539176941
train_iter_loss: 0.32047173380851746
train_iter_loss: 0.3424491882324219
train_iter_loss: 0.3541060984134674
train_iter_loss: 0.4296027719974518
train_iter_loss: 0.3388790786266327
train_iter_loss: 0.33377256989479065
train_iter_loss: 0.32967570424079895
train_iter_loss: 0.30973225831985474
train_iter_loss: 0.33115154504776
train_iter_loss: 0.36183837056159973
train_iter_loss: 0.31161174178123474
train_iter_loss: 0.4054006040096283
train_iter_loss: 0.3171626925468445
train_iter_loss: 0.3523995280265808
train_iter_loss: 0.31909051537513733
train_iter_loss: 0.3779611885547638
train_iter_loss: 0.32638853788375854
train_iter_loss: 0.34084200859069824
train_iter_loss: 0.3992224633693695
train_iter_loss: 0.454967737197876
train_iter_loss: 0.33668115735054016
train_iter_loss: 0.3284360468387604
train_iter_loss: 0.47296932339668274
train_iter_loss: 0.31840160489082336
train_iter_loss: 0.4247734546661377
train_iter_loss: 0.32527896761894226
train_iter_loss: 0.2755076587200165
train_iter_loss: 0.3287506401538849
train_iter_loss: 0.36377280950546265
train_iter_loss: 0.41461509466171265
train_iter_loss: 0.35689157247543335
train_iter_loss: 0.3301760256290436
train_iter_loss: 0.3345947563648224
train_iter_loss: 0.34101444482803345
train_iter_loss: 0.30227527022361755
train_iter_loss: 0.35978201031684875
train_iter_loss: 0.4521680772304535
train_iter_loss: 0.3697551190853119
train_iter_loss: 0.34686917066574097
train_iter_loss: 0.3459451496601105
train_iter_loss: 0.36588308215141296
train_iter_loss: 0.38151460886001587
train_iter_loss: 0.3865869343280792
train_iter_loss: 0.3183102011680603
train_iter_loss: 0.34889864921569824
train_iter_loss: 0.2857853174209595
train_iter_loss: 0.3560965359210968
train_iter_loss: 0.3489207625389099
train_iter_loss: 0.3524414598941803
train_iter_loss: 0.37759602069854736
train_iter_loss: 0.34259793162345886
train_iter_loss: 0.38112691044807434
train_iter_loss: 0.3578650653362274
train_iter_loss: 0.3251539468765259
train_iter_loss: 0.31976985931396484
train_iter_loss: 0.3970111012458801
train_iter_loss: 0.3563447892665863
train_iter_loss: 0.34630540013313293
train_iter_loss: 0.34922611713409424
train_iter_loss: 0.35229000449180603
train_iter_loss: 0.34851396083831787
train loss :0.3532
---------------------
Validation seg loss: 0.3851455032544316 at epoch 11
********************
best_val_epoch_loss:  0.3851455032544316
MODEL UPDATED
epoch =     12/  1000, exp = train
train_iter_loss: 0.2955997586250305
train_iter_loss: 0.35548877716064453
train_iter_loss: 0.3233073651790619
train_iter_loss: 0.3228214681148529
train_iter_loss: 0.3297293782234192
train_iter_loss: 0.3613702654838562
train_iter_loss: 0.3558320999145508
train_iter_loss: 0.3054347634315491
train_iter_loss: 0.33558160066604614
train_iter_loss: 0.49087077379226685
train_iter_loss: 0.3011889159679413
train_iter_loss: 0.4010491967201233
train_iter_loss: 0.3473222255706787
train_iter_loss: 0.3057540953159332
train_iter_loss: 0.3800444006919861
train_iter_loss: 0.3248019218444824
train_iter_loss: 0.33789896965026855
train_iter_loss: 0.31097280979156494
train_iter_loss: 0.33626845479011536
train_iter_loss: 0.32073429226875305
train_iter_loss: 0.33517128229141235
train_iter_loss: 0.31257784366607666
train_iter_loss: 0.4101875424385071
train_iter_loss: 0.4098367989063263
train_iter_loss: 0.38625580072402954
train_iter_loss: 0.33705955743789673
train_iter_loss: 0.33684241771698
train_iter_loss: 0.40933483839035034
train_iter_loss: 0.379370778799057
train_iter_loss: 0.3683184087276459
train_iter_loss: 0.37280428409576416
train_iter_loss: 0.4431966543197632
train_iter_loss: 0.3646811842918396
train_iter_loss: 0.3389013409614563
train_iter_loss: 0.3117932677268982
train_iter_loss: 0.3187686502933502
train_iter_loss: 0.32399269938468933
train_iter_loss: 0.3334871828556061
train_iter_loss: 0.3129800260066986
train_iter_loss: 0.32521602511405945
train_iter_loss: 0.29669588804244995
train_iter_loss: 0.3545103073120117
train_iter_loss: 0.33783724904060364
train_iter_loss: 0.40420445799827576
train_iter_loss: 0.3242044746875763
train_iter_loss: 0.29721498489379883
train_iter_loss: 0.44780442118644714
train_iter_loss: 0.30716022849082947
train_iter_loss: 0.31532174348831177
train_iter_loss: 0.348827064037323
train_iter_loss: 0.3523011803627014
train_iter_loss: 0.31742945313453674
train_iter_loss: 0.3610169589519501
train_iter_loss: 0.34710896015167236
train_iter_loss: 0.3844200372695923
train_iter_loss: 0.35674530267715454
train_iter_loss: 0.3290293514728546
train_iter_loss: 0.440544456243515
train_iter_loss: 0.38784170150756836
train_iter_loss: 0.37810027599334717
train_iter_loss: 0.34458738565444946
train_iter_loss: 0.3491024076938629
train_iter_loss: 0.35528987646102905
train_iter_loss: 0.3289906978607178
train_iter_loss: 0.33087608218193054
train_iter_loss: 0.349754273891449
train_iter_loss: 0.33757612109184265
train_iter_loss: 0.34734365344047546
train_iter_loss: 0.3463627099990845
train_iter_loss: 0.40681472420692444
train_iter_loss: 0.3262110650539398
train_iter_loss: 0.30149540305137634
train_iter_loss: 0.3593919575214386
train_iter_loss: 0.37457120418548584
train_iter_loss: 0.3162875473499298
train_iter_loss: 0.3033676743507385
train_iter_loss: 0.33134207129478455
train_iter_loss: 0.3291162848472595
train_iter_loss: 0.3489314019680023
train_iter_loss: 0.35686540603637695
train_iter_loss: 0.43009430170059204
train_iter_loss: 0.34474584460258484
train_iter_loss: 0.31501293182373047
train_iter_loss: 0.36052030324935913
train_iter_loss: 0.3356103301048279
train_iter_loss: 0.33084017038345337
train_iter_loss: 0.3370896875858307
train_iter_loss: 0.3824332058429718
train_iter_loss: 0.32301539182662964
train_iter_loss: 0.33218955993652344
train_iter_loss: 0.335472047328949
train_iter_loss: 0.36656734347343445
train_iter_loss: 0.3116302788257599
train_iter_loss: 0.3091205358505249
train_iter_loss: 0.36653468012809753
train_iter_loss: 0.4278983175754547
train_iter_loss: 0.347162127494812
train_iter_loss: 0.31894782185554504
train_iter_loss: 0.3059321343898773
train_iter_loss: 0.37504252791404724
train_iter_loss: 0.3105229139328003
train_iter_loss: 0.2961897552013397
train_iter_loss: 0.3424404561519623
train_iter_loss: 0.3429821729660034
train_iter_loss: 0.3641014099121094
train_iter_loss: 0.3637736439704895
train_iter_loss: 0.30206069350242615
train_iter_loss: 0.41095420718193054
train_iter_loss: 0.31402215361595154
train_iter_loss: 0.33746337890625
train_iter_loss: 0.31664514541625977
train_iter_loss: 0.3706345856189728
train_iter_loss: 0.33892375230789185
train_iter_loss: 0.29058805108070374
train_iter_loss: 0.3335488438606262
train_iter_loss: 0.3497415781021118
train_iter_loss: 0.3202410042285919
train_iter_loss: 0.32750800251960754
train_iter_loss: 0.33451491594314575
train_iter_loss: 0.25941234827041626
train_iter_loss: 0.3366886377334595
train_iter_loss: 0.2882159650325775
train_iter_loss: 0.3375938832759857
train_iter_loss: 0.31255143880844116
train_iter_loss: 0.3262128233909607
train_iter_loss: 0.30872416496276855
train_iter_loss: 0.3400877118110657
train_iter_loss: 0.38638535141944885
train_iter_loss: 0.30937430262565613
train_iter_loss: 0.3844524025917053
train_iter_loss: 0.32880091667175293
train_iter_loss: 0.345723420381546
train_iter_loss: 0.3173757791519165
train_iter_loss: 0.33036112785339355
train_iter_loss: 0.3798869252204895
train_iter_loss: 0.40475043654441833
train_iter_loss: 0.3641279935836792
train_iter_loss: 0.29742854833602905
train_iter_loss: 0.31655964255332947
train_iter_loss: 0.3187994658946991
train_iter_loss: 0.3252711594104767
train_iter_loss: 0.35220760107040405
train_iter_loss: 0.3234182894229889
train_iter_loss: 0.323039174079895
train_iter_loss: 0.31344038248062134
train_iter_loss: 0.33429035544395447
train_iter_loss: 0.310566782951355
train_iter_loss: 0.30968138575553894
train_iter_loss: 0.3415680527687073
train_iter_loss: 0.29336392879486084
train_iter_loss: 0.3524191677570343
train_iter_loss: 0.30583664774894714
train_iter_loss: 0.3716557025909424
train_iter_loss: 0.30957016348838806
train_iter_loss: 0.30777257680892944
train_iter_loss: 0.3063688278198242
train_iter_loss: 0.335561603307724
train_iter_loss: 0.35305237770080566
train_iter_loss: 0.3647859990596771
train_iter_loss: 0.33812010288238525
train_iter_loss: 0.32442086935043335
train_iter_loss: 0.3255332410335541
train_iter_loss: 0.29458582401275635
train_iter_loss: 0.39743590354919434
train_iter_loss: 0.28476694226264954
train_iter_loss: 0.40366679430007935
train_iter_loss: 0.3444814682006836
train_iter_loss: 0.334592342376709
train_iter_loss: 0.4055067300796509
train_iter_loss: 0.36643460392951965
train_iter_loss: 0.3249608874320984
train_iter_loss: 0.38002875447273254
train_iter_loss: 0.38874495029449463
train_iter_loss: 0.36756056547164917
train_iter_loss: 0.31640109419822693
train_iter_loss: 0.3414146900177002
train_iter_loss: 0.3142159879207611
train_iter_loss: 0.31850382685661316
train_iter_loss: 0.3106424808502197
train_iter_loss: 0.3528241217136383
train_iter_loss: 0.33469724655151367
train_iter_loss: 0.32473814487457275
train_iter_loss: 0.331022709608078
train_iter_loss: 0.3223632276058197
train_iter_loss: 0.3049287497997284
train_iter_loss: 0.30702945590019226
train_iter_loss: 0.32032912969589233
train_iter_loss: 0.34923455119132996
train_iter_loss: 0.30626899003982544
train_iter_loss: 0.39245113730430603
train_iter_loss: 0.31850630044937134
train_iter_loss: 0.3283119201660156
train_iter_loss: 0.3229399025440216
train_iter_loss: 0.2988913953304291
train_iter_loss: 0.3253231346607208
train_iter_loss: 0.34808215498924255
train_iter_loss: 0.3521285653114319
train_iter_loss: 0.33441996574401855
train_iter_loss: 0.33440065383911133
train_iter_loss: 0.37827861309051514
train loss :0.3434
---------------------
Validation seg loss: 0.3739825959475535 at epoch 12
********************
best_val_epoch_loss:  0.3739825959475535
MODEL UPDATED
epoch =     13/  1000, exp = train
train_iter_loss: 0.39067527651786804
train_iter_loss: 0.31221315264701843
train_iter_loss: 0.349880188703537
train_iter_loss: 0.4401646554470062
train_iter_loss: 0.33213430643081665
train_iter_loss: 0.3127291798591614
train_iter_loss: 0.3346874415874481
train_iter_loss: 0.29449957609176636
train_iter_loss: 0.301159530878067
train_iter_loss: 0.3149651288986206
train_iter_loss: 0.3137599229812622
train_iter_loss: 0.3614034652709961
train_iter_loss: 0.35879555344581604
train_iter_loss: 0.3066657483577728
train_iter_loss: 0.3322831392288208
train_iter_loss: 0.3719102442264557
train_iter_loss: 0.3376312553882599
train_iter_loss: 0.34074291586875916
train_iter_loss: 0.32320812344551086
train_iter_loss: 0.31927403807640076
train_iter_loss: 0.3293937146663666
train_iter_loss: 0.42409881949424744
train_iter_loss: 0.3372170925140381
train_iter_loss: 0.2489723116159439
train_iter_loss: 0.34201580286026
train_iter_loss: 0.3314233124256134
train_iter_loss: 0.329685777425766
train_iter_loss: 0.32020169496536255
train_iter_loss: 0.35679537057876587
train_iter_loss: 0.33640551567077637
train_iter_loss: 0.3972901403903961
train_iter_loss: 0.29564201831817627
train_iter_loss: 0.36173757910728455
train_iter_loss: 0.2797525227069855
train_iter_loss: 0.3231964707374573
train_iter_loss: 0.3668733239173889
train_iter_loss: 0.33262568712234497
train_iter_loss: 0.3209370970726013
train_iter_loss: 0.3393474519252777
train_iter_loss: 0.3697580099105835
train_iter_loss: 0.28893929719924927
train_iter_loss: 0.2834041118621826
train_iter_loss: 0.33135342597961426
train_iter_loss: 0.31488168239593506
train_iter_loss: 0.3109665513038635
train_iter_loss: 0.37335559725761414
train_iter_loss: 0.37343472242355347
train_iter_loss: 0.3770703077316284
train_iter_loss: 0.3259067237377167
train_iter_loss: 0.3075007498264313
train_iter_loss: 0.3243301212787628
train_iter_loss: 0.30990856885910034
train_iter_loss: 0.3306916654109955
train_iter_loss: 0.3435935080051422
train_iter_loss: 0.31368348002433777
train_iter_loss: 0.375134140253067
train_iter_loss: 0.39455851912498474
train_iter_loss: 0.33654430508613586
train_iter_loss: 0.34680625796318054
train_iter_loss: 0.32426849007606506
train_iter_loss: 0.31183597445487976
train_iter_loss: 0.33381667733192444
train_iter_loss: 0.28894010186195374
train_iter_loss: 0.31480079889297485
train_iter_loss: 0.3614679276943207
train_iter_loss: 0.30948925018310547
train_iter_loss: 0.3403938412666321
train_iter_loss: 0.3099190890789032
train_iter_loss: 0.3794950544834137
train_iter_loss: 0.3292447030544281
train_iter_loss: 0.3168465495109558
train_iter_loss: 0.33585289120674133
train_iter_loss: 0.3219851553440094
train_iter_loss: 0.34979188442230225
train_iter_loss: 0.29762229323387146
train_iter_loss: 0.33540794253349304
train_iter_loss: 0.39279815554618835
train_iter_loss: 0.31339532136917114
train_iter_loss: 0.3561539053916931
train_iter_loss: 0.3282613456249237
train_iter_loss: 0.3405413031578064
train_iter_loss: 0.32656043767929077
train_iter_loss: 0.397919237613678
train_iter_loss: 0.289029598236084
train_iter_loss: 0.3148271441459656
train_iter_loss: 0.31700366735458374
train_iter_loss: 0.31031304597854614
train_iter_loss: 0.3455563187599182
train_iter_loss: 0.31762564182281494
train_iter_loss: 0.36905407905578613
train_iter_loss: 0.3336041271686554
train_iter_loss: 0.31446897983551025
train_iter_loss: 0.31834957003593445
train_iter_loss: 0.37558814883232117
train_iter_loss: 0.31012481451034546
train_iter_loss: 0.33180534839630127
train_iter_loss: 0.38867926597595215
train_iter_loss: 0.3052172362804413
train_iter_loss: 0.32358866930007935
train_iter_loss: 0.3597259223461151
train_iter_loss: 0.3351481854915619
train_iter_loss: 0.34760719537734985
train_iter_loss: 0.3944467604160309
train_iter_loss: 0.3320394456386566
train_iter_loss: 0.3287614583969116
train_iter_loss: 0.2986993193626404
train_iter_loss: 0.34226712584495544
train_iter_loss: 0.3418019413948059
train_iter_loss: 0.3602432608604431
train_iter_loss: 0.3284331262111664
train_iter_loss: 0.300020694732666
train_iter_loss: 0.33864688873291016
train_iter_loss: 0.3005043864250183
train_iter_loss: 0.3300424814224243
train_iter_loss: 0.3046376407146454
train_iter_loss: 0.3184036910533905
train_iter_loss: 0.36936476826667786
train_iter_loss: 0.3637864887714386
train_iter_loss: 0.38346803188323975
train_iter_loss: 0.31144705414772034
train_iter_loss: 0.35953667759895325
train_iter_loss: 0.30871695280075073
train_iter_loss: 0.3109194338321686
train_iter_loss: 0.3920961320400238
train_iter_loss: 0.2984043061733246
train_iter_loss: 0.3025021255016327
train_iter_loss: 0.3611363470554352
train_iter_loss: 0.30605393648147583
train_iter_loss: 0.3131377398967743
train_iter_loss: 0.328058123588562
train_iter_loss: 0.3708568513393402
train_iter_loss: 0.3178843557834625
train_iter_loss: 0.3409896194934845
train_iter_loss: 0.33811214566230774
train_iter_loss: 0.310304194688797
train_iter_loss: 0.31647321581840515
train_iter_loss: 0.34878626465797424
train_iter_loss: 0.34581318497657776
train_iter_loss: 0.3106424808502197
train_iter_loss: 0.31585103273391724
train_iter_loss: 0.3321022391319275
train_iter_loss: 0.31488457322120667
train_iter_loss: 0.43915024399757385
train_iter_loss: 0.2896871268749237
train_iter_loss: 0.32009708881378174
train_iter_loss: 0.31238579750061035
train_iter_loss: 0.3219092786312103
train_iter_loss: 0.39810895919799805
train_iter_loss: 0.33561813831329346
train_iter_loss: 0.3270624279975891
train_iter_loss: 0.3371215760707855
train_iter_loss: 0.3707694709300995
train_iter_loss: 0.3154227137565613
train_iter_loss: 0.3142550587654114
train_iter_loss: 0.3042806088924408
train_iter_loss: 0.3169274628162384
train_iter_loss: 0.30262747406959534
train_iter_loss: 0.34765610098838806
train_iter_loss: 0.32160288095474243
train_iter_loss: 0.3164329528808594
train_iter_loss: 0.30934298038482666
train_iter_loss: 0.2826406955718994
train_iter_loss: 0.3167589604854584
train_iter_loss: 0.344582736492157
train_iter_loss: 0.27646809816360474
train_iter_loss: 0.3351192772388458
train_iter_loss: 0.33507755398750305
train_iter_loss: 0.3839015066623688
train_iter_loss: 0.3316836655139923
train_iter_loss: 0.42590516805648804
train_iter_loss: 0.3172239661216736
train_iter_loss: 0.4558202624320984
train_iter_loss: 0.36042988300323486
train_iter_loss: 0.35556766390800476
train_iter_loss: 0.3032465875148773
train_iter_loss: 0.39259710907936096
train_iter_loss: 0.3520524501800537
train_iter_loss: 0.3114900588989258
train_iter_loss: 0.3313245177268982
train_iter_loss: 0.2831709682941437
train_iter_loss: 0.3389524221420288
train_iter_loss: 0.3905879557132721
train_iter_loss: 0.3177867829799652
train_iter_loss: 0.3411772847175598
train_iter_loss: 0.29213663935661316
train_iter_loss: 0.3269767463207245
train_iter_loss: 0.25933146476745605
train_iter_loss: 0.32931217551231384
train_iter_loss: 0.30989688634872437
train_iter_loss: 0.37019509077072144
train_iter_loss: 0.3059227466583252
train_iter_loss: 0.38634490966796875
train_iter_loss: 0.3124329745769501
train_iter_loss: 0.36432069540023804
train_iter_loss: 0.3674570620059967
train_iter_loss: 0.3377317786216736
train_iter_loss: 0.29772061109542847
train_iter_loss: 0.33420130610466003
train_iter_loss: 0.34129443764686584
train_iter_loss: 0.32101064920425415
train loss :0.3363
---------------------
Validation seg loss: 0.358372947236277 at epoch 13
********************
best_val_epoch_loss:  0.358372947236277
MODEL UPDATED
epoch =     14/  1000, exp = train
train_iter_loss: 0.33568355441093445
train_iter_loss: 0.384082555770874
train_iter_loss: 0.34082046151161194
train_iter_loss: 0.34128791093826294
train_iter_loss: 0.3036403954029083
train_iter_loss: 0.34249642491340637
train_iter_loss: 0.3873206079006195
train_iter_loss: 0.31946441531181335
train_iter_loss: 0.2691556215286255
train_iter_loss: 0.29921436309814453
train_iter_loss: 0.3127603828907013
train_iter_loss: 0.319740355014801
train_iter_loss: 0.33390477299690247
train_iter_loss: 0.31271427869796753
train_iter_loss: 0.28317907452583313
train_iter_loss: 0.31137585639953613
train_iter_loss: 0.3185488283634186
train_iter_loss: 0.30169081687927246
train_iter_loss: 0.3487314283847809
train_iter_loss: 0.3201040029525757
train_iter_loss: 0.39926841855049133
train_iter_loss: 0.30738964676856995
train_iter_loss: 0.4031306803226471
train_iter_loss: 0.3529229164123535
train_iter_loss: 0.30356040596961975
train_iter_loss: 0.31879347562789917
train_iter_loss: 0.3442929983139038
train_iter_loss: 0.3008502721786499
train_iter_loss: 0.3261624574661255
train_iter_loss: 0.3148549795150757
train_iter_loss: 0.3116309940814972
train_iter_loss: 0.3090241849422455
train_iter_loss: 0.32346734404563904
train_iter_loss: 0.39133813977241516
train_iter_loss: 0.3147396147251129
train_iter_loss: 0.31499049067497253
train_iter_loss: 0.3082188069820404
train_iter_loss: 0.2910887897014618
train_iter_loss: 0.3324938118457794
train_iter_loss: 0.3392164409160614
train_iter_loss: 0.3007572889328003
train_iter_loss: 0.38092508912086487
train_iter_loss: 0.32362988591194153
train_iter_loss: 0.37308555841445923
train_iter_loss: 0.31071990728378296
train_iter_loss: 0.32593777775764465
train_iter_loss: 0.27318665385246277
train_iter_loss: 0.3303040564060211
train_iter_loss: 0.3066900074481964
train_iter_loss: 0.29075634479522705
train_iter_loss: 0.257586270570755
train_iter_loss: 0.30211755633354187
train_iter_loss: 0.38952478766441345
train_iter_loss: 0.3212176263332367
train_iter_loss: 0.2787688374519348
train_iter_loss: 0.3027551770210266
train_iter_loss: 0.31972095370292664
train_iter_loss: 0.3399200439453125
train_iter_loss: 0.3421073257923126
train_iter_loss: 0.2995162010192871
train_iter_loss: 0.29358795285224915
train_iter_loss: 0.306924968957901
train_iter_loss: 0.33661437034606934
train_iter_loss: 0.29222571849823
train_iter_loss: 0.4078598916530609
train_iter_loss: 0.3549130856990814
train_iter_loss: 0.3062214255332947
train_iter_loss: 0.36279943585395813
train_iter_loss: 0.3120008111000061
train_iter_loss: 0.3279479742050171
train_iter_loss: 0.2975231409072876
train_iter_loss: 0.32883983850479126
train_iter_loss: 0.3641388416290283
train_iter_loss: 0.3596426844596863
train_iter_loss: 0.36377719044685364
train_iter_loss: 0.3268093168735504
train_iter_loss: 0.32851654291152954
train_iter_loss: 0.2904677391052246
train_iter_loss: 0.31324708461761475
train_iter_loss: 0.4303063750267029
train_iter_loss: 0.42424988746643066
train_iter_loss: 0.3114272356033325
train_iter_loss: 0.3184383809566498
train_iter_loss: 0.2870360016822815
train_iter_loss: 0.3371090590953827
train_iter_loss: 0.29415130615234375
train_iter_loss: 0.3495161831378937
train_iter_loss: 0.3029007613658905
train_iter_loss: 0.30473101139068604
train_iter_loss: 0.3013356029987335
train_iter_loss: 0.3102399706840515
train_iter_loss: 0.33198943734169006
train_iter_loss: 0.35967326164245605
train_iter_loss: 0.2932339608669281
train_iter_loss: 0.3253733813762665
train_iter_loss: 0.32402345538139343
train_iter_loss: 0.27968651056289673
train_iter_loss: 0.29248371720314026
train_iter_loss: 0.29108738899230957
train_iter_loss: 0.2975616455078125
train_iter_loss: 0.3088764250278473
train_iter_loss: 0.29459795355796814
train_iter_loss: 0.3486560583114624
train_iter_loss: 0.32594671845436096
train_iter_loss: 0.38555580377578735
train_iter_loss: 0.38130882382392883
train_iter_loss: 0.3793773651123047
train_iter_loss: 0.3356492817401886
train_iter_loss: 0.31680357456207275
train_iter_loss: 0.32169216871261597
train_iter_loss: 0.2992820143699646
train_iter_loss: 0.3191104829311371
train_iter_loss: 0.32756784558296204
train_iter_loss: 0.3290947675704956
train_iter_loss: 0.2989475429058075
train_iter_loss: 0.3366314470767975
train_iter_loss: 0.2970625162124634
train_iter_loss: 0.3715437948703766
train_iter_loss: 0.29667598009109497
train_iter_loss: 0.3581092059612274
train_iter_loss: 0.3287780284881592
train_iter_loss: 0.37557005882263184
train_iter_loss: 0.33142921328544617
train_iter_loss: 0.3030269145965576
train_iter_loss: 0.3486047685146332
train_iter_loss: 0.3334472179412842
train_iter_loss: 0.32151493430137634
train_iter_loss: 0.32976046204566956
train_iter_loss: 0.3074274957180023
train_iter_loss: 0.3020878732204437
train_iter_loss: 0.3336183428764343
train_iter_loss: 0.3193414807319641
train_iter_loss: 0.3378559648990631
train_iter_loss: 0.3105979263782501
train_iter_loss: 0.3831208050251007
train_iter_loss: 0.3508348762989044
train_iter_loss: 0.3941507041454315
train_iter_loss: 0.3169027864933014
train_iter_loss: 0.3587508201599121
train_iter_loss: 0.30973148345947266
train_iter_loss: 0.31561100482940674
train_iter_loss: 0.29218363761901855
train_iter_loss: 0.3002937138080597
train_iter_loss: 0.30542463064193726
train_iter_loss: 0.3200882375240326
train_iter_loss: 0.3243972659111023
train_iter_loss: 0.2902630567550659
train_iter_loss: 0.31676921248435974
train_iter_loss: 0.29689937829971313
train_iter_loss: 0.2943616509437561
train_iter_loss: 0.3894461393356323
train_iter_loss: 0.32595157623291016
train_iter_loss: 0.3724895119667053
train_iter_loss: 0.2964946925640106
train_iter_loss: 0.4337213933467865
train_iter_loss: 0.2967209815979004
train_iter_loss: 0.31727343797683716
train_iter_loss: 0.3442338705062866
train_iter_loss: 0.40707919001579285
train_iter_loss: 0.3342289924621582
train_iter_loss: 0.31293588876724243
train_iter_loss: 0.3581121265888214
train_iter_loss: 0.3547545373439789
train_iter_loss: 0.35378405451774597
train_iter_loss: 0.33228030800819397
train_iter_loss: 0.26595398783683777
train_iter_loss: 0.3223733901977539
train_iter_loss: 0.37957632541656494
train_iter_loss: 0.3117210566997528
train_iter_loss: 0.3475154936313629
train_iter_loss: 0.2944454848766327
train_iter_loss: 0.3312077522277832
train_iter_loss: 0.3187761604785919
train_iter_loss: 0.34711363911628723
train_iter_loss: 0.30417364835739136
train_iter_loss: 0.30976784229278564
train_iter_loss: 0.4074253439903259
train_iter_loss: 0.41274282336235046
train_iter_loss: 0.28052619099617004
train_iter_loss: 0.30838513374328613
train_iter_loss: 0.29715853929519653
train_iter_loss: 0.2870648205280304
train_iter_loss: 0.32366493344306946
train_iter_loss: 0.29640820622444153
train_iter_loss: 0.3742985129356384
train_iter_loss: 0.29519638419151306
train_iter_loss: 0.28999030590057373
train_iter_loss: 0.2884118854999542
train_iter_loss: 0.2908018231391907
train_iter_loss: 0.29079583287239075
train_iter_loss: 0.3324875831604004
train_iter_loss: 0.2956477999687195
train_iter_loss: 0.32472553849220276
train_iter_loss: 0.2895977795124054
train_iter_loss: 0.3529190719127655
train_iter_loss: 0.29994675517082214
train_iter_loss: 0.3110228180885315
train_iter_loss: 0.2718912363052368
train_iter_loss: 0.34109967947006226
train_iter_loss: 0.3578794002532959
train loss :0.3280
---------------------
Validation seg loss: 0.35912512060043944 at epoch 14
epoch =     15/  1000, exp = train
train_iter_loss: 0.277840793132782
train_iter_loss: 0.2863810062408447
train_iter_loss: 0.29414552450180054
train_iter_loss: 0.4008654057979584
train_iter_loss: 0.30632004141807556
train_iter_loss: 0.32175081968307495
train_iter_loss: 0.3575335144996643
train_iter_loss: 0.3184159994125366
train_iter_loss: 0.33367133140563965
train_iter_loss: 0.2905257046222687
train_iter_loss: 0.36423182487487793
train_iter_loss: 0.3318406939506531
train_iter_loss: 0.3848649859428406
train_iter_loss: 0.329987108707428
train_iter_loss: 0.3538598120212555
train_iter_loss: 0.306458443403244
train_iter_loss: 0.3827815353870392
train_iter_loss: 0.3023301064968109
train_iter_loss: 0.2818411886692047
train_iter_loss: 0.29793792963027954
train_iter_loss: 0.31602180004119873
train_iter_loss: 0.30465617775917053
train_iter_loss: 0.30072078108787537
train_iter_loss: 0.32106801867485046
train_iter_loss: 0.33268019556999207
train_iter_loss: 0.3413490056991577
train_iter_loss: 0.4467155635356903
train_iter_loss: 0.325588583946228
train_iter_loss: 0.31527194380760193
train_iter_loss: 0.3286287486553192
train_iter_loss: 0.31835269927978516
train_iter_loss: 0.34664657711982727
train_iter_loss: 0.288230836391449
train_iter_loss: 0.29407885670661926
train_iter_loss: 0.2834671437740326
train_iter_loss: 0.3472805321216583
train_iter_loss: 0.2765657603740692
train_iter_loss: 0.29753178358078003
train_iter_loss: 0.3452582359313965
train_iter_loss: 0.29252251982688904
train_iter_loss: 0.2628383934497833
train_iter_loss: 0.31310778856277466
train_iter_loss: 0.27502933144569397
train_iter_loss: 0.3477916717529297
train_iter_loss: 0.3057269752025604
train_iter_loss: 0.3156788647174835
train_iter_loss: 0.3237415850162506
train_iter_loss: 0.30482831597328186
train_iter_loss: 0.3037147521972656
train_iter_loss: 0.29578152298927307
train_iter_loss: 0.2980959713459015
train_iter_loss: 0.32617974281311035
train_iter_loss: 0.28608426451683044
train_iter_loss: 0.30833256244659424
train_iter_loss: 0.291574090719223
train_iter_loss: 0.334293007850647
train_iter_loss: 0.35602620244026184
train_iter_loss: 0.34797656536102295
train_iter_loss: 0.26804617047309875
train_iter_loss: 0.3034513294696808
train_iter_loss: 0.3284086287021637
train_iter_loss: 0.3163398802280426
train_iter_loss: 0.3377748131752014
train_iter_loss: 0.2979523539543152
train_iter_loss: 0.27285879850387573
train_iter_loss: 0.4532475471496582
train_iter_loss: 0.35147783160209656
train_iter_loss: 0.2779693901538849
train_iter_loss: 0.27366164326667786
train_iter_loss: 0.3074984550476074
train_iter_loss: 0.31925466656684875
train_iter_loss: 0.4369458556175232
train_iter_loss: 0.34024232625961304
train_iter_loss: 0.2739078402519226
train_iter_loss: 0.4013344943523407
train_iter_loss: 0.3503866195678711
train_iter_loss: 0.33961519598960876
train_iter_loss: 0.3303965628147125
train_iter_loss: 0.3406587541103363
train_iter_loss: 0.308726966381073
train_iter_loss: 0.3170108199119568
train_iter_loss: 0.2927539050579071
train_iter_loss: 0.3060134947299957
train_iter_loss: 0.2786075472831726
train_iter_loss: 0.30985137820243835
train_iter_loss: 0.3148989975452423
train_iter_loss: 0.30375197529792786
train_iter_loss: 0.25666841864585876
train_iter_loss: 0.3485931158065796
train_iter_loss: 0.30186328291893005
train_iter_loss: 0.4327794313430786
train_iter_loss: 0.3103025257587433
train_iter_loss: 0.2941853106021881
train_iter_loss: 0.3108239471912384
train_iter_loss: 0.3272433876991272
train_iter_loss: 0.30455848574638367
train_iter_loss: 0.2824878692626953
train_iter_loss: 0.2951889932155609
train_iter_loss: 0.34218132495880127
train_iter_loss: 0.31843096017837524
train_iter_loss: 0.3583233654499054
train_iter_loss: 0.3486495316028595
train_iter_loss: 0.2924325168132782
train_iter_loss: 0.31779882311820984
train_iter_loss: 0.3348332345485687
train_iter_loss: 0.30497878789901733
train_iter_loss: 0.33988600969314575
train_iter_loss: 0.32962852716445923
train_iter_loss: 0.3567202091217041
train_iter_loss: 0.3328041434288025
train_iter_loss: 0.2870708107948303
train_iter_loss: 0.30957096815109253
train_iter_loss: 0.310069739818573
train_iter_loss: 0.28034883737564087
train_iter_loss: 0.2929965555667877
train_iter_loss: 0.30659568309783936
train_iter_loss: 0.3457263708114624
train_iter_loss: 0.3029710650444031
train_iter_loss: 0.2838731110095978
train_iter_loss: 0.28158071637153625
train_iter_loss: 0.3031952977180481
train_iter_loss: 0.30483412742614746
train_iter_loss: 0.2828405797481537
train_iter_loss: 0.2972572147846222
train_iter_loss: 0.48595938086509705
train_iter_loss: 0.32775482535362244
train_iter_loss: 0.28608018159866333
train_iter_loss: 0.2856162190437317
train_iter_loss: 0.32420748472213745
train_iter_loss: 0.3045509457588196
train_iter_loss: 0.2997135519981384
train_iter_loss: 0.29977887868881226
train_iter_loss: 0.34875527024269104
train_iter_loss: 0.3603001534938812
train_iter_loss: 0.2856066823005676
train_iter_loss: 0.2615772783756256
train_iter_loss: 0.29369431734085083
train_iter_loss: 0.2998324930667877
train_iter_loss: 0.3419293165206909
train_iter_loss: 0.3380567729473114
train_iter_loss: 0.318291574716568
train_iter_loss: 0.3703904151916504
train_iter_loss: 0.30713412165641785
train_iter_loss: 0.2998897135257721
train_iter_loss: 0.43122535943984985
train_iter_loss: 0.3357616364955902
train_iter_loss: 0.267063170671463
train_iter_loss: 0.3266110122203827
train_iter_loss: 0.29605191946029663
train_iter_loss: 0.3274385929107666
train_iter_loss: 0.36481133103370667
train_iter_loss: 0.31858423352241516
train_iter_loss: 0.28232911229133606
train_iter_loss: 0.3085649907588959
train_iter_loss: 0.2964896559715271
train_iter_loss: 0.35320043563842773
train_iter_loss: 0.3017273247241974
train_iter_loss: 0.3772396147251129
train_iter_loss: 0.3237914741039276
train_iter_loss: 0.34160369634628296
train_iter_loss: 0.27384042739868164
train_iter_loss: 0.29062339663505554
train_iter_loss: 0.2935976982116699
train_iter_loss: 0.29872968792915344
train_iter_loss: 0.28715765476226807
train_iter_loss: 0.3687223494052887
train_iter_loss: 0.29217734932899475
train_iter_loss: 0.28643912076950073
train_iter_loss: 0.32451680302619934
train_iter_loss: 0.3215157985687256
train_iter_loss: 0.2837204039096832
train_iter_loss: 0.25747302174568176
train_iter_loss: 0.37250545620918274
train_iter_loss: 0.3295949399471283
train_iter_loss: 0.29891127347946167
train_iter_loss: 0.32960543036460876
train_iter_loss: 0.2620113790035248
train_iter_loss: 0.26698222756385803
train_iter_loss: 0.30179259181022644
train_iter_loss: 0.2687380313873291
train_iter_loss: 0.3384135663509369
train_iter_loss: 0.31743571162223816
train_iter_loss: 0.26212048530578613
train_iter_loss: 0.32306647300720215
train_iter_loss: 0.29909548163414
train_iter_loss: 0.29557451605796814
train_iter_loss: 0.30488717555999756
train_iter_loss: 0.30343273282051086
train_iter_loss: 0.3354823589324951
train_iter_loss: 0.34657663106918335
train_iter_loss: 0.37291041016578674
train_iter_loss: 0.33771422505378723
train_iter_loss: 0.3092324137687683
train_iter_loss: 0.3100622296333313
train_iter_loss: 0.44374436140060425
train_iter_loss: 0.2939261794090271
train_iter_loss: 0.3368329703807831
train_iter_loss: 0.31596794724464417
train_iter_loss: 0.3691410720348358
train_iter_loss: 0.3154121935367584
train loss :0.3204
---------------------
Validation seg loss: 0.3525039585974981 at epoch 15
********************
best_val_epoch_loss:  0.3525039585974981
MODEL UPDATED
epoch =     16/  1000, exp = train
train_iter_loss: 0.3306657075881958
train_iter_loss: 0.2994074821472168
train_iter_loss: 0.4310602843761444
train_iter_loss: 0.32241132855415344
train_iter_loss: 0.29926684498786926
train_iter_loss: 0.24233904480934143
train_iter_loss: 0.29910725355148315
train_iter_loss: 0.29917067289352417
train_iter_loss: 0.33404985070228577
train_iter_loss: 0.3302493691444397
train_iter_loss: 0.29524990916252136
train_iter_loss: 0.31009194254875183
train_iter_loss: 0.292569100856781
train_iter_loss: 0.4096441864967346
train_iter_loss: 0.295719176530838
train_iter_loss: 0.2989923357963562
train_iter_loss: 0.27033793926239014
train_iter_loss: 0.29951807856559753
train_iter_loss: 0.30028975009918213
train_iter_loss: 0.29620304703712463
train_iter_loss: 0.24391059577465057
train_iter_loss: 0.28013837337493896
train_iter_loss: 0.2948836386203766
train_iter_loss: 0.38059303164482117
train_iter_loss: 0.2836589217185974
train_iter_loss: 0.32550448179244995
train_iter_loss: 0.2834417521953583
train_iter_loss: 0.27572527527809143
train_iter_loss: 0.31233295798301697
train_iter_loss: 0.28854861855506897
train_iter_loss: 0.3170962929725647
train_iter_loss: 0.2744208574295044
train_iter_loss: 0.2735115885734558
train_iter_loss: 0.3090836703777313
train_iter_loss: 0.2877432703971863
train_iter_loss: 0.3087756037712097
train_iter_loss: 0.2819213271141052
train_iter_loss: 0.333487868309021
train_iter_loss: 0.35980796813964844
train_iter_loss: 0.30286097526550293
train_iter_loss: 0.31755703687667847
train_iter_loss: 0.2656213045120239
train_iter_loss: 0.3684629201889038
train_iter_loss: 0.3195614516735077
train_iter_loss: 0.3235887289047241
train_iter_loss: 0.34073394536972046
train_iter_loss: 0.33912602066993713
train_iter_loss: 0.31404706835746765
train_iter_loss: 0.3253260552883148
train_iter_loss: 0.3044077754020691
train_iter_loss: 0.3825365900993347
train_iter_loss: 0.32817164063453674
train_iter_loss: 0.2941683828830719
train_iter_loss: 0.3967229127883911
train_iter_loss: 0.31482306122779846
train_iter_loss: 0.33485016226768494
train_iter_loss: 0.35949230194091797
train_iter_loss: 0.30982324481010437
train_iter_loss: 0.3078354001045227
train_iter_loss: 0.3044378161430359
train_iter_loss: 0.2862161099910736
train_iter_loss: 0.2859865427017212
train_iter_loss: 0.2840421795845032
train_iter_loss: 0.28210943937301636
train_iter_loss: 0.3138040006160736
train_iter_loss: 0.3389038145542145
train_iter_loss: 0.3073318600654602
train_iter_loss: 0.288589209318161
train_iter_loss: 0.28422728180885315
train_iter_loss: 0.2524391710758209
train_iter_loss: 0.2753283381462097
train_iter_loss: 0.37834179401397705
train_iter_loss: 0.3591632544994354
train_iter_loss: 0.277464896440506
train_iter_loss: 0.3096202611923218
train_iter_loss: 0.30209073424339294
train_iter_loss: 0.26712313294410706
train_iter_loss: 0.38857316970825195
train_iter_loss: 0.32702746987342834
train_iter_loss: 0.27746474742889404
train_iter_loss: 0.33489125967025757
train_iter_loss: 0.28821396827697754
train_iter_loss: 0.33030372858047485
train_iter_loss: 0.3691920340061188
train_iter_loss: 0.29273831844329834
train_iter_loss: 0.3285696804523468
train_iter_loss: 0.26339346170425415
train_iter_loss: 0.3654782474040985
train_iter_loss: 0.3739897310733795
train_iter_loss: 0.32039114832878113
train_iter_loss: 0.26607292890548706
train_iter_loss: 0.2828381061553955
train_iter_loss: 0.32761266827583313
train_iter_loss: 0.381084144115448
train_iter_loss: 0.36531949043273926
train_iter_loss: 0.28967398405075073
train_iter_loss: 0.27196088433265686
train_iter_loss: 0.2984369695186615
train_iter_loss: 0.3069971203804016
train_iter_loss: 0.3931461274623871
train_iter_loss: 0.2645392417907715
train_iter_loss: 0.2835032045841217
train_iter_loss: 0.33577895164489746
train_iter_loss: 0.3012861907482147
train_iter_loss: 0.3265239894390106
train_iter_loss: 0.33478569984436035
train_iter_loss: 0.31062138080596924
train_iter_loss: 0.40567222237586975
train_iter_loss: 0.2933826148509979
train_iter_loss: 0.28016626834869385
train_iter_loss: 0.2804321050643921
train_iter_loss: 0.294174462556839
train_iter_loss: 0.3803690969944
train_iter_loss: 0.42770811915397644
train_iter_loss: 0.3093278408050537
train_iter_loss: 0.3022424876689911
train_iter_loss: 0.3412858843803406
train_iter_loss: 0.27900198101997375
train_iter_loss: 0.3412933051586151
train_iter_loss: 0.3685811758041382
train_iter_loss: 0.2979544699192047
train_iter_loss: 0.30855104327201843
train_iter_loss: 0.3372163772583008
train_iter_loss: 0.3815017342567444
train_iter_loss: 0.2647368907928467
train_iter_loss: 0.3048706650733948
train_iter_loss: 0.2886924147605896
train_iter_loss: 0.34802958369255066
train_iter_loss: 0.24649499356746674
train_iter_loss: 0.323552668094635
train_iter_loss: 0.33281633257865906
train_iter_loss: 0.41609105467796326
train_iter_loss: 0.2792911231517792
train_iter_loss: 0.3006139099597931
train_iter_loss: 0.29407554864883423
train_iter_loss: 0.2664681077003479
train_iter_loss: 0.4229627549648285
train_iter_loss: 0.2883407175540924
train_iter_loss: 0.29255521297454834
train_iter_loss: 0.29851841926574707
train_iter_loss: 0.3007705807685852
train_iter_loss: 0.3157140910625458
train_iter_loss: 0.2818579375743866
train_iter_loss: 0.2824726998806
train_iter_loss: 0.2606455385684967
train_iter_loss: 0.31122612953186035
train_iter_loss: 0.29401424527168274
train_iter_loss: 0.2870512306690216
train_iter_loss: 0.32716643810272217
train_iter_loss: 0.2980421483516693
train_iter_loss: 0.28762760758399963
train_iter_loss: 0.293364942073822
train_iter_loss: 0.285543292760849
train_iter_loss: 0.3346516788005829
train_iter_loss: 0.32791516184806824
train_iter_loss: 0.38675037026405334
train_iter_loss: 0.30736464262008667
train_iter_loss: 0.3611186444759369
train_iter_loss: 0.30035990476608276
train_iter_loss: 0.3526282012462616
train_iter_loss: 0.324480265378952
train_iter_loss: 0.289029061794281
train_iter_loss: 0.2905008792877197
train_iter_loss: 0.26634642481803894
train_iter_loss: 0.28415414690971375
train_iter_loss: 0.33368533849716187
train_iter_loss: 0.2931015193462372
train_iter_loss: 0.32732725143432617
train_iter_loss: 0.3923647701740265
train_iter_loss: 0.3100704252719879
train_iter_loss: 0.29663896560668945
train_iter_loss: 0.31342244148254395
train_iter_loss: 0.31707510352134705
train_iter_loss: 0.29447823762893677
train_iter_loss: 0.3370548188686371
train_iter_loss: 0.3055521249771118
train_iter_loss: 0.2885163426399231
train_iter_loss: 0.3300637900829315
train_iter_loss: 0.2791074812412262
train_iter_loss: 0.2623347342014313
train_iter_loss: 0.29754340648651123
train_iter_loss: 0.26679733395576477
train_iter_loss: 0.33191025257110596
train_iter_loss: 0.30435553193092346
train_iter_loss: 0.28656005859375
train_iter_loss: 0.28498315811157227
train_iter_loss: 0.372596800327301
train_iter_loss: 0.28399911522865295
train_iter_loss: 0.33477672934532166
train_iter_loss: 0.32046979665756226
train_iter_loss: 0.3556370139122009
train_iter_loss: 0.3894294798374176
train_iter_loss: 0.28394049406051636
train_iter_loss: 0.2869702875614166
train_iter_loss: 0.29922065138816833
train_iter_loss: 0.3044107258319855
train_iter_loss: 0.2924674153327942
train_iter_loss: 0.2626568675041199
train_iter_loss: 0.29399198293685913
train_iter_loss: 0.3434320092201233
train loss :0.3148
---------------------
Validation seg loss: 0.33825411563212016 at epoch 16
********************
best_val_epoch_loss:  0.33825411563212016
MODEL UPDATED
epoch =     17/  1000, exp = train
train_iter_loss: 0.27736198902130127
train_iter_loss: 0.3120625913143158
train_iter_loss: 0.28398725390434265
train_iter_loss: 0.3433400094509125
train_iter_loss: 0.36368292570114136
train_iter_loss: 0.30854532122612
train_iter_loss: 0.26866674423217773
train_iter_loss: 0.2691585123538971
train_iter_loss: 0.3477739691734314
train_iter_loss: 0.4364650249481201
train_iter_loss: 0.26435115933418274
train_iter_loss: 0.33895745873451233
train_iter_loss: 0.2952573001384735
train_iter_loss: 0.3754749000072479
train_iter_loss: 0.30302029848098755
train_iter_loss: 0.3133755326271057
train_iter_loss: 0.30168968439102173
train_iter_loss: 0.3149327039718628
train_iter_loss: 0.2951638400554657
train_iter_loss: 0.3631199300289154
train_iter_loss: 0.29087376594543457
train_iter_loss: 0.3369898498058319
train_iter_loss: 0.2749533951282501
train_iter_loss: 0.27317488193511963
train_iter_loss: 0.28022822737693787
train_iter_loss: 0.4817001521587372
train_iter_loss: 0.2707954943180084
train_iter_loss: 0.2627779543399811
train_iter_loss: 0.32356446981430054
train_iter_loss: 0.28190600872039795
train_iter_loss: 0.3025369942188263
train_iter_loss: 0.35364142060279846
train_iter_loss: 0.29684683680534363
train_iter_loss: 0.30003243684768677
train_iter_loss: 0.30613306164741516
train_iter_loss: 0.3067612946033478
train_iter_loss: 0.2728394567966461
train_iter_loss: 0.30276423692703247
train_iter_loss: 0.28714728355407715
train_iter_loss: 0.29904890060424805
train_iter_loss: 0.3217678964138031
train_iter_loss: 0.30018723011016846
train_iter_loss: 0.3158060312271118
train_iter_loss: 0.29326575994491577
train_iter_loss: 0.2983231842517853
train_iter_loss: 0.2962108254432678
train_iter_loss: 0.31962850689888
train_iter_loss: 0.2820604741573334
train_iter_loss: 0.3030136525630951
train_iter_loss: 0.3220456838607788
train_iter_loss: 0.42647793889045715
train_iter_loss: 0.37744054198265076
train_iter_loss: 0.2980620563030243
train_iter_loss: 0.3336256146430969
train_iter_loss: 0.2671276926994324
train_iter_loss: 0.2662116587162018
train_iter_loss: 0.30658313632011414
train_iter_loss: 0.34192290902137756
train_iter_loss: 0.3773062825202942
train_iter_loss: 0.26581811904907227
train_iter_loss: 0.33434510231018066
train_iter_loss: 0.45978662371635437
train_iter_loss: 0.28870874643325806
train_iter_loss: 0.39429575204849243
train_iter_loss: 0.30997535586357117
train_iter_loss: 0.2647317051887512
train_iter_loss: 0.27820929884910583
train_iter_loss: 0.2710307836532593
train_iter_loss: 0.2777572274208069
train_iter_loss: 0.398296058177948
train_iter_loss: 0.2828975319862366
train_iter_loss: 0.2645787000656128
train_iter_loss: 0.3099871277809143
train_iter_loss: 0.3088597357273102
train_iter_loss: 0.3392115533351898
train_iter_loss: 0.32582926750183105
train_iter_loss: 0.28452441096305847
train_iter_loss: 0.314977765083313
train_iter_loss: 0.31984513998031616
train_iter_loss: 0.32068851590156555
train_iter_loss: 0.31909748911857605
train_iter_loss: 0.3399147689342499
train_iter_loss: 0.24803590774536133
train_iter_loss: 0.2751818597316742
train_iter_loss: 0.2877776324748993
train_iter_loss: 0.29812175035476685
train_iter_loss: 0.2875184416770935
train_iter_loss: 0.2843853533267975
train_iter_loss: 0.32146474719047546
train_iter_loss: 0.2734968960285187
train_iter_loss: 0.29363057017326355
train_iter_loss: 0.26640602946281433
train_iter_loss: 0.2955732047557831
train_iter_loss: 0.3009887635707855
train_iter_loss: 0.2763935327529907
train_iter_loss: 0.3069609999656677
train_iter_loss: 0.28911909461021423
train_iter_loss: 0.2469993233680725
train_iter_loss: 0.24576300382614136
train_iter_loss: 0.3289673626422882
train_iter_loss: 0.3281470239162445
train_iter_loss: 0.2538103759288788
train_iter_loss: 0.3190597891807556
train_iter_loss: 0.314667671918869
train_iter_loss: 0.3157236874103546
train_iter_loss: 0.2655942142009735
train_iter_loss: 0.35533902049064636
train_iter_loss: 0.3500387370586395
train_iter_loss: 0.28825637698173523
train_iter_loss: 0.3154864013195038
train_iter_loss: 0.2681135833263397
train_iter_loss: 0.30009907484054565
train_iter_loss: 0.2764348089694977
train_iter_loss: 0.32881075143814087
train_iter_loss: 0.30918383598327637
train_iter_loss: 0.33967486023902893
train_iter_loss: 0.31829214096069336
train_iter_loss: 0.2749953269958496
train_iter_loss: 0.2705812454223633
train_iter_loss: 0.3557591736316681
train_iter_loss: 0.3073085844516754
train_iter_loss: 0.2950751483440399
train_iter_loss: 0.3695410192012787
train_iter_loss: 0.3041960299015045
train_iter_loss: 0.27984651923179626
train_iter_loss: 0.3091922700405121
train_iter_loss: 0.3020764887332916
train_iter_loss: 0.2838408648967743
train_iter_loss: 0.26146644353866577
train_iter_loss: 0.2832167446613312
train_iter_loss: 0.262398362159729
train_iter_loss: 0.2853301167488098
train_iter_loss: 0.33265912532806396
train_iter_loss: 0.3521609306335449
train_iter_loss: 0.2779674828052521
train_iter_loss: 0.3007679879665375
train_iter_loss: 0.3593885898590088
train_iter_loss: 0.29169127345085144
train_iter_loss: 0.30254462361335754
train_iter_loss: 0.29969140887260437
train_iter_loss: 0.38527920842170715
train_iter_loss: 0.28385525941848755
train_iter_loss: 0.28938040137290955
train_iter_loss: 0.3507775366306305
train_iter_loss: 0.28054842352867126
train_iter_loss: 0.4026605188846588
train_iter_loss: 0.3296847641468048
train_iter_loss: 0.28349846601486206
train_iter_loss: 0.27004003524780273
train_iter_loss: 0.31746387481689453
train_iter_loss: 0.2785419523715973
train_iter_loss: 0.3430192470550537
train_iter_loss: 0.3961566090583801
train_iter_loss: 0.2795192301273346
train_iter_loss: 0.2949950695037842
train_iter_loss: 0.35608816146850586
train_iter_loss: 0.29082947969436646
train_iter_loss: 0.27821996808052063
train_iter_loss: 0.34046342968940735
train_iter_loss: 0.3113632798194885
train_iter_loss: 0.27344268560409546
train_iter_loss: 0.2707800567150116
train_iter_loss: 0.4011399745941162
train_iter_loss: 0.2929934859275818
train_iter_loss: 0.319024920463562
train_iter_loss: 0.4324871897697449
train_iter_loss: 0.31872689723968506
train_iter_loss: 0.34151700139045715
train_iter_loss: 0.32948917150497437
train_iter_loss: 0.30710190534591675
train_iter_loss: 0.2969988286495209
train_iter_loss: 0.2972784638404846
train_iter_loss: 0.3009795844554901
train_iter_loss: 0.35523244738578796
train_iter_loss: 0.3075301945209503
train_iter_loss: 0.2969842553138733
train_iter_loss: 0.4044991731643677
train_iter_loss: 0.31583288311958313
train_iter_loss: 0.2920340597629547
train_iter_loss: 0.2744161784648895
train_iter_loss: 0.27083197236061096
train_iter_loss: 0.28913918137550354
train_iter_loss: 0.30510640144348145
train_iter_loss: 0.277639240026474
train_iter_loss: 0.2811996638774872
train_iter_loss: 0.28756406903266907
train_iter_loss: 0.2602444291114807
train_iter_loss: 0.3517685532569885
train_iter_loss: 0.3474486470222473
train_iter_loss: 0.27016323804855347
train_iter_loss: 0.29373404383659363
train_iter_loss: 0.24835412204265594
train_iter_loss: 0.34939703345298767
train_iter_loss: 0.26619085669517517
train_iter_loss: 0.263376921415329
train_iter_loss: 0.2810662090778351
train_iter_loss: 0.2774801254272461
train_iter_loss: 0.32063737511634827
train_iter_loss: 0.2833814024925232
train_iter_loss: 0.26701027154922485
train loss :0.3102
---------------------
Validation seg loss: 0.34292358652038396 at epoch 17
epoch =     18/  1000, exp = train
train_iter_loss: 0.3475470244884491
train_iter_loss: 0.2950880825519562
train_iter_loss: 0.315745085477829
train_iter_loss: 0.2852451801300049
train_iter_loss: 0.3407396674156189
train_iter_loss: 0.2787366509437561
train_iter_loss: 0.29488763213157654
train_iter_loss: 0.28528642654418945
train_iter_loss: 0.27484816312789917
train_iter_loss: 0.3001706898212433
train_iter_loss: 0.311938613653183
train_iter_loss: 0.2795027494430542
train_iter_loss: 0.2929740846157074
train_iter_loss: 0.2977992594242096
train_iter_loss: 0.34845998883247375
train_iter_loss: 0.47096654772758484
train_iter_loss: 0.345242977142334
train_iter_loss: 0.27314260601997375
train_iter_loss: 0.35623058676719666
train_iter_loss: 0.2737894356250763
train_iter_loss: 0.31539687514305115
train_iter_loss: 0.3023892045021057
train_iter_loss: 0.3118414878845215
train_iter_loss: 0.30093151330947876
train_iter_loss: 0.3148888349533081
train_iter_loss: 0.4889909625053406
train_iter_loss: 0.3539063036441803
train_iter_loss: 0.3106097877025604
train_iter_loss: 0.32843202352523804
train_iter_loss: 0.29294607043266296
train_iter_loss: 0.2792849540710449
train_iter_loss: 0.30924952030181885
train_iter_loss: 0.3388475775718689
train_iter_loss: 0.3371967077255249
train_iter_loss: 0.2730129063129425
train_iter_loss: 0.2651859521865845
train_iter_loss: 0.3057945668697357
train_iter_loss: 0.3930674195289612
train_iter_loss: 0.28173959255218506
train_iter_loss: 0.2697598934173584
train_iter_loss: 0.2936866581439972
train_iter_loss: 0.340735524892807
train_iter_loss: 0.35806748270988464
train_iter_loss: 0.29160019755363464
train_iter_loss: 0.2648787796497345
train_iter_loss: 0.2874709367752075
train_iter_loss: 0.26455485820770264
train_iter_loss: 0.2655375301837921
train_iter_loss: 0.2818538248538971
train_iter_loss: 0.2778299152851105
train_iter_loss: 0.25327789783477783
train_iter_loss: 0.28288906812667847
train_iter_loss: 0.30513426661491394
train_iter_loss: 0.24420730769634247
train_iter_loss: 0.32620659470558167
train_iter_loss: 0.2689821422100067
train_iter_loss: 0.38324543833732605
train_iter_loss: 0.298312246799469
train_iter_loss: 0.3204634487628937
train_iter_loss: 0.2701975703239441
train_iter_loss: 0.3022761344909668
train_iter_loss: 0.2967637777328491
train_iter_loss: 0.2745945155620575
train_iter_loss: 0.3435990512371063
train_iter_loss: 0.28123393654823303
train_iter_loss: 0.3110558092594147
train_iter_loss: 0.2836194336414337
train_iter_loss: 0.33651456236839294
train_iter_loss: 0.26808059215545654
train_iter_loss: 0.33448106050491333
train_iter_loss: 0.28627467155456543
train_iter_loss: 0.3796238601207733
train_iter_loss: 0.31473642587661743
train_iter_loss: 0.28485044836997986
train_iter_loss: 0.27039676904678345
train_iter_loss: 0.2834501266479492
train_iter_loss: 0.3339969217777252
train_iter_loss: 0.3169157803058624
train_iter_loss: 0.31550052762031555
train_iter_loss: 0.24966062605381012
train_iter_loss: 0.28708943724632263
train_iter_loss: 0.3375186622142792
train_iter_loss: 0.25503015518188477
train_iter_loss: 0.29174569249153137
train_iter_loss: 0.3497975170612335
train_iter_loss: 0.26499462127685547
train_iter_loss: 0.3250308036804199
train_iter_loss: 0.27466386556625366
train_iter_loss: 0.26778852939605713
train_iter_loss: 0.24449677765369415
train_iter_loss: 0.2894369065761566
train_iter_loss: 0.24168705940246582
train_iter_loss: 0.2686001658439636
train_iter_loss: 0.25896960496902466
train_iter_loss: 0.3392031490802765
train_iter_loss: 0.41018739342689514
train_iter_loss: 0.37305161356925964
train_iter_loss: 0.2613811194896698
train_iter_loss: 0.27485066652297974
train_iter_loss: 0.30024296045303345
train_iter_loss: 0.302414208650589
train_iter_loss: 0.25919416546821594
train_iter_loss: 0.3062223792076111
train_iter_loss: 0.34181877970695496
train_iter_loss: 0.28227296471595764
train_iter_loss: 0.27577364444732666
train_iter_loss: 0.31401485204696655
train_iter_loss: 0.3047714829444885
train_iter_loss: 0.2612784206867218
train_iter_loss: 0.3283194601535797
train_iter_loss: 0.3179285526275635
train_iter_loss: 0.26569291949272156
train_iter_loss: 0.32672086358070374
train_iter_loss: 0.29121097922325134
train_iter_loss: 0.31255102157592773
train_iter_loss: 0.2809559404850006
train_iter_loss: 0.3334372639656067
train_iter_loss: 0.3300100266933441
train_iter_loss: 0.25319531559944153
train_iter_loss: 0.3485998213291168
train_iter_loss: 0.295261025428772
train_iter_loss: 0.3062899708747864
train_iter_loss: 0.33306774497032166
train_iter_loss: 0.2815459668636322
train_iter_loss: 0.327163964509964
train_iter_loss: 0.283700168132782
train_iter_loss: 0.27995580434799194
train_iter_loss: 0.293368399143219
train_iter_loss: 0.2866922914981842
train_iter_loss: 0.23791922628879547
train_iter_loss: 0.25736647844314575
train_iter_loss: 0.3122482895851135
train_iter_loss: 0.3027421236038208
train_iter_loss: 0.3207184374332428
train_iter_loss: 0.2960034906864166
train_iter_loss: 0.27254173159599304
train_iter_loss: 0.2570716142654419
train_iter_loss: 0.3424072563648224
train_iter_loss: 0.3080275356769562
train_iter_loss: 0.29506564140319824
train_iter_loss: 0.3874981701374054
train_iter_loss: 0.3181256353855133
train_iter_loss: 0.2474052906036377
train_iter_loss: 0.23406654596328735
train_iter_loss: 0.3179016411304474
train_iter_loss: 0.2746591866016388
train_iter_loss: 0.2865985333919525
train_iter_loss: 0.313451886177063
train_iter_loss: 0.2531260550022125
train_iter_loss: 0.2475701868534088
train_iter_loss: 0.27911314368247986
train_iter_loss: 0.28009048104286194
train_iter_loss: 0.2881401479244232
train_iter_loss: 0.2854475975036621
train_iter_loss: 0.367489218711853
train_iter_loss: 0.3058711886405945
train_iter_loss: 0.26804572343826294
train_iter_loss: 0.27063387632369995
train_iter_loss: 0.2779260277748108
train_iter_loss: 0.3261013329029083
train_iter_loss: 0.2941493093967438
train_iter_loss: 0.3320845067501068
train_iter_loss: 0.2646675407886505
train_iter_loss: 0.31102558970451355
train_iter_loss: 0.38215547800064087
train_iter_loss: 0.377022385597229
train_iter_loss: 0.2579873204231262
train_iter_loss: 0.3646937608718872
train_iter_loss: 0.31805115938186646
train_iter_loss: 0.24847257137298584
train_iter_loss: 0.2931387424468994
train_iter_loss: 0.2901580035686493
train_iter_loss: 0.36875781416893005
train_iter_loss: 0.2495957911014557
train_iter_loss: 0.27909785509109497
train_iter_loss: 0.3114630877971649
train_iter_loss: 0.3029308021068573
train_iter_loss: 0.30471521615982056
train_iter_loss: 0.2331596314907074
train_iter_loss: 0.3667644262313843
train_iter_loss: 0.3238987624645233
train_iter_loss: 0.27605485916137695
train_iter_loss: 0.36609113216400146
train_iter_loss: 0.31819307804107666
train_iter_loss: 0.2654462456703186
train_iter_loss: 0.28301000595092773
train_iter_loss: 0.27031412720680237
train_iter_loss: 0.3830462396144867
train_iter_loss: 0.3239552676677704
train_iter_loss: 0.3041929304599762
train_iter_loss: 0.3021261394023895
train_iter_loss: 0.29561108350753784
train_iter_loss: 0.26288551092147827
train_iter_loss: 0.2849513590335846
train_iter_loss: 0.28473395109176636
train_iter_loss: 0.2721288800239563
train_iter_loss: 0.2726733684539795
train_iter_loss: 0.34554165601730347
train_iter_loss: 0.3770679831504822
train_iter_loss: 0.3294466733932495
train loss :0.3043
---------------------
Validation seg loss: 0.33820404238858315 at epoch 18
********************
best_val_epoch_loss:  0.33820404238858315
MODEL UPDATED
epoch =     19/  1000, exp = train
train_iter_loss: 0.2851795554161072
train_iter_loss: 0.3247325122356415
train_iter_loss: 0.28804701566696167
train_iter_loss: 0.308502733707428
train_iter_loss: 0.3849621117115021
train_iter_loss: 0.3738366961479187
train_iter_loss: 0.2567070722579956
train_iter_loss: 0.36313897371292114
train_iter_loss: 0.3181372582912445
train_iter_loss: 0.31577351689338684
train_iter_loss: 0.2747098207473755
train_iter_loss: 0.28958606719970703
train_iter_loss: 0.27172228693962097
train_iter_loss: 0.3909325897693634
train_iter_loss: 0.32255688309669495
train_iter_loss: 0.24619299173355103
train_iter_loss: 0.2703436315059662
train_iter_loss: 0.28095901012420654
train_iter_loss: 0.22670623660087585
train_iter_loss: 0.2778310477733612
train_iter_loss: 0.30931392312049866
train_iter_loss: 0.27511927485466003
train_iter_loss: 0.33783063292503357
train_iter_loss: 0.3089461028575897
train_iter_loss: 0.3302935063838959
train_iter_loss: 0.31212958693504333
train_iter_loss: 0.2756806015968323
train_iter_loss: 0.47553542256355286
train_iter_loss: 0.280123770236969
train_iter_loss: 0.2672733962535858
train_iter_loss: 0.28599411249160767
train_iter_loss: 0.26973316073417664
train_iter_loss: 0.37989309430122375
train_iter_loss: 0.3936808407306671
train_iter_loss: 0.292047917842865
train_iter_loss: 0.30100104212760925
train_iter_loss: 0.2773474454879761
train_iter_loss: 0.29594936966896057
train_iter_loss: 0.3470543920993805
train_iter_loss: 0.34800902009010315
train_iter_loss: 0.26671403646469116
train_iter_loss: 0.28921788930892944
train_iter_loss: 0.28395697474479675
train_iter_loss: 0.2806346118450165
train_iter_loss: 0.32652920484542847
train_iter_loss: 0.3266681730747223
train_iter_loss: 0.25523054599761963
train_iter_loss: 0.278720498085022
train_iter_loss: 0.3539140224456787
train_iter_loss: 0.2759281396865845
train_iter_loss: 0.3132902979850769
train_iter_loss: 0.2808268964290619
train_iter_loss: 0.2699110507965088
train_iter_loss: 0.27356427907943726
train_iter_loss: 0.3436470925807953
train_iter_loss: 0.2689211070537567
train_iter_loss: 0.34606418013572693
train_iter_loss: 0.29638367891311646
train_iter_loss: 0.24336394667625427
train_iter_loss: 0.281989187002182
train_iter_loss: 0.3183198869228363
train_iter_loss: 0.2918301522731781
train_iter_loss: 0.2844774127006531
train_iter_loss: 0.2964703440666199
train_iter_loss: 0.33460575342178345
train_iter_loss: 0.25348255038261414
train_iter_loss: 0.2506311237812042
train_iter_loss: 0.25871187448501587
train_iter_loss: 0.27945709228515625
train_iter_loss: 0.25489339232444763
train_iter_loss: 0.3280147314071655
train_iter_loss: 0.28195589780807495
train_iter_loss: 0.29916998744010925
train_iter_loss: 0.33744022250175476
train_iter_loss: 0.27587461471557617
train_iter_loss: 0.27654337882995605
train_iter_loss: 0.29570621252059937
train_iter_loss: 0.2852441370487213
train_iter_loss: 0.2749423682689667
train_iter_loss: 0.26086142659187317
train_iter_loss: 0.2550114393234253
train_iter_loss: 0.33028048276901245
train_iter_loss: 0.26168787479400635
train_iter_loss: 0.2831744849681854
train_iter_loss: 0.30669379234313965
train_iter_loss: 0.3193327784538269
train_iter_loss: 0.29451265931129456
train_iter_loss: 0.2896776795387268
train_iter_loss: 0.2433299422264099
train_iter_loss: 0.28085237741470337
train_iter_loss: 0.2873547077178955
train_iter_loss: 0.3750866651535034
train_iter_loss: 0.2445482462644577
train_iter_loss: 0.31265079975128174
train_iter_loss: 0.29640984535217285
train_iter_loss: 0.35233908891677856
train_iter_loss: 0.2875668406486511
train_iter_loss: 0.24582691490650177
train_iter_loss: 0.37061867117881775
train_iter_loss: 0.3907404839992523
train_iter_loss: 0.33700957894325256
train_iter_loss: 0.2411036640405655
train_iter_loss: 0.2477358877658844
train_iter_loss: 0.25804734230041504
train_iter_loss: 0.32495081424713135
train_iter_loss: 0.38866156339645386
train_iter_loss: 0.303803414106369
train_iter_loss: 0.31731870770454407
train_iter_loss: 0.24410106241703033
train_iter_loss: 0.26420027017593384
train_iter_loss: 0.2509572207927704
train_iter_loss: 0.2954518496990204
train_iter_loss: 0.3254104256629944
train_iter_loss: 0.3183099627494812
train_iter_loss: 0.310526967048645
train_iter_loss: 0.412747859954834
train_iter_loss: 0.28109145164489746
train_iter_loss: 0.40190520882606506
train_iter_loss: 0.2731320858001709
train_iter_loss: 0.2759191691875458
train_iter_loss: 0.26405611634254456
train_iter_loss: 0.329311341047287
train_iter_loss: 0.31751567125320435
train_iter_loss: 0.2563820481300354
train_iter_loss: 0.24963442981243134
train_iter_loss: 0.28852179646492004
train_iter_loss: 0.2757236063480377
train_iter_loss: 0.2816011607646942
train_iter_loss: 0.2762606739997864
train_iter_loss: 0.31036266684532166
train_iter_loss: 0.3023519814014435
train_iter_loss: 0.3409336805343628
train_iter_loss: 0.2982587516307831
train_iter_loss: 0.2769298553466797
train_iter_loss: 0.288655161857605
train_iter_loss: 0.2979710102081299
train_iter_loss: 0.25922638177871704
train_iter_loss: 0.3442284166812897
train_iter_loss: 0.3066079020500183
train_iter_loss: 0.25446557998657227
train_iter_loss: 0.3007727563381195
train_iter_loss: 0.31210803985595703
train_iter_loss: 0.25881364941596985
train_iter_loss: 0.2687336802482605
train_iter_loss: 0.2690633535385132
train_iter_loss: 0.31767386198043823
train_iter_loss: 0.2702028751373291
train_iter_loss: 0.2753904461860657
train_iter_loss: 0.3666941821575165
train_iter_loss: 0.2697681486606598
train_iter_loss: 0.25550371408462524
train_iter_loss: 0.2916516661643982
train_iter_loss: 0.3194907009601593
train_iter_loss: 0.2684701979160309
train_iter_loss: 0.2722899615764618
train_iter_loss: 0.26727110147476196
train_iter_loss: 0.27618372440338135
train_iter_loss: 0.2886667251586914
train_iter_loss: 0.25760746002197266
train_iter_loss: 0.33317241072654724
train_iter_loss: 0.3179718255996704
train_iter_loss: 0.31110870838165283
train_iter_loss: 0.3049679398536682
train_iter_loss: 0.31069815158843994
train_iter_loss: 0.289796382188797
train_iter_loss: 0.25288644433021545
train_iter_loss: 0.30707260966300964
train_iter_loss: 0.2797136902809143
train_iter_loss: 0.31078070402145386
train_iter_loss: 0.32040396332740784
train_iter_loss: 0.2539674937725067
train_iter_loss: 0.27232176065444946
train_iter_loss: 0.3039078414440155
train_iter_loss: 0.3115236759185791
train_iter_loss: 0.30997711420059204
train_iter_loss: 0.2772502899169922
train_iter_loss: 0.2642097771167755
train_iter_loss: 0.27604562044143677
train_iter_loss: 0.43700510263442993
train_iter_loss: 0.24733364582061768
train_iter_loss: 0.2889266312122345
train_iter_loss: 0.35262325406074524
train_iter_loss: 0.2422318458557129
train_iter_loss: 0.34919050335884094
train_iter_loss: 0.29300662875175476
train_iter_loss: 0.3549920916557312
train_iter_loss: 0.29672738909721375
train_iter_loss: 0.28579938411712646
train_iter_loss: 0.2947411835193634
train_iter_loss: 0.2785760164260864
train_iter_loss: 0.27385714650154114
train_iter_loss: 0.2949897050857544
train_iter_loss: 0.28994020819664
train_iter_loss: 0.2719751298427582
train_iter_loss: 0.3530539870262146
train_iter_loss: 0.2690829336643219
train_iter_loss: 0.2879035174846649
train_iter_loss: 0.3097701668739319
train_iter_loss: 0.3454779386520386
train_iter_loss: 0.2817162871360779
train loss :0.2998
---------------------
Validation seg loss: 0.3379652533891066 at epoch 19
********************
best_val_epoch_loss:  0.3379652533891066
MODEL UPDATED
epoch =     20/  1000, exp = train
train_iter_loss: 0.37210813164711
train_iter_loss: 0.25624868273735046
train_iter_loss: 0.2604779303073883
train_iter_loss: 0.33336204290390015
train_iter_loss: 0.283546507358551
train_iter_loss: 0.2716474235057831
train_iter_loss: 0.30188682675361633
train_iter_loss: 0.25150376558303833
train_iter_loss: 0.2512610852718353
train_iter_loss: 0.3097027838230133
train_iter_loss: 0.2845933437347412
train_iter_loss: 0.2629624903202057
train_iter_loss: 0.2848036289215088
train_iter_loss: 0.2960878014564514
train_iter_loss: 0.2876969873905182
train_iter_loss: 0.24870403110980988
train_iter_loss: 0.2895840108394623
train_iter_loss: 0.26304179430007935
train_iter_loss: 0.2744123935699463
train_iter_loss: 0.29524585604667664
train_iter_loss: 0.2581225037574768
train_iter_loss: 0.34810033440589905
train_iter_loss: 0.26179659366607666
train_iter_loss: 0.2776472270488739
train_iter_loss: 0.2778165936470032
train_iter_loss: 0.27843812108039856
train_iter_loss: 0.27090418338775635
train_iter_loss: 0.24119018018245697
train_iter_loss: 0.27846065163612366
train_iter_loss: 0.3040933310985565
train_iter_loss: 0.3875252604484558
train_iter_loss: 0.30883336067199707
train_iter_loss: 0.2593386471271515
train_iter_loss: 0.31627917289733887
train_iter_loss: 0.29057830572128296
train_iter_loss: 0.3081522285938263
train_iter_loss: 0.33597007393836975
train_iter_loss: 0.34735825657844543
train_iter_loss: 0.2823815941810608
train_iter_loss: 0.32681453227996826
train_iter_loss: 0.2887541949748993
train_iter_loss: 0.2699010372161865
train_iter_loss: 0.2812616527080536
train_iter_loss: 0.27071139216423035
train_iter_loss: 0.35627493262290955
train_iter_loss: 0.28852248191833496
train_iter_loss: 0.38311025500297546
train_iter_loss: 0.2804991900920868
train_iter_loss: 0.325777143239975
train_iter_loss: 0.3361441493034363
train_iter_loss: 0.258948415517807
train_iter_loss: 0.2671295404434204
train_iter_loss: 0.3727596700191498
train_iter_loss: 0.31589409708976746
train_iter_loss: 0.2623879015445709
train_iter_loss: 0.28846418857574463
train_iter_loss: 0.27972838282585144
train_iter_loss: 0.30077266693115234
train_iter_loss: 0.3020547926425934
train_iter_loss: 0.3274173438549042
train_iter_loss: 0.30316033959388733
train_iter_loss: 0.256351113319397
train_iter_loss: 0.3161194622516632
train_iter_loss: 0.2664209306240082
train_iter_loss: 0.27366626262664795
train_iter_loss: 0.24131660163402557
train_iter_loss: 0.2762216031551361
train_iter_loss: 0.23904640972614288
train_iter_loss: 0.3571114242076874
train_iter_loss: 0.24776530265808105
train_iter_loss: 0.25288182497024536
train_iter_loss: 0.2425817996263504
train_iter_loss: 0.5427374243736267
train_iter_loss: 0.27046042680740356
train_iter_loss: 0.2619335651397705
train_iter_loss: 0.4130038022994995
train_iter_loss: 0.2456030249595642
train_iter_loss: 0.3080874979496002
train_iter_loss: 0.3204386830329895
train_iter_loss: 0.2675105929374695
train_iter_loss: 0.2118680626153946
train_iter_loss: 0.36822301149368286
train_iter_loss: 0.27885740995407104
train_iter_loss: 0.29337984323501587
train_iter_loss: 0.30385029315948486
train_iter_loss: 0.287883996963501
train_iter_loss: 0.27935221791267395
train_iter_loss: 0.26680684089660645
train_iter_loss: 0.27916839718818665
train_iter_loss: 0.27991318702697754
train_iter_loss: 0.2978942394256592
train_iter_loss: 0.28755250573158264
train_iter_loss: 0.31705769896507263
train_iter_loss: 0.39719268679618835
train_iter_loss: 0.2905491292476654
train_iter_loss: 0.28726935386657715
train_iter_loss: 0.3359431028366089
train_iter_loss: 0.2751826345920563
train_iter_loss: 0.34614327549934387
train_iter_loss: 0.268209308385849
train_iter_loss: 0.3845536410808563
train_iter_loss: 0.29936933517456055
train_iter_loss: 0.3654247522354126
train_iter_loss: 0.3217765688896179
train_iter_loss: 0.30071958899497986
train_iter_loss: 0.25988104939460754
train_iter_loss: 0.27773818373680115
train_iter_loss: 0.29870614409446716
train_iter_loss: 0.3178998827934265
train_iter_loss: 0.26929688453674316
train_iter_loss: 0.28773781657218933
train_iter_loss: 0.3532293736934662
train_iter_loss: 0.27933427691459656
train_iter_loss: 0.3108159899711609
train_iter_loss: 0.31066223978996277
train_iter_loss: 0.3389471769332886
train_iter_loss: 0.28178101778030396
train_iter_loss: 0.318553626537323
train_iter_loss: 0.3150946795940399
train_iter_loss: 0.23654508590698242
train_iter_loss: 0.26074546575546265
train_iter_loss: 0.2974870800971985
train_iter_loss: 0.3165736496448517
train_iter_loss: 0.3145858645439148
train_iter_loss: 0.29661840200424194
train_iter_loss: 0.2992672026157379
train_iter_loss: 0.30049461126327515
train_iter_loss: 0.281767874956131
train_iter_loss: 0.2678435444831848
train_iter_loss: 0.26668137311935425
train_iter_loss: 0.3638719618320465
train_iter_loss: 0.2419486790895462
train_iter_loss: 0.36219874024391174
train_iter_loss: 0.2760215997695923
train_iter_loss: 0.3431125283241272
train_iter_loss: 0.2738574147224426
train_iter_loss: 0.24258989095687866
train_iter_loss: 0.27105778455734253
train_iter_loss: 0.28901129961013794
train_iter_loss: 0.2929127812385559
train_iter_loss: 0.2660495638847351
train_iter_loss: 0.3110540807247162
train_iter_loss: 0.36165696382522583
train_iter_loss: 0.26769697666168213
train_iter_loss: 0.2674836218357086
train_iter_loss: 0.4160439670085907
train_iter_loss: 0.23350262641906738
train_iter_loss: 0.24929086863994598
train_iter_loss: 0.2919885218143463
train_iter_loss: 0.23416446149349213
train_iter_loss: 0.3106958270072937
train_iter_loss: 0.3120028078556061
train_iter_loss: 0.24580051004886627
train_iter_loss: 0.289743036031723
train_iter_loss: 0.2778399884700775
train_iter_loss: 0.3455139696598053
train_iter_loss: 0.3749556243419647
train_iter_loss: 0.2350568175315857
train_iter_loss: 0.3032035231590271
train_iter_loss: 0.2991742193698883
train_iter_loss: 0.296740859746933
train_iter_loss: 0.2904070317745209
train_iter_loss: 0.31488722562789917
train_iter_loss: 0.2736862003803253
train_iter_loss: 0.2501833438873291
train_iter_loss: 0.32987990975379944
train_iter_loss: 0.33828026056289673
train_iter_loss: 0.2828477621078491
train_iter_loss: 0.3414528965950012
train_iter_loss: 0.30144861340522766
train_iter_loss: 0.34930360317230225
train_iter_loss: 0.27258479595184326
train_iter_loss: 0.2969409227371216
train_iter_loss: 0.3801128566265106
train_iter_loss: 0.30859988927841187
train_iter_loss: 0.24914811551570892
train_iter_loss: 0.23689748346805573
train_iter_loss: 0.25654831528663635
train_iter_loss: 0.2551806569099426
train_iter_loss: 0.33538442850112915
train_iter_loss: 0.24338982999324799
train_iter_loss: 0.2820635437965393
train_iter_loss: 0.29524874687194824
train_iter_loss: 0.27908697724342346
train_iter_loss: 0.2734300494194031
train_iter_loss: 0.32422512769699097
train_iter_loss: 0.27805212140083313
train_iter_loss: 0.24578441679477692
train_iter_loss: 0.27947044372558594
train_iter_loss: 0.23847708106040955
train_iter_loss: 0.27727824449539185
train_iter_loss: 0.2697005867958069
train_iter_loss: 0.2342492640018463
train_iter_loss: 0.25437596440315247
train_iter_loss: 0.26955893635749817
train_iter_loss: 0.3517283499240875
train_iter_loss: 0.2687676250934601
train_iter_loss: 0.376507043838501
train_iter_loss: 0.2825675904750824
train_iter_loss: 0.23850074410438538
train loss :0.2963
---------------------
Validation seg loss: 0.3372627482661661 at epoch 20
********************
best_val_epoch_loss:  0.3372627482661661
MODEL UPDATED
epoch =     21/  1000, exp = train
train_iter_loss: 0.27021512389183044
train_iter_loss: 0.3066112697124481
train_iter_loss: 0.24220553040504456
train_iter_loss: 0.2559294104576111
train_iter_loss: 0.27525126934051514
train_iter_loss: 0.36630740761756897
train_iter_loss: 0.34070107340812683
train_iter_loss: 0.3572313189506531
train_iter_loss: 0.3691045045852661
train_iter_loss: 0.2647145390510559
train_iter_loss: 0.2414885014295578
train_iter_loss: 0.29352790117263794
train_iter_loss: 0.406800240278244
train_iter_loss: 0.3442825675010681
train_iter_loss: 0.3004620373249054
train_iter_loss: 0.3296718895435333
train_iter_loss: 0.2633584439754486
train_iter_loss: 0.2810367941856384
train_iter_loss: 0.2893631160259247
train_iter_loss: 0.28964266180992126
train_iter_loss: 0.27943816781044006
train_iter_loss: 0.2649120092391968
train_iter_loss: 0.3531639277935028
train_iter_loss: 0.2935046851634979
train_iter_loss: 0.2776430547237396
train_iter_loss: 0.27126380801200867
train_iter_loss: 0.2818770706653595
train_iter_loss: 0.2849773168563843
train_iter_loss: 0.27948006987571716
train_iter_loss: 0.28664666414260864
train_iter_loss: 0.32128870487213135
train_iter_loss: 0.3131639063358307
train_iter_loss: 0.28611063957214355
train_iter_loss: 0.40186089277267456
train_iter_loss: 0.25182369351387024
train_iter_loss: 0.28592821955680847
train_iter_loss: 0.2777665853500366
train_iter_loss: 0.30087220668792725
train_iter_loss: 0.29970264434814453
train_iter_loss: 0.3904520273208618
train_iter_loss: 0.24735690653324127
train_iter_loss: 0.2742472290992737
train_iter_loss: 0.33137622475624084
train_iter_loss: 0.30292803049087524
train_iter_loss: 0.29060569405555725
train_iter_loss: 0.29559874534606934
train_iter_loss: 0.25969237089157104
train_iter_loss: 0.288269579410553
train_iter_loss: 0.257259726524353
train_iter_loss: 0.24660292267799377
train_iter_loss: 0.24654439091682434
train_iter_loss: 0.27636078000068665
train_iter_loss: 0.25983116030693054
train_iter_loss: 0.29734495282173157
train_iter_loss: 0.31985628604888916
train_iter_loss: 0.2562090754508972
train_iter_loss: 0.2835495173931122
train_iter_loss: 0.279070645570755
train_iter_loss: 0.3107098340988159
train_iter_loss: 0.26556825637817383
train_iter_loss: 0.271369606256485
train_iter_loss: 0.2856764495372772
train_iter_loss: 0.27219775319099426
train_iter_loss: 0.27167636156082153
train_iter_loss: 0.2566338777542114
train_iter_loss: 0.3148394227027893
train_iter_loss: 0.24690404534339905
train_iter_loss: 0.2472224086523056
train_iter_loss: 0.24881482124328613
train_iter_loss: 0.26015177369117737
train_iter_loss: 0.24016931653022766
train_iter_loss: 0.2994973957538605
train_iter_loss: 0.355949342250824
train_iter_loss: 0.27383536100387573
train_iter_loss: 0.33786267042160034
train_iter_loss: 0.2782972753047943
train_iter_loss: 0.273565411567688
train_iter_loss: 0.3032796084880829
train_iter_loss: 0.38520145416259766
train_iter_loss: 0.291103333234787
train_iter_loss: 0.27662593126296997
train_iter_loss: 0.2976592183113098
train_iter_loss: 0.26084068417549133
train_iter_loss: 0.37599360942840576
train_iter_loss: 0.28816381096839905
train_iter_loss: 0.2771074175834656
train_iter_loss: 0.25624775886535645
train_iter_loss: 0.2718620002269745
train_iter_loss: 0.2990805208683014
train_iter_loss: 0.29933038353919983
train_iter_loss: 0.2700085937976837
train_iter_loss: 0.3038499057292938
train_iter_loss: 0.2818107306957245
train_iter_loss: 0.26253119111061096
train_iter_loss: 0.2632986307144165
train_iter_loss: 0.30424466729164124
train_iter_loss: 0.3125055730342865
train_iter_loss: 0.27827611565589905
train_iter_loss: 0.3085772395133972
train_iter_loss: 0.3641214072704315
train_iter_loss: 0.396101176738739
train_iter_loss: 0.300967812538147
train_iter_loss: 0.24647857248783112
train_iter_loss: 0.3619481325149536
train_iter_loss: 0.27350595593452454
train_iter_loss: 0.2592094838619232
train_iter_loss: 0.29109686613082886
train_iter_loss: 0.2622133493423462
train_iter_loss: 0.30881258845329285
train_iter_loss: 0.2575511038303375
train_iter_loss: 0.2585350275039673
train_iter_loss: 0.32715022563934326
train_iter_loss: 0.2985420823097229
train_iter_loss: 0.24672013521194458
train_iter_loss: 0.2656470537185669
train_iter_loss: 0.25428512692451477
train_iter_loss: 0.22557605803012848
train_iter_loss: 0.2492367923259735
train_iter_loss: 0.266994446516037
train_iter_loss: 0.2944977283477783
train_iter_loss: 0.2918687164783478
train_iter_loss: 0.30620646476745605
train_iter_loss: 0.2448306530714035
train_iter_loss: 0.3364560604095459
train_iter_loss: 0.290737122297287
train_iter_loss: 0.25989314913749695
train_iter_loss: 0.2286568284034729
train_iter_loss: 0.23365511000156403
train_iter_loss: 0.30684053897857666
train_iter_loss: 0.37271276116371155
train_iter_loss: 0.256121963262558
train_iter_loss: 0.3428575396537781
train_iter_loss: 0.2526616156101227
train_iter_loss: 0.2396625429391861
train_iter_loss: 0.2479957491159439
train_iter_loss: 0.28283703327178955
train_iter_loss: 0.27913200855255127
train_iter_loss: 0.23829081654548645
train_iter_loss: 0.2513246238231659
train_iter_loss: 0.27821287512779236
train_iter_loss: 0.36058181524276733
train_iter_loss: 0.26761510968208313
train_iter_loss: 0.377308189868927
train_iter_loss: 0.34993767738342285
train_iter_loss: 0.2760345935821533
train_iter_loss: 0.27262812852859497
train_iter_loss: 0.35230252146720886
train_iter_loss: 0.24721579253673553
train_iter_loss: 0.312761127948761
train_iter_loss: 0.22797870635986328
train_iter_loss: 0.3708331882953644
train_iter_loss: 0.28797248005867004
train_iter_loss: 0.267052561044693
train_iter_loss: 0.3525327146053314
train_iter_loss: 0.24188292026519775
train_iter_loss: 0.2634686231613159
train_iter_loss: 0.28148433566093445
train_iter_loss: 0.28881722688674927
train_iter_loss: 0.3021261692047119
train_iter_loss: 0.23598016798496246
train_iter_loss: 0.26151207089424133
train_iter_loss: 0.3067189157009125
train_iter_loss: 0.28661048412323
train_iter_loss: 0.23801393806934357
train_iter_loss: 0.2743588387966156
train_iter_loss: 0.2788619101047516
train_iter_loss: 0.2480756938457489
train_iter_loss: 0.32190847396850586
train_iter_loss: 0.38073059916496277
train_iter_loss: 0.272810697555542
train_iter_loss: 0.27754467725753784
train_iter_loss: 0.2798977196216583
train_iter_loss: 0.3560088574886322
train_iter_loss: 0.27772441506385803
train_iter_loss: 0.271967351436615
train_iter_loss: 0.27251875400543213
train_iter_loss: 0.3120328187942505
train_iter_loss: 0.28315380215644836
train_iter_loss: 0.27392658591270447
train_iter_loss: 0.32370853424072266
train_iter_loss: 0.2541484236717224
train_iter_loss: 0.2921852469444275
train_iter_loss: 0.3901391327381134
train_iter_loss: 0.3606584966182709
train_iter_loss: 0.3066726326942444
train_iter_loss: 0.2525911331176758
train_iter_loss: 0.27845460176467896
train_iter_loss: 0.25389736890792847
train_iter_loss: 0.32067587971687317
train_iter_loss: 0.24753446877002716
train_iter_loss: 0.28577664494514465
train_iter_loss: 0.2764197587966919
train_iter_loss: 0.37184667587280273
train_iter_loss: 0.24600434303283691
train_iter_loss: 0.2657231092453003
train_iter_loss: 0.27866360545158386
train_iter_loss: 0.29039466381073
train_iter_loss: 0.323067307472229
train_iter_loss: 0.29432380199432373
train_iter_loss: 0.39744362235069275
train loss :0.2922
---------------------
Validation seg loss: 0.32280977998139726 at epoch 21
********************
best_val_epoch_loss:  0.32280977998139726
MODEL UPDATED
epoch =     22/  1000, exp = train
train_iter_loss: 0.35056933760643005
train_iter_loss: 0.274801105260849
train_iter_loss: 0.2717766761779785
train_iter_loss: 0.2936752140522003
train_iter_loss: 0.2742408514022827
train_iter_loss: 0.2520253658294678
train_iter_loss: 0.2497462034225464
train_iter_loss: 0.2506338059902191
train_iter_loss: 0.2945444881916046
train_iter_loss: 0.251643568277359
train_iter_loss: 0.2418268620967865
train_iter_loss: 0.25948962569236755
train_iter_loss: 0.26211047172546387
train_iter_loss: 0.2680942416191101
train_iter_loss: 0.285643070936203
train_iter_loss: 0.29019397497177124
train_iter_loss: 0.26570218801498413
train_iter_loss: 0.3031565845012665
train_iter_loss: 0.24088658392429352
train_iter_loss: 0.3114399313926697
train_iter_loss: 0.33947521448135376
train_iter_loss: 0.2720932066440582
train_iter_loss: 0.26912957429885864
train_iter_loss: 0.32428908348083496
train_iter_loss: 0.25334230065345764
train_iter_loss: 0.30099406838417053
train_iter_loss: 0.2659376859664917
train_iter_loss: 0.3220967650413513
train_iter_loss: 0.25705739855766296
train_iter_loss: 0.24166633188724518
train_iter_loss: 0.29498305916786194
train_iter_loss: 0.280788391828537
train_iter_loss: 0.2967451512813568
train_iter_loss: 0.30119588971138
train_iter_loss: 0.31740397214889526
train_iter_loss: 0.35083550214767456
train_iter_loss: 0.4055637717247009
train_iter_loss: 0.30730339884757996
train_iter_loss: 0.3163755536079407
train_iter_loss: 0.4115685224533081
train_iter_loss: 0.2757057547569275
train_iter_loss: 0.32363978028297424
train_iter_loss: 0.24909837543964386
train_iter_loss: 0.3179698586463928
train_iter_loss: 0.2705371379852295
train_iter_loss: 0.2569398880004883
train_iter_loss: 0.24495317041873932
train_iter_loss: 0.26369720697402954
train_iter_loss: 0.25612398982048035
train_iter_loss: 0.28383830189704895
train_iter_loss: 0.29877105355262756
train_iter_loss: 0.31178897619247437
train_iter_loss: 0.27136585116386414
train_iter_loss: 0.26613283157348633
train_iter_loss: 0.4011761248111725
train_iter_loss: 0.25146061182022095
train_iter_loss: 0.2507655918598175
train_iter_loss: 0.2851536273956299
train_iter_loss: 0.24288000166416168
train_iter_loss: 0.3565981984138489
train_iter_loss: 0.2656536400318146
train_iter_loss: 0.264407753944397
train_iter_loss: 0.2937447726726532
train_iter_loss: 0.2484109252691269
train_iter_loss: 0.3583950996398926
train_iter_loss: 0.25708478689193726
train_iter_loss: 0.2990148663520813
train_iter_loss: 0.3208114802837372
train_iter_loss: 0.28985610604286194
train_iter_loss: 0.2290191948413849
train_iter_loss: 0.29681479930877686
train_iter_loss: 0.28912490606307983
train_iter_loss: 0.2564274072647095
train_iter_loss: 0.28965669870376587
train_iter_loss: 0.28441429138183594
train_iter_loss: 0.27036145329475403
train_iter_loss: 0.25248271226882935
train_iter_loss: 0.2851163446903229
train_iter_loss: 0.28359466791152954
train_iter_loss: 0.2671029269695282
train_iter_loss: 0.2627250552177429
train_iter_loss: 0.2809681296348572
train_iter_loss: 0.2737787067890167
train_iter_loss: 0.29125529527664185
train_iter_loss: 0.2547939121723175
train_iter_loss: 0.2920057475566864
train_iter_loss: 0.3767740726470947
train_iter_loss: 0.24045412242412567
train_iter_loss: 0.2733380198478699
train_iter_loss: 0.3081366717815399
train_iter_loss: 0.2965375483036041
train_iter_loss: 0.23830124735832214
train_iter_loss: 0.3377671241760254
train_iter_loss: 0.3004164397716522
train_iter_loss: 0.2903708219528198
train_iter_loss: 0.2849343717098236
train_iter_loss: 0.26290997862815857
train_iter_loss: 0.4726259410381317
train_iter_loss: 0.3474965989589691
train_iter_loss: 0.2678472697734833
train_iter_loss: 0.3137267529964447
train_iter_loss: 0.3611481785774231
train_iter_loss: 0.2203512340784073
train_iter_loss: 0.2869472801685333
train_iter_loss: 0.31804320216178894
train_iter_loss: 0.3418455123901367
train_iter_loss: 0.27240505814552307
train_iter_loss: 0.40516120195388794
train_iter_loss: 0.2554161846637726
train_iter_loss: 0.2520459294319153
train_iter_loss: 0.2874698042869568
train_iter_loss: 0.2664407193660736
train_iter_loss: 0.25012609362602234
train_iter_loss: 0.3090290129184723
train_iter_loss: 0.36582204699516296
train_iter_loss: 0.26893696188926697
train_iter_loss: 0.2526947557926178
train_iter_loss: 0.24872957170009613
train_iter_loss: 0.24279329180717468
train_iter_loss: 0.35503625869750977
train_iter_loss: 0.28929340839385986
train_iter_loss: 0.2716578543186188
train_iter_loss: 0.30298474431037903
train_iter_loss: 0.2589998245239258
train_iter_loss: 0.33193066716194153
train_iter_loss: 0.3323870301246643
train_iter_loss: 0.2584684193134308
train_iter_loss: 0.2386290729045868
train_iter_loss: 0.24366545677185059
train_iter_loss: 0.30090105533599854
train_iter_loss: 0.2452404797077179
train_iter_loss: 0.2765476405620575
train_iter_loss: 0.27191755175590515
train_iter_loss: 0.25387611985206604
train_iter_loss: 0.31610164046287537
train_iter_loss: 0.2854663133621216
train_iter_loss: 0.2615987956523895
train_iter_loss: 0.32248473167419434
train_iter_loss: 0.2802942991256714
train_iter_loss: 0.2690582871437073
train_iter_loss: 0.3633977174758911
train_iter_loss: 0.34941181540489197
train_iter_loss: 0.23290541768074036
train_iter_loss: 0.29573264718055725
train_iter_loss: 0.28113096952438354
train_iter_loss: 0.31310462951660156
train_iter_loss: 0.34517258405685425
train_iter_loss: 0.27309492230415344
train_iter_loss: 0.24243375658988953
train_iter_loss: 0.29700812697410583
train_iter_loss: 0.25570446252822876
train_iter_loss: 0.2945080101490021
train_iter_loss: 0.3242250382900238
train_iter_loss: 0.25733521580696106
train_iter_loss: 0.329109251499176
train_iter_loss: 0.2779056429862976
train_iter_loss: 0.24145649373531342
train_iter_loss: 0.29838573932647705
train_iter_loss: 0.25332480669021606
train_iter_loss: 0.2389148771762848
train_iter_loss: 0.25251099467277527
train_iter_loss: 0.27935975790023804
train_iter_loss: 0.24436438083648682
train_iter_loss: 0.24122871458530426
train_iter_loss: 0.36007022857666016
train_iter_loss: 0.22613096237182617
train_iter_loss: 0.30376723408699036
train_iter_loss: 0.29352840781211853
train_iter_loss: 0.2951575517654419
train_iter_loss: 0.24307839572429657
train_iter_loss: 0.3672870993614197
train_iter_loss: 0.2824283540248871
train_iter_loss: 0.26198142766952515
train_iter_loss: 0.2848359942436218
train_iter_loss: 0.25250881910324097
train_iter_loss: 0.46999427676200867
train_iter_loss: 0.28848710656166077
train_iter_loss: 0.25044316053390503
train_iter_loss: 0.27151453495025635
train_iter_loss: 0.35531380772590637
train_iter_loss: 0.2813906967639923
train_iter_loss: 0.26996779441833496
train_iter_loss: 0.3963750898838043
train_iter_loss: 0.29425734281539917
train_iter_loss: 0.26460203528404236
train_iter_loss: 0.2339739352464676
train_iter_loss: 0.23937958478927612
train_iter_loss: 0.273908406496048
train_iter_loss: 0.24708496034145355
train_iter_loss: 0.26291564106941223
train_iter_loss: 0.3177703320980072
train_iter_loss: 0.23049908876419067
train_iter_loss: 0.39194169640541077
train_iter_loss: 0.22940954566001892
train_iter_loss: 0.2501208186149597
train_iter_loss: 0.3749803602695465
train_iter_loss: 0.27275240421295166
train_iter_loss: 0.3012807071208954
train_iter_loss: 0.2886766791343689
train_iter_loss: 0.4120630621910095
train loss :0.2903
---------------------
Validation seg loss: 0.32746908602849495 at epoch 22
epoch =     23/  1000, exp = train
train_iter_loss: 0.27222204208374023
train_iter_loss: 0.3174941837787628
train_iter_loss: 0.2681005597114563
train_iter_loss: 0.31756874918937683
train_iter_loss: 0.2778967022895813
train_iter_loss: 0.26411303877830505
train_iter_loss: 0.27442315220832825
train_iter_loss: 0.36648789048194885
train_iter_loss: 0.2677919268608093
train_iter_loss: 0.3306451439857483
train_iter_loss: 0.3063547909259796
train_iter_loss: 0.23593397438526154
train_iter_loss: 0.3219861090183258
train_iter_loss: 0.23058916628360748
train_iter_loss: 0.24251244962215424
train_iter_loss: 0.29702574014663696
train_iter_loss: 0.22336766123771667
train_iter_loss: 0.24419021606445312
train_iter_loss: 0.3440094292163849
train_iter_loss: 0.2827930152416229
train_iter_loss: 0.28387540578842163
train_iter_loss: 0.2521386742591858
train_iter_loss: 0.22323691844940186
train_iter_loss: 0.3004915118217468
train_iter_loss: 0.25927093625068665
train_iter_loss: 0.33137935400009155
train_iter_loss: 0.2312435805797577
train_iter_loss: 0.3285166323184967
train_iter_loss: 0.32573872804641724
train_iter_loss: 0.26828160881996155
train_iter_loss: 0.3359149098396301
train_iter_loss: 0.24558204412460327
train_iter_loss: 0.2314920425415039
train_iter_loss: 0.2332671880722046
train_iter_loss: 0.25099530816078186
train_iter_loss: 0.23532220721244812
train_iter_loss: 0.2554749846458435
train_iter_loss: 0.2590563893318176
train_iter_loss: 0.38977161049842834
train_iter_loss: 0.30422693490982056
train_iter_loss: 0.30836236476898193
train_iter_loss: 0.25283947587013245
train_iter_loss: 0.27756524085998535
train_iter_loss: 0.2793453335762024
train_iter_loss: 0.2664684057235718
train_iter_loss: 0.26376014947891235
train_iter_loss: 0.3082261383533478
train_iter_loss: 0.3024476170539856
train_iter_loss: 0.26932114362716675
train_iter_loss: 0.2270466834306717
train_iter_loss: 0.24985377490520477
train_iter_loss: 0.39255303144454956
train_iter_loss: 0.3143617510795593
train_iter_loss: 0.3190111815929413
train_iter_loss: 0.26336440443992615
train_iter_loss: 0.28112223744392395
train_iter_loss: 0.31014442443847656
train_iter_loss: 0.32035064697265625
train_iter_loss: 0.33945128321647644
train_iter_loss: 0.3202592730522156
train_iter_loss: 0.3049769103527069
train_iter_loss: 0.25685036182403564
train_iter_loss: 0.2927725911140442
train_iter_loss: 0.2539926767349243
train_iter_loss: 0.31133824586868286
train_iter_loss: 0.2615455687046051
train_iter_loss: 0.27572867274284363
train_iter_loss: 0.27665600180625916
train_iter_loss: 0.3310265839099884
train_iter_loss: 0.27899086475372314
train_iter_loss: 0.2492886483669281
train_iter_loss: 0.25831103324890137
train_iter_loss: 0.41315266489982605
train_iter_loss: 0.27100837230682373
train_iter_loss: 0.2839684784412384
train_iter_loss: 0.2648732662200928
train_iter_loss: 0.2965044379234314
train_iter_loss: 0.340423047542572
train_iter_loss: 0.2542080879211426
train_iter_loss: 0.26887455582618713
train_iter_loss: 0.3506649136543274
train_iter_loss: 0.3340393900871277
train_iter_loss: 0.2555032968521118
train_iter_loss: 0.2856464087963104
train_iter_loss: 0.36289986968040466
train_iter_loss: 0.24741464853286743
train_iter_loss: 0.23986761271953583
train_iter_loss: 0.3144139349460602
train_iter_loss: 0.3243018090724945
train_iter_loss: 0.26240015029907227
train_iter_loss: 0.41625508666038513
train_iter_loss: 0.27787476778030396
train_iter_loss: 0.30753323435783386
train_iter_loss: 0.24575164914131165
train_iter_loss: 0.26551157236099243
train_iter_loss: 0.3065854012966156
train_iter_loss: 0.26534515619277954
train_iter_loss: 0.24662472307682037
train_iter_loss: 0.25826308131217957
train_iter_loss: 0.2879807949066162
train_iter_loss: 0.2248944640159607
train_iter_loss: 0.26654303073883057
train_iter_loss: 0.335188090801239
train_iter_loss: 0.2809736430644989
train_iter_loss: 0.2539447546005249
train_iter_loss: 0.26395314931869507
train_iter_loss: 0.30061668157577515
train_iter_loss: 0.3728715479373932
train_iter_loss: 0.28154894709587097
train_iter_loss: 0.28414052724838257
train_iter_loss: 0.25921663641929626
train_iter_loss: 0.2513011693954468
train_iter_loss: 0.3305920362472534
train_iter_loss: 0.2609899938106537
train_iter_loss: 0.23872298002243042
train_iter_loss: 0.3392799496650696
train_iter_loss: 0.3080974221229553
train_iter_loss: 0.27254346013069153
train_iter_loss: 0.3131369948387146
train_iter_loss: 0.27867746353149414
train_iter_loss: 0.33419519662857056
train_iter_loss: 0.26533937454223633
train_iter_loss: 0.32966649532318115
train_iter_loss: 0.2413952797651291
train_iter_loss: 0.2859894931316376
train_iter_loss: 0.2696199417114258
train_iter_loss: 0.2545117139816284
train_iter_loss: 0.3246447741985321
train_iter_loss: 0.29592931270599365
train_iter_loss: 0.2851886451244354
train_iter_loss: 0.2338925302028656
train_iter_loss: 0.31889116764068604
train_iter_loss: 0.2281164824962616
train_iter_loss: 0.280368834733963
train_iter_loss: 0.25489696860313416
train_iter_loss: 0.2306244820356369
train_iter_loss: 0.20681913197040558
train_iter_loss: 0.3523246645927429
train_iter_loss: 0.250857949256897
train_iter_loss: 0.32845109701156616
train_iter_loss: 0.25727662444114685
train_iter_loss: 0.3119746446609497
train_iter_loss: 0.2234555184841156
train_iter_loss: 0.3315242528915405
train_iter_loss: 0.24293144047260284
train_iter_loss: 0.2562958598136902
train_iter_loss: 0.2945745885372162
train_iter_loss: 0.24917803704738617
train_iter_loss: 0.2509733736515045
train_iter_loss: 0.33368024230003357
train_iter_loss: 0.371914267539978
train_iter_loss: 0.30181795358657837
train_iter_loss: 0.23594585061073303
train_iter_loss: 0.3092605769634247
train_iter_loss: 0.27608203887939453
train_iter_loss: 0.248054638504982
train_iter_loss: 0.3010612726211548
train_iter_loss: 0.34728845953941345
train_iter_loss: 0.23811951279640198
train_iter_loss: 0.23386436700820923
train_iter_loss: 0.28032171726226807
train_iter_loss: 0.26915979385375977
train_iter_loss: 0.31513911485671997
train_iter_loss: 0.3136255741119385
train_iter_loss: 0.2493760734796524
train_iter_loss: 0.24595396220684052
train_iter_loss: 0.27366143465042114
train_iter_loss: 0.2582074701786041
train_iter_loss: 0.4227801561355591
train_iter_loss: 0.2595458924770355
train_iter_loss: 0.30066487193107605
train_iter_loss: 0.3492969870567322
train_iter_loss: 0.3011731803417206
train_iter_loss: 0.2757064700126648
train_iter_loss: 0.29732125997543335
train_iter_loss: 0.20559966564178467
train_iter_loss: 0.2432195097208023
train_iter_loss: 0.37701016664505005
train_iter_loss: 0.27039408683776855
train_iter_loss: 0.2624571621417999
train_iter_loss: 0.25759586691856384
train_iter_loss: 0.2283712774515152
train_iter_loss: 0.2878780961036682
train_iter_loss: 0.34373700618743896
train_iter_loss: 0.29299691319465637
train_iter_loss: 0.2618951201438904
train_iter_loss: 0.23944859206676483
train_iter_loss: 0.29499495029449463
train_iter_loss: 0.2814842760562897
train_iter_loss: 0.3663821816444397
train_iter_loss: 0.24797534942626953
train_iter_loss: 0.28091129660606384
train_iter_loss: 0.28077617287635803
train_iter_loss: 0.287324994802475
train_iter_loss: 0.24645882844924927
train_iter_loss: 0.3401203453540802
train_iter_loss: 0.24643957614898682
train_iter_loss: 0.35368281602859497
train_iter_loss: 0.26003700494766235
train_iter_loss: 0.30082613229751587
train loss :0.2868
---------------------
Validation seg loss: 0.3245587461399582 at epoch 23
epoch =     24/  1000, exp = train
train_iter_loss: 0.327143132686615
train_iter_loss: 0.43525394797325134
train_iter_loss: 0.2711753249168396
train_iter_loss: 0.3646281957626343
train_iter_loss: 0.3521157503128052
train_iter_loss: 0.2357722967863083
train_iter_loss: 0.2942239046096802
train_iter_loss: 0.3036070466041565
train_iter_loss: 0.21892905235290527
train_iter_loss: 0.3851320147514343
train_iter_loss: 0.25586506724357605
train_iter_loss: 0.364260733127594
train_iter_loss: 0.22453716397285461
train_iter_loss: 0.284338116645813
train_iter_loss: 0.26025551557540894
train_iter_loss: 0.23837821185588837
train_iter_loss: 0.25472354888916016
train_iter_loss: 0.2339140772819519
train_iter_loss: 0.2338070422410965
train_iter_loss: 0.32540351152420044
train_iter_loss: 0.3844935894012451
train_iter_loss: 0.25348708033561707
train_iter_loss: 0.2870933413505554
train_iter_loss: 0.2841523587703705
train_iter_loss: 0.29764479398727417
train_iter_loss: 0.2975676953792572
train_iter_loss: 0.31719914078712463
train_iter_loss: 0.2597237527370453
train_iter_loss: 0.255159854888916
train_iter_loss: 0.25691521167755127
train_iter_loss: 0.22167302668094635
train_iter_loss: 0.24758395552635193
train_iter_loss: 0.2546504735946655
train_iter_loss: 0.2354145050048828
train_iter_loss: 0.3993915617465973
train_iter_loss: 0.2682705223560333
train_iter_loss: 0.2669086158275604
train_iter_loss: 0.27663907408714294
train_iter_loss: 0.3526616096496582
train_iter_loss: 0.3155950903892517
train_iter_loss: 0.2783127725124359
train_iter_loss: 0.2763308584690094
train_iter_loss: 0.30397775769233704
train_iter_loss: 0.29899805784225464
train_iter_loss: 0.29600703716278076
train_iter_loss: 0.35987916588783264
train_iter_loss: 0.27776652574539185
train_iter_loss: 0.26533395051956177
train_iter_loss: 0.36316198110580444
train_iter_loss: 0.29950231313705444
train_iter_loss: 0.26406264305114746
train_iter_loss: 0.2562834620475769
train_iter_loss: 0.2705834209918976
train_iter_loss: 0.23199918866157532
train_iter_loss: 0.24066045880317688
train_iter_loss: 0.30771109461784363
train_iter_loss: 0.2528814375400543
train_iter_loss: 0.3010721802711487
train_iter_loss: 0.3099403977394104
train_iter_loss: 0.28877270221710205
train_iter_loss: 0.2775554358959198
train_iter_loss: 0.2281610518693924
train_iter_loss: 0.2784317135810852
train_iter_loss: 0.26394298672676086
train_iter_loss: 0.2957715392112732
train_iter_loss: 0.2410070151090622
train_iter_loss: 0.25815054774284363
train_iter_loss: 0.2366168349981308
train_iter_loss: 0.26648807525634766
train_iter_loss: 0.2386634796857834
train_iter_loss: 0.22676575183868408
train_iter_loss: 0.3060356676578522
train_iter_loss: 0.24355022609233856
train_iter_loss: 0.24736535549163818
train_iter_loss: 0.271140992641449
train_iter_loss: 0.2262788563966751
train_iter_loss: 0.22655487060546875
train_iter_loss: 0.3498704433441162
train_iter_loss: 0.29729798436164856
train_iter_loss: 0.28038087487220764
train_iter_loss: 0.25141388177871704
train_iter_loss: 0.29737433791160583
train_iter_loss: 0.34778541326522827
train_iter_loss: 0.2526579797267914
train_iter_loss: 0.26330137252807617
train_iter_loss: 0.2854618728160858
train_iter_loss: 0.2577117681503296
train_iter_loss: 0.3243632912635803
train_iter_loss: 0.2919313907623291
train_iter_loss: 0.24735170602798462
train_iter_loss: 0.23485109210014343
train_iter_loss: 0.3514350354671478
train_iter_loss: 0.2699425220489502
train_iter_loss: 0.265641987323761
train_iter_loss: 0.2513654828071594
train_iter_loss: 0.2880100905895233
train_iter_loss: 0.2459288239479065
train_iter_loss: 0.31993234157562256
train_iter_loss: 0.44057565927505493
train_iter_loss: 0.2421034276485443
train_iter_loss: 0.33429205417633057
train_iter_loss: 0.32725900411605835
train_iter_loss: 0.2951641380786896
train_iter_loss: 0.2669786810874939
train_iter_loss: 0.32863643765449524
train_iter_loss: 0.2863747775554657
train_iter_loss: 0.271480917930603
train_iter_loss: 0.2564392685890198
train_iter_loss: 0.26436933875083923
train_iter_loss: 0.4207766652107239
train_iter_loss: 0.37384361028671265
train_iter_loss: 0.2622620463371277
train_iter_loss: 0.26986557245254517
train_iter_loss: 0.21676482260227203
train_iter_loss: 0.3216899633407593
train_iter_loss: 0.23242345452308655
train_iter_loss: 0.2586284279823303
train_iter_loss: 0.2512703537940979
train_iter_loss: 0.31027698516845703
train_iter_loss: 0.2908041477203369
train_iter_loss: 0.21992959082126617
train_iter_loss: 0.258421927690506
train_iter_loss: 0.2763538956642151
train_iter_loss: 0.31828993558883667
train_iter_loss: 0.2453567236661911
train_iter_loss: 0.31478413939476013
train_iter_loss: 0.3620147705078125
train_iter_loss: 0.25815755128860474
train_iter_loss: 0.28410232067108154
train_iter_loss: 0.29039543867111206
train_iter_loss: 0.25964027643203735
train_iter_loss: 0.2519473433494568
train_iter_loss: 0.24864578247070312
train_iter_loss: 0.3502434194087982
train_iter_loss: 0.3153761625289917
train_iter_loss: 0.23190875351428986
train_iter_loss: 0.22854603826999664
train_iter_loss: 0.320092111825943
train_iter_loss: 0.27598512172698975
train_iter_loss: 0.28617820143699646
train_iter_loss: 0.24716167151927948
train_iter_loss: 0.2536017596721649
train_iter_loss: 0.2438722848892212
train_iter_loss: 0.25225022435188293
train_iter_loss: 0.30812570452690125
train_iter_loss: 0.26601317524909973
train_iter_loss: 0.4385290741920471
train_iter_loss: 0.24609670042991638
train_iter_loss: 0.24838246405124664
train_iter_loss: 0.27986839413642883
train_iter_loss: 0.24502168595790863
train_iter_loss: 0.2390262931585312
train_iter_loss: 0.24110525846481323
train_iter_loss: 0.2826884686946869
train_iter_loss: 0.31431475281715393
train_iter_loss: 0.2986021637916565
train_iter_loss: 0.3428770899772644
train_iter_loss: 0.3059382140636444
train_iter_loss: 0.24668464064598083
train_iter_loss: 0.2571606934070587
train_iter_loss: 0.23307998478412628
train_iter_loss: 0.25930410623550415
train_iter_loss: 0.39348334074020386
train_iter_loss: 0.2806987464427948
train_iter_loss: 0.23547647893428802
train_iter_loss: 0.2724810838699341
train_iter_loss: 0.27656063437461853
train_iter_loss: 0.3152599036693573
train_iter_loss: 0.22871893644332886
train_iter_loss: 0.30929261445999146
train_iter_loss: 0.2572963237762451
train_iter_loss: 0.2702639698982239
train_iter_loss: 0.3288516104221344
train_iter_loss: 0.23048560321331024
train_iter_loss: 0.2816276550292969
train_iter_loss: 0.3708822429180145
train_iter_loss: 0.2960556745529175
train_iter_loss: 0.3204613924026489
train_iter_loss: 0.2799045741558075
train_iter_loss: 0.32383260130882263
train_iter_loss: 0.2653754949569702
train_iter_loss: 0.2662367820739746
train_iter_loss: 0.2360379844903946
train_iter_loss: 0.30132558941841125
train_iter_loss: 0.24057768285274506
train_iter_loss: 0.2705673575401306
train_iter_loss: 0.2082310914993286
train_iter_loss: 0.24180668592453003
train_iter_loss: 0.26544222235679626
train_iter_loss: 0.2830584645271301
train_iter_loss: 0.2444387525320053
train_iter_loss: 0.2993762195110321
train_iter_loss: 0.28944897651672363
train_iter_loss: 0.252524197101593
train_iter_loss: 0.2913684844970703
train_iter_loss: 0.31936928629875183
train_iter_loss: 0.2762695848941803
train_iter_loss: 0.26461324095726013
train_iter_loss: 0.2433752864599228
train_iter_loss: 0.328431099653244
train loss :0.2838
---------------------
Validation seg loss: 0.32220785291689746 at epoch 24
********************
best_val_epoch_loss:  0.32220785291689746
MODEL UPDATED
epoch =     25/  1000, exp = train
train_iter_loss: 0.22340407967567444
train_iter_loss: 0.22383299469947815
train_iter_loss: 0.30460619926452637
train_iter_loss: 0.2401716113090515
train_iter_loss: 0.2607816755771637
train_iter_loss: 0.28343331813812256
train_iter_loss: 0.3248650133609772
train_iter_loss: 0.2599136233329773
train_iter_loss: 0.302946537733078
train_iter_loss: 0.29148924350738525
train_iter_loss: 0.2884899973869324
train_iter_loss: 0.2551717758178711
train_iter_loss: 0.30209338665008545
train_iter_loss: 0.2426196038722992
train_iter_loss: 0.25165438652038574
train_iter_loss: 0.287161648273468
train_iter_loss: 0.2734713554382324
train_iter_loss: 0.24698562920093536
train_iter_loss: 0.25385868549346924
train_iter_loss: 0.3355996012687683
train_iter_loss: 0.22976472973823547
train_iter_loss: 0.26042675971984863
train_iter_loss: 0.28896722197532654
train_iter_loss: 0.29883047938346863
train_iter_loss: 0.3153805732727051
train_iter_loss: 0.2453770637512207
train_iter_loss: 0.24486762285232544
train_iter_loss: 0.22591710090637207
train_iter_loss: 0.25612834095954895
train_iter_loss: 0.26606154441833496
train_iter_loss: 0.2947565019130707
train_iter_loss: 0.23637929558753967
train_iter_loss: 0.29005786776542664
train_iter_loss: 0.2707577049732208
train_iter_loss: 0.24803203344345093
train_iter_loss: 0.2527114748954773
train_iter_loss: 0.3657052218914032
train_iter_loss: 0.3345353603363037
train_iter_loss: 0.30262723565101624
train_iter_loss: 0.2818216383457184
train_iter_loss: 0.28633633255958557
train_iter_loss: 0.2552312910556793
train_iter_loss: 0.3252425193786621
train_iter_loss: 0.3009377717971802
train_iter_loss: 0.39307963848114014
train_iter_loss: 0.26640498638153076
train_iter_loss: 0.2500865161418915
train_iter_loss: 0.31290507316589355
train_iter_loss: 0.2934807240962982
train_iter_loss: 0.24706386029720306
train_iter_loss: 0.27093908190727234
train_iter_loss: 0.24565118551254272
train_iter_loss: 0.24865688383579254
train_iter_loss: 0.2544679641723633
train_iter_loss: 0.28106689453125
train_iter_loss: 0.295331746339798
train_iter_loss: 0.22941391170024872
train_iter_loss: 0.3224719166755676
train_iter_loss: 0.2874366343021393
train_iter_loss: 0.22338256239891052
train_iter_loss: 0.3499632179737091
train_iter_loss: 0.24795326590538025
train_iter_loss: 0.27084702253341675
train_iter_loss: 0.22765812277793884
train_iter_loss: 0.31386280059814453
train_iter_loss: 0.3461308777332306
train_iter_loss: 0.359088659286499
train_iter_loss: 0.2782468795776367
train_iter_loss: 0.25723883509635925
train_iter_loss: 0.2460995465517044
train_iter_loss: 0.23996645212173462
train_iter_loss: 0.2915615439414978
train_iter_loss: 0.3066779375076294
train_iter_loss: 0.2719215750694275
train_iter_loss: 0.34888628125190735
train_iter_loss: 0.2621318995952606
train_iter_loss: 0.29823365807533264
train_iter_loss: 0.279011994600296
train_iter_loss: 0.2322595715522766
train_iter_loss: 0.28434956073760986
train_iter_loss: 0.2945674955844879
train_iter_loss: 0.27341318130493164
train_iter_loss: 0.22764243185520172
train_iter_loss: 0.2908872663974762
train_iter_loss: 0.34890052676200867
train_iter_loss: 0.24064448475837708
train_iter_loss: 0.24611277878284454
train_iter_loss: 0.25522705912590027
train_iter_loss: 0.24524900317192078
train_iter_loss: 0.25029444694519043
train_iter_loss: 0.26435643434524536
train_iter_loss: 0.2625943720340729
train_iter_loss: 0.26179465651512146
train_iter_loss: 0.25055742263793945
train_iter_loss: 0.2534275949001312
train_iter_loss: 0.3041972517967224
train_iter_loss: 0.241404727101326
train_iter_loss: 0.2948012351989746
train_iter_loss: 0.3645818829536438
train_iter_loss: 0.2990797460079193
train_iter_loss: 0.27527284622192383
train_iter_loss: 0.34984132647514343
train_iter_loss: 0.35833826661109924
train_iter_loss: 0.22294963896274567
train_iter_loss: 0.24918006360530853
train_iter_loss: 0.2625557482242584
train_iter_loss: 0.24065706133842468
train_iter_loss: 0.24874632060527802
train_iter_loss: 0.2529069185256958
train_iter_loss: 0.2550828456878662
train_iter_loss: 0.2973068654537201
train_iter_loss: 0.35888829827308655
train_iter_loss: 0.2380116581916809
train_iter_loss: 0.2668623626232147
train_iter_loss: 0.2183421552181244
train_iter_loss: 0.33214813470840454
train_iter_loss: 0.3162294924259186
train_iter_loss: 0.3020097613334656
train_iter_loss: 0.27469754219055176
train_iter_loss: 0.23831471800804138
train_iter_loss: 0.2615087330341339
train_iter_loss: 0.23634223639965057
train_iter_loss: 0.26652032136917114
train_iter_loss: 0.2281125783920288
train_iter_loss: 0.26756054162979126
train_iter_loss: 0.28233227133750916
train_iter_loss: 0.2809940278530121
train_iter_loss: 0.30084463953971863
train_iter_loss: 0.3025853931903839
train_iter_loss: 0.31172648072242737
train_iter_loss: 0.23526352643966675
train_iter_loss: 0.23530174791812897
train_iter_loss: 0.3571692705154419
train_iter_loss: 0.2577062249183655
train_iter_loss: 0.296603262424469
train_iter_loss: 0.22853843867778778
train_iter_loss: 0.19959713518619537
train_iter_loss: 0.2634933888912201
train_iter_loss: 0.2999080717563629
train_iter_loss: 0.2840036153793335
train_iter_loss: 0.2643294930458069
train_iter_loss: 0.23285718262195587
train_iter_loss: 0.2910429537296295
train_iter_loss: 0.27543461322784424
train_iter_loss: 0.2615951597690582
train_iter_loss: 0.33572521805763245
train_iter_loss: 0.2972024977207184
train_iter_loss: 0.2901347279548645
train_iter_loss: 0.314336895942688
train_iter_loss: 0.32502928376197815
train_iter_loss: 0.2821810245513916
train_iter_loss: 0.3196079134941101
train_iter_loss: 0.24069185554981232
train_iter_loss: 0.2729257643222809
train_iter_loss: 0.2783490717411041
train_iter_loss: 0.2888355553150177
train_iter_loss: 0.3273047208786011
train_iter_loss: 0.3244127631187439
train_iter_loss: 0.39950084686279297
train_iter_loss: 0.2869234085083008
train_iter_loss: 0.2465699464082718
train_iter_loss: 0.36221981048583984
train_iter_loss: 0.3072332441806793
train_iter_loss: 0.28665924072265625
train_iter_loss: 0.25487837195396423
train_iter_loss: 0.24207943677902222
train_iter_loss: 0.2815444767475128
train_iter_loss: 0.24747398495674133
train_iter_loss: 0.29356813430786133
train_iter_loss: 0.4704870283603668
train_iter_loss: 0.2738014757633209
train_iter_loss: 0.26217663288116455
train_iter_loss: 0.3318983316421509
train_iter_loss: 0.39043867588043213
train_iter_loss: 0.29359379410743713
train_iter_loss: 0.2462102472782135
train_iter_loss: 0.26721036434173584
train_iter_loss: 0.23302289843559265
train_iter_loss: 0.25875693559646606
train_iter_loss: 0.2761642634868622
train_iter_loss: 0.31528493762016296
train_iter_loss: 0.24748194217681885
train_iter_loss: 0.2363254874944687
train_iter_loss: 0.2595301568508148
train_iter_loss: 0.33586159348487854
train_iter_loss: 0.2926348149776459
train_iter_loss: 0.2109047770500183
train_iter_loss: 0.24659857153892517
train_iter_loss: 0.2953587770462036
train_iter_loss: 0.4491458833217621
train_iter_loss: 0.2841305136680603
train_iter_loss: 0.28613072633743286
train_iter_loss: 0.32278257608413696
train_iter_loss: 0.2437261939048767
train_iter_loss: 0.22370222210884094
train_iter_loss: 0.24227045476436615
train_iter_loss: 0.22543424367904663
train_iter_loss: 0.2575225234031677
train_iter_loss: 0.2597537934780121
train_iter_loss: 0.25325360894203186
train loss :0.2810
---------------------
Validation seg loss: 0.32543288044772056 at epoch 25
epoch =     26/  1000, exp = train
train_iter_loss: 0.2567247152328491
train_iter_loss: 0.2259175330400467
train_iter_loss: 0.23390056192874908
train_iter_loss: 0.2968918979167938
train_iter_loss: 0.3720376789569855
train_iter_loss: 0.24834293127059937
train_iter_loss: 0.3220333755016327
train_iter_loss: 0.31078726053237915
train_iter_loss: 0.2604770064353943
train_iter_loss: 0.2768964469432831
train_iter_loss: 0.2860400676727295
train_iter_loss: 0.24489815533161163
train_iter_loss: 0.354928582906723
train_iter_loss: 0.31124022603034973
train_iter_loss: 0.27416637539863586
train_iter_loss: 0.2455664724111557
train_iter_loss: 0.2331080436706543
train_iter_loss: 0.2194206267595291
train_iter_loss: 0.21553979814052582
train_iter_loss: 0.2806779146194458
train_iter_loss: 0.27689969539642334
train_iter_loss: 0.31297072768211365
train_iter_loss: 0.2346336394548416
train_iter_loss: 0.29699641466140747
train_iter_loss: 0.264302521944046
train_iter_loss: 0.2895475924015045
train_iter_loss: 0.38173848390579224
train_iter_loss: 0.23944154381752014
train_iter_loss: 0.3464106619358063
train_iter_loss: 0.29664376378059387
train_iter_loss: 0.2457195520401001
train_iter_loss: 0.2908041477203369
train_iter_loss: 0.33776265382766724
train_iter_loss: 0.30629801750183105
train_iter_loss: 0.4154990017414093
train_iter_loss: 0.30559033155441284
train_iter_loss: 0.30184876918792725
train_iter_loss: 0.21148338913917542
train_iter_loss: 0.28241613507270813
train_iter_loss: 0.4046584367752075
train_iter_loss: 0.27387169003486633
train_iter_loss: 0.24626466631889343
train_iter_loss: 0.2715785503387451
train_iter_loss: 0.2725673019886017
train_iter_loss: 0.2388698160648346
train_iter_loss: 0.2611478865146637
train_iter_loss: 0.3529502749443054
train_iter_loss: 0.25711941719055176
train_iter_loss: 0.30542418360710144
train_iter_loss: 0.32267946004867554
train_iter_loss: 0.27637410163879395
train_iter_loss: 0.2806842029094696
train_iter_loss: 0.23439618945121765
train_iter_loss: 0.29164496064186096
train_iter_loss: 0.3093869686126709
train_iter_loss: 0.3311478793621063
train_iter_loss: 0.2931741178035736
train_iter_loss: 0.2639666497707367
train_iter_loss: 0.2501707673072815
train_iter_loss: 0.3201533257961273
train_iter_loss: 0.27963170409202576
train_iter_loss: 0.294438898563385
train_iter_loss: 0.2907160222530365
train_iter_loss: 0.22486643493175507
train_iter_loss: 0.2613970637321472
train_iter_loss: 0.2623479962348938
train_iter_loss: 0.23118355870246887
train_iter_loss: 0.29803261160850525
train_iter_loss: 0.251590758562088
train_iter_loss: 0.2436157613992691
train_iter_loss: 0.2538730800151825
train_iter_loss: 0.2552388906478882
train_iter_loss: 0.24628129601478577
train_iter_loss: 0.30739590525627136
train_iter_loss: 0.2692960500717163
train_iter_loss: 0.2754591405391693
train_iter_loss: 0.3266684114933014
train_iter_loss: 0.2717830538749695
train_iter_loss: 0.22284318506717682
train_iter_loss: 0.26856136322021484
train_iter_loss: 0.2714443504810333
train_iter_loss: 0.512864351272583
train_iter_loss: 0.27438995242118835
train_iter_loss: 0.30143651366233826
train_iter_loss: 0.2623652517795563
train_iter_loss: 0.2757363021373749
train_iter_loss: 0.3641376793384552
train_iter_loss: 0.3277442157268524
train_iter_loss: 0.21543049812316895
train_iter_loss: 0.2675889730453491
train_iter_loss: 0.34834933280944824
train_iter_loss: 0.25380417704582214
train_iter_loss: 0.2667091190814972
train_iter_loss: 0.2506023943424225
train_iter_loss: 0.22595101594924927
train_iter_loss: 0.2543981075286865
train_iter_loss: 0.26860707998275757
train_iter_loss: 0.3575819134712219
train_iter_loss: 0.3107837736606598
train_iter_loss: 0.2256578803062439
train_iter_loss: 0.26207682490348816
train_iter_loss: 0.2442917823791504
train_iter_loss: 0.356135755777359
train_iter_loss: 0.24166128039360046
train_iter_loss: 0.2735437750816345
train_iter_loss: 0.3000490665435791
train_iter_loss: 0.22492274641990662
train_iter_loss: 0.2919917702674866
train_iter_loss: 0.26995837688446045
train_iter_loss: 0.280383437871933
train_iter_loss: 0.28752896189689636
train_iter_loss: 0.3352945148944855
train_iter_loss: 0.2509351372718811
train_iter_loss: 0.23613250255584717
train_iter_loss: 0.37062153220176697
train_iter_loss: 0.23724275827407837
train_iter_loss: 0.24232083559036255
train_iter_loss: 0.24464523792266846
train_iter_loss: 0.2067645639181137
train_iter_loss: 0.25389716029167175
train_iter_loss: 0.21797531843185425
train_iter_loss: 0.24781844019889832
train_iter_loss: 0.29570522904396057
train_iter_loss: 0.23399126529693604
train_iter_loss: 0.2263008952140808
train_iter_loss: 0.2430095672607422
train_iter_loss: 0.28033316135406494
train_iter_loss: 0.31148189306259155
train_iter_loss: 0.24481719732284546
train_iter_loss: 0.3876560628414154
train_iter_loss: 0.24973709881305695
train_iter_loss: 0.28606992959976196
train_iter_loss: 0.3845188617706299
train_iter_loss: 0.3819850981235504
train_iter_loss: 0.22994892299175262
train_iter_loss: 0.249959334731102
train_iter_loss: 0.32742834091186523
train_iter_loss: 0.2505194842815399
train_iter_loss: 0.2375452071428299
train_iter_loss: 0.25548291206359863
train_iter_loss: 0.24563317000865936
train_iter_loss: 0.23385600745677948
train_iter_loss: 0.2777876555919647
train_iter_loss: 0.3367130160331726
train_iter_loss: 0.3192349076271057
train_iter_loss: 0.28958845138549805
train_iter_loss: 0.28799283504486084
train_iter_loss: 0.3002045154571533
train_iter_loss: 0.2612295150756836
train_iter_loss: 0.25191670656204224
train_iter_loss: 0.2295430451631546
train_iter_loss: 0.23958159983158112
train_iter_loss: 0.23573629558086395
train_iter_loss: 0.22245290875434875
train_iter_loss: 0.32953059673309326
train_iter_loss: 0.25371575355529785
train_iter_loss: 0.3004717528820038
train_iter_loss: 0.24392251670360565
train_iter_loss: 0.3439101278781891
train_iter_loss: 0.41906967759132385
train_iter_loss: 0.2393999844789505
train_iter_loss: 0.2219657003879547
train_iter_loss: 0.22136840224266052
train_iter_loss: 0.24950559437274933
train_iter_loss: 0.29013991355895996
train_iter_loss: 0.23755143582820892
train_iter_loss: 0.27478525042533875
train_iter_loss: 0.24890685081481934
train_iter_loss: 0.2574073076248169
train_iter_loss: 0.21138043701648712
train_iter_loss: 0.24212554097175598
train_iter_loss: 0.2730165123939514
train_iter_loss: 0.23465920984745026
train_iter_loss: 0.26477324962615967
train_iter_loss: 0.25624170899391174
train_iter_loss: 0.26473936438560486
train_iter_loss: 0.2489440143108368
train_iter_loss: 0.26723533868789673
train_iter_loss: 0.3148825764656067
train_iter_loss: 0.23566751182079315
train_iter_loss: 0.3967588543891907
train_iter_loss: 0.325687050819397
train_iter_loss: 0.22829674184322357
train_iter_loss: 0.24172455072402954
train_iter_loss: 0.2221280187368393
train_iter_loss: 0.2630844712257385
train_iter_loss: 0.25284847617149353
train_iter_loss: 0.2616066336631775
train_iter_loss: 0.20704273879528046
train_iter_loss: 0.30774861574172974
train_iter_loss: 0.2838650643825531
train_iter_loss: 0.30079811811447144
train_iter_loss: 0.23111197352409363
train_iter_loss: 0.3183087706565857
train_iter_loss: 0.3472460210323334
train_iter_loss: 0.2880840003490448
train_iter_loss: 0.2821408808231354
train_iter_loss: 0.24242554605007172
train_iter_loss: 0.25226548314094543
train_iter_loss: 0.3054006099700928
train loss :0.2790
---------------------
Validation seg loss: 0.31856278512837755 at epoch 26
********************
best_val_epoch_loss:  0.31856278512837755
MODEL UPDATED
epoch =     27/  1000, exp = train
train_iter_loss: 0.2211645394563675
train_iter_loss: 0.21438224613666534
train_iter_loss: 0.2900129556655884
train_iter_loss: 0.21760891377925873
train_iter_loss: 0.3092500567436218
train_iter_loss: 0.3115362823009491
train_iter_loss: 0.25784969329833984
train_iter_loss: 0.24918708205223083
train_iter_loss: 0.29876285791397095
train_iter_loss: 0.23245540261268616
train_iter_loss: 0.23582008481025696
train_iter_loss: 0.31183236837387085
train_iter_loss: 0.23638905584812164
train_iter_loss: 0.29889994859695435
train_iter_loss: 0.24690566956996918
train_iter_loss: 0.21652814745903015
train_iter_loss: 0.21038424968719482
train_iter_loss: 0.34842926263809204
train_iter_loss: 0.26239222288131714
train_iter_loss: 0.3131169378757477
train_iter_loss: 0.3163110315799713
train_iter_loss: 0.31062817573547363
train_iter_loss: 0.24715951085090637
train_iter_loss: 0.29794007539749146
train_iter_loss: 0.27759602665901184
train_iter_loss: 0.26882535219192505
train_iter_loss: 0.2515862286090851
train_iter_loss: 0.28913623094558716
train_iter_loss: 0.35027599334716797
train_iter_loss: 0.24832920730113983
train_iter_loss: 0.2690415382385254
train_iter_loss: 0.2455662488937378
train_iter_loss: 0.25035732984542847
train_iter_loss: 0.2402440458536148
train_iter_loss: 0.2324688881635666
train_iter_loss: 0.23914870619773865
train_iter_loss: 0.2688579857349396
train_iter_loss: 0.3602387607097626
train_iter_loss: 0.2669193148612976
train_iter_loss: 0.2513442039489746
train_iter_loss: 0.26350584626197815
train_iter_loss: 0.2290397435426712
train_iter_loss: 0.21539324522018433
train_iter_loss: 0.2901967167854309
train_iter_loss: 0.24648094177246094
train_iter_loss: 0.2805740535259247
train_iter_loss: 0.3390384018421173
train_iter_loss: 0.21650449931621552
train_iter_loss: 0.3308735191822052
train_iter_loss: 0.2454138845205307
train_iter_loss: 0.39982515573501587
train_iter_loss: 0.22672522068023682
train_iter_loss: 0.28373685479164124
train_iter_loss: 0.233520045876503
train_iter_loss: 0.34397101402282715
train_iter_loss: 0.23050180077552795
train_iter_loss: 0.24977269768714905
train_iter_loss: 0.23809432983398438
train_iter_loss: 0.2325427532196045
train_iter_loss: 0.2389191836118698
train_iter_loss: 0.29174330830574036
train_iter_loss: 0.26107025146484375
train_iter_loss: 0.2810570001602173
train_iter_loss: 0.23586350679397583
train_iter_loss: 0.34895840287208557
train_iter_loss: 0.26260972023010254
train_iter_loss: 0.24350053071975708
train_iter_loss: 0.24425432085990906
train_iter_loss: 0.296067476272583
train_iter_loss: 0.26871827244758606
train_iter_loss: 0.33190929889678955
train_iter_loss: 0.20472677052021027
train_iter_loss: 0.24620263278484344
train_iter_loss: 0.26234328746795654
train_iter_loss: 0.2644234001636505
train_iter_loss: 0.31027352809906006
train_iter_loss: 0.27631640434265137
train_iter_loss: 0.28095799684524536
train_iter_loss: 0.28189700841903687
train_iter_loss: 0.2600606083869934
train_iter_loss: 0.28183868527412415
train_iter_loss: 0.2865844964981079
train_iter_loss: 0.23888318240642548
train_iter_loss: 0.29310476779937744
train_iter_loss: 0.27396759390830994
train_iter_loss: 0.27825117111206055
train_iter_loss: 0.29360830783843994
train_iter_loss: 0.2911796271800995
train_iter_loss: 0.28806203603744507
train_iter_loss: 0.29441961646080017
train_iter_loss: 0.27578532695770264
train_iter_loss: 0.2877095639705658
train_iter_loss: 0.2817530632019043
train_iter_loss: 0.29175713658332825
train_iter_loss: 0.2318970412015915
train_iter_loss: 0.25945764780044556
train_iter_loss: 0.26222705841064453
train_iter_loss: 0.20209947228431702
train_iter_loss: 0.2981645166873932
train_iter_loss: 0.3127973973751068
train_iter_loss: 0.28671184182167053
train_iter_loss: 0.25687965750694275
train_iter_loss: 0.30325552821159363
train_iter_loss: 0.26936760544776917
train_iter_loss: 0.3316584527492523
train_iter_loss: 0.2585248351097107
train_iter_loss: 0.21671162545681
train_iter_loss: 0.22967596352100372
train_iter_loss: 0.2893524467945099
train_iter_loss: 0.23232266306877136
train_iter_loss: 0.2855910062789917
train_iter_loss: 0.30290183424949646
train_iter_loss: 0.28073206543922424
train_iter_loss: 0.28035834431648254
train_iter_loss: 0.23980796337127686
train_iter_loss: 0.255336195230484
train_iter_loss: 0.2525078058242798
train_iter_loss: 0.29625189304351807
train_iter_loss: 0.226957768201828
train_iter_loss: 0.39964061975479126
train_iter_loss: 0.2666569650173187
train_iter_loss: 0.3911476135253906
train_iter_loss: 0.35672906041145325
train_iter_loss: 0.2179601490497589
train_iter_loss: 0.24040821194648743
train_iter_loss: 0.3446614146232605
train_iter_loss: 0.2926369905471802
train_iter_loss: 0.25308963656425476
train_iter_loss: 0.23388543725013733
train_iter_loss: 0.28662803769111633
train_iter_loss: 0.2911149561405182
train_iter_loss: 0.24224475026130676
train_iter_loss: 0.33133453130722046
train_iter_loss: 0.25995516777038574
train_iter_loss: 0.23245003819465637
train_iter_loss: 0.2530861794948578
train_iter_loss: 0.4428112208843231
train_iter_loss: 0.27516818046569824
train_iter_loss: 0.25664860010147095
train_iter_loss: 0.27663055062294006
train_iter_loss: 0.26439952850341797
train_iter_loss: 0.28615400195121765
train_iter_loss: 0.29419395327568054
train_iter_loss: 0.37397924065589905
train_iter_loss: 0.28443828225135803
train_iter_loss: 0.20906777679920197
train_iter_loss: 0.3537878394126892
train_iter_loss: 0.280677855014801
train_iter_loss: 0.2822144627571106
train_iter_loss: 0.2183266431093216
train_iter_loss: 0.23423832654953003
train_iter_loss: 0.2625683546066284
train_iter_loss: 0.2403746396303177
train_iter_loss: 0.39877402782440186
train_iter_loss: 0.21462206542491913
train_iter_loss: 0.36378708481788635
train_iter_loss: 0.2593459486961365
train_iter_loss: 0.25691133737564087
train_iter_loss: 0.41231322288513184
train_iter_loss: 0.23046515882015228
train_iter_loss: 0.23862743377685547
train_iter_loss: 0.26767152547836304
train_iter_loss: 0.29725518822669983
train_iter_loss: 0.30579355359077454
train_iter_loss: 0.2588013708591461
train_iter_loss: 0.31825172901153564
train_iter_loss: 0.2784159779548645
train_iter_loss: 0.2743857502937317
train_iter_loss: 0.302996963262558
train_iter_loss: 0.2423635870218277
train_iter_loss: 0.2444586604833603
train_iter_loss: 0.30353212356567383
train_iter_loss: 0.2116701751947403
train_iter_loss: 0.31547340750694275
train_iter_loss: 0.2703184187412262
train_iter_loss: 0.2544606924057007
train_iter_loss: 0.24837124347686768
train_iter_loss: 0.2284986972808838
train_iter_loss: 0.26317813992500305
train_iter_loss: 0.2160542905330658
train_iter_loss: 0.34684544801712036
train_iter_loss: 0.33712753653526306
train_iter_loss: 0.2265096753835678
train_iter_loss: 0.31471920013427734
train_iter_loss: 0.23533280193805695
train_iter_loss: 0.2737618088722229
train_iter_loss: 0.2944790720939636
train_iter_loss: 0.2318640947341919
train_iter_loss: 0.25208306312561035
train_iter_loss: 0.3348621428012848
train_iter_loss: 0.24155183136463165
train_iter_loss: 0.225917249917984
train_iter_loss: 0.26001983880996704
train_iter_loss: 0.3059298098087311
train_iter_loss: 0.2719852328300476
train_iter_loss: 0.26945385336875916
train_iter_loss: 0.2650127708911896
train_iter_loss: 0.27329620718955994
train_iter_loss: 0.22428284585475922
train_iter_loss: 0.27120527625083923
train loss :0.2756
---------------------
Validation seg loss: 0.32157156236891477 at epoch 27
epoch =     28/  1000, exp = train
train_iter_loss: 0.2691660225391388
train_iter_loss: 0.35184600949287415
train_iter_loss: 0.257269024848938
train_iter_loss: 0.27108055353164673
train_iter_loss: 0.24838830530643463
train_iter_loss: 0.21656325459480286
train_iter_loss: 0.39214152097702026
train_iter_loss: 0.21348480880260468
train_iter_loss: 0.25402742624282837
train_iter_loss: 0.3639529049396515
train_iter_loss: 0.40184885263442993
train_iter_loss: 0.2934422492980957
train_iter_loss: 0.22284424304962158
train_iter_loss: 0.24913625419139862
train_iter_loss: 0.31568700075149536
train_iter_loss: 0.3126560151576996
train_iter_loss: 0.25620216131210327
train_iter_loss: 0.31125470995903015
train_iter_loss: 0.24927303194999695
train_iter_loss: 0.2391066700220108
train_iter_loss: 0.2702402174472809
train_iter_loss: 0.24436956644058228
train_iter_loss: 0.2936471700668335
train_iter_loss: 0.2442903220653534
train_iter_loss: 0.28264597058296204
train_iter_loss: 0.26168787479400635
train_iter_loss: 0.2848856747150421
train_iter_loss: 0.3916514813899994
train_iter_loss: 0.3401585519313812
train_iter_loss: 0.2181735783815384
train_iter_loss: 0.2235308140516281
train_iter_loss: 0.24139229953289032
train_iter_loss: 0.28936946392059326
train_iter_loss: 0.28848177194595337
train_iter_loss: 0.22832539677619934
train_iter_loss: 0.2657737135887146
train_iter_loss: 0.2696494162082672
train_iter_loss: 0.23716898262500763
train_iter_loss: 0.27100059390068054
train_iter_loss: 0.325396329164505
train_iter_loss: 0.24538330733776093
train_iter_loss: 0.2950649857521057
train_iter_loss: 0.2479848861694336
train_iter_loss: 0.257851243019104
train_iter_loss: 0.22434386610984802
train_iter_loss: 0.21925146877765656
train_iter_loss: 0.3154295086860657
train_iter_loss: 0.36305034160614014
train_iter_loss: 0.2532055079936981
train_iter_loss: 0.2885380685329437
train_iter_loss: 0.23881316184997559
train_iter_loss: 0.2391311228275299
train_iter_loss: 0.2965112626552582
train_iter_loss: 0.31434115767478943
train_iter_loss: 0.2599479556083679
train_iter_loss: 0.38485294580459595
train_iter_loss: 0.3185213506221771
train_iter_loss: 0.22641846537590027
train_iter_loss: 0.2580060660839081
train_iter_loss: 0.3047387897968292
train_iter_loss: 0.22960694134235382
train_iter_loss: 0.25094670057296753
train_iter_loss: 0.269683301448822
train_iter_loss: 0.35453057289123535
train_iter_loss: 0.2823988199234009
train_iter_loss: 0.2294006049633026
train_iter_loss: 0.2536638081073761
train_iter_loss: 0.26428964734077454
train_iter_loss: 0.2819218635559082
train_iter_loss: 0.22050730884075165
train_iter_loss: 0.24944646656513214
train_iter_loss: 0.23529782891273499
train_iter_loss: 0.2277575433254242
train_iter_loss: 0.30973121523857117
train_iter_loss: 0.2868698239326477
train_iter_loss: 0.2080552726984024
train_iter_loss: 0.222985178232193
train_iter_loss: 0.24145819246768951
train_iter_loss: 0.22474831342697144
train_iter_loss: 0.25619080662727356
train_iter_loss: 0.2057264894247055
train_iter_loss: 0.29605749249458313
train_iter_loss: 0.3280338644981384
train_iter_loss: 0.31126704812049866
train_iter_loss: 0.24761554598808289
train_iter_loss: 0.25256645679473877
train_iter_loss: 0.33357420563697815
train_iter_loss: 0.3428640365600586
train_iter_loss: 0.33481675386428833
train_iter_loss: 0.2182846963405609
train_iter_loss: 0.22538171708583832
train_iter_loss: 0.36335840821266174
train_iter_loss: 0.43272003531455994
train_iter_loss: 0.2523258924484253
train_iter_loss: 0.30922454595565796
train_iter_loss: 0.24105079472064972
train_iter_loss: 0.4036051332950592
train_iter_loss: 0.23851342499256134
train_iter_loss: 0.23097927868366241
train_iter_loss: 0.23004677891731262
train_iter_loss: 0.24968387186527252
train_iter_loss: 0.23448781669139862
train_iter_loss: 0.2640974819660187
train_iter_loss: 0.2473008930683136
train_iter_loss: 0.2561173141002655
train_iter_loss: 0.2627841830253601
train_iter_loss: 0.2600278854370117
train_iter_loss: 0.24467158317565918
train_iter_loss: 0.2956687808036804
train_iter_loss: 0.2396852672100067
train_iter_loss: 0.22156023979187012
train_iter_loss: 0.29514774680137634
train_iter_loss: 0.2560596764087677
train_iter_loss: 0.2275199294090271
train_iter_loss: 0.26801541447639465
train_iter_loss: 0.33690309524536133
train_iter_loss: 0.20514772832393646
train_iter_loss: 0.23616580665111542
train_iter_loss: 0.2703603208065033
train_iter_loss: 0.2983342707157135
train_iter_loss: 0.24913622438907623
train_iter_loss: 0.19653359055519104
train_iter_loss: 0.2684708535671234
train_iter_loss: 0.24778875708580017
train_iter_loss: 0.3671114146709442
train_iter_loss: 0.2165522277355194
train_iter_loss: 0.2453138679265976
train_iter_loss: 0.24382784962654114
train_iter_loss: 0.2545260190963745
train_iter_loss: 0.24922488629817963
train_iter_loss: 0.29723992943763733
train_iter_loss: 0.2678675949573517
train_iter_loss: 0.2743404805660248
train_iter_loss: 0.3825720548629761
train_iter_loss: 0.2637201249599457
train_iter_loss: 0.2892359495162964
train_iter_loss: 0.32869455218315125
train_iter_loss: 0.2586095929145813
train_iter_loss: 0.2696969211101532
train_iter_loss: 0.27520450949668884
train_iter_loss: 0.3147370219230652
train_iter_loss: 0.25649023056030273
train_iter_loss: 0.25156646966934204
train_iter_loss: 0.28328797221183777
train_iter_loss: 0.23001936078071594
train_iter_loss: 0.29977884888648987
train_iter_loss: 0.2767189145088196
train_iter_loss: 0.28163206577301025
train_iter_loss: 0.23542353510856628
train_iter_loss: 0.2308504432439804
train_iter_loss: 0.2432587742805481
train_iter_loss: 0.27764105796813965
train_iter_loss: 0.21414214372634888
train_iter_loss: 0.2909042537212372
train_iter_loss: 0.211205393075943
train_iter_loss: 0.26375624537467957
train_iter_loss: 0.456595778465271
train_iter_loss: 0.4017319977283478
train_iter_loss: 0.21233931183815002
train_iter_loss: 0.253794401884079
train_iter_loss: 0.24861492216587067
train_iter_loss: 0.27512678503990173
train_iter_loss: 0.30156606435775757
train_iter_loss: 0.3123701810836792
train_iter_loss: 0.3376297056674957
train_iter_loss: 0.27863577008247375
train_iter_loss: 0.21789312362670898
train_iter_loss: 0.30498695373535156
train_iter_loss: 0.24418941140174866
train_iter_loss: 0.22516438364982605
train_iter_loss: 0.22609637677669525
train_iter_loss: 0.276574969291687
train_iter_loss: 0.22166189551353455
train_iter_loss: 0.26795607805252075
train_iter_loss: 0.25798165798187256
train_iter_loss: 0.29067546129226685
train_iter_loss: 0.23251010477542877
train_iter_loss: 0.3006928861141205
train_iter_loss: 0.2450546771287918
train_iter_loss: 0.35692712664604187
train_iter_loss: 0.3421112895011902
train_iter_loss: 0.26574409008026123
train_iter_loss: 0.22301478683948517
train_iter_loss: 0.2920006215572357
train_iter_loss: 0.31473469734191895
train_iter_loss: 0.24145744740962982
train_iter_loss: 0.30923691391944885
train_iter_loss: 0.2640557289123535
train_iter_loss: 0.3541712760925293
train_iter_loss: 0.2605881094932556
train_iter_loss: 0.2256118357181549
train_iter_loss: 0.2628537118434906
train_iter_loss: 0.3117954432964325
train_iter_loss: 0.24651603400707245
train_iter_loss: 0.27070149779319763
train_iter_loss: 0.29563820362091064
train_iter_loss: 0.40391969680786133
train_iter_loss: 0.2766062915325165
train_iter_loss: 0.24507096409797668
train_iter_loss: 0.4115692973136902
train loss :0.2761
---------------------
Validation seg loss: 0.3172610603132338 at epoch 28
********************
best_val_epoch_loss:  0.3172610603132338
MODEL UPDATED
epoch =     29/  1000, exp = train
train_iter_loss: 0.23292110860347748
train_iter_loss: 0.23311875760555267
train_iter_loss: 0.32085442543029785
train_iter_loss: 0.2631302773952484
train_iter_loss: 0.25251683592796326
train_iter_loss: 0.2809774577617645
train_iter_loss: 0.2700686454772949
train_iter_loss: 0.31642335653305054
train_iter_loss: 0.27481505274772644
train_iter_loss: 0.21780997514724731
train_iter_loss: 0.3058582842350006
train_iter_loss: 0.24391396343708038
train_iter_loss: 0.25666168332099915
train_iter_loss: 0.27789416909217834
train_iter_loss: 0.27870312333106995
train_iter_loss: 0.27322888374328613
train_iter_loss: 0.2779425382614136
train_iter_loss: 0.23013967275619507
train_iter_loss: 0.28720200061798096
train_iter_loss: 0.24964778125286102
train_iter_loss: 0.34620150923728943
train_iter_loss: 0.30647313594818115
train_iter_loss: 0.23963777720928192
train_iter_loss: 0.2547079920768738
train_iter_loss: 0.29323121905326843
train_iter_loss: 0.22673729062080383
train_iter_loss: 0.4054339826107025
train_iter_loss: 0.20416703820228577
train_iter_loss: 0.2784197926521301
train_iter_loss: 0.34740200638771057
train_iter_loss: 0.20649971067905426
train_iter_loss: 0.2864075005054474
train_iter_loss: 0.20250990986824036
train_iter_loss: 0.270225465297699
train_iter_loss: 0.2524557411670685
train_iter_loss: 0.2764752209186554
train_iter_loss: 0.4604771137237549
train_iter_loss: 0.23588357865810394
train_iter_loss: 0.30771180987358093
train_iter_loss: 0.2901422381401062
train_iter_loss: 0.25892627239227295
train_iter_loss: 0.25171470642089844
train_iter_loss: 0.24537184834480286
train_iter_loss: 0.277290403842926
train_iter_loss: 0.25071829557418823
train_iter_loss: 0.2695387005805969
train_iter_loss: 0.32623934745788574
train_iter_loss: 0.24370169639587402
train_iter_loss: 0.3132724165916443
train_iter_loss: 0.2961632013320923
train_iter_loss: 0.26925328373908997
train_iter_loss: 0.354837566614151
train_iter_loss: 0.24811707437038422
train_iter_loss: 0.22852839529514313
train_iter_loss: 0.25039470195770264
train_iter_loss: 0.28274255990982056
train_iter_loss: 0.288322776556015
train_iter_loss: 0.2228856384754181
train_iter_loss: 0.27641740441322327
train_iter_loss: 0.3198501169681549
train_iter_loss: 0.29691222310066223
train_iter_loss: 0.2769065797328949
train_iter_loss: 0.24229182302951813
train_iter_loss: 0.35432305932044983
train_iter_loss: 0.2520393133163452
train_iter_loss: 0.23096328973770142
train_iter_loss: 0.2609356641769409
train_iter_loss: 0.25064316391944885
train_iter_loss: 0.2384496033191681
train_iter_loss: 0.25735944509506226
train_iter_loss: 0.2796429991722107
train_iter_loss: 0.24667035043239594
train_iter_loss: 0.27749764919281006
train_iter_loss: 0.2394929826259613
train_iter_loss: 0.22402946650981903
train_iter_loss: 0.23010702431201935
train_iter_loss: 0.2449716478586197
train_iter_loss: 0.22404062747955322
train_iter_loss: 0.2472858428955078
train_iter_loss: 0.224262073636055
train_iter_loss: 0.21622824668884277
train_iter_loss: 0.25017186999320984
train_iter_loss: 0.2332073152065277
train_iter_loss: 0.25495001673698425
train_iter_loss: 0.22596149146556854
train_iter_loss: 0.30457353591918945
train_iter_loss: 0.20549975335597992
train_iter_loss: 0.24205628037452698
train_iter_loss: 0.2913218140602112
train_iter_loss: 0.2573615312576294
train_iter_loss: 0.2422252595424652
train_iter_loss: 0.29601117968559265
train_iter_loss: 0.3285360038280487
train_iter_loss: 0.33203619718551636
train_iter_loss: 0.2440202683210373
train_iter_loss: 0.24709399044513702
train_iter_loss: 0.21829640865325928
train_iter_loss: 0.20355124771595
train_iter_loss: 0.24875983595848083
train_iter_loss: 0.30204734206199646
train_iter_loss: 0.23113727569580078
train_iter_loss: 0.21080078184604645
train_iter_loss: 0.25806015729904175
train_iter_loss: 0.22826920449733734
train_iter_loss: 0.2431718409061432
train_iter_loss: 0.3088997006416321
train_iter_loss: 0.27759674191474915
train_iter_loss: 0.25092941522598267
train_iter_loss: 0.27274638414382935
train_iter_loss: 0.27717435359954834
train_iter_loss: 0.2689981162548065
train_iter_loss: 0.2999715507030487
train_iter_loss: 0.22748762369155884
train_iter_loss: 0.23985759913921356
train_iter_loss: 0.23823747038841248
train_iter_loss: 0.24366827309131622
train_iter_loss: 0.23813316226005554
train_iter_loss: 0.2895488142967224
train_iter_loss: 0.2395709753036499
train_iter_loss: 0.3229251801967621
train_iter_loss: 0.26803895831108093
train_iter_loss: 0.21825407445430756
train_iter_loss: 0.37047678232192993
train_iter_loss: 0.21968866884708405
train_iter_loss: 0.22621361911296844
train_iter_loss: 0.2331705093383789
train_iter_loss: 0.41957056522369385
train_iter_loss: 0.2945283353328705
train_iter_loss: 0.26854363083839417
train_iter_loss: 0.2719113230705261
train_iter_loss: 0.23203730583190918
train_iter_loss: 0.2168179750442505
train_iter_loss: 0.40085306763648987
train_iter_loss: 0.24552768468856812
train_iter_loss: 0.2981543242931366
train_iter_loss: 0.25259920954704285
train_iter_loss: 0.3445269465446472
train_iter_loss: 0.361995130777359
train_iter_loss: 0.24895170331001282
train_iter_loss: 0.25182685256004333
train_iter_loss: 0.24107547104358673
train_iter_loss: 0.27799737453460693
train_iter_loss: 0.27235549688339233
train_iter_loss: 0.34423673152923584
train_iter_loss: 0.2461961805820465
train_iter_loss: 0.23302394151687622
train_iter_loss: 0.21090587973594666
train_iter_loss: 0.25012892484664917
train_iter_loss: 0.3395369052886963
train_iter_loss: 0.21619702875614166
train_iter_loss: 0.23146386444568634
train_iter_loss: 0.22734354436397552
train_iter_loss: 0.2724268138408661
train_iter_loss: 0.2733907401561737
train_iter_loss: 0.2271338403224945
train_iter_loss: 0.29479727149009705
train_iter_loss: 0.39012065529823303
train_iter_loss: 0.28292030096054077
train_iter_loss: 0.2661544680595398
train_iter_loss: 0.2309928983449936
train_iter_loss: 0.2420206367969513
train_iter_loss: 0.24434860050678253
train_iter_loss: 0.29089590907096863
train_iter_loss: 0.2923222482204437
train_iter_loss: 0.2896536886692047
train_iter_loss: 0.23985742032527924
train_iter_loss: 0.27056559920310974
train_iter_loss: 0.21770749986171722
train_iter_loss: 0.33510175347328186
train_iter_loss: 0.26322683691978455
train_iter_loss: 0.2954584062099457
train_iter_loss: 0.2875884175300598
train_iter_loss: 0.2824435532093048
train_iter_loss: 0.24468182027339935
train_iter_loss: 0.2546263039112091
train_iter_loss: 0.26543229818344116
train_iter_loss: 0.24630464613437653
train_iter_loss: 0.2333216518163681
train_iter_loss: 0.26702263951301575
train_iter_loss: 0.2038240134716034
train_iter_loss: 0.21343474090099335
train_iter_loss: 0.4103321135044098
train_iter_loss: 0.2532825469970703
train_iter_loss: 0.3573020100593567
train_iter_loss: 0.3429642915725708
train_iter_loss: 0.2538887858390808
train_iter_loss: 0.23802025616168976
train_iter_loss: 0.3793949782848358
train_iter_loss: 0.22737301886081696
train_iter_loss: 0.23754893243312836
train_iter_loss: 0.26316261291503906
train_iter_loss: 0.2458358258008957
train_iter_loss: 0.3649126887321472
train_iter_loss: 0.24738408625125885
train_iter_loss: 0.2575521767139435
train_iter_loss: 0.2814331650733948
train_iter_loss: 0.3337478041648865
train_iter_loss: 0.3126141428947449
train_iter_loss: 0.28029343485832214
train_iter_loss: 0.2654564678668976
train loss :0.2710
---------------------
Validation seg loss: 0.31797014443941835 at epoch 29
epoch =     30/  1000, exp = train
train_iter_loss: 0.2858147621154785
train_iter_loss: 0.3529570996761322
train_iter_loss: 0.25680267810821533
train_iter_loss: 0.22206680476665497
train_iter_loss: 0.3450956642627716
train_iter_loss: 0.2112460732460022
train_iter_loss: 0.19438466429710388
train_iter_loss: 0.305885910987854
train_iter_loss: 0.3390464186668396
train_iter_loss: 0.22362448275089264
train_iter_loss: 0.3255223035812378
train_iter_loss: 0.2705817222595215
train_iter_loss: 0.264804482460022
train_iter_loss: 0.2945052981376648
train_iter_loss: 0.23794250190258026
train_iter_loss: 0.2292022556066513
train_iter_loss: 0.24223767220973969
train_iter_loss: 0.2569141983985901
train_iter_loss: 0.29357239603996277
train_iter_loss: 0.2966817021369934
train_iter_loss: 0.21992792189121246
train_iter_loss: 0.27301719784736633
train_iter_loss: 0.26320144534111023
train_iter_loss: 0.26667267084121704
train_iter_loss: 0.28711727261543274
train_iter_loss: 0.2514601945877075
train_iter_loss: 0.2366618514060974
train_iter_loss: 0.27061575651168823
train_iter_loss: 0.26424843072891235
train_iter_loss: 0.250236451625824
train_iter_loss: 0.21273860335350037
train_iter_loss: 0.2850129008293152
train_iter_loss: 0.2775917649269104
train_iter_loss: 0.2330458015203476
train_iter_loss: 0.20699577033519745
train_iter_loss: 0.20954200625419617
train_iter_loss: 0.3925735652446747
train_iter_loss: 0.24376177787780762
train_iter_loss: 0.22373463213443756
train_iter_loss: 0.24025976657867432
train_iter_loss: 0.2069041132926941
train_iter_loss: 0.27273058891296387
train_iter_loss: 0.3281325697898865
train_iter_loss: 0.2894921600818634
train_iter_loss: 0.2810279428958893
train_iter_loss: 0.4103580713272095
train_iter_loss: 0.3193502724170685
train_iter_loss: 0.2550395131111145
train_iter_loss: 0.2922287583351135
train_iter_loss: 0.21201910078525543
train_iter_loss: 0.2112417370080948
train_iter_loss: 0.22130322456359863
train_iter_loss: 0.22304625809192657
train_iter_loss: 0.2632301151752472
train_iter_loss: 0.24095742404460907
train_iter_loss: 0.29846349358558655
train_iter_loss: 0.24196796119213104
train_iter_loss: 0.2689327895641327
train_iter_loss: 0.21380840241909027
train_iter_loss: 0.22849564254283905
train_iter_loss: 0.2690087556838989
train_iter_loss: 0.23202846944332123
train_iter_loss: 0.2897040545940399
train_iter_loss: 0.2630701959133148
train_iter_loss: 0.3669567406177521
train_iter_loss: 0.2520267963409424
train_iter_loss: 0.3937242329120636
train_iter_loss: 0.21957142651081085
train_iter_loss: 0.2589277923107147
train_iter_loss: 0.3961089253425598
train_iter_loss: 0.2928585112094879
train_iter_loss: 0.25784754753112793
train_iter_loss: 0.2507413625717163
train_iter_loss: 0.2783129811286926
train_iter_loss: 0.2574532628059387
train_iter_loss: 0.3623405694961548
train_iter_loss: 0.25473400950431824
train_iter_loss: 0.25864776968955994
train_iter_loss: 0.299144446849823
train_iter_loss: 0.22493448853492737
train_iter_loss: 0.31862393021583557
train_iter_loss: 0.2852585017681122
train_iter_loss: 0.20666956901550293
train_iter_loss: 0.28097760677337646
train_iter_loss: 0.289302796125412
train_iter_loss: 0.2579476535320282
train_iter_loss: 0.3043602406978607
train_iter_loss: 0.2839100658893585
train_iter_loss: 0.3155616223812103
train_iter_loss: 0.30271369218826294
train_iter_loss: 0.24317589402198792
train_iter_loss: 0.31537097692489624
train_iter_loss: 0.20003126561641693
train_iter_loss: 0.29875463247299194
train_iter_loss: 0.2381449043750763
train_iter_loss: 0.24210254848003387
train_iter_loss: 0.2522030174732208
train_iter_loss: 0.3331371545791626
train_iter_loss: 0.3028344213962555
train_iter_loss: 0.4823760390281677
train_iter_loss: 0.2732706367969513
train_iter_loss: 0.2733749449253082
train_iter_loss: 0.22547319531440735
train_iter_loss: 0.2950306832790375
train_iter_loss: 0.22614745795726776
train_iter_loss: 0.2654452323913574
train_iter_loss: 0.26901036500930786
train_iter_loss: 0.24609467387199402
train_iter_loss: 0.424384206533432
train_iter_loss: 0.28634214401245117
train_iter_loss: 0.32535287737846375
train_iter_loss: 0.2413538098335266
train_iter_loss: 0.25577595829963684
train_iter_loss: 0.27488455176353455
train_iter_loss: 0.24476143717765808
train_iter_loss: 0.33038944005966187
train_iter_loss: 0.26410046219825745
train_iter_loss: 0.2523646056652069
train_iter_loss: 0.2382058948278427
train_iter_loss: 0.2365390509366989
train_iter_loss: 0.2526586055755615
train_iter_loss: 0.19879576563835144
train_iter_loss: 0.23753879964351654
train_iter_loss: 0.30530792474746704
train_iter_loss: 0.288705974817276
train_iter_loss: 0.2076433151960373
train_iter_loss: 0.24164138734340668
train_iter_loss: 0.22418171167373657
train_iter_loss: 0.35218045115470886
train_iter_loss: 0.2523384988307953
train_iter_loss: 0.2060835361480713
train_iter_loss: 0.23465895652770996
train_iter_loss: 0.29149502515792847
train_iter_loss: 0.26461565494537354
train_iter_loss: 0.2485698163509369
train_iter_loss: 0.2838762402534485
train_iter_loss: 0.2523955702781677
train_iter_loss: 0.19505155086517334
train_iter_loss: 0.29633286595344543
train_iter_loss: 0.33430448174476624
train_iter_loss: 0.2453758716583252
train_iter_loss: 0.2669747769832611
train_iter_loss: 0.28117597103118896
train_iter_loss: 0.24466346204280853
train_iter_loss: 0.2164038121700287
train_iter_loss: 0.22115859389305115
train_iter_loss: 0.26443782448768616
train_iter_loss: 0.24074116349220276
train_iter_loss: 0.23418903350830078
train_iter_loss: 0.32450997829437256
train_iter_loss: 0.3129288852214813
train_iter_loss: 0.3358248174190521
train_iter_loss: 0.21560364961624146
train_iter_loss: 0.3369789123535156
train_iter_loss: 0.1947735995054245
train_iter_loss: 0.2164376676082611
train_iter_loss: 0.27239492535591125
train_iter_loss: 0.2204105705022812
train_iter_loss: 0.22597335278987885
train_iter_loss: 0.21809783577919006
train_iter_loss: 0.3647603392601013
train_iter_loss: 0.33618226647377014
train_iter_loss: 0.24571098387241364
train_iter_loss: 0.3234544098377228
train_iter_loss: 0.3603303134441376
train_iter_loss: 0.2507186830043793
train_iter_loss: 0.22194641828536987
train_iter_loss: 0.2312185913324356
train_iter_loss: 0.2527480125427246
train_iter_loss: 0.2471897304058075
train_iter_loss: 0.2355699986219406
train_iter_loss: 0.2647668123245239
train_iter_loss: 0.25106868147850037
train_iter_loss: 0.23540091514587402
train_iter_loss: 0.22111861407756805
train_iter_loss: 0.23872987926006317
train_iter_loss: 0.28047508001327515
train_iter_loss: 0.21997880935668945
train_iter_loss: 0.28900206089019775
train_iter_loss: 0.24007326364517212
train_iter_loss: 0.3108496367931366
train_iter_loss: 0.20606939494609833
train_iter_loss: 0.25712382793426514
train_iter_loss: 0.2762066125869751
train_iter_loss: 0.39118921756744385
train_iter_loss: 0.22353465855121613
train_iter_loss: 0.340919554233551
train_iter_loss: 0.3061475157737732
train_iter_loss: 0.3163667619228363
train_iter_loss: 0.3012346923351288
train_iter_loss: 0.27835991978645325
train_iter_loss: 0.32535821199417114
train_iter_loss: 0.2581328749656677
train_iter_loss: 0.2928917407989502
train_iter_loss: 0.22537380456924438
train_iter_loss: 0.2166285216808319
train_iter_loss: 0.272505521774292
train_iter_loss: 0.31910645961761475
train_iter_loss: 0.29134178161621094
train_iter_loss: 0.20913472771644592
train loss :0.2709
---------------------
Validation seg loss: 0.3099326714873314 at epoch 30
********************
best_val_epoch_loss:  0.3099326714873314
MODEL UPDATED
epoch =     31/  1000, exp = train
train_iter_loss: 0.24391642212867737
train_iter_loss: 0.18958966434001923
train_iter_loss: 0.32114502787590027
train_iter_loss: 0.31851208209991455
train_iter_loss: 0.27273428440093994
train_iter_loss: 0.24978947639465332
train_iter_loss: 0.2717105746269226
train_iter_loss: 0.23148098587989807
train_iter_loss: 0.2577158510684967
train_iter_loss: 0.27555540204048157
train_iter_loss: 0.2756366431713104
train_iter_loss: 0.28247639536857605
train_iter_loss: 0.2670348882675171
train_iter_loss: 0.23254261910915375
train_iter_loss: 0.23019543290138245
train_iter_loss: 0.2417389154434204
train_iter_loss: 0.3015683591365814
train_iter_loss: 0.31124815344810486
train_iter_loss: 0.19726109504699707
train_iter_loss: 0.24021215736865997
train_iter_loss: 0.23523128032684326
train_iter_loss: 0.22594675421714783
train_iter_loss: 0.2589274048805237
train_iter_loss: 0.20665036141872406
train_iter_loss: 0.29663270711898804
train_iter_loss: 0.2759200632572174
train_iter_loss: 0.2751019597053528
train_iter_loss: 0.2910575270652771
train_iter_loss: 0.20856605470180511
train_iter_loss: 0.23199990391731262
train_iter_loss: 0.21515382826328278
train_iter_loss: 0.24496783316135406
train_iter_loss: 0.29044657945632935
train_iter_loss: 0.22819620370864868
train_iter_loss: 0.24629202485084534
train_iter_loss: 0.2551865577697754
train_iter_loss: 0.3582802414894104
train_iter_loss: 0.33182528614997864
train_iter_loss: 0.37723028659820557
train_iter_loss: 0.2743532657623291
train_iter_loss: 0.2375279814004898
train_iter_loss: 0.2401212453842163
train_iter_loss: 0.31608954071998596
train_iter_loss: 0.26021188497543335
train_iter_loss: 0.3220459222793579
train_iter_loss: 0.24780352413654327
train_iter_loss: 0.23088839650154114
train_iter_loss: 0.38424643874168396
train_iter_loss: 0.2391696274280548
train_iter_loss: 0.22215360403060913
train_iter_loss: 0.22749322652816772
train_iter_loss: 0.28000587224960327
train_iter_loss: 0.24468699097633362
train_iter_loss: 0.21270930767059326
train_iter_loss: 0.29455652832984924
train_iter_loss: 0.3871316611766815
train_iter_loss: 0.25052395462989807
train_iter_loss: 0.27551552653312683
train_iter_loss: 0.24591553211212158
train_iter_loss: 0.2531752288341522
train_iter_loss: 0.25258150696754456
train_iter_loss: 0.26127591729164124
train_iter_loss: 0.25451067090034485
train_iter_loss: 0.3547568917274475
train_iter_loss: 0.21195858716964722
train_iter_loss: 0.276899129152298
train_iter_loss: 0.29658186435699463
train_iter_loss: 0.3138272166252136
train_iter_loss: 0.2631484866142273
train_iter_loss: 0.24675124883651733
train_iter_loss: 0.2060847133398056
train_iter_loss: 0.3229081332683563
train_iter_loss: 0.2519209086894989
train_iter_loss: 0.26811012625694275
train_iter_loss: 0.2290002554655075
train_iter_loss: 0.2387169748544693
train_iter_loss: 0.24256151914596558
train_iter_loss: 0.307944655418396
train_iter_loss: 0.26280543208122253
train_iter_loss: 0.20364995300769806
train_iter_loss: 0.24118199944496155
train_iter_loss: 0.30892664194107056
train_iter_loss: 0.21974407136440277
train_iter_loss: 0.28448641300201416
train_iter_loss: 0.19828222692012787
train_iter_loss: 0.28390637040138245
train_iter_loss: 0.3450329899787903
train_iter_loss: 0.27744048833847046
train_iter_loss: 0.23314312100410461
train_iter_loss: 0.22837676107883453
train_iter_loss: 0.23390249907970428
train_iter_loss: 0.21276353299617767
train_iter_loss: 0.22165276110172272
train_iter_loss: 0.23892377316951752
train_iter_loss: 0.2686185836791992
train_iter_loss: 0.26337799429893494
train_iter_loss: 0.25530123710632324
train_iter_loss: 0.24363689124584198
train_iter_loss: 0.2159784883260727
train_iter_loss: 0.2714594304561615
train_iter_loss: 0.38803479075431824
train_iter_loss: 0.3810330033302307
train_iter_loss: 0.3536333441734314
train_iter_loss: 0.3227519094944
train_iter_loss: 0.3683163821697235
train_iter_loss: 0.21527808904647827
train_iter_loss: 0.2607341408729553
train_iter_loss: 0.26935580372810364
train_iter_loss: 0.22947658598423004
train_iter_loss: 0.27606654167175293
train_iter_loss: 0.24559082090854645
train_iter_loss: 0.3090634047985077
train_iter_loss: 0.27164092659950256
train_iter_loss: 0.2830466032028198
train_iter_loss: 0.2904365658760071
train_iter_loss: 0.21396242082118988
train_iter_loss: 0.26766642928123474
train_iter_loss: 0.27201494574546814
train_iter_loss: 0.2560470700263977
train_iter_loss: 0.2642204761505127
train_iter_loss: 0.2604285478591919
train_iter_loss: 0.25111982226371765
train_iter_loss: 0.2608705461025238
train_iter_loss: 0.3014392554759979
train_iter_loss: 0.29793351888656616
train_iter_loss: 0.3310484290122986
train_iter_loss: 0.22177910804748535
train_iter_loss: 0.2125207632780075
train_iter_loss: 0.2451440989971161
train_iter_loss: 0.2986418306827545
train_iter_loss: 0.417400985956192
train_iter_loss: 0.2664884924888611
train_iter_loss: 0.19583040475845337
train_iter_loss: 0.21974045038223267
train_iter_loss: 0.33316555619239807
train_iter_loss: 0.30040082335472107
train_iter_loss: 0.2343011051416397
train_iter_loss: 0.2804935872554779
train_iter_loss: 0.22850751876831055
train_iter_loss: 0.3760072588920593
train_iter_loss: 0.2606794536113739
train_iter_loss: 0.3105643093585968
train_iter_loss: 0.22220684587955475
train_iter_loss: 0.28269442915916443
train_iter_loss: 0.2249358743429184
train_iter_loss: 0.23756761848926544
train_iter_loss: 0.2977912425994873
train_iter_loss: 0.21123209595680237
train_iter_loss: 0.23796166479587555
train_iter_loss: 0.2991742193698883
train_iter_loss: 0.2390139102935791
train_iter_loss: 0.21630537509918213
train_iter_loss: 0.41836342215538025
train_iter_loss: 0.21415135264396667
train_iter_loss: 0.2681610584259033
train_iter_loss: 0.24273228645324707
train_iter_loss: 0.28801199793815613
train_iter_loss: 0.4025225043296814
train_iter_loss: 0.22752299904823303
train_iter_loss: 0.21431869268417358
train_iter_loss: 0.2847326695919037
train_iter_loss: 0.25038179755210876
train_iter_loss: 0.23795120418071747
train_iter_loss: 0.21982109546661377
train_iter_loss: 0.3514034152030945
train_iter_loss: 0.30455583333969116
train_iter_loss: 0.25058886408805847
train_iter_loss: 0.2462044209241867
train_iter_loss: 0.2880624532699585
train_iter_loss: 0.28181350231170654
train_iter_loss: 0.22862151265144348
train_iter_loss: 0.2254972755908966
train_iter_loss: 0.2873838245868683
train_iter_loss: 0.21224696934223175
train_iter_loss: 0.21374279260635376
train_iter_loss: 0.2782372832298279
train_iter_loss: 0.26624608039855957
train_iter_loss: 0.2143605500459671
train_iter_loss: 0.29007428884506226
train_iter_loss: 0.23780107498168945
train_iter_loss: 0.3995564877986908
train_iter_loss: 0.2803284823894501
train_iter_loss: 0.22251977026462555
train_iter_loss: 0.4081054627895355
train_iter_loss: 0.36020946502685547
train_iter_loss: 0.234108567237854
train_iter_loss: 0.2631131708621979
train_iter_loss: 0.22076430916786194
train_iter_loss: 0.23322349786758423
train_iter_loss: 0.2659587562084198
train_iter_loss: 0.2946377694606781
train_iter_loss: 0.25612780451774597
train_iter_loss: 0.28239282965660095
train_iter_loss: 0.2413739562034607
train_iter_loss: 0.20475876331329346
train_iter_loss: 0.2691178321838379
train_iter_loss: 0.19617728888988495
train_iter_loss: 0.2515445947647095
train_iter_loss: 0.24898818135261536
train_iter_loss: 0.29601186513900757
train loss :0.2684
---------------------
Validation seg loss: 0.31679356351213633 at epoch 31
epoch =     32/  1000, exp = train
train_iter_loss: 0.26227375864982605
train_iter_loss: 0.20489045977592468
train_iter_loss: 0.33191564679145813
train_iter_loss: 0.2624545693397522
train_iter_loss: 0.2736150920391083
train_iter_loss: 0.23878955841064453
train_iter_loss: 0.24999168515205383
train_iter_loss: 0.29217252135276794
train_iter_loss: 0.2451878786087036
train_iter_loss: 0.3298666179180145
train_iter_loss: 0.2845762073993683
train_iter_loss: 0.2773979902267456
train_iter_loss: 0.18447673320770264
train_iter_loss: 0.32870349287986755
train_iter_loss: 0.23112532496452332
train_iter_loss: 0.2273799031972885
train_iter_loss: 0.2515130937099457
train_iter_loss: 0.22572919726371765
train_iter_loss: 0.2565309703350067
train_iter_loss: 0.21555952727794647
train_iter_loss: 0.23606739938259125
train_iter_loss: 0.24470318853855133
train_iter_loss: 0.22516007721424103
train_iter_loss: 0.34277087450027466
train_iter_loss: 0.3324768841266632
train_iter_loss: 0.314750075340271
train_iter_loss: 0.2533751428127289
train_iter_loss: 0.3204158544540405
train_iter_loss: 0.222300186753273
train_iter_loss: 0.33985328674316406
train_iter_loss: 0.3413732945919037
train_iter_loss: 0.2739693224430084
train_iter_loss: 0.28443190455436707
train_iter_loss: 0.24487285315990448
train_iter_loss: 0.2420365959405899
train_iter_loss: 0.20809800922870636
train_iter_loss: 0.2030690759420395
train_iter_loss: 0.48710188269615173
train_iter_loss: 0.2332414835691452
train_iter_loss: 0.39800986647605896
train_iter_loss: 0.2778937518596649
train_iter_loss: 0.23627670109272003
train_iter_loss: 0.3049919307231903
train_iter_loss: 0.21878765523433685
train_iter_loss: 0.3320801854133606
train_iter_loss: 0.2594626545906067
train_iter_loss: 0.38626599311828613
train_iter_loss: 0.33390334248542786
train_iter_loss: 0.214181050658226
train_iter_loss: 0.2154799848794937
train_iter_loss: 0.22245223820209503
train_iter_loss: 0.3307880759239197
train_iter_loss: 0.2955038845539093
train_iter_loss: 0.19673703610897064
train_iter_loss: 0.2183646410703659
train_iter_loss: 0.3219723105430603
train_iter_loss: 0.314909428358078
train_iter_loss: 0.2651542127132416
train_iter_loss: 0.2742431163787842
train_iter_loss: 0.2608352303504944
train_iter_loss: 0.22378458082675934
train_iter_loss: 0.2679443359375
train_iter_loss: 0.2273780107498169
train_iter_loss: 0.29444557428359985
train_iter_loss: 0.20904658734798431
train_iter_loss: 0.2994915246963501
train_iter_loss: 0.26374170184135437
train_iter_loss: 0.26372238993644714
train_iter_loss: 0.2871440649032593
train_iter_loss: 0.3780972957611084
train_iter_loss: 0.29487937688827515
train_iter_loss: 0.20047412812709808
train_iter_loss: 0.2813950479030609
train_iter_loss: 0.2898250222206116
train_iter_loss: 0.23798459768295288
train_iter_loss: 0.3318730890750885
train_iter_loss: 0.2646733224391937
train_iter_loss: 0.22625502943992615
train_iter_loss: 0.25775161385536194
train_iter_loss: 0.2456064075231552
train_iter_loss: 0.24091099202632904
train_iter_loss: 0.22360974550247192
train_iter_loss: 0.26563847064971924
train_iter_loss: 0.29013198614120483
train_iter_loss: 0.2702239751815796
train_iter_loss: 0.261778324842453
train_iter_loss: 0.26520633697509766
train_iter_loss: 0.3098392188549042
train_iter_loss: 0.20200280845165253
train_iter_loss: 0.44152507185935974
train_iter_loss: 0.23661093413829803
train_iter_loss: 0.2087232768535614
train_iter_loss: 0.2655748128890991
train_iter_loss: 0.23823489248752594
train_iter_loss: 0.2699061930179596
train_iter_loss: 0.25750142335891724
train_iter_loss: 0.2946303188800812
train_iter_loss: 0.28749728202819824
train_iter_loss: 0.3135232627391815
train_iter_loss: 0.24494542181491852
train_iter_loss: 0.2678622901439667
train_iter_loss: 0.24171894788742065
train_iter_loss: 0.2677430808544159
train_iter_loss: 0.4285658001899719
train_iter_loss: 0.226400688290596
train_iter_loss: 0.2911220192909241
train_iter_loss: 0.26018258929252625
train_iter_loss: 0.25733324885368347
train_iter_loss: 0.23189154267311096
train_iter_loss: 0.27329522371292114
train_iter_loss: 0.29589763283729553
train_iter_loss: 0.23312130570411682
train_iter_loss: 0.22022126615047455
train_iter_loss: 0.2676054537296295
train_iter_loss: 0.2557429075241089
train_iter_loss: 0.2554423213005066
train_iter_loss: 0.32895800471305847
train_iter_loss: 0.2913733124732971
train_iter_loss: 0.1835663914680481
train_iter_loss: 0.2155619114637375
train_iter_loss: 0.24271419644355774
train_iter_loss: 0.3433772325515747
train_iter_loss: 0.25327762961387634
train_iter_loss: 0.21560616791248322
train_iter_loss: 0.2460079938173294
train_iter_loss: 0.3111446797847748
train_iter_loss: 0.23338072001934052
train_iter_loss: 0.2896074652671814
train_iter_loss: 0.2365047037601471
train_iter_loss: 0.23884440958499908
train_iter_loss: 0.3910210132598877
train_iter_loss: 0.2264028787612915
train_iter_loss: 0.19644825160503387
train_iter_loss: 0.20377272367477417
train_iter_loss: 0.22048622369766235
train_iter_loss: 0.24925565719604492
train_iter_loss: 0.22486507892608643
train_iter_loss: 0.26737645268440247
train_iter_loss: 0.32428106665611267
train_iter_loss: 0.22979390621185303
train_iter_loss: 0.25403285026550293
train_iter_loss: 0.24100439250469208
train_iter_loss: 0.23527009785175323
train_iter_loss: 0.37809398770332336
train_iter_loss: 0.2935083210468292
train_iter_loss: 0.22660353779792786
train_iter_loss: 0.2501091957092285
train_iter_loss: 0.25074779987335205
train_iter_loss: 0.3212049603462219
train_iter_loss: 0.2805696427822113
train_iter_loss: 0.2658573389053345
train_iter_loss: 0.3016289174556732
train_iter_loss: 0.26713746786117554
train_iter_loss: 0.25574561953544617
train_iter_loss: 0.20773421227931976
train_iter_loss: 0.2396663874387741
train_iter_loss: 0.24677212536334991
train_iter_loss: 0.22273790836334229
train_iter_loss: 0.24846450984477997
train_iter_loss: 0.3128729462623596
train_iter_loss: 0.20438861846923828
train_iter_loss: 0.2212357372045517
train_iter_loss: 0.2578752636909485
train_iter_loss: 0.35093507170677185
train_iter_loss: 0.2230994999408722
train_iter_loss: 0.19142575562000275
train_iter_loss: 0.24734824895858765
train_iter_loss: 0.24264445900917053
train_iter_loss: 0.259341835975647
train_iter_loss: 0.25340211391448975
train_iter_loss: 0.2206486612558365
train_iter_loss: 0.2596382796764374
train_iter_loss: 0.21759578585624695
train_iter_loss: 0.2943076193332672
train_iter_loss: 0.20583109557628632
train_iter_loss: 0.2585013508796692
train_iter_loss: 0.2577914893627167
train_iter_loss: 0.23044046759605408
train_iter_loss: 0.23496843874454498
train_iter_loss: 0.22296223044395447
train_iter_loss: 0.2467348277568817
train_iter_loss: 0.2559075653553009
train_iter_loss: 0.23169036209583282
train_iter_loss: 0.3231126368045807
train_iter_loss: 0.2704545557498932
train_iter_loss: 0.19737665355205536
train_iter_loss: 0.27613234519958496
train_iter_loss: 0.33562201261520386
train_iter_loss: 0.28910592198371887
train_iter_loss: 0.24814638495445251
train_iter_loss: 0.20812618732452393
train_iter_loss: 0.23357905447483063
train_iter_loss: 0.27516138553619385
train_iter_loss: 0.400334894657135
train_iter_loss: 0.24263770878314972
train_iter_loss: 0.2610231637954712
train_iter_loss: 0.46638697385787964
train_iter_loss: 0.28480786085128784
train_iter_loss: 0.23855485022068024
train_iter_loss: 0.2507264316082001
train loss :0.2677
---------------------
Validation seg loss: 0.31410967108775983 at epoch 32
epoch =     33/  1000, exp = train
train_iter_loss: 0.24411074817180634
train_iter_loss: 0.25711318850517273
train_iter_loss: 0.23422908782958984
train_iter_loss: 0.24542751908302307
train_iter_loss: 0.2614682614803314
train_iter_loss: 0.22180375456809998
train_iter_loss: 0.2744837701320648
train_iter_loss: 0.23385366797447205
train_iter_loss: 0.2651839852333069
train_iter_loss: 0.292965292930603
train_iter_loss: 0.24819792807102203
train_iter_loss: 0.22227224707603455
train_iter_loss: 0.25864672660827637
train_iter_loss: 0.26816126704216003
train_iter_loss: 0.3439873158931732
train_iter_loss: 0.25637325644493103
train_iter_loss: 0.22754333913326263
train_iter_loss: 0.2985571622848511
train_iter_loss: 0.2860758900642395
train_iter_loss: 0.4156109690666199
train_iter_loss: 0.2808704674243927
train_iter_loss: 0.309485524892807
train_iter_loss: 0.2667774260044098
train_iter_loss: 0.22834435105323792
train_iter_loss: 0.23595239222049713
train_iter_loss: 0.29016053676605225
train_iter_loss: 0.21917133033275604
train_iter_loss: 0.24199874699115753
train_iter_loss: 0.24897851049900055
train_iter_loss: 0.23185494542121887
train_iter_loss: 0.2690862715244293
train_iter_loss: 0.24120059609413147
train_iter_loss: 0.24813693761825562
train_iter_loss: 0.19169656932353973
train_iter_loss: 0.33934587240219116
train_iter_loss: 0.22502627968788147
train_iter_loss: 0.2122560739517212
train_iter_loss: 0.3631487786769867
train_iter_loss: 0.2629046142101288
train_iter_loss: 0.31884652376174927
train_iter_loss: 0.2781214714050293
train_iter_loss: 0.3341909348964691
train_iter_loss: 0.2636832594871521
train_iter_loss: 0.24130383133888245
train_iter_loss: 0.28043511509895325
train_iter_loss: 0.2255123406648636
train_iter_loss: 0.2929622232913971
train_iter_loss: 0.22943046689033508
train_iter_loss: 0.24825748801231384
train_iter_loss: 0.2696211636066437
train_iter_loss: 0.2016017585992813
train_iter_loss: 0.3008522391319275
train_iter_loss: 0.32150864601135254
train_iter_loss: 0.24079960584640503
train_iter_loss: 0.25132766366004944
train_iter_loss: 0.23505830764770508
train_iter_loss: 0.2404126226902008
train_iter_loss: 0.23187537491321564
train_iter_loss: 0.1960095912218094
train_iter_loss: 0.2421162873506546
train_iter_loss: 0.2393437772989273
train_iter_loss: 0.24542789161205292
train_iter_loss: 0.1900482475757599
train_iter_loss: 0.23576432466506958
train_iter_loss: 0.27367115020751953
train_iter_loss: 0.2691541612148285
train_iter_loss: 0.21108591556549072
train_iter_loss: 0.238615483045578
train_iter_loss: 0.3558987081050873
train_iter_loss: 0.23993411660194397
train_iter_loss: 0.22658520936965942
train_iter_loss: 0.2454797327518463
train_iter_loss: 0.23223894834518433
train_iter_loss: 0.22073616087436676
train_iter_loss: 0.3360176086425781
train_iter_loss: 0.22646638751029968
train_iter_loss: 0.2769825756549835
train_iter_loss: 0.2428707778453827
train_iter_loss: 0.2515224516391754
train_iter_loss: 0.23615841567516327
train_iter_loss: 0.2349969893693924
train_iter_loss: 0.22153949737548828
train_iter_loss: 0.24446237087249756
train_iter_loss: 0.2939060926437378
train_iter_loss: 0.47745054960250854
train_iter_loss: 0.21781741082668304
train_iter_loss: 0.3204726576805115
train_iter_loss: 0.2228379100561142
train_iter_loss: 0.21292969584465027
train_iter_loss: 0.22296854853630066
train_iter_loss: 0.20705465972423553
train_iter_loss: 0.23333324491977692
train_iter_loss: 0.28995412588119507
train_iter_loss: 0.21878303587436676
train_iter_loss: 0.257463663816452
train_iter_loss: 0.19153299927711487
train_iter_loss: 0.2852367162704468
train_iter_loss: 0.2735369801521301
train_iter_loss: 0.23273448646068573
train_iter_loss: 0.26944220066070557
train_iter_loss: 0.2767457365989685
train_iter_loss: 0.2507452964782715
train_iter_loss: 0.2771676480770111
train_iter_loss: 0.3812648355960846
train_iter_loss: 0.26928576827049255
train_iter_loss: 0.27477073669433594
train_iter_loss: 0.21208563446998596
train_iter_loss: 0.2391301393508911
train_iter_loss: 0.23700883984565735
train_iter_loss: 0.2903357446193695
train_iter_loss: 0.3422439992427826
train_iter_loss: 0.2620278000831604
train_iter_loss: 0.2211536020040512
train_iter_loss: 0.2557242512702942
train_iter_loss: 0.2930945158004761
train_iter_loss: 0.2654005289077759
train_iter_loss: 0.39146938920021057
train_iter_loss: 0.23992760479450226
train_iter_loss: 0.25256142020225525
train_iter_loss: 0.2160336673259735
train_iter_loss: 0.22450557351112366
train_iter_loss: 0.31996825337409973
train_iter_loss: 0.2568652927875519
train_iter_loss: 0.36108458042144775
train_iter_loss: 0.2261035293340683
train_iter_loss: 0.21701493859291077
train_iter_loss: 0.3423241972923279
train_iter_loss: 0.21792231500148773
train_iter_loss: 0.3215188682079315
train_iter_loss: 0.24663959443569183
train_iter_loss: 0.27682459354400635
train_iter_loss: 0.3057990074157715
train_iter_loss: 0.24674665927886963
train_iter_loss: 0.31956276297569275
train_iter_loss: 0.23171931505203247
train_iter_loss: 0.3383658826351166
train_iter_loss: 0.23315197229385376
train_iter_loss: 0.23926734924316406
train_iter_loss: 0.2268376499414444
train_iter_loss: 0.20260491967201233
train_iter_loss: 0.27749162912368774
train_iter_loss: 0.21308328211307526
train_iter_loss: 0.2589849829673767
train_iter_loss: 0.24185670912265778
train_iter_loss: 0.24094924330711365
train_iter_loss: 0.3211650550365448
train_iter_loss: 0.3266749680042267
train_iter_loss: 0.2910442650318146
train_iter_loss: 0.2969472110271454
train_iter_loss: 0.2336767613887787
train_iter_loss: 0.2259645015001297
train_iter_loss: 0.27680933475494385
train_iter_loss: 0.3140317499637604
train_iter_loss: 0.2811625599861145
train_iter_loss: 0.21356377005577087
train_iter_loss: 0.22340011596679688
train_iter_loss: 0.3151816427707672
train_iter_loss: 0.2264428734779358
train_iter_loss: 0.39229917526245117
train_iter_loss: 0.27794092893600464
train_iter_loss: 0.22759559750556946
train_iter_loss: 0.2533801198005676
train_iter_loss: 0.20033203065395355
train_iter_loss: 0.22486810386180878
train_iter_loss: 0.24795061349868774
train_iter_loss: 0.24045777320861816
train_iter_loss: 0.27462807297706604
train_iter_loss: 0.21318981051445007
train_iter_loss: 0.2764909863471985
train_iter_loss: 0.286720871925354
train_iter_loss: 0.2796826660633087
train_iter_loss: 0.2663927674293518
train_iter_loss: 0.261345237493515
train_iter_loss: 0.24348211288452148
train_iter_loss: 0.27403709292411804
train_iter_loss: 0.24915027618408203
train_iter_loss: 0.32438403367996216
train_iter_loss: 0.19962641596794128
train_iter_loss: 0.3583195209503174
train_iter_loss: 0.23871006071567535
train_iter_loss: 0.2350999116897583
train_iter_loss: 0.26653140783309937
train_iter_loss: 0.21609368920326233
train_iter_loss: 0.3625148832798004
train_iter_loss: 0.2567673921585083
train_iter_loss: 0.26372915506362915
train_iter_loss: 0.2795915901660919
train_iter_loss: 0.27997204661369324
train_iter_loss: 0.37171003222465515
train_iter_loss: 0.2942837178707123
train_iter_loss: 0.23576529324054718
train_iter_loss: 0.24263988435268402
train_iter_loss: 0.3587791919708252
train_iter_loss: 0.3030284345149994
train_iter_loss: 0.2142975926399231
train_iter_loss: 0.25239282846450806
train_iter_loss: 0.2273976057767868
train_iter_loss: 0.3384269177913666
train_iter_loss: 0.29580333828926086
train_iter_loss: 0.2356313318014145
train loss :0.2651
---------------------
Validation seg loss: 0.3116445029681584 at epoch 33
epoch =     34/  1000, exp = train
train_iter_loss: 0.23184902966022491
train_iter_loss: 0.41396796703338623
train_iter_loss: 0.2786557376384735
train_iter_loss: 0.2324998825788498
train_iter_loss: 0.20442387461662292
train_iter_loss: 0.231344535946846
train_iter_loss: 0.20810222625732422
train_iter_loss: 0.28415676951408386
train_iter_loss: 0.23404325544834137
train_iter_loss: 0.20021487772464752
train_iter_loss: 0.2425824999809265
train_iter_loss: 0.28802353143692017
train_iter_loss: 0.3810007572174072
train_iter_loss: 0.2662580609321594
train_iter_loss: 0.30304160714149475
train_iter_loss: 0.23859697580337524
train_iter_loss: 0.308779239654541
train_iter_loss: 0.2353593111038208
train_iter_loss: 0.21449752151966095
train_iter_loss: 0.2783419191837311
train_iter_loss: 0.20437069237232208
train_iter_loss: 0.2578798830509186
train_iter_loss: 0.34846580028533936
train_iter_loss: 0.24898700416088104
train_iter_loss: 0.18495522439479828
train_iter_loss: 0.23703189194202423
train_iter_loss: 0.3064921200275421
train_iter_loss: 0.22807559370994568
train_iter_loss: 0.2598332464694977
train_iter_loss: 0.37036970257759094
train_iter_loss: 0.2698168158531189
train_iter_loss: 0.3308202922344208
train_iter_loss: 0.2035592496395111
train_iter_loss: 0.25574877858161926
train_iter_loss: 0.24148009717464447
train_iter_loss: 0.22061830759048462
train_iter_loss: 0.25415921211242676
train_iter_loss: 0.3051717281341553
train_iter_loss: 0.21838344633579254
train_iter_loss: 0.3029167652130127
train_iter_loss: 0.37406837940216064
train_iter_loss: 0.29544323682785034
train_iter_loss: 0.306583434343338
train_iter_loss: 0.23115645349025726
train_iter_loss: 0.27224305272102356
train_iter_loss: 0.2822333574295044
train_iter_loss: 0.2700309455394745
train_iter_loss: 0.23253649473190308
train_iter_loss: 0.25326603651046753
train_iter_loss: 0.2472689300775528
train_iter_loss: 0.2798923850059509
train_iter_loss: 0.3467850089073181
train_iter_loss: 0.22408922016620636
train_iter_loss: 0.2595506012439728
train_iter_loss: 0.2361464947462082
train_iter_loss: 0.2080298811197281
train_iter_loss: 0.2663651704788208
train_iter_loss: 0.20412971079349518
train_iter_loss: 0.25174570083618164
train_iter_loss: 0.21919478476047516
train_iter_loss: 0.25731709599494934
train_iter_loss: 0.2024335414171219
train_iter_loss: 0.26950061321258545
train_iter_loss: 0.24917063117027283
train_iter_loss: 0.30317941308021545
train_iter_loss: 0.2240850180387497
train_iter_loss: 0.28915074467658997
train_iter_loss: 0.2680906355381012
train_iter_loss: 0.2616002559661865
train_iter_loss: 0.2688290774822235
train_iter_loss: 0.29473257064819336
train_iter_loss: 0.23738008737564087
train_iter_loss: 0.28570792078971863
train_iter_loss: 0.23495888710021973
train_iter_loss: 0.4259144365787506
train_iter_loss: 0.3379887640476227
train_iter_loss: 0.23764555156230927
train_iter_loss: 0.22424519062042236
train_iter_loss: 0.20285029709339142
train_iter_loss: 0.22366517782211304
train_iter_loss: 0.3622775077819824
train_iter_loss: 0.23087789118289948
train_iter_loss: 0.3114018440246582
train_iter_loss: 0.2446829080581665
train_iter_loss: 0.22876252233982086
train_iter_loss: 0.2425832897424698
train_iter_loss: 0.21746547520160675
train_iter_loss: 0.20851688086986542
train_iter_loss: 0.21983492374420166
train_iter_loss: 0.2759306728839874
train_iter_loss: 0.27524077892303467
train_iter_loss: 0.33507347106933594
train_iter_loss: 0.263527512550354
train_iter_loss: 0.27931469678878784
train_iter_loss: 0.22671151161193848
train_iter_loss: 0.3167925477027893
train_iter_loss: 0.3258536756038666
train_iter_loss: 0.20382079482078552
train_iter_loss: 0.22541674971580505
train_iter_loss: 0.26898646354675293
train_iter_loss: 0.2775993049144745
train_iter_loss: 0.21645036339759827
train_iter_loss: 0.21713992953300476
train_iter_loss: 0.2081218659877777
train_iter_loss: 0.3078862428665161
train_iter_loss: 0.24168424308300018
train_iter_loss: 0.3891605734825134
train_iter_loss: 0.3875746428966522
train_iter_loss: 0.3759848177433014
train_iter_loss: 0.3094036877155304
train_iter_loss: 0.2584502696990967
train_iter_loss: 0.2975318729877472
train_iter_loss: 0.28264570236206055
train_iter_loss: 0.2097271829843521
train_iter_loss: 0.3129788935184479
train_iter_loss: 0.26577049493789673
train_iter_loss: 0.2451886236667633
train_iter_loss: 0.2916083335876465
train_iter_loss: 0.3708723783493042
train_iter_loss: 0.3225756883621216
train_iter_loss: 0.22195380926132202
train_iter_loss: 0.30478519201278687
train_iter_loss: 0.24712525308132172
train_iter_loss: 0.3246862292289734
train_iter_loss: 0.20822878181934357
train_iter_loss: 0.25362929701805115
train_iter_loss: 0.2802196741104126
train_iter_loss: 0.20523834228515625
train_iter_loss: 0.2524065673351288
train_iter_loss: 0.22655367851257324
train_iter_loss: 0.24608568847179413
train_iter_loss: 0.2346021682024002
train_iter_loss: 0.215986967086792
train_iter_loss: 0.21668721735477448
train_iter_loss: 0.3068734407424927
train_iter_loss: 0.28073135018348694
train_iter_loss: 0.4038858413696289
train_iter_loss: 0.2675601840019226
train_iter_loss: 0.22514596581459045
train_iter_loss: 0.2555783689022064
train_iter_loss: 0.2749903202056885
train_iter_loss: 0.20534716546535492
train_iter_loss: 0.32831844687461853
train_iter_loss: 0.31040069460868835
train_iter_loss: 0.22219884395599365
train_iter_loss: 0.3708418011665344
train_iter_loss: 0.2666935920715332
train_iter_loss: 0.28015244007110596
train_iter_loss: 0.2559781074523926
train_iter_loss: 0.3192516267299652
train_iter_loss: 0.3207228183746338
train_iter_loss: 0.28914403915405273
train_iter_loss: 0.28290554881095886
train_iter_loss: 0.2323271632194519
train_iter_loss: 0.2692120373249054
train_iter_loss: 0.23772411048412323
train_iter_loss: 0.24172711372375488
train_iter_loss: 0.20152197778224945
train_iter_loss: 0.27382850646972656
train_iter_loss: 0.21747085452079773
train_iter_loss: 0.20741023123264313
train_iter_loss: 0.24384869635105133
train_iter_loss: 0.30896881222724915
train_iter_loss: 0.2961345911026001
train_iter_loss: 0.23725000023841858
train_iter_loss: 0.2711651027202606
train_iter_loss: 0.22765935957431793
train_iter_loss: 0.25771668553352356
train_iter_loss: 0.2020663321018219
train_iter_loss: 0.2366175353527069
train_iter_loss: 0.23862460255622864
train_iter_loss: 0.20111776888370514
train_iter_loss: 0.23589123785495758
train_iter_loss: 0.22792042791843414
train_iter_loss: 0.22426922619342804
train_iter_loss: 0.2644486427307129
train_iter_loss: 0.28351595997810364
train_iter_loss: 0.2502162456512451
train_iter_loss: 0.2377348244190216
train_iter_loss: 0.2631996273994446
train_iter_loss: 0.2996041476726532
train_iter_loss: 0.23076114058494568
train_iter_loss: 0.19345426559448242
train_iter_loss: 0.2391268014907837
train_iter_loss: 0.23564772307872772
train_iter_loss: 0.2481139898300171
train_iter_loss: 0.24686574935913086
train_iter_loss: 0.22819209098815918
train_iter_loss: 0.23914110660552979
train_iter_loss: 0.20849232375621796
train_iter_loss: 0.2989034950733185
train_iter_loss: 0.257577121257782
train_iter_loss: 0.31467750668525696
train_iter_loss: 0.21649298071861267
train_iter_loss: 0.22084064781665802
train_iter_loss: 0.3388877809047699
train_iter_loss: 0.222704216837883
train_iter_loss: 0.25911250710487366
train_iter_loss: 0.2455243319272995
train_iter_loss: 0.2345733493566513
train loss :0.2644
---------------------
Validation seg loss: 0.31019170160563486 at epoch 34
epoch =     35/  1000, exp = train
train_iter_loss: 0.24388240277767181
train_iter_loss: 0.22690895199775696
train_iter_loss: 0.23914378881454468
train_iter_loss: 0.3498613238334656
train_iter_loss: 0.25942564010620117
train_iter_loss: 0.2683733403682709
train_iter_loss: 0.3026333451271057
train_iter_loss: 0.19454187154769897
train_iter_loss: 0.23600585758686066
train_iter_loss: 0.3359682857990265
train_iter_loss: 0.2859034836292267
train_iter_loss: 0.20489783585071564
train_iter_loss: 0.22908669710159302
train_iter_loss: 0.2200382500886917
train_iter_loss: 0.2439965456724167
train_iter_loss: 0.2380228489637375
train_iter_loss: 0.30613964796066284
train_iter_loss: 0.29828017950057983
train_iter_loss: 0.24037908017635345
train_iter_loss: 0.2244442105293274
train_iter_loss: 0.37902361154556274
train_iter_loss: 0.24271035194396973
train_iter_loss: 0.25308218598365784
train_iter_loss: 0.19709736108779907
train_iter_loss: 0.27598634362220764
train_iter_loss: 0.25185319781303406
train_iter_loss: 0.24807099997997284
train_iter_loss: 0.2995123565196991
train_iter_loss: 0.2399042844772339
train_iter_loss: 0.23808354139328003
train_iter_loss: 0.22570548951625824
train_iter_loss: 0.22507987916469574
train_iter_loss: 0.26342350244522095
train_iter_loss: 0.3020845353603363
train_iter_loss: 0.33133241534233093
train_iter_loss: 0.23118454217910767
train_iter_loss: 0.27484413981437683
train_iter_loss: 0.23807112872600555
train_iter_loss: 0.2459183633327484
train_iter_loss: 0.3239954113960266
train_iter_loss: 0.3159193992614746
train_iter_loss: 0.32998812198638916
train_iter_loss: 0.27477917075157166
train_iter_loss: 0.22359155118465424
train_iter_loss: 0.27088579535484314
train_iter_loss: 0.2735837996006012
train_iter_loss: 0.2856820225715637
train_iter_loss: 0.3363722562789917
train_iter_loss: 0.2108430564403534
train_iter_loss: 0.2349105030298233
train_iter_loss: 0.22739894688129425
train_iter_loss: 0.2946532964706421
train_iter_loss: 0.27702564001083374
train_iter_loss: 0.2936464250087738
train_iter_loss: 0.2624654769897461
train_iter_loss: 0.23036687076091766
train_iter_loss: 0.2939489185810089
train_iter_loss: 0.2937681972980499
train_iter_loss: 0.3008715808391571
train_iter_loss: 0.2869006395339966
train_iter_loss: 0.29718250036239624
train_iter_loss: 0.29024362564086914
train_iter_loss: 0.296808123588562
train_iter_loss: 0.28561151027679443
train_iter_loss: 0.2292778044939041
train_iter_loss: 0.2741711139678955
train_iter_loss: 0.20338492095470428
train_iter_loss: 0.2739714980125427
train_iter_loss: 0.2619151175022125
train_iter_loss: 0.23248040676116943
train_iter_loss: 0.22022488713264465
train_iter_loss: 0.2509032189846039
train_iter_loss: 0.2538561522960663
train_iter_loss: 0.2554452419281006
train_iter_loss: 0.27595341205596924
train_iter_loss: 0.2447059154510498
train_iter_loss: 0.2416967898607254
train_iter_loss: 0.26650235056877136
train_iter_loss: 0.22740662097930908
train_iter_loss: 0.23325441777706146
train_iter_loss: 0.28097444772720337
train_iter_loss: 0.22463685274124146
train_iter_loss: 0.21946804225444794
train_iter_loss: 0.22265172004699707
train_iter_loss: 0.26056358218193054
train_iter_loss: 0.3656979203224182
train_iter_loss: 0.26586347818374634
train_iter_loss: 0.2952221930027008
train_iter_loss: 0.26933252811431885
train_iter_loss: 0.2207803726196289
train_iter_loss: 0.29551178216934204
train_iter_loss: 0.17853698134422302
train_iter_loss: 0.22812172770500183
train_iter_loss: 0.22376903891563416
train_iter_loss: 0.29642075300216675
train_iter_loss: 0.19634245336055756
train_iter_loss: 0.31280598044395447
train_iter_loss: 0.2555484473705292
train_iter_loss: 0.21294187009334564
train_iter_loss: 0.26194533705711365
train_iter_loss: 0.19690768420696259
train_iter_loss: 0.22039449214935303
train_iter_loss: 0.36612364649772644
train_iter_loss: 0.22895896434783936
train_iter_loss: 0.2094597965478897
train_iter_loss: 0.3000083565711975
train_iter_loss: 0.28588396310806274
train_iter_loss: 0.1870945245027542
train_iter_loss: 0.4126174747943878
train_iter_loss: 0.19315055012702942
train_iter_loss: 0.283829003572464
train_iter_loss: 0.33507198095321655
train_iter_loss: 0.26566949486732483
train_iter_loss: 0.2145242542028427
train_iter_loss: 0.26712319254875183
train_iter_loss: 0.2962089776992798
train_iter_loss: 0.2563154101371765
train_iter_loss: 0.24813205003738403
train_iter_loss: 0.291652649641037
train_iter_loss: 0.31830286979675293
train_iter_loss: 0.23255176842212677
train_iter_loss: 0.2035544216632843
train_iter_loss: 0.29347196221351624
train_iter_loss: 0.2508840560913086
train_iter_loss: 0.25834256410598755
train_iter_loss: 0.24532926082611084
train_iter_loss: 0.27510184049606323
train_iter_loss: 0.21867062151432037
train_iter_loss: 0.39009350538253784
train_iter_loss: 0.2713322043418884
train_iter_loss: 0.21946190297603607
train_iter_loss: 0.2865290641784668
train_iter_loss: 0.2939954102039337
train_iter_loss: 0.2586928606033325
train_iter_loss: 0.22417768836021423
train_iter_loss: 0.2374793291091919
train_iter_loss: 0.2146729975938797
train_iter_loss: 0.23772743344306946
train_iter_loss: 0.22014516592025757
train_iter_loss: 0.23651030659675598
train_iter_loss: 0.2864457964897156
train_iter_loss: 0.23215587437152863
train_iter_loss: 0.22008982300758362
train_iter_loss: 0.2632310092449188
train_iter_loss: 0.19672469794750214
train_iter_loss: 0.4709893465042114
train_iter_loss: 0.3475693464279175
train_iter_loss: 0.20338235795497894
train_iter_loss: 0.24080312252044678
train_iter_loss: 0.2765565812587738
train_iter_loss: 0.2296028435230255
train_iter_loss: 0.2470526099205017
train_iter_loss: 0.30784475803375244
train_iter_loss: 0.2817137837409973
train_iter_loss: 0.24345548450946808
train_iter_loss: 0.3200930655002594
train_iter_loss: 0.20493733882904053
train_iter_loss: 0.24009433388710022
train_iter_loss: 0.20332719385623932
train_iter_loss: 0.29286259412765503
train_iter_loss: 0.25117310881614685
train_iter_loss: 0.25163865089416504
train_iter_loss: 0.22617807984352112
train_iter_loss: 0.24754348397254944
train_iter_loss: 0.2498873919248581
train_iter_loss: 0.27720797061920166
train_iter_loss: 0.33942168951034546
train_iter_loss: 0.22189141809940338
train_iter_loss: 0.2099311351776123
train_iter_loss: 0.3137277662754059
train_iter_loss: 0.24569293856620789
train_iter_loss: 0.20299239456653595
train_iter_loss: 0.27041810750961304
train_iter_loss: 0.24331682920455933
train_iter_loss: 0.2191137671470642
train_iter_loss: 0.2347528338432312
train_iter_loss: 0.38130974769592285
train_iter_loss: 0.23505078256130219
train_iter_loss: 0.2580222487449646
train_iter_loss: 0.23463310301303864
train_iter_loss: 0.22392909228801727
train_iter_loss: 0.2080439031124115
train_iter_loss: 0.3167871832847595
train_iter_loss: 0.24494726955890656
train_iter_loss: 0.21801252663135529
train_iter_loss: 0.2800362706184387
train_iter_loss: 0.22000652551651
train_iter_loss: 0.27971702814102173
train_iter_loss: 0.5350711941719055
train_iter_loss: 0.21777896583080292
train_iter_loss: 0.28630971908569336
train_iter_loss: 0.2658554017543793
train_iter_loss: 0.27004119753837585
train_iter_loss: 0.25371676683425903
train_iter_loss: 0.25764337182044983
train_iter_loss: 0.282779723405838
train_iter_loss: 0.2601305842399597
train_iter_loss: 0.23711860179901123
train_iter_loss: 0.24760349094867706
train_iter_loss: 0.3370548188686371
train loss :0.2637
---------------------
Validation seg loss: 0.3149516860831459 at epoch 35
epoch =     36/  1000, exp = train
train_iter_loss: 0.2914572060108185
train_iter_loss: 0.20219025015830994
train_iter_loss: 0.2989387512207031
train_iter_loss: 0.29910725355148315
train_iter_loss: 0.254905104637146
train_iter_loss: 0.22949491441249847
train_iter_loss: 0.21257218718528748
train_iter_loss: 0.23870469629764557
train_iter_loss: 0.2121395617723465
train_iter_loss: 0.43058791756629944
train_iter_loss: 0.2926921844482422
train_iter_loss: 0.20961688458919525
train_iter_loss: 0.26949256658554077
train_iter_loss: 0.28331536054611206
train_iter_loss: 0.3103519380092621
train_iter_loss: 0.20416928827762604
train_iter_loss: 0.25291189551353455
train_iter_loss: 0.21242311596870422
train_iter_loss: 0.2228155881166458
train_iter_loss: 0.2795755863189697
train_iter_loss: 0.24430687725543976
train_iter_loss: 0.2693907916545868
train_iter_loss: 0.22625264525413513
train_iter_loss: 0.27294570207595825
train_iter_loss: 0.24332843720912933
train_iter_loss: 0.24605663120746613
train_iter_loss: 0.2413235455751419
train_iter_loss: 0.18884794414043427
train_iter_loss: 0.28454938530921936
train_iter_loss: 0.2746923267841339
train_iter_loss: 0.2380845993757248
train_iter_loss: 0.24515946209430695
train_iter_loss: 0.25293201208114624
train_iter_loss: 0.24984806776046753
train_iter_loss: 0.2006206065416336
train_iter_loss: 0.3061748743057251
train_iter_loss: 0.21836312115192413
train_iter_loss: 0.25771600008010864
train_iter_loss: 0.24693188071250916
train_iter_loss: 0.25656643509864807
train_iter_loss: 0.2347714602947235
train_iter_loss: 0.34406208992004395
train_iter_loss: 0.24209272861480713
train_iter_loss: 0.2670803964138031
train_iter_loss: 0.21579508483409882
train_iter_loss: 0.22734852135181427
train_iter_loss: 0.22620990872383118
train_iter_loss: 0.20821882784366608
train_iter_loss: 0.23242594301700592
train_iter_loss: 0.25672993063926697
train_iter_loss: 0.280695378780365
train_iter_loss: 0.29434409737586975
train_iter_loss: 0.30853748321533203
train_iter_loss: 0.37320706248283386
train_iter_loss: 0.2964281141757965
train_iter_loss: 0.3562673330307007
train_iter_loss: 0.25339698791503906
train_iter_loss: 0.3627297878265381
train_iter_loss: 0.3530138432979584
train_iter_loss: 0.3883780837059021
train_iter_loss: 0.2668190598487854
train_iter_loss: 0.2722042500972748
train_iter_loss: 0.30087026953697205
train_iter_loss: 0.22764085233211517
train_iter_loss: 0.20195841789245605
train_iter_loss: 0.248794287443161
train_iter_loss: 0.24528868496418
train_iter_loss: 0.3448870778083801
train_iter_loss: 0.29647108912467957
train_iter_loss: 0.37170636653900146
train_iter_loss: 0.3074125051498413
train_iter_loss: 0.2172553390264511
train_iter_loss: 0.22620101273059845
train_iter_loss: 0.26670628786087036
train_iter_loss: 0.22435510158538818
train_iter_loss: 0.3072018325328827
train_iter_loss: 0.26505547761917114
train_iter_loss: 0.28282976150512695
train_iter_loss: 0.18933117389678955
train_iter_loss: 0.24149829149246216
train_iter_loss: 0.2665656805038452
train_iter_loss: 0.1882305145263672
train_iter_loss: 0.26634764671325684
train_iter_loss: 0.2829781472682953
train_iter_loss: 0.22645729780197144
train_iter_loss: 0.3104552924633026
train_iter_loss: 0.24538834393024445
train_iter_loss: 0.22576501965522766
train_iter_loss: 0.334863543510437
train_iter_loss: 0.2533191740512848
train_iter_loss: 0.2564923167228699
train_iter_loss: 0.2439194917678833
train_iter_loss: 0.2462385892868042
train_iter_loss: 0.29058387875556946
train_iter_loss: 0.1956852674484253
train_iter_loss: 0.2435951828956604
train_iter_loss: 0.21451982855796814
train_iter_loss: 0.4107652008533478
train_iter_loss: 0.23981896042823792
train_iter_loss: 0.21052585542201996
train_iter_loss: 0.22974644601345062
train_iter_loss: 0.265158474445343
train_iter_loss: 0.1968655288219452
train_iter_loss: 0.2111998349428177
train_iter_loss: 0.3131905794143677
train_iter_loss: 0.18444982171058655
train_iter_loss: 0.24208517372608185
train_iter_loss: 0.24244479835033417
train_iter_loss: 0.22339169681072235
train_iter_loss: 0.27635157108306885
train_iter_loss: 0.2550622224807739
train_iter_loss: 0.21370163559913635
train_iter_loss: 0.21316364407539368
train_iter_loss: 0.22130537033081055
train_iter_loss: 0.4184919595718384
train_iter_loss: 0.3037305176258087
train_iter_loss: 0.2950381934642792
train_iter_loss: 0.20082274079322815
train_iter_loss: 0.1951398402452469
train_iter_loss: 0.2236512303352356
train_iter_loss: 0.25533780455589294
train_iter_loss: 0.25951024889945984
train_iter_loss: 0.23487675189971924
train_iter_loss: 0.24616529047489166
train_iter_loss: 0.23998451232910156
train_iter_loss: 0.21510013937950134
train_iter_loss: 0.38113462924957275
train_iter_loss: 0.3502134680747986
train_iter_loss: 0.2980693280696869
train_iter_loss: 0.22579669952392578
train_iter_loss: 0.2642858028411865
train_iter_loss: 0.2615191340446472
train_iter_loss: 0.2898724675178528
train_iter_loss: 0.2500452697277069
train_iter_loss: 0.23304259777069092
train_iter_loss: 0.2678426504135132
train_iter_loss: 0.224685937166214
train_iter_loss: 0.22389528155326843
train_iter_loss: 0.27734270691871643
train_iter_loss: 0.2865215241909027
train_iter_loss: 0.2471621185541153
train_iter_loss: 0.24331799149513245
train_iter_loss: 0.23575501143932343
train_iter_loss: 0.2622760832309723
train_iter_loss: 0.31258276104927063
train_iter_loss: 0.20400094985961914
train_iter_loss: 0.24466398358345032
train_iter_loss: 0.2263457179069519
train_iter_loss: 0.23794396221637726
train_iter_loss: 0.2566610276699066
train_iter_loss: 0.2234116494655609
train_iter_loss: 0.295823872089386
train_iter_loss: 0.38911065459251404
train_iter_loss: 0.24275723099708557
train_iter_loss: 0.2809690535068512
train_iter_loss: 0.20911642909049988
train_iter_loss: 0.23953795433044434
train_iter_loss: 0.24380916357040405
train_iter_loss: 0.21169117093086243
train_iter_loss: 0.23868796229362488
train_iter_loss: 0.24449297785758972
train_iter_loss: 0.2346164435148239
train_iter_loss: 0.2572893798351288
train_iter_loss: 0.28024205565452576
train_iter_loss: 0.21457096934318542
train_iter_loss: 0.30356672406196594
train_iter_loss: 0.33990809321403503
train_iter_loss: 0.20301374793052673
train_iter_loss: 0.29150712490081787
train_iter_loss: 0.22227279841899872
train_iter_loss: 0.2775804102420807
train_iter_loss: 0.2886592447757721
train_iter_loss: 0.20320743322372437
train_iter_loss: 0.2704407572746277
train_iter_loss: 0.2499997764825821
train_iter_loss: 0.2755453288555145
train_iter_loss: 0.31676211953163147
train_iter_loss: 0.2593265771865845
train_iter_loss: 0.21878814697265625
train_iter_loss: 0.22049060463905334
train_iter_loss: 0.23592141270637512
train_iter_loss: 0.25037550926208496
train_iter_loss: 0.234937384724617
train_iter_loss: 0.3036944568157196
train_iter_loss: 0.2536110579967499
train_iter_loss: 0.2845389246940613
train_iter_loss: 0.3706732988357544
train_iter_loss: 0.39749208092689514
train_iter_loss: 0.29281026124954224
train_iter_loss: 0.256219744682312
train_iter_loss: 0.284010112285614
train_iter_loss: 0.22413140535354614
train_iter_loss: 0.2825589179992676
train_iter_loss: 0.18935826420783997
train_iter_loss: 0.34386610984802246
train_iter_loss: 0.24679647386074066
train_iter_loss: 0.3841061294078827
train_iter_loss: 0.21529865264892578
train_iter_loss: 0.2473466992378235
train_iter_loss: 0.25293320417404175
train loss :0.2630
---------------------
Validation seg loss: 0.3059567118871887 at epoch 36
********************
best_val_epoch_loss:  0.3059567118871887
MODEL UPDATED
epoch =     37/  1000, exp = train
train_iter_loss: 0.28085294365882874
train_iter_loss: 0.2555016279220581
train_iter_loss: 0.24301528930664062
train_iter_loss: 0.24999989569187164
train_iter_loss: 0.2452450692653656
train_iter_loss: 0.2458048164844513
train_iter_loss: 0.2800764739513397
train_iter_loss: 0.28676310181617737
train_iter_loss: 0.24470676481723785
train_iter_loss: 0.19627311825752258
train_iter_loss: 0.23294398188591003
train_iter_loss: 0.249720498919487
train_iter_loss: 0.2729076147079468
train_iter_loss: 0.23194827139377594
train_iter_loss: 0.29133665561676025
train_iter_loss: 0.32319870591163635
train_iter_loss: 0.29909297823905945
train_iter_loss: 0.24344104528427124
train_iter_loss: 0.2356104701757431
train_iter_loss: 0.1912468671798706
train_iter_loss: 0.19228431582450867
train_iter_loss: 0.26490139961242676
train_iter_loss: 0.23609885573387146
train_iter_loss: 0.23301145434379578
train_iter_loss: 0.27841678261756897
train_iter_loss: 0.2171344757080078
train_iter_loss: 0.22955049574375153
train_iter_loss: 0.23537574708461761
train_iter_loss: 0.2154453992843628
train_iter_loss: 0.2350659817457199
train_iter_loss: 0.2707365155220032
train_iter_loss: 0.25101515650749207
train_iter_loss: 0.24415040016174316
train_iter_loss: 0.23129113018512726
train_iter_loss: 0.2598147988319397
train_iter_loss: 0.24425263702869415
train_iter_loss: 0.19729188084602356
train_iter_loss: 0.23651453852653503
train_iter_loss: 0.22518984973430634
train_iter_loss: 0.31573647260665894
train_iter_loss: 0.3883728086948395
train_iter_loss: 0.24946711957454681
train_iter_loss: 0.25346168875694275
train_iter_loss: 0.19641633331775665
train_iter_loss: 0.22200901806354523
train_iter_loss: 0.23751980066299438
train_iter_loss: 0.34038111567497253
train_iter_loss: 0.25019571185112
train_iter_loss: 0.3446141183376312
train_iter_loss: 0.21593058109283447
train_iter_loss: 0.31270331144332886
train_iter_loss: 0.19832473993301392
train_iter_loss: 0.2808234691619873
train_iter_loss: 0.2864254415035248
train_iter_loss: 0.23072853684425354
train_iter_loss: 0.23564603924751282
train_iter_loss: 0.20209091901779175
train_iter_loss: 0.30459022521972656
train_iter_loss: 0.20781318843364716
train_iter_loss: 0.2783390283584595
train_iter_loss: 0.2492106854915619
train_iter_loss: 0.25203216075897217
train_iter_loss: 0.2968246638774872
train_iter_loss: 0.3594057857990265
train_iter_loss: 0.24323908984661102
train_iter_loss: 0.2257896363735199
train_iter_loss: 0.2648424208164215
train_iter_loss: 0.3020471930503845
train_iter_loss: 0.3193941116333008
train_iter_loss: 0.25440117716789246
train_iter_loss: 0.20819242298603058
train_iter_loss: 0.3246377110481262
train_iter_loss: 0.29684701561927795
train_iter_loss: 0.21941351890563965
train_iter_loss: 0.29109182953834534
train_iter_loss: 0.21530303359031677
train_iter_loss: 0.18241862952709198
train_iter_loss: 0.1956879198551178
train_iter_loss: 0.22304745018482208
train_iter_loss: 0.17843684554100037
train_iter_loss: 0.3177342116832733
train_iter_loss: 0.2270667850971222
train_iter_loss: 0.17176996171474457
train_iter_loss: 0.22511884570121765
train_iter_loss: 0.32985299825668335
train_iter_loss: 0.22627250850200653
train_iter_loss: 0.22810958325862885
train_iter_loss: 0.2550634443759918
train_iter_loss: 0.18864308297634125
train_iter_loss: 0.2578316926956177
train_iter_loss: 0.23903228342533112
train_iter_loss: 0.22288945317268372
train_iter_loss: 0.24013620615005493
train_iter_loss: 0.23588325083255768
train_iter_loss: 0.1919320672750473
train_iter_loss: 0.2816644608974457
train_iter_loss: 0.21521210670471191
train_iter_loss: 0.20737715065479279
train_iter_loss: 0.35560402274131775
train_iter_loss: 0.2541680634021759
train_iter_loss: 0.2316569983959198
train_iter_loss: 0.2502901554107666
train_iter_loss: 0.27669093012809753
train_iter_loss: 0.24524955451488495
train_iter_loss: 0.21174952387809753
train_iter_loss: 0.298820436000824
train_iter_loss: 0.2147865742444992
train_iter_loss: 0.22947709262371063
train_iter_loss: 0.22514371573925018
train_iter_loss: 0.2694104015827179
train_iter_loss: 0.2126171737909317
train_iter_loss: 0.2484610676765442
train_iter_loss: 0.222395122051239
train_iter_loss: 0.2465231567621231
train_iter_loss: 0.2751578390598297
train_iter_loss: 0.22213777899742126
train_iter_loss: 0.2322874218225479
train_iter_loss: 0.31572362780570984
train_iter_loss: 0.3012567460536957
train_iter_loss: 0.31186872720718384
train_iter_loss: 0.23171155154705048
train_iter_loss: 0.21461576223373413
train_iter_loss: 0.24754835665225983
train_iter_loss: 0.24845248460769653
train_iter_loss: 0.25800400972366333
train_iter_loss: 0.32576557993888855
train_iter_loss: 0.23403167724609375
train_iter_loss: 0.30308955907821655
train_iter_loss: 0.4359714090824127
train_iter_loss: 0.2596498131752014
train_iter_loss: 0.33733466267585754
train_iter_loss: 0.2550986111164093
train_iter_loss: 0.22933253645896912
train_iter_loss: 0.2639246881008148
train_iter_loss: 0.23356816172599792
train_iter_loss: 0.25944817066192627
train_iter_loss: 0.31123220920562744
train_iter_loss: 0.21129237115383148
train_iter_loss: 0.2388445883989334
train_iter_loss: 0.22764337062835693
train_iter_loss: 0.27111637592315674
train_iter_loss: 0.23457904160022736
train_iter_loss: 0.1731085181236267
train_iter_loss: 0.3087890148162842
train_iter_loss: 0.23773068189620972
train_iter_loss: 0.2939302623271942
train_iter_loss: 0.27673977613449097
train_iter_loss: 0.22443678975105286
train_iter_loss: 0.3484260141849518
train_iter_loss: 0.31331881880760193
train_iter_loss: 0.20554271340370178
train_iter_loss: 0.2237394005060196
train_iter_loss: 0.2582153379917145
train_iter_loss: 0.3808614909648895
train_iter_loss: 0.32975026965141296
train_iter_loss: 0.33251017332077026
train_iter_loss: 0.26883429288864136
train_iter_loss: 0.2488330751657486
train_iter_loss: 0.31181034445762634
train_iter_loss: 0.28684067726135254
train_iter_loss: 0.29294055700302124
train_iter_loss: 0.27940094470977783
train_iter_loss: 0.27813827991485596
train_iter_loss: 0.20751376450061798
train_iter_loss: 0.22610005736351013
train_iter_loss: 0.27904266119003296
train_iter_loss: 0.24638761579990387
train_iter_loss: 0.30182939767837524
train_iter_loss: 0.342243492603302
train_iter_loss: 0.35799893736839294
train_iter_loss: 0.24078111350536346
train_iter_loss: 0.20917296409606934
train_iter_loss: 0.26436129212379456
train_iter_loss: 0.25731638073921204
train_iter_loss: 0.21549764275550842
train_iter_loss: 0.22737781703472137
train_iter_loss: 0.34443771839141846
train_iter_loss: 0.2915111780166626
train_iter_loss: 0.20824937522411346
train_iter_loss: 0.36185407638549805
train_iter_loss: 0.33611804246902466
train_iter_loss: 0.3423524796962738
train_iter_loss: 0.4175318479537964
train_iter_loss: 0.2698291540145874
train_iter_loss: 0.2703040540218353
train_iter_loss: 0.2500480115413666
train_iter_loss: 0.21814413368701935
train_iter_loss: 0.2832029163837433
train_iter_loss: 0.24354702234268188
train_iter_loss: 0.2929700016975403
train_iter_loss: 0.20856407284736633
train_iter_loss: 0.21398624777793884
train_iter_loss: 0.32202836871147156
train_iter_loss: 0.364763468503952
train_iter_loss: 0.22909043729305267
train_iter_loss: 0.22906439006328583
train_iter_loss: 0.20800107717514038
train_iter_loss: 0.21689774096012115
train_iter_loss: 0.27331021428108215
train_iter_loss: 0.22284576296806335
train loss :0.2606
---------------------
Validation seg loss: 0.3057019848306224 at epoch 37
********************
best_val_epoch_loss:  0.3057019848306224
MODEL UPDATED
epoch =     38/  1000, exp = train
train_iter_loss: 0.31155022978782654
train_iter_loss: 0.4300013780593872
train_iter_loss: 0.23504382371902466
train_iter_loss: 0.2143961787223816
train_iter_loss: 0.21737894415855408
train_iter_loss: 0.25021645426750183
train_iter_loss: 0.33278965950012207
train_iter_loss: 0.24671489000320435
train_iter_loss: 0.20827406644821167
train_iter_loss: 0.22997301816940308
train_iter_loss: 0.3413531184196472
train_iter_loss: 0.23722612857818604
train_iter_loss: 0.23125401139259338
train_iter_loss: 0.2528923451900482
train_iter_loss: 0.27133363485336304
train_iter_loss: 0.22524689137935638
train_iter_loss: 0.248008131980896
train_iter_loss: 0.23927929997444153
train_iter_loss: 0.20894135534763336
train_iter_loss: 0.2611323893070221
train_iter_loss: 0.23610492050647736
train_iter_loss: 0.24823689460754395
train_iter_loss: 0.29268795251846313
train_iter_loss: 0.23549523949623108
train_iter_loss: 0.2836582660675049
train_iter_loss: 0.2812592387199402
train_iter_loss: 0.22177322208881378
train_iter_loss: 0.2583090364933014
train_iter_loss: 0.232259601354599
train_iter_loss: 0.283814936876297
train_iter_loss: 0.22196781635284424
train_iter_loss: 0.21565678715705872
train_iter_loss: 0.20776982605457306
train_iter_loss: 0.24401280283927917
train_iter_loss: 0.21878200769424438
train_iter_loss: 0.3395580053329468
train_iter_loss: 0.2915123701095581
train_iter_loss: 0.2224675714969635
train_iter_loss: 0.1942264586687088
train_iter_loss: 0.21901345252990723
train_iter_loss: 0.3248252868652344
train_iter_loss: 0.2523484528064728
train_iter_loss: 0.3123115599155426
train_iter_loss: 0.19573214650154114
train_iter_loss: 0.20074324309825897
train_iter_loss: 0.2691496014595032
train_iter_loss: 0.236167773604393
train_iter_loss: 0.23477911949157715
train_iter_loss: 0.27312612533569336
train_iter_loss: 0.29983726143836975
train_iter_loss: 0.17633549869060516
train_iter_loss: 0.37546566128730774
train_iter_loss: 0.23575910925865173
train_iter_loss: 0.2811453342437744
train_iter_loss: 0.37364819645881653
train_iter_loss: 0.26884734630584717
train_iter_loss: 0.3084322512149811
train_iter_loss: 0.2577367126941681
train_iter_loss: 0.20701974630355835
train_iter_loss: 0.23673491179943085
train_iter_loss: 0.2707267999649048
train_iter_loss: 0.20755094289779663
train_iter_loss: 0.3179916739463806
train_iter_loss: 0.2617672383785248
train_iter_loss: 0.32521727681159973
train_iter_loss: 0.2787640392780304
train_iter_loss: 0.2282530516386032
train_iter_loss: 0.3097086548805237
train_iter_loss: 0.24179302155971527
train_iter_loss: 0.23153455555438995
train_iter_loss: 0.3213801085948944
train_iter_loss: 0.24162833392620087
train_iter_loss: 0.35763412714004517
train_iter_loss: 0.39181020855903625
train_iter_loss: 0.2777431011199951
train_iter_loss: 0.3147571384906769
train_iter_loss: 0.22100886702537537
train_iter_loss: 0.24808333814144135
train_iter_loss: 0.3403528332710266
train_iter_loss: 0.23194079101085663
train_iter_loss: 0.22364476323127747
train_iter_loss: 0.26807335019111633
train_iter_loss: 0.24091367423534393
train_iter_loss: 0.26593640446662903
train_iter_loss: 0.20359618961811066
train_iter_loss: 0.22260701656341553
train_iter_loss: 0.2947317659854889
train_iter_loss: 0.34757646918296814
train_iter_loss: 0.22500351071357727
train_iter_loss: 0.25711512565612793
train_iter_loss: 0.26054081320762634
train_iter_loss: 0.22541259229183197
train_iter_loss: 0.24131378531455994
train_iter_loss: 0.21608462929725647
train_iter_loss: 0.2553741931915283
train_iter_loss: 0.20019502937793732
train_iter_loss: 0.2526504099369049
train_iter_loss: 0.28403767943382263
train_iter_loss: 0.3130056858062744
train_iter_loss: 0.22069796919822693
train_iter_loss: 0.28743019700050354
train_iter_loss: 0.30034691095352173
train_iter_loss: 0.25714176893234253
train_iter_loss: 0.33949461579322815
train_iter_loss: 0.28065791726112366
train_iter_loss: 0.24288244545459747
train_iter_loss: 0.23532994091510773
train_iter_loss: 0.2654973566532135
train_iter_loss: 0.2233474999666214
train_iter_loss: 0.30087369680404663
train_iter_loss: 0.22877855598926544
train_iter_loss: 0.20691797137260437
train_iter_loss: 0.2164289802312851
train_iter_loss: 0.40376970171928406
train_iter_loss: 0.2808079123497009
train_iter_loss: 0.23393018543720245
train_iter_loss: 0.31506791710853577
train_iter_loss: 0.24780285358428955
train_iter_loss: 0.2721208930015564
train_iter_loss: 0.33193591237068176
train_iter_loss: 0.31259962916374207
train_iter_loss: 0.21220345795154572
train_iter_loss: 0.21674910187721252
train_iter_loss: 0.25358065962791443
train_iter_loss: 0.21816878020763397
train_iter_loss: 0.2595587968826294
train_iter_loss: 0.20262932777404785
train_iter_loss: 0.250150203704834
train_iter_loss: 0.3328615725040436
train_iter_loss: 0.2063460499048233
train_iter_loss: 0.26272115111351013
train_iter_loss: 0.22538325190544128
train_iter_loss: 0.2050083875656128
train_iter_loss: 0.23722653090953827
train_iter_loss: 0.2602120339870453
train_iter_loss: 0.18864096701145172
train_iter_loss: 0.3160623013973236
train_iter_loss: 0.30437135696411133
train_iter_loss: 0.25666341185569763
train_iter_loss: 0.3965122103691101
train_iter_loss: 0.23516643047332764
train_iter_loss: 0.327196329832077
train_iter_loss: 0.24479572474956512
train_iter_loss: 0.30426836013793945
train_iter_loss: 0.25885021686553955
train_iter_loss: 0.27166563272476196
train_iter_loss: 0.24543236196041107
train_iter_loss: 0.2635866105556488
train_iter_loss: 0.25766482949256897
train_iter_loss: 0.274244487285614
train_iter_loss: 0.27026432752609253
train_iter_loss: 0.2840259075164795
train_iter_loss: 0.25681960582733154
train_iter_loss: 0.2227334976196289
train_iter_loss: 0.39254263043403625
train_iter_loss: 0.2336820363998413
train_iter_loss: 0.433723509311676
train_iter_loss: 0.26479870080947876
train_iter_loss: 0.3194310665130615
train_iter_loss: 0.23765037953853607
train_iter_loss: 0.23515081405639648
train_iter_loss: 0.23881740868091583
train_iter_loss: 0.21243426203727722
train_iter_loss: 0.4189111888408661
train_iter_loss: 0.19402211904525757
train_iter_loss: 0.21024973690509796
train_iter_loss: 0.30339205265045166
train_iter_loss: 0.3236936032772064
train_iter_loss: 0.24978342652320862
train_iter_loss: 0.2327970415353775
train_iter_loss: 0.24873118102550507
train_iter_loss: 0.24365463852882385
train_iter_loss: 0.17609749734401703
train_iter_loss: 0.24738985300064087
train_iter_loss: 0.25527316331863403
train_iter_loss: 0.23298396170139313
train_iter_loss: 0.23048250377178192
train_iter_loss: 0.18151968717575073
train_iter_loss: 0.1709066480398178
train_iter_loss: 0.20290696620941162
train_iter_loss: 0.23888808488845825
train_iter_loss: 0.2685318887233734
train_iter_loss: 0.22899039089679718
train_iter_loss: 0.3513863980770111
train_iter_loss: 0.228705495595932
train_iter_loss: 0.29644107818603516
train_iter_loss: 0.22711151838302612
train_iter_loss: 0.34078890085220337
train_iter_loss: 0.22236548364162445
train_iter_loss: 0.20227332413196564
train_iter_loss: 0.18723636865615845
train_iter_loss: 0.2066608965396881
train_iter_loss: 0.22098837792873383
train_iter_loss: 0.24476087093353271
train_iter_loss: 0.23211796581745148
train_iter_loss: 0.21339663863182068
train_iter_loss: 0.2447395920753479
train_iter_loss: 0.2700899839401245
train_iter_loss: 0.18428969383239746
train_iter_loss: 0.2500988245010376
train loss :0.2611
---------------------
Validation seg loss: 0.30746021740279106 at epoch 38
epoch =     39/  1000, exp = train
train_iter_loss: 0.2797844409942627
train_iter_loss: 0.26600584387779236
train_iter_loss: 0.22424650192260742
train_iter_loss: 0.2201015055179596
train_iter_loss: 0.2268209457397461
train_iter_loss: 0.28183409571647644
train_iter_loss: 0.24065665900707245
train_iter_loss: 0.41511690616607666
train_iter_loss: 0.27319297194480896
train_iter_loss: 0.20019873976707458
train_iter_loss: 0.2747754752635956
train_iter_loss: 0.44580692052841187
train_iter_loss: 0.22274233400821686
train_iter_loss: 0.24592117965221405
train_iter_loss: 0.22050003707408905
train_iter_loss: 0.26959317922592163
train_iter_loss: 0.22620531916618347
train_iter_loss: 0.2514011561870575
train_iter_loss: 0.2309008538722992
train_iter_loss: 0.25796929001808167
train_iter_loss: 0.22174814343452454
train_iter_loss: 0.21297407150268555
train_iter_loss: 0.19511565566062927
train_iter_loss: 0.23381994664669037
train_iter_loss: 0.1943587213754654
train_iter_loss: 0.2546811103820801
train_iter_loss: 0.20680612325668335
train_iter_loss: 0.2419433742761612
train_iter_loss: 0.25586146116256714
train_iter_loss: 0.22556942701339722
train_iter_loss: 0.2629662752151489
train_iter_loss: 0.26259294152259827
train_iter_loss: 0.2427913397550583
train_iter_loss: 0.22447246313095093
train_iter_loss: 0.2270621806383133
train_iter_loss: 0.26545214653015137
train_iter_loss: 0.20525778830051422
train_iter_loss: 0.1980799436569214
train_iter_loss: 0.33691921830177307
train_iter_loss: 0.23738214373588562
train_iter_loss: 0.23017051815986633
train_iter_loss: 0.2337021827697754
train_iter_loss: 0.2131783813238144
train_iter_loss: 0.28668537735939026
train_iter_loss: 0.2443375289440155
train_iter_loss: 0.2609808146953583
train_iter_loss: 0.22338499128818512
train_iter_loss: 0.20353825390338898
train_iter_loss: 0.24572674930095673
train_iter_loss: 0.2251448631286621
train_iter_loss: 0.19865471124649048
train_iter_loss: 0.31845399737358093
train_iter_loss: 0.1869780421257019
train_iter_loss: 0.24769499897956848
train_iter_loss: 0.283758282661438
train_iter_loss: 0.31930917501449585
train_iter_loss: 0.2416166067123413
train_iter_loss: 0.22348260879516602
train_iter_loss: 0.2650189697742462
train_iter_loss: 0.2552374601364136
train_iter_loss: 0.24268083274364471
train_iter_loss: 0.23972885310649872
train_iter_loss: 0.2753351926803589
train_iter_loss: 0.2711164951324463
train_iter_loss: 0.3582141697406769
train_iter_loss: 0.22670118510723114
train_iter_loss: 0.2021743357181549
train_iter_loss: 0.2872512936592102
train_iter_loss: 0.2381928414106369
train_iter_loss: 0.37572577595710754
train_iter_loss: 0.26024919748306274
train_iter_loss: 0.21995556354522705
train_iter_loss: 0.2463097721338272
train_iter_loss: 0.23127833008766174
train_iter_loss: 0.34179940819740295
train_iter_loss: 0.26975685358047485
train_iter_loss: 0.2063787579536438
train_iter_loss: 0.42726612091064453
train_iter_loss: 0.38736531138420105
train_iter_loss: 0.2518492639064789
train_iter_loss: 0.27076923847198486
train_iter_loss: 0.224450945854187
train_iter_loss: 0.3361891210079193
train_iter_loss: 0.25071612000465393
train_iter_loss: 0.20681005716323853
train_iter_loss: 0.18606533110141754
train_iter_loss: 0.39117860794067383
train_iter_loss: 0.2422725260257721
train_iter_loss: 0.2530408203601837
train_iter_loss: 0.2215956598520279
train_iter_loss: 0.23024515807628632
train_iter_loss: 0.2108204960823059
train_iter_loss: 0.28588610887527466
train_iter_loss: 0.2181369960308075
train_iter_loss: 0.23443783819675446
train_iter_loss: 0.2748965919017792
train_iter_loss: 0.1929563581943512
train_iter_loss: 0.278439998626709
train_iter_loss: 0.2557956576347351
train_iter_loss: 0.21979856491088867
train_iter_loss: 0.2304941713809967
train_iter_loss: 0.23332665860652924
train_iter_loss: 0.28488248586654663
train_iter_loss: 0.23978786170482635
train_iter_loss: 0.3011103570461273
train_iter_loss: 0.25207436084747314
train_iter_loss: 0.22057652473449707
train_iter_loss: 0.47480493783950806
train_iter_loss: 0.22480995953083038
train_iter_loss: 0.27904319763183594
train_iter_loss: 0.2036260962486267
train_iter_loss: 0.2204706072807312
train_iter_loss: 0.2442227154970169
train_iter_loss: 0.28591927886009216
train_iter_loss: 0.21291615068912506
train_iter_loss: 0.3174911141395569
train_iter_loss: 0.36724117398262024
train_iter_loss: 0.2323743999004364
train_iter_loss: 0.21365642547607422
train_iter_loss: 0.2810837924480438
train_iter_loss: 0.21715512871742249
train_iter_loss: 0.18444450199604034
train_iter_loss: 0.2720482349395752
train_iter_loss: 0.3044167757034302
train_iter_loss: 0.2922040522098541
train_iter_loss: 0.4179096817970276
train_iter_loss: 0.28984683752059937
train_iter_loss: 0.247230663895607
train_iter_loss: 0.2702767252922058
train_iter_loss: 0.3105652332305908
train_iter_loss: 0.20353396236896515
train_iter_loss: 0.22018758952617645
train_iter_loss: 0.22905181348323822
train_iter_loss: 0.2659177780151367
train_iter_loss: 0.29324236512184143
train_iter_loss: 0.25118911266326904
train_iter_loss: 0.2226090431213379
train_iter_loss: 0.2138776332139969
train_iter_loss: 0.24385106563568115
train_iter_loss: 0.23839709162712097
train_iter_loss: 0.26913321018218994
train_iter_loss: 0.31560829281806946
train_iter_loss: 0.24029317498207092
train_iter_loss: 0.1817454695701599
train_iter_loss: 0.2486705780029297
train_iter_loss: 0.4251273274421692
train_iter_loss: 0.25925683975219727
train_iter_loss: 0.20112785696983337
train_iter_loss: 0.23817051947116852
train_iter_loss: 0.27796271443367004
train_iter_loss: 0.21801301836967468
train_iter_loss: 0.3043738007545471
train_iter_loss: 0.21957330405712128
train_iter_loss: 0.3447721004486084
train_iter_loss: 0.22228209674358368
train_iter_loss: 0.24091732501983643
train_iter_loss: 0.30672553181648254
train_iter_loss: 0.4012877941131592
train_iter_loss: 0.1944272220134735
train_iter_loss: 0.41886672377586365
train_iter_loss: 0.20207403600215912
train_iter_loss: 0.19343110918998718
train_iter_loss: 0.26316431164741516
train_iter_loss: 0.262276828289032
train_iter_loss: 0.2011401504278183
train_iter_loss: 0.20327924191951752
train_iter_loss: 0.26522308588027954
train_iter_loss: 0.2754678726196289
train_iter_loss: 0.20719964802265167
train_iter_loss: 0.2795218229293823
train_iter_loss: 0.24058210849761963
train_iter_loss: 0.27473127841949463
train_iter_loss: 0.24553875625133514
train_iter_loss: 0.2185046672821045
train_iter_loss: 0.253676176071167
train_iter_loss: 0.20317961275577545
train_iter_loss: 0.2151786983013153
train_iter_loss: 0.3917567729949951
train_iter_loss: 0.2422000914812088
train_iter_loss: 0.46357056498527527
train_iter_loss: 0.2732504606246948
train_iter_loss: 0.22140122950077057
train_iter_loss: 0.2509586811065674
train_iter_loss: 0.3600168526172638
train_iter_loss: 0.2473902851343155
train_iter_loss: 0.262539267539978
train_iter_loss: 0.25917214155197144
train_iter_loss: 0.26035788655281067
train_iter_loss: 0.21557778120040894
train_iter_loss: 0.3254821300506592
train_iter_loss: 0.2502546012401581
train_iter_loss: 0.24058720469474792
train_iter_loss: 0.26415371894836426
train_iter_loss: 0.24071256816387177
train_iter_loss: 0.1887214630842209
train_iter_loss: 0.24107162654399872
train_iter_loss: 0.1903783082962036
train_iter_loss: 0.27435946464538574
train_iter_loss: 0.2333996593952179
train_iter_loss: 0.24589446187019348
train loss :0.2594
---------------------
Validation seg loss: 0.3064267193933703 at epoch 39
epoch =     40/  1000, exp = train
train_iter_loss: 0.20872756838798523
train_iter_loss: 0.22008362412452698
train_iter_loss: 0.20792025327682495
train_iter_loss: 0.20201583206653595
train_iter_loss: 0.23790813982486725
train_iter_loss: 0.2436605989933014
train_iter_loss: 0.2865402400493622
train_iter_loss: 0.2605400085449219
train_iter_loss: 0.26281487941741943
train_iter_loss: 0.2412661761045456
train_iter_loss: 0.3003232181072235
train_iter_loss: 0.24350087344646454
train_iter_loss: 0.26176634430885315
train_iter_loss: 0.24068430066108704
train_iter_loss: 0.21237894892692566
train_iter_loss: 0.28527966141700745
train_iter_loss: 0.2694791853427887
train_iter_loss: 0.25172239542007446
train_iter_loss: 0.3199072480201721
train_iter_loss: 0.3106083571910858
train_iter_loss: 0.228352889418602
train_iter_loss: 0.329757958650589
train_iter_loss: 0.41858506202697754
train_iter_loss: 0.19393053650856018
train_iter_loss: 0.26094257831573486
train_iter_loss: 0.21171835064888
train_iter_loss: 0.28993722796440125
train_iter_loss: 0.3027432858943939
train_iter_loss: 0.30527210235595703
train_iter_loss: 0.1982232928276062
train_iter_loss: 0.26936161518096924
train_iter_loss: 0.21354177594184875
train_iter_loss: 0.2851080894470215
train_iter_loss: 0.2922269105911255
train_iter_loss: 0.35994359850883484
train_iter_loss: 0.209028422832489
train_iter_loss: 0.232895165681839
train_iter_loss: 0.2695845663547516
train_iter_loss: 0.21761904656887054
train_iter_loss: 0.2284436970949173
train_iter_loss: 0.2499794065952301
train_iter_loss: 0.17888513207435608
train_iter_loss: 0.2315986156463623
train_iter_loss: 0.1968194991350174
train_iter_loss: 0.2874351143836975
train_iter_loss: 0.29897791147232056
train_iter_loss: 0.24707436561584473
train_iter_loss: 0.27590855956077576
train_iter_loss: 0.23087237775325775
train_iter_loss: 0.29985329508781433
train_iter_loss: 0.2525126039981842
train_iter_loss: 0.26492413878440857
train_iter_loss: 0.3596763610839844
train_iter_loss: 0.24953670799732208
train_iter_loss: 0.24920138716697693
train_iter_loss: 0.303543359041214
train_iter_loss: 0.23156143724918365
train_iter_loss: 0.2921850085258484
train_iter_loss: 0.2519834041595459
train_iter_loss: 0.288312166929245
train_iter_loss: 0.31424087285995483
train_iter_loss: 0.2020580917596817
train_iter_loss: 0.2337782382965088
train_iter_loss: 0.2190808802843094
train_iter_loss: 0.2686101198196411
train_iter_loss: 0.23514337837696075
train_iter_loss: 0.24205410480499268
train_iter_loss: 0.2690626084804535
train_iter_loss: 0.2713882625102997
train_iter_loss: 0.2882992625236511
train_iter_loss: 0.18476440012454987
train_iter_loss: 0.2268083542585373
train_iter_loss: 0.24473387002944946
train_iter_loss: 0.3122340738773346
train_iter_loss: 0.208716481924057
train_iter_loss: 0.21190127730369568
train_iter_loss: 0.19879798591136932
train_iter_loss: 0.2303057163953781
train_iter_loss: 0.304501473903656
train_iter_loss: 0.22915074229240417
train_iter_loss: 0.21695728600025177
train_iter_loss: 0.2592557668685913
train_iter_loss: 0.2399386614561081
train_iter_loss: 0.17229130864143372
train_iter_loss: 0.2168615758419037
train_iter_loss: 0.2283005714416504
train_iter_loss: 0.3705444931983948
train_iter_loss: 0.21640393137931824
train_iter_loss: 0.27701765298843384
train_iter_loss: 0.2364037185907364
train_iter_loss: 0.19117094576358795
train_iter_loss: 0.23933513462543488
train_iter_loss: 0.26020997762680054
train_iter_loss: 0.2181648164987564
train_iter_loss: 0.34363609552383423
train_iter_loss: 0.36900466680526733
train_iter_loss: 0.2250286191701889
train_iter_loss: 0.2289147675037384
train_iter_loss: 0.2904883623123169
train_iter_loss: 0.43238160014152527
train_iter_loss: 0.27616146206855774
train_iter_loss: 0.21891911327838898
train_iter_loss: 0.21297687292099
train_iter_loss: 0.23064342141151428
train_iter_loss: 0.2948727309703827
train_iter_loss: 0.2787460386753082
train_iter_loss: 0.2248178869485855
train_iter_loss: 0.235791876912117
train_iter_loss: 0.2315007895231247
train_iter_loss: 0.3683910071849823
train_iter_loss: 0.27951282262802124
train_iter_loss: 0.2808934450149536
train_iter_loss: 0.2857871651649475
train_iter_loss: 0.18808060884475708
train_iter_loss: 0.2241905927658081
train_iter_loss: 0.3213352859020233
train_iter_loss: 0.332279235124588
train_iter_loss: 0.2269764095544815
train_iter_loss: 0.20743206143379211
train_iter_loss: 0.26496395468711853
train_iter_loss: 0.30910325050354004
train_iter_loss: 0.2415568083524704
train_iter_loss: 0.31366610527038574
train_iter_loss: 0.2725166082382202
train_iter_loss: 0.21550416946411133
train_iter_loss: 0.22679097950458527
train_iter_loss: 0.2475832849740982
train_iter_loss: 0.20165148377418518
train_iter_loss: 0.20804889500141144
train_iter_loss: 0.22700552642345428
train_iter_loss: 0.2149726152420044
train_iter_loss: 0.2093065083026886
train_iter_loss: 0.2745339274406433
train_iter_loss: 0.31511491537094116
train_iter_loss: 0.18162694573402405
train_iter_loss: 0.22756491601467133
train_iter_loss: 0.2638995051383972
train_iter_loss: 0.21637669205665588
train_iter_loss: 0.26238688826560974
train_iter_loss: 0.28490009903907776
train_iter_loss: 0.3262186348438263
train_iter_loss: 0.21270500123500824
train_iter_loss: 0.46088120341300964
train_iter_loss: 0.21150663495063782
train_iter_loss: 0.2679058909416199
train_iter_loss: 0.21330897510051727
train_iter_loss: 0.3187173306941986
train_iter_loss: 0.22258293628692627
train_iter_loss: 0.21626481413841248
train_iter_loss: 0.1925686001777649
train_iter_loss: 0.2564670741558075
train_iter_loss: 0.17865756154060364
train_iter_loss: 0.26368477940559387
train_iter_loss: 0.2586513161659241
train_iter_loss: 0.3008041977882385
train_iter_loss: 0.21628214418888092
train_iter_loss: 0.25831204652786255
train_iter_loss: 0.2538350522518158
train_iter_loss: 0.23743118345737457
train_iter_loss: 0.22764837741851807
train_iter_loss: 0.2360323816537857
train_iter_loss: 0.25769343972206116
train_iter_loss: 0.21755178272724152
train_iter_loss: 0.24797223508358002
train_iter_loss: 0.27495628595352173
train_iter_loss: 0.2655046582221985
train_iter_loss: 0.252351850271225
train_iter_loss: 0.2259248048067093
train_iter_loss: 0.22890377044677734
train_iter_loss: 0.22902484238147736
train_iter_loss: 0.20871593058109283
train_iter_loss: 0.3121369779109955
train_iter_loss: 0.22769761085510254
train_iter_loss: 0.2796083390712738
train_iter_loss: 0.3014233410358429
train_iter_loss: 0.17157383263111115
train_iter_loss: 0.24202075600624084
train_iter_loss: 0.2176208198070526
train_iter_loss: 0.20453216135501862
train_iter_loss: 0.2371198534965515
train_iter_loss: 0.35927507281303406
train_iter_loss: 0.39623934030532837
train_iter_loss: 0.2851274013519287
train_iter_loss: 0.27223554253578186
train_iter_loss: 0.30874529480934143
train_iter_loss: 0.24111223220825195
train_iter_loss: 0.30455252528190613
train_iter_loss: 0.2808820307254791
train_iter_loss: 0.23701350390911102
train_iter_loss: 0.40934762358665466
train_iter_loss: 0.2768154740333557
train_iter_loss: 0.249210387468338
train_iter_loss: 0.22651858627796173
train_iter_loss: 0.24454830586910248
train_iter_loss: 0.23035958409309387
train_iter_loss: 0.20289431512355804
train_iter_loss: 0.2161847949028015
train_iter_loss: 0.23159033060073853
train_iter_loss: 0.32393431663513184
train_iter_loss: 0.22441445291042328
train loss :0.2578
---------------------
Validation seg loss: 0.301386334002018 at epoch 40
********************
best_val_epoch_loss:  0.301386334002018
MODEL UPDATED
epoch =     41/  1000, exp = train
train_iter_loss: 0.3080614507198334
train_iter_loss: 0.2198069840669632
train_iter_loss: 0.2958960235118866
train_iter_loss: 0.2525995671749115
train_iter_loss: 0.2700888216495514
train_iter_loss: 0.2435275912284851
train_iter_loss: 0.2929002642631531
train_iter_loss: 0.21141678094863892
train_iter_loss: 0.27389127016067505
train_iter_loss: 0.30024394392967224
train_iter_loss: 0.2517848312854767
train_iter_loss: 0.18759207427501678
train_iter_loss: 0.19509880244731903
train_iter_loss: 0.20294973254203796
train_iter_loss: 0.26504039764404297
train_iter_loss: 0.22451800107955933
train_iter_loss: 0.21099647879600525
train_iter_loss: 0.4132634997367859
train_iter_loss: 0.2814115881919861
train_iter_loss: 0.23072804510593414
train_iter_loss: 0.2603006064891815
train_iter_loss: 0.30369502305984497
train_iter_loss: 0.17605586349964142
train_iter_loss: 0.2736571133136749
train_iter_loss: 0.23223084211349487
train_iter_loss: 0.43275681138038635
train_iter_loss: 0.22368602454662323
train_iter_loss: 0.3149772882461548
train_iter_loss: 0.20260494947433472
train_iter_loss: 0.21793237328529358
train_iter_loss: 0.2029150128364563
train_iter_loss: 0.20435409247875214
train_iter_loss: 0.29028791189193726
train_iter_loss: 0.2583889961242676
train_iter_loss: 0.3444349467754364
train_iter_loss: 0.31908172369003296
train_iter_loss: 0.31035953760147095
train_iter_loss: 0.193609356880188
train_iter_loss: 0.26205870509147644
train_iter_loss: 0.23774611949920654
train_iter_loss: 0.21697406470775604
train_iter_loss: 0.24483485519886017
train_iter_loss: 0.37753525376319885
train_iter_loss: 0.2215307056903839
train_iter_loss: 0.4156768023967743
train_iter_loss: 0.274747759103775
train_iter_loss: 0.27538591623306274
train_iter_loss: 0.2524029314517975
train_iter_loss: 0.20606379210948944
train_iter_loss: 0.20322592556476593
train_iter_loss: 0.19968481361865997
train_iter_loss: 0.24202239513397217
train_iter_loss: 0.23531854152679443
train_iter_loss: 0.2621120810508728
train_iter_loss: 0.23765793442726135
train_iter_loss: 0.27175405621528625
train_iter_loss: 0.24761375784873962
train_iter_loss: 0.26394811272621155
train_iter_loss: 0.2384636253118515
train_iter_loss: 0.3377535343170166
train_iter_loss: 0.2625730335712433
train_iter_loss: 0.26245734095573425
train_iter_loss: 0.1860327273607254
train_iter_loss: 0.23253226280212402
train_iter_loss: 0.2289719134569168
train_iter_loss: 0.24971379339694977
train_iter_loss: 0.25346437096595764
train_iter_loss: 0.30754485726356506
train_iter_loss: 0.2139224410057068
train_iter_loss: 0.22400806844234467
train_iter_loss: 0.2031199038028717
train_iter_loss: 0.2131951004266739
train_iter_loss: 0.2132972776889801
train_iter_loss: 0.39443233609199524
train_iter_loss: 0.29920634627342224
train_iter_loss: 0.19934172928333282
train_iter_loss: 0.2738030254840851
train_iter_loss: 0.22629930078983307
train_iter_loss: 0.2380514144897461
train_iter_loss: 0.19827775657176971
train_iter_loss: 0.24586573243141174
train_iter_loss: 0.2091648131608963
train_iter_loss: 0.264108270406723
train_iter_loss: 0.24423840641975403
train_iter_loss: 0.23911349475383759
train_iter_loss: 0.22559970617294312
train_iter_loss: 0.3055911958217621
train_iter_loss: 0.37952250242233276
train_iter_loss: 0.19914676249027252
train_iter_loss: 0.25329190492630005
train_iter_loss: 0.23963244259357452
train_iter_loss: 0.2770307958126068
train_iter_loss: 0.21671682596206665
train_iter_loss: 0.33194538950920105
train_iter_loss: 0.2560862600803375
train_iter_loss: 0.24468713998794556
train_iter_loss: 0.19976213574409485
train_iter_loss: 0.18873432278633118
train_iter_loss: 0.25904974341392517
train_iter_loss: 0.2238508015871048
train_iter_loss: 0.23046982288360596
train_iter_loss: 0.2263345867395401
train_iter_loss: 0.24728964269161224
train_iter_loss: 0.20518085360527039
train_iter_loss: 0.30667757987976074
train_iter_loss: 0.22807514667510986
train_iter_loss: 0.24485374987125397
train_iter_loss: 0.22234004735946655
train_iter_loss: 0.21544702351093292
train_iter_loss: 0.2121751457452774
train_iter_loss: 0.2071315050125122
train_iter_loss: 0.2087206393480301
train_iter_loss: 0.22548004984855652
train_iter_loss: 0.32429268956184387
train_iter_loss: 0.19094744324684143
train_iter_loss: 0.23186850547790527
train_iter_loss: 0.272565633058548
train_iter_loss: 0.34455442428588867
train_iter_loss: 0.23586279153823853
train_iter_loss: 0.25643640756607056
train_iter_loss: 0.27514126896858215
train_iter_loss: 0.22253145277500153
train_iter_loss: 0.25363555550575256
train_iter_loss: 0.25505587458610535
train_iter_loss: 0.34089311957359314
train_iter_loss: 0.25390782952308655
train_iter_loss: 0.2539308965206146
train_iter_loss: 0.24492600560188293
train_iter_loss: 0.2584674656391144
train_iter_loss: 0.26590803265571594
train_iter_loss: 0.20608185231685638
train_iter_loss: 0.2845447361469269
train_iter_loss: 0.24293960630893707
train_iter_loss: 0.3972904086112976
train_iter_loss: 0.23739400506019592
train_iter_loss: 0.2337307333946228
train_iter_loss: 0.2182549089193344
train_iter_loss: 0.29709964990615845
train_iter_loss: 0.2432880997657776
train_iter_loss: 0.21697625517845154
train_iter_loss: 0.2899797558784485
train_iter_loss: 0.18505656719207764
train_iter_loss: 0.24246922135353088
train_iter_loss: 0.24554365873336792
train_iter_loss: 0.29410412907600403
train_iter_loss: 0.2759333550930023
train_iter_loss: 0.4572509527206421
train_iter_loss: 0.23721866309642792
train_iter_loss: 0.25740888714790344
train_iter_loss: 0.19925807416439056
train_iter_loss: 0.22475959360599518
train_iter_loss: 0.21942223608493805
train_iter_loss: 0.25361111760139465
train_iter_loss: 0.28987401723861694
train_iter_loss: 0.25136610865592957
train_iter_loss: 0.25847047567367554
train_iter_loss: 0.31754010915756226
train_iter_loss: 0.2922879159450531
train_iter_loss: 0.21628430485725403
train_iter_loss: 0.295781672000885
train_iter_loss: 0.30213436484336853
train_iter_loss: 0.22571143507957458
train_iter_loss: 0.24415773153305054
train_iter_loss: 0.24319994449615479
train_iter_loss: 0.26448336243629456
train_iter_loss: 0.2918016314506531
train_iter_loss: 0.262069970369339
train_iter_loss: 0.3665558397769928
train_iter_loss: 0.3090290129184723
train_iter_loss: 0.21110931038856506
train_iter_loss: 0.28308090567588806
train_iter_loss: 0.2570987343788147
train_iter_loss: 0.20965909957885742
train_iter_loss: 0.24831150472164154
train_iter_loss: 0.29335108399391174
train_iter_loss: 0.2664570212364197
train_iter_loss: 0.18231303989887238
train_iter_loss: 0.22362622618675232
train_iter_loss: 0.24730539321899414
train_iter_loss: 0.30638283491134644
train_iter_loss: 0.16998179256916046
train_iter_loss: 0.21729128062725067
train_iter_loss: 0.2024814933538437
train_iter_loss: 0.2967592775821686
train_iter_loss: 0.2916727066040039
train_iter_loss: 0.35352012515068054
train_iter_loss: 0.17670553922653198
train_iter_loss: 0.22784020006656647
train_iter_loss: 0.26175498962402344
train_iter_loss: 0.21122072637081146
train_iter_loss: 0.3069702386856079
train_iter_loss: 0.19150568544864655
train_iter_loss: 0.2821462154388428
train_iter_loss: 0.2902813255786896
train_iter_loss: 0.2956366240978241
train_iter_loss: 0.24564318358898163
train_iter_loss: 0.26652589440345764
train_iter_loss: 0.29292744398117065
train_iter_loss: 0.23882056772708893
train_iter_loss: 0.20658545196056366
train loss :0.2568
---------------------
Validation seg loss: 0.3068519298619819 at epoch 41
epoch =     42/  1000, exp = train
train_iter_loss: 0.3366299271583557
train_iter_loss: 0.2945285141468048
train_iter_loss: 0.2851913273334503
train_iter_loss: 0.32597437500953674
train_iter_loss: 0.3431047797203064
train_iter_loss: 0.20137964189052582
train_iter_loss: 0.20102562010288239
train_iter_loss: 0.29487013816833496
train_iter_loss: 0.3622380197048187
train_iter_loss: 0.2553921341896057
train_iter_loss: 0.22244268655776978
train_iter_loss: 0.33315426111221313
train_iter_loss: 0.23290888965129852
train_iter_loss: 0.25440359115600586
train_iter_loss: 0.24554529786109924
train_iter_loss: 0.2832585871219635
train_iter_loss: 0.2175038754940033
train_iter_loss: 0.2641952931880951
train_iter_loss: 0.2872200608253479
train_iter_loss: 0.22585614025592804
train_iter_loss: 0.2244776338338852
train_iter_loss: 0.3788678050041199
train_iter_loss: 0.25040581822395325
train_iter_loss: 0.28703516721725464
train_iter_loss: 0.21587282419204712
train_iter_loss: 0.18108227849006653
train_iter_loss: 0.28672876954078674
train_iter_loss: 0.20799434185028076
train_iter_loss: 0.21954870223999023
train_iter_loss: 0.21129922568798065
train_iter_loss: 0.21152326464653015
train_iter_loss: 0.20461899042129517
train_iter_loss: 0.36176344752311707
train_iter_loss: 0.22142837941646576
train_iter_loss: 0.29180964827537537
train_iter_loss: 0.28191712498664856
train_iter_loss: 0.3442738354206085
train_iter_loss: 0.2929028272628784
train_iter_loss: 0.2973274886608124
train_iter_loss: 0.2417917400598526
train_iter_loss: 0.24689136445522308
train_iter_loss: 0.224951833486557
train_iter_loss: 0.20764419436454773
train_iter_loss: 0.45388999581336975
train_iter_loss: 0.3017478883266449
train_iter_loss: 0.30155423283576965
train_iter_loss: 0.2217784970998764
train_iter_loss: 0.21188463270664215
train_iter_loss: 0.21106676757335663
train_iter_loss: 0.36472445726394653
train_iter_loss: 0.28378772735595703
train_iter_loss: 0.20801959931850433
train_iter_loss: 0.20064927637577057
train_iter_loss: 0.2531845271587372
train_iter_loss: 0.27527517080307007
train_iter_loss: 0.2201819121837616
train_iter_loss: 0.2254602313041687
train_iter_loss: 0.19001851975917816
train_iter_loss: 0.2238505333662033
train_iter_loss: 0.3385700583457947
train_iter_loss: 0.30138903856277466
train_iter_loss: 0.34695369005203247
train_iter_loss: 0.27442678809165955
train_iter_loss: 0.2501503527164459
train_iter_loss: 0.22751952707767487
train_iter_loss: 0.29373273253440857
train_iter_loss: 0.2089824676513672
train_iter_loss: 0.23333077132701874
train_iter_loss: 0.2649294435977936
train_iter_loss: 0.22098308801651
train_iter_loss: 0.28844547271728516
train_iter_loss: 0.36009418964385986
train_iter_loss: 0.2868105173110962
train_iter_loss: 0.2741207480430603
train_iter_loss: 0.2306736409664154
train_iter_loss: 0.2595112919807434
train_iter_loss: 0.2590950131416321
train_iter_loss: 0.2078445851802826
train_iter_loss: 0.23222722113132477
train_iter_loss: 0.21599751710891724
train_iter_loss: 0.22266145050525665
train_iter_loss: 0.259602814912796
train_iter_loss: 0.2611469626426697
train_iter_loss: 0.22630882263183594
train_iter_loss: 0.2034013569355011
train_iter_loss: 0.19458553194999695
train_iter_loss: 0.24878937005996704
train_iter_loss: 0.23573118448257446
train_iter_loss: 0.2826031446456909
train_iter_loss: 0.17864865064620972
train_iter_loss: 0.20402792096138
train_iter_loss: 0.2139030247926712
train_iter_loss: 0.2846316397190094
train_iter_loss: 0.2086203545331955
train_iter_loss: 0.23019976913928986
train_iter_loss: 0.2600095570087433
train_iter_loss: 0.24774745106697083
train_iter_loss: 0.23032651841640472
train_iter_loss: 0.20700520277023315
train_iter_loss: 0.3055168390274048
train_iter_loss: 0.23245278000831604
train_iter_loss: 0.21578896045684814
train_iter_loss: 0.22420501708984375
train_iter_loss: 0.2386457920074463
train_iter_loss: 0.319100558757782
train_iter_loss: 0.30513066053390503
train_iter_loss: 0.2916453778743744
train_iter_loss: 0.22304219007492065
train_iter_loss: 0.19273501634597778
train_iter_loss: 0.19484251737594604
train_iter_loss: 0.1964792013168335
train_iter_loss: 0.24230311810970306
train_iter_loss: 0.21047404408454895
train_iter_loss: 0.19334515929222107
train_iter_loss: 0.21274986863136292
train_iter_loss: 0.19802699983119965
train_iter_loss: 0.2174399495124817
train_iter_loss: 0.24961543083190918
train_iter_loss: 0.24429501593112946
train_iter_loss: 0.227700337767601
train_iter_loss: 0.19547851383686066
train_iter_loss: 0.22387433052062988
train_iter_loss: 0.23759713768959045
train_iter_loss: 0.2358100265264511
train_iter_loss: 0.2562227249145508
train_iter_loss: 0.23409786820411682
train_iter_loss: 0.29102709889411926
train_iter_loss: 0.34916797280311584
train_iter_loss: 0.2530486285686493
train_iter_loss: 0.26297518610954285
train_iter_loss: 0.3102976679801941
train_iter_loss: 0.37618139386177063
train_iter_loss: 0.19181029498577118
train_iter_loss: 0.23733936250209808
train_iter_loss: 0.20679156482219696
train_iter_loss: 0.192539781332016
train_iter_loss: 0.18876472115516663
train_iter_loss: 0.270143061876297
train_iter_loss: 0.24528607726097107
train_iter_loss: 0.23364046216011047
train_iter_loss: 0.2874135375022888
train_iter_loss: 0.1749659776687622
train_iter_loss: 0.20180198550224304
train_iter_loss: 0.20056235790252686
train_iter_loss: 0.23938529193401337
train_iter_loss: 0.22500492632389069
train_iter_loss: 0.25055256485939026
train_iter_loss: 0.26325368881225586
train_iter_loss: 0.254838228225708
train_iter_loss: 0.3089366555213928
train_iter_loss: 0.2295733094215393
train_iter_loss: 0.3593747317790985
train_iter_loss: 0.25788170099258423
train_iter_loss: 0.2588253915309906
train_iter_loss: 0.2691459357738495
train_iter_loss: 0.27066606283187866
train_iter_loss: 0.1961549073457718
train_iter_loss: 0.2617773711681366
train_iter_loss: 0.2408321052789688
train_iter_loss: 0.3018350303173065
train_iter_loss: 0.2417335957288742
train_iter_loss: 0.25921356678009033
train_iter_loss: 0.35276880860328674
train_iter_loss: 0.27333083748817444
train_iter_loss: 0.37576472759246826
train_iter_loss: 0.20926149189472198
train_iter_loss: 0.2718034088611603
train_iter_loss: 0.25122442841529846
train_iter_loss: 0.24020512402057648
train_iter_loss: 0.1945367008447647
train_iter_loss: 0.22146520018577576
train_iter_loss: 0.29060688614845276
train_iter_loss: 0.22721068561077118
train_iter_loss: 0.309866338968277
train_iter_loss: 0.2378586083650589
train_iter_loss: 0.1700976938009262
train_iter_loss: 0.19151975214481354
train_iter_loss: 0.18815749883651733
train_iter_loss: 0.22580541670322418
train_iter_loss: 0.3646184206008911
train_iter_loss: 0.2529773712158203
train_iter_loss: 0.2812311351299286
train_iter_loss: 0.27448198199272156
train_iter_loss: 0.23812657594680786
train_iter_loss: 0.2925690710544586
train_iter_loss: 0.24034877121448517
train_iter_loss: 0.19226330518722534
train_iter_loss: 0.1861455887556076
train_iter_loss: 0.23214809596538544
train_iter_loss: 0.28982117772102356
train_iter_loss: 0.28126734495162964
train_iter_loss: 0.40459972620010376
train_iter_loss: 0.24881567060947418
train_iter_loss: 0.2412547767162323
train_iter_loss: 0.2883366048336029
train_iter_loss: 0.23144227266311646
train_iter_loss: 0.27718430757522583
train_iter_loss: 0.22629103064537048
train_iter_loss: 0.29557862877845764
train_iter_loss: 0.24793291091918945
train loss :0.2552
---------------------
Validation seg loss: 0.3029919178137239 at epoch 42
epoch =     43/  1000, exp = train
train_iter_loss: 0.22117970883846283
train_iter_loss: 0.21080386638641357
train_iter_loss: 0.29695001244544983
train_iter_loss: 0.2366197258234024
train_iter_loss: 0.30649495124816895
train_iter_loss: 0.22851596772670746
train_iter_loss: 0.3305985629558563
train_iter_loss: 0.2932550609111786
train_iter_loss: 0.22706535458564758
train_iter_loss: 0.3027198016643524
train_iter_loss: 0.21681714057922363
train_iter_loss: 0.19991770386695862
train_iter_loss: 0.2739345133304596
train_iter_loss: 0.2335713654756546
train_iter_loss: 0.245118647813797
train_iter_loss: 0.22181092202663422
train_iter_loss: 0.23515258729457855
train_iter_loss: 0.2203083038330078
train_iter_loss: 0.2722000777721405
train_iter_loss: 0.3302193284034729
train_iter_loss: 0.29558202624320984
train_iter_loss: 0.3638453185558319
train_iter_loss: 0.17247813940048218
train_iter_loss: 0.21438094973564148
train_iter_loss: 0.30608034133911133
train_iter_loss: 0.2597939670085907
train_iter_loss: 0.2047475129365921
train_iter_loss: 0.24750423431396484
train_iter_loss: 0.30021804571151733
train_iter_loss: 0.2421594113111496
train_iter_loss: 0.1817261427640915
train_iter_loss: 0.21133457124233246
train_iter_loss: 0.18066705763339996
train_iter_loss: 0.2038773000240326
train_iter_loss: 0.21657517552375793
train_iter_loss: 0.25234702229499817
train_iter_loss: 0.2352602779865265
train_iter_loss: 0.21431808173656464
train_iter_loss: 0.22984114289283752
train_iter_loss: 0.21899302303791046
train_iter_loss: 0.23623476922512054
train_iter_loss: 0.3127860724925995
train_iter_loss: 0.22552372515201569
train_iter_loss: 0.2669052481651306
train_iter_loss: 0.22846174240112305
train_iter_loss: 0.2798023223876953
train_iter_loss: 0.2157939225435257
train_iter_loss: 0.3407757580280304
train_iter_loss: 0.2441130429506302
train_iter_loss: 0.20028957724571228
train_iter_loss: 0.21411851048469543
train_iter_loss: 0.24522815644741058
train_iter_loss: 0.19452373683452606
train_iter_loss: 0.3049403727054596
train_iter_loss: 0.24138492345809937
train_iter_loss: 0.3414367437362671
train_iter_loss: 0.355755478143692
train_iter_loss: 0.21793684363365173
train_iter_loss: 0.2949829697608948
train_iter_loss: 0.2777893841266632
train_iter_loss: 0.2708321809768677
train_iter_loss: 0.19849197566509247
train_iter_loss: 0.23058277368545532
train_iter_loss: 0.16743582487106323
train_iter_loss: 0.2661617398262024
train_iter_loss: 0.33832496404647827
train_iter_loss: 0.291517436504364
train_iter_loss: 0.2567155063152313
train_iter_loss: 0.24729028344154358
train_iter_loss: 0.2897375524044037
train_iter_loss: 0.3345318138599396
train_iter_loss: 0.2117670327425003
train_iter_loss: 0.2314854860305786
train_iter_loss: 0.26332366466522217
train_iter_loss: 0.2508147060871124
train_iter_loss: 0.19259925186634064
train_iter_loss: 0.30043721199035645
train_iter_loss: 0.2610049843788147
train_iter_loss: 0.27775025367736816
train_iter_loss: 0.21597807109355927
train_iter_loss: 0.2926177382469177
train_iter_loss: 0.31439122557640076
train_iter_loss: 0.21038313210010529
train_iter_loss: 0.1770351529121399
train_iter_loss: 0.23010636866092682
train_iter_loss: 0.2903541326522827
train_iter_loss: 0.2238558530807495
train_iter_loss: 0.21028302609920502
train_iter_loss: 0.1951194554567337
train_iter_loss: 0.2025744765996933
train_iter_loss: 0.2196446657180786
train_iter_loss: 0.22825664281845093
train_iter_loss: 0.20311565697193146
train_iter_loss: 0.26992782950401306
train_iter_loss: 0.2977401912212372
train_iter_loss: 0.2514176070690155
train_iter_loss: 0.2671201527118683
train_iter_loss: 0.2788441479206085
train_iter_loss: 0.21718938648700714
train_iter_loss: 0.2561320960521698
train_iter_loss: 0.25108250975608826
train_iter_loss: 0.276467502117157
train_iter_loss: 0.19094151258468628
train_iter_loss: 0.20633190870285034
train_iter_loss: 0.2042815387248993
train_iter_loss: 0.28298503160476685
train_iter_loss: 0.30475109815597534
train_iter_loss: 0.3592948913574219
train_iter_loss: 0.2683577835559845
train_iter_loss: 0.21088603138923645
train_iter_loss: 0.3358955979347229
train_iter_loss: 0.28733062744140625
train_iter_loss: 0.22388535737991333
train_iter_loss: 0.19955189526081085
train_iter_loss: 0.21303942799568176
train_iter_loss: 0.26936474442481995
train_iter_loss: 0.3257591724395752
train_iter_loss: 0.319076269865036
train_iter_loss: 0.2044401913881302
train_iter_loss: 0.30993735790252686
train_iter_loss: 0.2609676122665405
train_iter_loss: 0.27611473202705383
train_iter_loss: 0.3802039325237274
train_iter_loss: 0.24668660759925842
train_iter_loss: 0.1892600655555725
train_iter_loss: 0.25449851155281067
train_iter_loss: 0.20510338246822357
train_iter_loss: 0.3676012456417084
train_iter_loss: 0.24837146699428558
train_iter_loss: 0.2290818989276886
train_iter_loss: 0.21785233914852142
train_iter_loss: 0.26805102825164795
train_iter_loss: 0.22775205969810486
train_iter_loss: 0.24795569479465485
train_iter_loss: 0.24415670335292816
train_iter_loss: 0.28085142374038696
train_iter_loss: 0.21271491050720215
train_iter_loss: 0.2669923007488251
train_iter_loss: 0.23360352218151093
train_iter_loss: 0.2978419363498688
train_iter_loss: 0.26545268297195435
train_iter_loss: 0.2988618314266205
train_iter_loss: 0.24198968708515167
train_iter_loss: 0.2584742605686188
train_iter_loss: 0.2412434071302414
train_iter_loss: 0.22056035697460175
train_iter_loss: 0.20566736161708832
train_iter_loss: 0.328971803188324
train_iter_loss: 0.25699469447135925
train_iter_loss: 0.23469622433185577
train_iter_loss: 0.3611445724964142
train_iter_loss: 0.19316992163658142
train_iter_loss: 0.2223007082939148
train_iter_loss: 0.2952205240726471
train_iter_loss: 0.2076064646244049
train_iter_loss: 0.25977545976638794
train_iter_loss: 0.2626648545265198
train_iter_loss: 0.22718752920627594
train_iter_loss: 0.25897157192230225
train_iter_loss: 0.22888711094856262
train_iter_loss: 0.25597402453422546
train_iter_loss: 0.22770659625530243
train_iter_loss: 0.364634245634079
train_iter_loss: 0.23203757405281067
train_iter_loss: 0.1838233768939972
train_iter_loss: 0.24699150025844574
train_iter_loss: 0.31313157081604004
train_iter_loss: 0.3669569790363312
train_iter_loss: 0.2521328330039978
train_iter_loss: 0.2711198031902313
train_iter_loss: 0.20173972845077515
train_iter_loss: 0.25370723009109497
train_iter_loss: 0.20925840735435486
train_iter_loss: 0.24292531609535217
train_iter_loss: 0.41074779629707336
train_iter_loss: 0.2921222746372223
train_iter_loss: 0.18462811410427094
train_iter_loss: 0.23328305780887604
train_iter_loss: 0.20031404495239258
train_iter_loss: 0.2250557392835617
train_iter_loss: 0.258497029542923
train_iter_loss: 0.29506716132164
train_iter_loss: 0.19605951011180878
train_iter_loss: 0.20425677299499512
train_iter_loss: 0.24020922183990479
train_iter_loss: 0.22209592163562775
train_iter_loss: 0.23766720294952393
train_iter_loss: 0.348687082529068
train_iter_loss: 0.3061878979206085
train_iter_loss: 0.28079625964164734
train_iter_loss: 0.1962592899799347
train_iter_loss: 0.19897915422916412
train_iter_loss: 0.25734972953796387
train_iter_loss: 0.19825886189937592
train_iter_loss: 0.2758472263813019
train_iter_loss: 0.2774406373500824
train_iter_loss: 0.2447633594274521
train_iter_loss: 0.4308076500892639
train_iter_loss: 0.25864413380622864
train_iter_loss: 0.25095734000205994
train loss :0.2555
---------------------
Validation seg loss: 0.30247260131082443 at epoch 43
epoch =     44/  1000, exp = train
train_iter_loss: 0.2984361946582794
train_iter_loss: 0.27631473541259766
train_iter_loss: 0.21095304191112518
train_iter_loss: 0.2694627344608307
train_iter_loss: 0.20182383060455322
train_iter_loss: 0.25025561451911926
train_iter_loss: 0.24223646521568298
train_iter_loss: 0.3059932291507721
train_iter_loss: 0.24236330389976501
train_iter_loss: 0.17184489965438843
train_iter_loss: 0.2920398414134979
train_iter_loss: 0.2539169490337372
train_iter_loss: 0.2492879033088684
train_iter_loss: 0.25379645824432373
train_iter_loss: 0.257479190826416
train_iter_loss: 0.2839949131011963
train_iter_loss: 0.2636357247829437
train_iter_loss: 0.3665064573287964
train_iter_loss: 0.22119396924972534
train_iter_loss: 0.31406092643737793
train_iter_loss: 0.22069215774536133
train_iter_loss: 0.35094955563545227
train_iter_loss: 0.20388084650039673
train_iter_loss: 0.24306203424930573
train_iter_loss: 0.2836148142814636
train_iter_loss: 0.25609108805656433
train_iter_loss: 0.2520489990711212
train_iter_loss: 0.3295445740222931
train_iter_loss: 0.2106795608997345
train_iter_loss: 0.2851082682609558
train_iter_loss: 0.2661926746368408
train_iter_loss: 0.3318234384059906
train_iter_loss: 0.3065088987350464
train_iter_loss: 0.2460520714521408
train_iter_loss: 0.21364115178585052
train_iter_loss: 0.22292852401733398
train_iter_loss: 0.22127124667167664
train_iter_loss: 0.2461756467819214
train_iter_loss: 0.26535746455192566
train_iter_loss: 0.239641010761261
train_iter_loss: 0.24721595644950867
train_iter_loss: 0.22279837727546692
train_iter_loss: 0.23601993918418884
train_iter_loss: 0.2127753049135208
train_iter_loss: 0.22317561507225037
train_iter_loss: 0.27165892720222473
train_iter_loss: 0.26291555166244507
train_iter_loss: 0.3632056713104248
train_iter_loss: 0.28028979897499084
train_iter_loss: 0.33178579807281494
train_iter_loss: 0.22543542087078094
train_iter_loss: 0.28675004839897156
train_iter_loss: 0.18229089677333832
train_iter_loss: 0.20557929575443268
train_iter_loss: 0.2875957190990448
train_iter_loss: 0.2590716779232025
train_iter_loss: 0.25838518142700195
train_iter_loss: 0.20578713715076447
train_iter_loss: 0.25109371542930603
train_iter_loss: 0.23275162279605865
train_iter_loss: 0.260345995426178
train_iter_loss: 0.18679103255271912
train_iter_loss: 0.24560381472110748
train_iter_loss: 0.2716619670391083
train_iter_loss: 0.2479352504014969
train_iter_loss: 0.18824994564056396
train_iter_loss: 0.21609635651111603
train_iter_loss: 0.2025967240333557
train_iter_loss: 0.3387109339237213
train_iter_loss: 0.3830488324165344
train_iter_loss: 0.23104363679885864
train_iter_loss: 0.19421367347240448
train_iter_loss: 0.24647259712219238
train_iter_loss: 0.20401157438755035
train_iter_loss: 0.2033950686454773
train_iter_loss: 0.2190856635570526
train_iter_loss: 0.4315422475337982
train_iter_loss: 0.1996995508670807
train_iter_loss: 0.17725202441215515
train_iter_loss: 0.25243911147117615
train_iter_loss: 0.3306683301925659
train_iter_loss: 0.26201558113098145
train_iter_loss: 0.25905972719192505
train_iter_loss: 0.21422429382801056
train_iter_loss: 0.23978190124034882
train_iter_loss: 0.2376284897327423
train_iter_loss: 0.18826442956924438
train_iter_loss: 0.24497541785240173
train_iter_loss: 0.21744121611118317
train_iter_loss: 0.28466716408729553
train_iter_loss: 0.21167050302028656
train_iter_loss: 0.22735540568828583
train_iter_loss: 0.24148975312709808
train_iter_loss: 0.28822392225265503
train_iter_loss: 0.19818228483200073
train_iter_loss: 0.29741349816322327
train_iter_loss: 0.2538066506385803
train_iter_loss: 0.1713683158159256
train_iter_loss: 0.3326866328716278
train_iter_loss: 0.2807563245296478
train_iter_loss: 0.2531880736351013
train_iter_loss: 0.3446471691131592
train_iter_loss: 0.25259700417518616
train_iter_loss: 0.26533958315849304
train_iter_loss: 0.23655475676059723
train_iter_loss: 0.371100515127182
train_iter_loss: 0.2757660448551178
train_iter_loss: 0.19311897456645966
train_iter_loss: 0.3781498372554779
train_iter_loss: 0.3062557876110077
train_iter_loss: 0.24665027856826782
train_iter_loss: 0.37676775455474854
train_iter_loss: 0.2474924772977829
train_iter_loss: 0.2490975558757782
train_iter_loss: 0.19484274089336395
train_iter_loss: 0.34133249521255493
train_iter_loss: 0.19431370496749878
train_iter_loss: 0.1802537739276886
train_iter_loss: 0.2913936376571655
train_iter_loss: 0.2698528468608856
train_iter_loss: 0.290424644947052
train_iter_loss: 0.2479277402162552
train_iter_loss: 0.31666791439056396
train_iter_loss: 0.2283218502998352
train_iter_loss: 0.21066376566886902
train_iter_loss: 0.28170502185821533
train_iter_loss: 0.21011202037334442
train_iter_loss: 0.3330477178096771
train_iter_loss: 0.2619379460811615
train_iter_loss: 0.34224334359169006
train_iter_loss: 0.20712576806545258
train_iter_loss: 0.23580297827720642
train_iter_loss: 0.20053428411483765
train_iter_loss: 0.21866774559020996
train_iter_loss: 0.28861603140830994
train_iter_loss: 0.2092430740594864
train_iter_loss: 0.25966447591781616
train_iter_loss: 0.25914278626441956
train_iter_loss: 0.24662084877490997
train_iter_loss: 0.28459811210632324
train_iter_loss: 0.16726398468017578
train_iter_loss: 0.2903904318809509
train_iter_loss: 0.2913995385169983
train_iter_loss: 0.3016679883003235
train_iter_loss: 0.24023421108722687
train_iter_loss: 0.24586132168769836
train_iter_loss: 0.19535568356513977
train_iter_loss: 0.3706667721271515
train_iter_loss: 0.2581396698951721
train_iter_loss: 0.21587055921554565
train_iter_loss: 0.22680477797985077
train_iter_loss: 0.351273775100708
train_iter_loss: 0.2250400334596634
train_iter_loss: 0.2687363922595978
train_iter_loss: 0.2372581660747528
train_iter_loss: 0.24230150878429413
train_iter_loss: 0.24019986391067505
train_iter_loss: 0.22121256589889526
train_iter_loss: 0.21231716871261597
train_iter_loss: 0.27431562542915344
train_iter_loss: 0.3226448595523834
train_iter_loss: 0.17294585704803467
train_iter_loss: 0.2297525256872177
train_iter_loss: 0.3316460847854614
train_iter_loss: 0.253106951713562
train_iter_loss: 0.28119149804115295
train_iter_loss: 0.239065483212471
train_iter_loss: 0.24941012263298035
train_iter_loss: 0.2720555067062378
train_iter_loss: 0.2584543824195862
train_iter_loss: 0.1893848031759262
train_iter_loss: 0.23556974530220032
train_iter_loss: 0.21988797187805176
train_iter_loss: 0.2941168546676636
train_iter_loss: 0.26694896817207336
train_iter_loss: 0.23736201226711273
train_iter_loss: 0.2849962115287781
train_iter_loss: 0.1875205636024475
train_iter_loss: 0.2639966905117035
train_iter_loss: 0.21016740798950195
train_iter_loss: 0.23704595863819122
train_iter_loss: 0.21233732998371124
train_iter_loss: 0.23012444376945496
train_iter_loss: 0.2243282049894333
train_iter_loss: 0.2209954708814621
train_iter_loss: 0.20844703912734985
train_iter_loss: 0.22319680452346802
train_iter_loss: 0.2455626130104065
train_iter_loss: 0.19771285355091095
train_iter_loss: 0.28912353515625
train_iter_loss: 0.22609847784042358
train_iter_loss: 0.26658883690834045
train_iter_loss: 0.3154381215572357
train_iter_loss: 0.2243037074804306
train_iter_loss: 0.25069740414619446
train_iter_loss: 0.2722122073173523
train_iter_loss: 0.2559680938720703
train_iter_loss: 0.19986660778522491
train_iter_loss: 0.18004626035690308
train_iter_loss: 0.29279401898384094
train loss :0.2553
---------------------
Validation seg loss: 0.30520664956772103 at epoch 44
epoch =     45/  1000, exp = train
train_iter_loss: 0.18122774362564087
train_iter_loss: 0.24090446531772614
train_iter_loss: 0.2440992295742035
train_iter_loss: 0.22410370409488678
train_iter_loss: 0.2472134679555893
train_iter_loss: 0.21702565252780914
train_iter_loss: 0.3019273579120636
train_iter_loss: 0.3546518087387085
train_iter_loss: 0.2724146544933319
train_iter_loss: 0.21297621726989746
train_iter_loss: 0.3012601435184479
train_iter_loss: 0.2635282874107361
train_iter_loss: 0.17158792912960052
train_iter_loss: 0.27005714178085327
train_iter_loss: 0.2209126204252243
train_iter_loss: 0.24462108314037323
train_iter_loss: 0.26493799686431885
train_iter_loss: 0.3369161784648895
train_iter_loss: 0.26770883798599243
train_iter_loss: 0.272922158241272
train_iter_loss: 0.25319212675094604
train_iter_loss: 0.3055098056793213
train_iter_loss: 0.2624417543411255
train_iter_loss: 0.3132936656475067
train_iter_loss: 0.26865893602371216
train_iter_loss: 0.20812848210334778
train_iter_loss: 0.1880313903093338
train_iter_loss: 0.3724510967731476
train_iter_loss: 0.24095286428928375
train_iter_loss: 0.25648537278175354
train_iter_loss: 0.21242576837539673
train_iter_loss: 0.2959921956062317
train_iter_loss: 0.28879573941230774
train_iter_loss: 0.2118401974439621
train_iter_loss: 0.2221716046333313
train_iter_loss: 0.1693190038204193
train_iter_loss: 0.3016543388366699
train_iter_loss: 0.2681708037853241
train_iter_loss: 0.1933499127626419
train_iter_loss: 0.276678204536438
train_iter_loss: 0.27924931049346924
train_iter_loss: 0.25946709513664246
train_iter_loss: 0.2367500513792038
train_iter_loss: 0.20511192083358765
train_iter_loss: 0.290911465883255
train_iter_loss: 0.2092321813106537
train_iter_loss: 0.18662509322166443
train_iter_loss: 0.1860135942697525
train_iter_loss: 0.23018208146095276
train_iter_loss: 0.2698214650154114
train_iter_loss: 0.26250776648521423
train_iter_loss: 0.22995774447917938
train_iter_loss: 0.25679320096969604
train_iter_loss: 0.21587558090686798
train_iter_loss: 0.29995161294937134
train_iter_loss: 0.242078498005867
train_iter_loss: 0.2436586171388626
train_iter_loss: 0.24985815584659576
train_iter_loss: 0.19511285424232483
train_iter_loss: 0.24944160878658295
train_iter_loss: 0.24952909350395203
train_iter_loss: 0.27204862236976624
train_iter_loss: 0.23946520686149597
train_iter_loss: 0.27535369992256165
train_iter_loss: 0.2667321264743805
train_iter_loss: 0.2531551420688629
train_iter_loss: 0.24365638196468353
train_iter_loss: 0.2724771499633789
train_iter_loss: 0.206199049949646
train_iter_loss: 0.2164214849472046
train_iter_loss: 0.24391146004199982
train_iter_loss: 0.23570409417152405
train_iter_loss: 0.23590461909770966
train_iter_loss: 0.1916554868221283
train_iter_loss: 0.22620396316051483
train_iter_loss: 0.22963424026966095
train_iter_loss: 0.21566131711006165
train_iter_loss: 0.33851900696754456
train_iter_loss: 0.2846935987472534
train_iter_loss: 0.30454838275909424
train_iter_loss: 0.22482657432556152
train_iter_loss: 0.22430458664894104
train_iter_loss: 0.34763121604919434
train_iter_loss: 0.25452497601509094
train_iter_loss: 0.26263192296028137
train_iter_loss: 0.41830742359161377
train_iter_loss: 0.27798619866371155
train_iter_loss: 0.29662418365478516
train_iter_loss: 0.21154466271400452
train_iter_loss: 0.1998348832130432
train_iter_loss: 0.3213696777820587
train_iter_loss: 0.27164226770401
train_iter_loss: 0.2772010862827301
train_iter_loss: 0.3161974251270294
train_iter_loss: 0.23235923051834106
train_iter_loss: 0.31217387318611145
train_iter_loss: 0.2851109206676483
train_iter_loss: 0.2045365869998932
train_iter_loss: 0.2707803547382355
train_iter_loss: 0.2444060891866684
train_iter_loss: 0.19485530257225037
train_iter_loss: 0.2191687375307083
train_iter_loss: 0.26701819896698
train_iter_loss: 0.19910143315792084
train_iter_loss: 0.22042714059352875
train_iter_loss: 0.21054032444953918
train_iter_loss: 0.2894099950790405
train_iter_loss: 0.22797352075576782
train_iter_loss: 0.27169254422187805
train_iter_loss: 0.17958447337150574
train_iter_loss: 0.23041513562202454
train_iter_loss: 0.2097925841808319
train_iter_loss: 0.1716972440481186
train_iter_loss: 0.19334186613559723
train_iter_loss: 0.23700618743896484
train_iter_loss: 0.20612846314907074
train_iter_loss: 0.22677907347679138
train_iter_loss: 0.2588146924972534
train_iter_loss: 0.2747189402580261
train_iter_loss: 0.2513431906700134
train_iter_loss: 0.22342664003372192
train_iter_loss: 0.3365962505340576
train_iter_loss: 0.2251691371202469
train_iter_loss: 0.23413003981113434
train_iter_loss: 0.2187814712524414
train_iter_loss: 0.2887245714664459
train_iter_loss: 0.24027442932128906
train_iter_loss: 0.2899407148361206
train_iter_loss: 0.28267839550971985
train_iter_loss: 0.23743687570095062
train_iter_loss: 0.2512344419956207
train_iter_loss: 0.21175844967365265
train_iter_loss: 0.2395746260881424
train_iter_loss: 0.2582462728023529
train_iter_loss: 0.18667720258235931
train_iter_loss: 0.21234606206417084
train_iter_loss: 0.2320757657289505
train_iter_loss: 0.24377647042274475
train_iter_loss: 0.2123928964138031
train_iter_loss: 0.2744956612586975
train_iter_loss: 0.19881072640419006
train_iter_loss: 0.22876028716564178
train_iter_loss: 0.2697632610797882
train_iter_loss: 0.2636779546737671
train_iter_loss: 0.34400007128715515
train_iter_loss: 0.33483392000198364
train_iter_loss: 0.32465222477912903
train_iter_loss: 0.21809165179729462
train_iter_loss: 0.4231659770011902
train_iter_loss: 0.2527320384979248
train_iter_loss: 0.20522892475128174
train_iter_loss: 0.17551971971988678
train_iter_loss: 0.3499959409236908
train_iter_loss: 0.388928085565567
train_iter_loss: 0.29915177822113037
train_iter_loss: 0.2647012174129486
train_iter_loss: 0.19585543870925903
train_iter_loss: 0.2161070853471756
train_iter_loss: 0.31253761053085327
train_iter_loss: 0.3528097867965698
train_iter_loss: 0.23318561911582947
train_iter_loss: 0.31763893365859985
train_iter_loss: 0.3086757957935333
train_iter_loss: 0.20868338644504547
train_iter_loss: 0.27696579694747925
train_iter_loss: 0.24247229099273682
train_iter_loss: 0.21410132944583893
train_iter_loss: 0.2208532691001892
train_iter_loss: 0.24251535534858704
train_iter_loss: 0.24407093226909637
train_iter_loss: 0.21637874841690063
train_iter_loss: 0.26148107647895813
train_iter_loss: 0.35664328932762146
train_iter_loss: 0.24376411736011505
train_iter_loss: 0.23035238683223724
train_iter_loss: 0.2008158415555954
train_iter_loss: 0.321710467338562
train_iter_loss: 0.21469341218471527
train_iter_loss: 0.30683639645576477
train_iter_loss: 0.2739950716495514
train_iter_loss: 0.19778496026992798
train_iter_loss: 0.2520820200443268
train_iter_loss: 0.18249374628067017
train_iter_loss: 0.2593311369419098
train_iter_loss: 0.2463909536600113
train_iter_loss: 0.2980819642543793
train_iter_loss: 0.25533008575439453
train_iter_loss: 0.2483617067337036
train_iter_loss: 0.21355405449867249
train_iter_loss: 0.2525293529033661
train_iter_loss: 0.30949950218200684
train_iter_loss: 0.21914663910865784
train_iter_loss: 0.2571088373661041
train_iter_loss: 0.23837408423423767
train_iter_loss: 0.24088214337825775
train_iter_loss: 0.24698008596897125
train_iter_loss: 0.22002126276493073
train_iter_loss: 0.20875327289104462
train_iter_loss: 0.25268760323524475
train_iter_loss: 0.19234168529510498
train loss :0.2536
---------------------
Validation seg loss: 0.30497416115875514 at epoch 45
epoch =     46/  1000, exp = train
train_iter_loss: 0.28210195899009705
train_iter_loss: 0.2701309621334076
train_iter_loss: 0.25063690543174744
train_iter_loss: 0.3003389835357666
train_iter_loss: 0.3880119025707245
train_iter_loss: 0.3144165575504303
train_iter_loss: 0.20648664236068726
train_iter_loss: 0.31975221633911133
train_iter_loss: 0.27406805753707886
train_iter_loss: 0.2259766161441803
train_iter_loss: 0.17707304656505585
train_iter_loss: 0.24040935933589935
train_iter_loss: 0.22731830179691315
train_iter_loss: 0.23858784139156342
train_iter_loss: 0.2490759789943695
train_iter_loss: 0.2095046043395996
train_iter_loss: 0.19274908304214478
train_iter_loss: 0.22837267816066742
train_iter_loss: 0.23724430799484253
train_iter_loss: 0.2607165277004242
train_iter_loss: 0.1809917837381363
train_iter_loss: 0.21513089537620544
train_iter_loss: 0.26652762293815613
train_iter_loss: 0.22243228554725647
train_iter_loss: 0.2510654628276825
train_iter_loss: 0.22061151266098022
train_iter_loss: 0.2365092635154724
train_iter_loss: 0.2492930293083191
train_iter_loss: 0.24463100731372833
train_iter_loss: 0.22983303666114807
train_iter_loss: 0.25590193271636963
train_iter_loss: 0.21322549879550934
train_iter_loss: 0.3594152629375458
train_iter_loss: 0.2984202206134796
train_iter_loss: 0.20364589989185333
train_iter_loss: 0.28257879614830017
train_iter_loss: 0.32556432485580444
train_iter_loss: 0.21174003183841705
train_iter_loss: 0.21808888018131256
train_iter_loss: 0.3359013795852661
train_iter_loss: 0.2592135965824127
train_iter_loss: 0.24863556027412415
train_iter_loss: 0.28022366762161255
train_iter_loss: 0.22158604860305786
train_iter_loss: 0.20898018777370453
train_iter_loss: 0.18552814424037933
train_iter_loss: 0.2598973512649536
train_iter_loss: 0.2282090187072754
train_iter_loss: 0.20538866519927979
train_iter_loss: 0.23802250623703003
train_iter_loss: 0.27726805210113525
train_iter_loss: 0.26714184880256653
train_iter_loss: 0.1830281764268875
train_iter_loss: 0.2039850801229477
train_iter_loss: 0.29927220940589905
train_iter_loss: 0.2356206625699997
train_iter_loss: 0.236698716878891
train_iter_loss: 0.24191057682037354
train_iter_loss: 0.2907143533229828
train_iter_loss: 0.2539922893047333
train_iter_loss: 0.42996758222579956
train_iter_loss: 0.2437230944633484
train_iter_loss: 0.27964621782302856
train_iter_loss: 0.22894909977912903
train_iter_loss: 0.23617318272590637
train_iter_loss: 0.2041042447090149
train_iter_loss: 0.26439735293388367
train_iter_loss: 0.222358837723732
train_iter_loss: 0.30306145548820496
train_iter_loss: 0.24030224978923798
train_iter_loss: 0.285494863986969
train_iter_loss: 0.2203700989484787
train_iter_loss: 0.25169381499290466
train_iter_loss: 0.17986713349819183
train_iter_loss: 0.2316475808620453
train_iter_loss: 0.20594742894172668
train_iter_loss: 0.3458775281906128
train_iter_loss: 0.17267854511737823
train_iter_loss: 0.3058690130710602
train_iter_loss: 0.3242243528366089
train_iter_loss: 0.21528208255767822
train_iter_loss: 0.25238364934921265
train_iter_loss: 0.26163220405578613
train_iter_loss: 0.20982427895069122
train_iter_loss: 0.27371564507484436
train_iter_loss: 0.22743187844753265
train_iter_loss: 0.2772434949874878
train_iter_loss: 0.19290068745613098
train_iter_loss: 0.28444644808769226
train_iter_loss: 0.21527598798274994
train_iter_loss: 0.28787392377853394
train_iter_loss: 0.210226908326149
train_iter_loss: 0.20738793909549713
train_iter_loss: 0.19001227617263794
train_iter_loss: 0.29478076100349426
train_iter_loss: 0.25898900628089905
train_iter_loss: 0.21680285036563873
train_iter_loss: 0.22451116144657135
train_iter_loss: 0.27159202098846436
train_iter_loss: 0.2875862419605255
train_iter_loss: 0.22333389520645142
train_iter_loss: 0.19893532991409302
train_iter_loss: 0.2202518880367279
train_iter_loss: 0.19791296124458313
train_iter_loss: 0.1875176578760147
train_iter_loss: 0.2842821776866913
train_iter_loss: 0.23107770085334778
train_iter_loss: 0.26353713870048523
train_iter_loss: 0.2515597939491272
train_iter_loss: 0.2899056077003479
train_iter_loss: 0.2851302921772003
train_iter_loss: 0.28413042426109314
train_iter_loss: 0.35384202003479004
train_iter_loss: 0.24592512845993042
train_iter_loss: 0.26751187443733215
train_iter_loss: 0.1995171159505844
train_iter_loss: 0.2321363091468811
train_iter_loss: 0.24898023903369904
train_iter_loss: 0.22020864486694336
train_iter_loss: 0.21820887923240662
train_iter_loss: 0.2584073841571808
train_iter_loss: 0.26544854044914246
train_iter_loss: 0.3470461070537567
train_iter_loss: 0.2186012715101242
train_iter_loss: 0.2196347564458847
train_iter_loss: 0.25180530548095703
train_iter_loss: 0.2642645537853241
train_iter_loss: 0.2429632693529129
train_iter_loss: 0.2671235501766205
train_iter_loss: 0.25125429034233093
train_iter_loss: 0.32985156774520874
train_iter_loss: 0.24644391238689423
train_iter_loss: 0.2295973300933838
train_iter_loss: 0.2015748769044876
train_iter_loss: 0.22230710089206696
train_iter_loss: 0.23217153549194336
train_iter_loss: 0.2228846400976181
train_iter_loss: 0.28322479128837585
train_iter_loss: 0.18770499527454376
train_iter_loss: 0.2275419682264328
train_iter_loss: 0.22357246279716492
train_iter_loss: 0.3536536693572998
train_iter_loss: 0.3218034505844116
train_iter_loss: 0.20458249747753143
train_iter_loss: 0.2576914131641388
train_iter_loss: 0.20497776567935944
train_iter_loss: 0.2191554307937622
train_iter_loss: 0.37631723284721375
train_iter_loss: 0.23181410133838654
train_iter_loss: 0.23046275973320007
train_iter_loss: 0.2588823437690735
train_iter_loss: 0.2602897584438324
train_iter_loss: 0.20272395014762878
train_iter_loss: 0.40137189626693726
train_iter_loss: 0.30666422843933105
train_iter_loss: 0.2540784776210785
train_iter_loss: 0.2983904480934143
train_iter_loss: 0.2142050862312317
train_iter_loss: 0.2701607942581177
train_iter_loss: 0.1987074911594391
train_iter_loss: 0.2306564301252365
train_iter_loss: 0.25851354002952576
train_iter_loss: 0.2948110103607178
train_iter_loss: 0.3107878565788269
train_iter_loss: 0.199365496635437
train_iter_loss: 0.26148736476898193
train_iter_loss: 0.2898957133293152
train_iter_loss: 0.303202360868454
train_iter_loss: 0.19940675795078278
train_iter_loss: 0.19610534608364105
train_iter_loss: 0.34803250432014465
train_iter_loss: 0.2546081840991974
train_iter_loss: 0.2784855365753174
train_iter_loss: 0.27975818514823914
train_iter_loss: 0.21239537000656128
train_iter_loss: 0.2230047881603241
train_iter_loss: 0.21434921026229858
train_iter_loss: 0.2560020983219147
train_iter_loss: 0.19423113763332367
train_iter_loss: 0.2735845446586609
train_iter_loss: 0.18460743129253387
train_iter_loss: 0.265789657831192
train_iter_loss: 0.22331346571445465
train_iter_loss: 0.23439620435237885
train_iter_loss: 0.1690620630979538
train_iter_loss: 0.17542070150375366
train_iter_loss: 0.3501208424568176
train_iter_loss: 0.24657182395458221
train_iter_loss: 0.2384272813796997
train_iter_loss: 0.26060742139816284
train_iter_loss: 0.23164772987365723
train_iter_loss: 0.2426741123199463
train_iter_loss: 0.19242002069950104
train_iter_loss: 0.2392669916152954
train_iter_loss: 0.33344388008117676
train_iter_loss: 0.2686102092266083
train_iter_loss: 0.2443384975194931
train_iter_loss: 0.23454563319683075
train_iter_loss: 0.2412271350622177
train_iter_loss: 0.2721210718154907
train loss :0.2516
---------------------
Validation seg loss: 0.30721704029249697 at epoch 46
epoch =     47/  1000, exp = train
train_iter_loss: 0.2898220717906952
train_iter_loss: 0.23332048952579498
train_iter_loss: 0.3359103500843048
train_iter_loss: 0.24990375339984894
train_iter_loss: 0.21899360418319702
train_iter_loss: 0.2666196823120117
train_iter_loss: 0.21501249074935913
train_iter_loss: 0.32098063826560974
train_iter_loss: 0.21002545952796936
train_iter_loss: 0.3676682412624359
train_iter_loss: 0.20150607824325562
train_iter_loss: 0.33899012207984924
train_iter_loss: 0.3851672112941742
train_iter_loss: 0.23995615541934967
train_iter_loss: 0.2168726772069931
train_iter_loss: 0.23571494221687317
train_iter_loss: 0.23869602382183075
train_iter_loss: 0.17664311826229095
train_iter_loss: 0.23363976180553436
train_iter_loss: 0.2323826253414154
train_iter_loss: 0.19957487285137177
train_iter_loss: 0.24304728209972382
train_iter_loss: 0.26220378279685974
train_iter_loss: 0.2651519775390625
train_iter_loss: 0.31202682852745056
train_iter_loss: 0.229732483625412
train_iter_loss: 0.26061519980430603
train_iter_loss: 0.3616146147251129
train_iter_loss: 0.22862355411052704
train_iter_loss: 0.27158042788505554
train_iter_loss: 0.27981889247894287
train_iter_loss: 0.3323774039745331
train_iter_loss: 0.22132554650306702
train_iter_loss: 0.30419445037841797
train_iter_loss: 0.21518847346305847
train_iter_loss: 0.20071884989738464
train_iter_loss: 0.23770689964294434
train_iter_loss: 0.20493978261947632
train_iter_loss: 0.26120761036872864
train_iter_loss: 0.4066316485404968
train_iter_loss: 0.21862080693244934
train_iter_loss: 0.20726165175437927
train_iter_loss: 0.30427467823028564
train_iter_loss: 0.18443377315998077
train_iter_loss: 0.26775723695755005
train_iter_loss: 0.23829792439937592
train_iter_loss: 0.4091501533985138
train_iter_loss: 0.3366642892360687
train_iter_loss: 0.22651204466819763
train_iter_loss: 0.2000722587108612
train_iter_loss: 0.25657835602760315
train_iter_loss: 0.22198200225830078
train_iter_loss: 0.3071448802947998
train_iter_loss: 0.2322428822517395
train_iter_loss: 0.17969073355197906
train_iter_loss: 0.2002294361591339
train_iter_loss: 0.22697922587394714
train_iter_loss: 0.26542404294013977
train_iter_loss: 0.3584138751029968
train_iter_loss: 0.2557069957256317
train_iter_loss: 0.22182677686214447
train_iter_loss: 0.3295319974422455
train_iter_loss: 0.23008911311626434
train_iter_loss: 0.22772003710269928
train_iter_loss: 0.21047449111938477
train_iter_loss: 0.2337062954902649
train_iter_loss: 0.18041697144508362
train_iter_loss: 0.2620536983013153
train_iter_loss: 0.2487504780292511
train_iter_loss: 0.18174044787883759
train_iter_loss: 0.28494876623153687
train_iter_loss: 0.20914322137832642
train_iter_loss: 0.19380247592926025
train_iter_loss: 0.23229973018169403
train_iter_loss: 0.34069597721099854
train_iter_loss: 0.17846927046775818
train_iter_loss: 0.21794602274894714
train_iter_loss: 0.26890867948532104
train_iter_loss: 0.26108527183532715
train_iter_loss: 0.2720516622066498
train_iter_loss: 0.24438847601413727
train_iter_loss: 0.2053014487028122
train_iter_loss: 0.2924613058567047
train_iter_loss: 0.23848174512386322
train_iter_loss: 0.273661732673645
train_iter_loss: 0.28400927782058716
train_iter_loss: 0.39734894037246704
train_iter_loss: 0.28751787543296814
train_iter_loss: 0.2796294093132019
train_iter_loss: 0.19472704827785492
train_iter_loss: 0.24361324310302734
train_iter_loss: 0.2600454092025757
train_iter_loss: 0.17182360589504242
train_iter_loss: 0.2557388246059418
train_iter_loss: 0.31842154264450073
train_iter_loss: 0.2042989432811737
train_iter_loss: 0.25231871008872986
train_iter_loss: 0.17556820809841156
train_iter_loss: 0.19601117074489594
train_iter_loss: 0.2215743213891983
train_iter_loss: 0.19499939680099487
train_iter_loss: 0.2706719636917114
train_iter_loss: 0.24548716843128204
train_iter_loss: 0.21378862857818604
train_iter_loss: 0.22170454263687134
train_iter_loss: 0.24467137455940247
train_iter_loss: 0.23808059096336365
train_iter_loss: 0.22705021500587463
train_iter_loss: 0.22454477846622467
train_iter_loss: 0.21029095351696014
train_iter_loss: 0.20195730030536652
train_iter_loss: 0.2824145555496216
train_iter_loss: 0.20905593037605286
train_iter_loss: 0.17378495633602142
train_iter_loss: 0.2062375843524933
train_iter_loss: 0.31386229395866394
train_iter_loss: 0.21375103294849396
train_iter_loss: 0.2224220484495163
train_iter_loss: 0.37252581119537354
train_iter_loss: 0.2727615535259247
train_iter_loss: 0.24654734134674072
train_iter_loss: 0.18331360816955566
train_iter_loss: 0.297170490026474
train_iter_loss: 0.21183335781097412
train_iter_loss: 0.220228910446167
train_iter_loss: 0.26952216029167175
train_iter_loss: 0.2566373646259308
train_iter_loss: 0.22226367890834808
train_iter_loss: 0.22248056530952454
train_iter_loss: 0.4586489200592041
train_iter_loss: 0.2177044004201889
train_iter_loss: 0.19289331138134003
train_iter_loss: 0.28097352385520935
train_iter_loss: 0.22110652923583984
train_iter_loss: 0.24754776060581207
train_iter_loss: 0.2196509689092636
train_iter_loss: 0.2068108469247818
train_iter_loss: 0.2077774703502655
train_iter_loss: 0.3384096026420593
train_iter_loss: 0.2762567400932312
train_iter_loss: 0.23222984373569489
train_iter_loss: 0.19487781822681427
train_iter_loss: 0.2661525011062622
train_iter_loss: 0.2659260034561157
train_iter_loss: 0.30225327610969543
train_iter_loss: 0.21973755955696106
train_iter_loss: 0.258177250623703
train_iter_loss: 0.33509573340415955
train_iter_loss: 0.23975689709186554
train_iter_loss: 0.24994561076164246
train_iter_loss: 0.3376202881336212
train_iter_loss: 0.20728890597820282
train_iter_loss: 0.21918006241321564
train_iter_loss: 0.36022356152534485
train_iter_loss: 0.33149614930152893
train_iter_loss: 0.2638396918773651
train_iter_loss: 0.27163267135620117
train_iter_loss: 0.22280026972293854
train_iter_loss: 0.26458409428596497
train_iter_loss: 0.2878085970878601
train_iter_loss: 0.31042370200157166
train_iter_loss: 0.22127504646778107
train_iter_loss: 0.23102952539920807
train_iter_loss: 0.2814367413520813
train_iter_loss: 0.24733294546604156
train_iter_loss: 0.2225792109966278
train_iter_loss: 0.22242718935012817
train_iter_loss: 0.3882416784763336
train_iter_loss: 0.20819208025932312
train_iter_loss: 0.35063835978507996
train_iter_loss: 0.23065069317817688
train_iter_loss: 0.18670211732387543
train_iter_loss: 0.19882741570472717
train_iter_loss: 0.23024208843708038
train_iter_loss: 0.25351130962371826
train_iter_loss: 0.24597980082035065
train_iter_loss: 0.23469330370426178
train_iter_loss: 0.2076304405927658
train_iter_loss: 0.20426981151103973
train_iter_loss: 0.21508358418941498
train_iter_loss: 0.2930358648300171
train_iter_loss: 0.2032240331172943
train_iter_loss: 0.2224610447883606
train_iter_loss: 0.20962248742580414
train_iter_loss: 0.26846227049827576
train_iter_loss: 0.20781899988651276
train_iter_loss: 0.21479466557502747
train_iter_loss: 0.23718558251857758
train_iter_loss: 0.23477420210838318
train_iter_loss: 0.32860544323921204
train_iter_loss: 0.2337387502193451
train_iter_loss: 0.26447853446006775
train_iter_loss: 0.25320902466773987
train_iter_loss: 0.209455206990242
train_iter_loss: 0.2375507652759552
train_iter_loss: 0.24211186170578003
train_iter_loss: 0.21409602463245392
train_iter_loss: 0.2668595016002655
train_iter_loss: 0.21457472443580627
train_iter_loss: 0.24004434049129486
train loss :0.2521
---------------------
Validation seg loss: 0.30313502680861726 at epoch 47
epoch =     48/  1000, exp = train
train_iter_loss: 0.29182085394859314
train_iter_loss: 0.20814116299152374
train_iter_loss: 0.39284390211105347
train_iter_loss: 0.31814393401145935
train_iter_loss: 0.24398063123226166
train_iter_loss: 0.23770810663700104
train_iter_loss: 0.2807610034942627
train_iter_loss: 0.19580316543579102
train_iter_loss: 0.21065248548984528
train_iter_loss: 0.24926066398620605
train_iter_loss: 0.226675882935524
train_iter_loss: 0.2691936194896698
train_iter_loss: 0.31833580136299133
train_iter_loss: 0.2955850660800934
train_iter_loss: 0.20268332958221436
train_iter_loss: 0.1943572610616684
train_iter_loss: 0.2680398225784302
train_iter_loss: 0.18386463820934296
train_iter_loss: 0.2736645042896271
train_iter_loss: 0.3381761908531189
train_iter_loss: 0.18213634192943573
train_iter_loss: 0.36181700229644775
train_iter_loss: 0.3810325562953949
train_iter_loss: 0.2650716006755829
train_iter_loss: 0.33031991124153137
train_iter_loss: 0.1998569369316101
train_iter_loss: 0.21665644645690918
train_iter_loss: 0.2566984295845032
train_iter_loss: 0.27558591961860657
train_iter_loss: 0.3200475573539734
train_iter_loss: 0.2178744077682495
train_iter_loss: 0.2899545431137085
train_iter_loss: 0.23843152821063995
train_iter_loss: 0.25330933928489685
train_iter_loss: 0.2225947380065918
train_iter_loss: 0.2394120991230011
train_iter_loss: 0.20303890109062195
train_iter_loss: 0.21867460012435913
train_iter_loss: 0.23542849719524384
train_iter_loss: 0.2449934333562851
train_iter_loss: 0.3787570893764496
train_iter_loss: 0.26409539580345154
train_iter_loss: 0.22582508623600006
train_iter_loss: 0.25285014510154724
train_iter_loss: 0.2789900004863739
train_iter_loss: 0.24291552603244781
train_iter_loss: 0.20732082426548004
train_iter_loss: 0.29041197896003723
train_iter_loss: 0.26065632700920105
train_iter_loss: 0.23537451028823853
train_iter_loss: 0.2773367166519165
train_iter_loss: 0.2807909846305847
train_iter_loss: 0.2727212607860565
train_iter_loss: 0.29615312814712524
train_iter_loss: 0.19341768324375153
train_iter_loss: 0.2695392072200775
train_iter_loss: 0.2561992406845093
train_iter_loss: 0.22241593897342682
train_iter_loss: 0.30994388461112976
train_iter_loss: 0.25160127878189087
train_iter_loss: 0.2115987092256546
train_iter_loss: 0.31044667959213257
train_iter_loss: 0.22247903048992157
train_iter_loss: 0.2900504171848297
train_iter_loss: 0.21591044962406158
train_iter_loss: 0.20872986316680908
train_iter_loss: 0.31552889943122864
train_iter_loss: 0.2476453334093094
train_iter_loss: 0.2021118551492691
train_iter_loss: 0.22198623418807983
train_iter_loss: 0.1969154328107834
train_iter_loss: 0.22259855270385742
train_iter_loss: 0.212546244263649
train_iter_loss: 0.20052984356880188
train_iter_loss: 0.20246729254722595
train_iter_loss: 0.28349053859710693
train_iter_loss: 0.26010018587112427
train_iter_loss: 0.23508983850479126
train_iter_loss: 0.1985546052455902
train_iter_loss: 0.4934532046318054
train_iter_loss: 0.17885924875736237
train_iter_loss: 0.2289101630449295
train_iter_loss: 0.32096365094184875
train_iter_loss: 0.2955624461174011
train_iter_loss: 0.22811445593833923
train_iter_loss: 0.23236767947673798
train_iter_loss: 0.33901655673980713
train_iter_loss: 0.20904584228992462
train_iter_loss: 0.29504090547561646
train_iter_loss: 0.3257390856742859
train_iter_loss: 0.2094174027442932
train_iter_loss: 0.22319145500659943
train_iter_loss: 0.2404392510652542
train_iter_loss: 0.28254610300064087
train_iter_loss: 0.25703248381614685
train_iter_loss: 0.24880658090114594
train_iter_loss: 0.18598398566246033
train_iter_loss: 0.3696761429309845
train_iter_loss: 0.27388036251068115
train_iter_loss: 0.2583315372467041
train_iter_loss: 0.23128841817378998
train_iter_loss: 0.1932603120803833
train_iter_loss: 0.2047705501317978
train_iter_loss: 0.27584904432296753
train_iter_loss: 0.25587353110313416
train_iter_loss: 0.27798810601234436
train_iter_loss: 0.24427425861358643
train_iter_loss: 0.1931552290916443
train_iter_loss: 0.2060917466878891
train_iter_loss: 0.20611786842346191
train_iter_loss: 0.21074849367141724
train_iter_loss: 0.2704295516014099
train_iter_loss: 0.18790078163146973
train_iter_loss: 0.23771589994430542
train_iter_loss: 0.23412702977657318
train_iter_loss: 0.1697922646999359
train_iter_loss: 0.2970660626888275
train_iter_loss: 0.2512246072292328
train_iter_loss: 0.2718872129917145
train_iter_loss: 0.2784558832645416
train_iter_loss: 0.3846360743045807
train_iter_loss: 0.25058504939079285
train_iter_loss: 0.23029710352420807
train_iter_loss: 0.26484042406082153
train_iter_loss: 0.20814678072929382
train_iter_loss: 0.22599568963050842
train_iter_loss: 0.4088725447654724
train_iter_loss: 0.1762901097536087
train_iter_loss: 0.19535396993160248
train_iter_loss: 0.26143231987953186
train_iter_loss: 0.29649272561073303
train_iter_loss: 0.3087064027786255
train_iter_loss: 0.26617226004600525
train_iter_loss: 0.24769198894500732
train_iter_loss: 0.17062415182590485
train_iter_loss: 0.1852550506591797
train_iter_loss: 0.2002149075269699
train_iter_loss: 0.28708764910697937
train_iter_loss: 0.18520492315292358
train_iter_loss: 0.2146640568971634
train_iter_loss: 0.26966729760169983
train_iter_loss: 0.18626317381858826
train_iter_loss: 0.1831437051296234
train_iter_loss: 0.17545244097709656
train_iter_loss: 0.2624712288379669
train_iter_loss: 0.24842633306980133
train_iter_loss: 0.2071903496980667
train_iter_loss: 0.2936262786388397
train_iter_loss: 0.36373579502105713
train_iter_loss: 0.24598829448223114
train_iter_loss: 0.17284011840820312
train_iter_loss: 0.33225715160369873
train_iter_loss: 0.18617093563079834
train_iter_loss: 0.21166762709617615
train_iter_loss: 0.20636433362960815
train_iter_loss: 0.1914968639612198
train_iter_loss: 0.21928748488426208
train_iter_loss: 0.2430938482284546
train_iter_loss: 0.1776135265827179
train_iter_loss: 0.22570954263210297
train_iter_loss: 0.20002929866313934
train_iter_loss: 0.21694782376289368
train_iter_loss: 0.3766896724700928
train_iter_loss: 0.2127968668937683
train_iter_loss: 0.3210281431674957
train_iter_loss: 0.2018209993839264
train_iter_loss: 0.2392902821302414
train_iter_loss: 0.21965456008911133
train_iter_loss: 0.25381550192832947
train_iter_loss: 0.2095431685447693
train_iter_loss: 0.2340715229511261
train_iter_loss: 0.36561593413352966
train_iter_loss: 0.1951618790626526
train_iter_loss: 0.1880027949810028
train_iter_loss: 0.3392399847507477
train_iter_loss: 0.19281423091888428
train_iter_loss: 0.17670387029647827
train_iter_loss: 0.20973077416419983
train_iter_loss: 0.2848617732524872
train_iter_loss: 0.2631392478942871
train_iter_loss: 0.2149394452571869
train_iter_loss: 0.22719432413578033
train_iter_loss: 0.22909879684448242
train_iter_loss: 0.30726051330566406
train_iter_loss: 0.30998778343200684
train_iter_loss: 0.28157058358192444
train_iter_loss: 0.3154509365558624
train_iter_loss: 0.24833281338214874
train_iter_loss: 0.21505649387836456
train_iter_loss: 0.32891735434532166
train_iter_loss: 0.19819916784763336
train_iter_loss: 0.28694432973861694
train_iter_loss: 0.2511340379714966
train_iter_loss: 0.4980303645133972
train_iter_loss: 0.2497456967830658
train_iter_loss: 0.24911285936832428
train_iter_loss: 0.3001871109008789
train_iter_loss: 0.20467710494995117
train_iter_loss: 0.22675204277038574
train_iter_loss: 0.2986159920692444
train loss :0.2532
---------------------
Validation seg loss: 0.3027209998020586 at epoch 48
epoch =     49/  1000, exp = train
train_iter_loss: 0.28420084714889526
train_iter_loss: 0.24923835694789886
train_iter_loss: 0.25702351331710815
train_iter_loss: 0.2299501597881317
train_iter_loss: 0.2535090744495392
train_iter_loss: 0.23312252759933472
train_iter_loss: 0.23422807455062866
train_iter_loss: 0.2583054304122925
train_iter_loss: 0.2376873791217804
train_iter_loss: 0.18892869353294373
train_iter_loss: 0.18276286125183105
train_iter_loss: 0.27818745374679565
train_iter_loss: 0.22697694599628448
train_iter_loss: 0.171412393450737
train_iter_loss: 0.18151521682739258
train_iter_loss: 0.2877178490161896
train_iter_loss: 0.40511059761047363
train_iter_loss: 0.33866679668426514
train_iter_loss: 0.34957343339920044
train_iter_loss: 0.29180651903152466
train_iter_loss: 0.19081027805805206
train_iter_loss: 0.22494810819625854
train_iter_loss: 0.16572625935077667
train_iter_loss: 0.21332848072052002
train_iter_loss: 0.2810932397842407
train_iter_loss: 0.3221854567527771
train_iter_loss: 0.2833176851272583
train_iter_loss: 0.28890344500541687
train_iter_loss: 0.23608079552650452
train_iter_loss: 0.26278066635131836
train_iter_loss: 0.2723325192928314
train_iter_loss: 0.24140918254852295
train_iter_loss: 0.2582551836967468
train_iter_loss: 0.2918410003185272
train_iter_loss: 0.23357653617858887
train_iter_loss: 0.24541665613651276
train_iter_loss: 0.32969915866851807
train_iter_loss: 0.25778138637542725
train_iter_loss: 0.26630792021751404
train_iter_loss: 0.22521989047527313
train_iter_loss: 0.3012158274650574
train_iter_loss: 0.2954246997833252
train_iter_loss: 0.2140137255191803
train_iter_loss: 0.23646916449069977
train_iter_loss: 0.21938006579875946
train_iter_loss: 0.2326580435037613
train_iter_loss: 0.2076321691274643
train_iter_loss: 0.2341732680797577
train_iter_loss: 0.22029830515384674
train_iter_loss: 0.2125462144613266
train_iter_loss: 0.2627200782299042
train_iter_loss: 0.269262433052063
train_iter_loss: 0.3185754120349884
train_iter_loss: 0.2604350447654724
train_iter_loss: 0.22050583362579346
train_iter_loss: 0.21359407901763916
train_iter_loss: 0.2823638319969177
train_iter_loss: 0.23111730813980103
train_iter_loss: 0.20104141533374786
train_iter_loss: 0.21132391691207886
train_iter_loss: 0.3160113990306854
train_iter_loss: 0.16273486614227295
train_iter_loss: 0.30872347950935364
train_iter_loss: 0.20376673340797424
train_iter_loss: 0.3313664495944977
train_iter_loss: 0.253150999546051
train_iter_loss: 0.34159988164901733
train_iter_loss: 0.26737838983535767
train_iter_loss: 0.1956481784582138
train_iter_loss: 0.3717125654220581
train_iter_loss: 0.22369462251663208
train_iter_loss: 0.21481843292713165
train_iter_loss: 0.23798097670078278
train_iter_loss: 0.23937302827835083
train_iter_loss: 0.3936072885990143
train_iter_loss: 0.25025177001953125
train_iter_loss: 0.32833385467529297
train_iter_loss: 0.30034300684928894
train_iter_loss: 0.21134614944458008
train_iter_loss: 0.22071997821331024
train_iter_loss: 0.1743427813053131
train_iter_loss: 0.28779909014701843
train_iter_loss: 0.24729177355766296
train_iter_loss: 0.25401291251182556
train_iter_loss: 0.31377822160720825
train_iter_loss: 0.20770812034606934
train_iter_loss: 0.20132218301296234
train_iter_loss: 0.18557588756084442
train_iter_loss: 0.22412808239459991
train_iter_loss: 0.25677916407585144
train_iter_loss: 0.27069053053855896
train_iter_loss: 0.29417911171913147
train_iter_loss: 0.3151494562625885
train_iter_loss: 0.2544516324996948
train_iter_loss: 0.18426275253295898
train_iter_loss: 0.18482252955436707
train_iter_loss: 0.23941335082054138
train_iter_loss: 0.36224883794784546
train_iter_loss: 0.1887921243906021
train_iter_loss: 0.20561809837818146
train_iter_loss: 0.3144296705722809
train_iter_loss: 0.20931954681873322
train_iter_loss: 0.2646406888961792
train_iter_loss: 0.26934051513671875
train_iter_loss: 0.3555581271648407
train_iter_loss: 0.257060170173645
train_iter_loss: 0.20142315328121185
train_iter_loss: 0.23744350671768188
train_iter_loss: 0.2904577851295471
train_iter_loss: 0.3334505259990692
train_iter_loss: 0.1946476399898529
train_iter_loss: 0.2147846817970276
train_iter_loss: 0.19896745681762695
train_iter_loss: 0.21635310351848602
train_iter_loss: 0.27440351247787476
train_iter_loss: 0.21435005962848663
train_iter_loss: 0.2609175145626068
train_iter_loss: 0.1982913762331009
train_iter_loss: 0.2626507878303528
train_iter_loss: 0.2453477531671524
train_iter_loss: 0.20171098411083221
train_iter_loss: 0.22638268768787384
train_iter_loss: 0.25909069180488586
train_iter_loss: 0.21294595301151276
train_iter_loss: 0.24624083936214447
train_iter_loss: 0.24753062427043915
train_iter_loss: 0.2577413022518158
train_iter_loss: 0.26508641242980957
train_iter_loss: 0.17447678744792938
train_iter_loss: 0.2543794810771942
train_iter_loss: 0.2212551385164261
train_iter_loss: 0.23238913714885712
train_iter_loss: 0.28213340044021606
train_iter_loss: 0.233802929520607
train_iter_loss: 0.3504350185394287
train_iter_loss: 0.2628447115421295
train_iter_loss: 0.27349406480789185
train_iter_loss: 0.2381264865398407
train_iter_loss: 0.21264050900936127
train_iter_loss: 0.26595160365104675
train_iter_loss: 0.39747706055641174
train_iter_loss: 0.21408085525035858
train_iter_loss: 0.26672908663749695
train_iter_loss: 0.19126521050930023
train_iter_loss: 0.1893046498298645
train_iter_loss: 0.2503940761089325
train_iter_loss: 0.24796541035175323
train_iter_loss: 0.3157222867012024
train_iter_loss: 0.17782950401306152
train_iter_loss: 0.22108058631420135
train_iter_loss: 0.21772460639476776
train_iter_loss: 0.27280503511428833
train_iter_loss: 0.2764425575733185
train_iter_loss: 0.21958118677139282
train_iter_loss: 0.20289181172847748
train_iter_loss: 0.20697736740112305
train_iter_loss: 0.2733975946903229
train_iter_loss: 0.26116329431533813
train_iter_loss: 0.2014918476343155
train_iter_loss: 0.23561178147792816
train_iter_loss: 0.22185973823070526
train_iter_loss: 0.2574414312839508
train_iter_loss: 0.3001280128955841
train_iter_loss: 0.28403711318969727
train_iter_loss: 0.23011918365955353
train_iter_loss: 0.2280200570821762
train_iter_loss: 0.23566646873950958
train_iter_loss: 0.23445741832256317
train_iter_loss: 0.23491816222667694
train_iter_loss: 0.20780642330646515
train_iter_loss: 0.23219743371009827
train_iter_loss: 0.23841550946235657
train_iter_loss: 0.2992875576019287
train_iter_loss: 0.24413570761680603
train_iter_loss: 0.1986851990222931
train_iter_loss: 0.21275442838668823
train_iter_loss: 0.22647693753242493
train_iter_loss: 0.2085624784231186
train_iter_loss: 0.2547609508037567
train_iter_loss: 0.27894648909568787
train_iter_loss: 0.23422421514987946
train_iter_loss: 0.21016106009483337
train_iter_loss: 0.25547486543655396
train_iter_loss: 0.2512105405330658
train_iter_loss: 0.2651064395904541
train_iter_loss: 0.20982998609542847
train_iter_loss: 0.23306505382061005
train_iter_loss: 0.2064286768436432
train_iter_loss: 0.2127443253993988
train_iter_loss: 0.23075151443481445
train_iter_loss: 0.2447427660226822
train_iter_loss: 0.2446081042289734
train_iter_loss: 0.22818276286125183
train_iter_loss: 0.22041314840316772
train_iter_loss: 0.2667718231678009
train_iter_loss: 0.23800601065158844
train_iter_loss: 0.3194538950920105
train_iter_loss: 0.27408185601234436
train_iter_loss: 0.19637371599674225
train_iter_loss: 0.3785124719142914
train loss :0.2504
---------------------
Validation seg loss: 0.3047876941426745 at epoch 49
epoch =     50/  1000, exp = train
train_iter_loss: 0.26888859272003174
train_iter_loss: 0.34242984652519226
train_iter_loss: 0.1937757283449173
train_iter_loss: 0.3147949278354645
train_iter_loss: 0.24762749671936035
train_iter_loss: 0.206262469291687
train_iter_loss: 0.38781091570854187
train_iter_loss: 0.29760292172431946
train_iter_loss: 0.2118036150932312
train_iter_loss: 0.2320420742034912
train_iter_loss: 0.30730050802230835
train_iter_loss: 0.18574972450733185
train_iter_loss: 0.20757463574409485
train_iter_loss: 0.21187850832939148
train_iter_loss: 0.2055768072605133
train_iter_loss: 0.3326459527015686
train_iter_loss: 0.22308170795440674
train_iter_loss: 0.2459808886051178
train_iter_loss: 0.23389707505702972
train_iter_loss: 0.19528727233409882
train_iter_loss: 0.27451327443122864
train_iter_loss: 0.16951723396778107
train_iter_loss: 0.21453481912612915
train_iter_loss: 0.2560274004936218
train_iter_loss: 0.2856319844722748
train_iter_loss: 0.19481097161769867
train_iter_loss: 0.22272323071956635
train_iter_loss: 0.1896224319934845
train_iter_loss: 0.20144154131412506
train_iter_loss: 0.24707001447677612
train_iter_loss: 0.2572166919708252
train_iter_loss: 0.18705067038536072
train_iter_loss: 0.23800137639045715
train_iter_loss: 0.17358927428722382
train_iter_loss: 0.2483089715242386
train_iter_loss: 0.24024628102779388
train_iter_loss: 0.2240932136774063
train_iter_loss: 0.19659323990345
train_iter_loss: 0.20575976371765137
train_iter_loss: 0.24080915749073029
train_iter_loss: 0.2333924025297165
train_iter_loss: 0.2719893753528595
train_iter_loss: 0.2889273166656494
train_iter_loss: 0.19633382558822632
train_iter_loss: 0.2122945487499237
train_iter_loss: 0.2045465111732483
train_iter_loss: 0.25621020793914795
train_iter_loss: 0.24976395070552826
train_iter_loss: 0.19747811555862427
train_iter_loss: 0.20079754292964935
train_iter_loss: 0.2365112453699112
train_iter_loss: 0.21592824161052704
train_iter_loss: 0.2402513176202774
train_iter_loss: 0.37238016724586487
train_iter_loss: 0.26065632700920105
train_iter_loss: 0.2977190315723419
train_iter_loss: 0.20360223948955536
train_iter_loss: 0.21178515255451202
train_iter_loss: 0.2227163463830948
train_iter_loss: 0.20920373499393463
train_iter_loss: 0.2409304678440094
train_iter_loss: 0.23164910078048706
train_iter_loss: 0.2708997428417206
train_iter_loss: 0.30065158009529114
train_iter_loss: 0.2572574019432068
train_iter_loss: 0.21707504987716675
train_iter_loss: 0.2574075758457184
train_iter_loss: 0.35267460346221924
train_iter_loss: 0.23906412720680237
train_iter_loss: 0.21550250053405762
train_iter_loss: 0.15334410965442657
train_iter_loss: 0.1989055573940277
train_iter_loss: 0.37779685854911804
train_iter_loss: 0.2314709722995758
train_iter_loss: 0.25066685676574707
train_iter_loss: 0.27584895491600037
train_iter_loss: 0.22862347960472107
train_iter_loss: 0.26825761795043945
train_iter_loss: 0.26632413268089294
train_iter_loss: 0.26680538058280945
train_iter_loss: 0.20964518189430237
train_iter_loss: 0.2565292716026306
train_iter_loss: 0.2538510262966156
train_iter_loss: 0.22554880380630493
train_iter_loss: 0.22041243314743042
train_iter_loss: 0.2520930767059326
train_iter_loss: 0.27021482586860657
train_iter_loss: 0.312361478805542
train_iter_loss: 0.23881466686725616
train_iter_loss: 0.23191922903060913
train_iter_loss: 0.17460550367832184
train_iter_loss: 0.2411474883556366
train_iter_loss: 0.2538895010948181
train_iter_loss: 0.24682500958442688
train_iter_loss: 0.23242618143558502
train_iter_loss: 0.21424877643585205
train_iter_loss: 0.20844098925590515
train_iter_loss: 0.2311507910490036
train_iter_loss: 0.26468998193740845
train_iter_loss: 0.3828979432582855
train_iter_loss: 0.25450336933135986
train_iter_loss: 0.2578188180923462
train_iter_loss: 0.2971232533454895
train_iter_loss: 0.21697506308555603
train_iter_loss: 0.30329403281211853
train_iter_loss: 0.31668367981910706
train_iter_loss: 0.23604190349578857
train_iter_loss: 0.2042449563741684
train_iter_loss: 0.2689262330532074
train_iter_loss: 0.3397364318370819
train_iter_loss: 0.25998029112815857
train_iter_loss: 0.3976319432258606
train_iter_loss: 0.2438538372516632
train_iter_loss: 0.19637958705425262
train_iter_loss: 0.2141028791666031
train_iter_loss: 0.26764318346977234
train_iter_loss: 0.24680066108703613
train_iter_loss: 0.205668106675148
train_iter_loss: 0.22107458114624023
train_iter_loss: 0.2245130091905594
train_iter_loss: 0.18939633667469025
train_iter_loss: 0.24066968262195587
train_iter_loss: 0.29416424036026
train_iter_loss: 0.3192378580570221
train_iter_loss: 0.19962231814861298
train_iter_loss: 0.3751705288887024
train_iter_loss: 0.2005382776260376
train_iter_loss: 0.30009040236473083
train_iter_loss: 0.1965552568435669
train_iter_loss: 0.23541024327278137
train_iter_loss: 0.35655805468559265
train_iter_loss: 0.22567711770534515
train_iter_loss: 0.33053186535835266
train_iter_loss: 0.20001068711280823
train_iter_loss: 0.21156853437423706
train_iter_loss: 0.18852387368679047
train_iter_loss: 0.17042675614356995
train_iter_loss: 0.24402718245983124
train_iter_loss: 0.29788440465927124
train_iter_loss: 0.24550098180770874
train_iter_loss: 0.21241894364356995
train_iter_loss: 0.19813339412212372
train_iter_loss: 0.45228567719459534
train_iter_loss: 0.306819349527359
train_iter_loss: 0.2410816252231598
train_iter_loss: 0.17576847970485687
train_iter_loss: 0.27228057384490967
train_iter_loss: 0.2090630680322647
train_iter_loss: 0.22951124608516693
train_iter_loss: 0.21923492848873138
train_iter_loss: 0.2186785638332367
train_iter_loss: 0.19786033034324646
train_iter_loss: 0.25107550621032715
train_iter_loss: 0.23424339294433594
train_iter_loss: 0.2581329643726349
train_iter_loss: 0.2081255167722702
train_iter_loss: 0.2191709727048874
train_iter_loss: 0.24544192850589752
train_iter_loss: 0.23191507160663605
train_iter_loss: 0.2941073477268219
train_iter_loss: 0.2806302309036255
train_iter_loss: 0.23439671099185944
train_iter_loss: 0.23721398413181305
train_iter_loss: 0.2998766601085663
train_iter_loss: 0.20892785489559174
train_iter_loss: 0.2347594052553177
train_iter_loss: 0.18303312361240387
train_iter_loss: 0.19654440879821777
train_iter_loss: 0.22418077290058136
train_iter_loss: 0.2861071825027466
train_iter_loss: 0.22792214155197144
train_iter_loss: 0.25595682859420776
train_iter_loss: 0.2282213717699051
train_iter_loss: 0.2781343162059784
train_iter_loss: 0.3924938440322876
train_iter_loss: 0.2441829890012741
train_iter_loss: 0.22329862415790558
train_iter_loss: 0.20187537372112274
train_iter_loss: 0.24745319783687592
train_iter_loss: 0.19789747893810272
train_iter_loss: 0.32574644684791565
train_iter_loss: 0.2360396683216095
train_iter_loss: 0.23930537700653076
train_iter_loss: 0.2539212703704834
train_iter_loss: 0.3760825991630554
train_iter_loss: 0.23448973894119263
train_iter_loss: 0.3219279646873474
train_iter_loss: 0.18637996912002563
train_iter_loss: 0.21152862906455994
train_iter_loss: 0.2600925862789154
train_iter_loss: 0.26290059089660645
train_iter_loss: 0.3593807518482208
train_iter_loss: 0.20231743156909943
train_iter_loss: 0.2791872024536133
train_iter_loss: 0.2248767763376236
train_iter_loss: 0.21603117883205414
train_iter_loss: 0.2179686427116394
train_iter_loss: 0.27642616629600525
train_iter_loss: 0.391837477684021
train_iter_loss: 0.3523356020450592
train loss :0.2498
---------------------
Validation seg loss: 0.3032663791387711 at epoch 50
epoch =     51/  1000, exp = train
train_iter_loss: 0.34334349632263184
train_iter_loss: 0.1916281282901764
train_iter_loss: 0.26408466696739197
train_iter_loss: 0.24515023827552795
train_iter_loss: 0.24452610313892365
train_iter_loss: 0.25470978021621704
train_iter_loss: 0.2631238102912903
train_iter_loss: 0.2068127691745758
train_iter_loss: 0.263378381729126
train_iter_loss: 0.3243027329444885
train_iter_loss: 0.24959436058998108
train_iter_loss: 0.21998713910579681
train_iter_loss: 0.15410538017749786
train_iter_loss: 0.2488335818052292
train_iter_loss: 0.2676795721054077
train_iter_loss: 0.19093057513237
train_iter_loss: 0.3449162542819977
train_iter_loss: 0.2512020766735077
train_iter_loss: 0.2627987861633301
train_iter_loss: 0.24040421843528748
train_iter_loss: 0.2973497211933136
train_iter_loss: 0.3713192641735077
train_iter_loss: 0.2113892138004303
train_iter_loss: 0.2902432978153229
train_iter_loss: 0.2452247142791748
train_iter_loss: 0.22128598392009735
train_iter_loss: 0.31184816360473633
train_iter_loss: 0.18078643083572388
train_iter_loss: 0.2673817276954651
train_iter_loss: 0.26208826899528503
train_iter_loss: 0.19139288365840912
train_iter_loss: 0.20589207112789154
train_iter_loss: 0.21687912940979004
train_iter_loss: 0.2180262804031372
train_iter_loss: 0.39706841111183167
train_iter_loss: 0.27237704396247864
train_iter_loss: 0.31905972957611084
train_iter_loss: 0.2786697447299957
train_iter_loss: 0.31033509969711304
train_iter_loss: 0.19931980967521667
train_iter_loss: 0.28827595710754395
train_iter_loss: 0.1778932809829712
train_iter_loss: 0.22195932269096375
train_iter_loss: 0.2168075442314148
train_iter_loss: 0.22315193712711334
train_iter_loss: 0.2966768741607666
train_iter_loss: 0.2847973108291626
train_iter_loss: 0.2654356062412262
train_iter_loss: 0.20705384016036987
train_iter_loss: 0.20667225122451782
train_iter_loss: 0.22762760519981384
train_iter_loss: 0.2562028169631958
train_iter_loss: 0.3738096058368683
train_iter_loss: 0.2810896039009094
train_iter_loss: 0.2462802529335022
train_iter_loss: 0.24319767951965332
train_iter_loss: 0.22001224756240845
train_iter_loss: 0.20284898579120636
train_iter_loss: 0.24577440321445465
train_iter_loss: 0.22076943516731262
train_iter_loss: 0.2542058527469635
train_iter_loss: 0.27483680844306946
train_iter_loss: 0.18985866010189056
train_iter_loss: 0.2677554190158844
train_iter_loss: 0.25087302923202515
train_iter_loss: 0.2632361650466919
train_iter_loss: 0.24096302688121796
train_iter_loss: 0.2427210956811905
train_iter_loss: 0.21755976974964142
train_iter_loss: 0.20500393211841583
train_iter_loss: 0.19638174772262573
train_iter_loss: 0.25011298060417175
train_iter_loss: 0.21760068833827972
train_iter_loss: 0.24709133803844452
train_iter_loss: 0.22178663313388824
train_iter_loss: 0.2672359347343445
train_iter_loss: 0.2210370898246765
train_iter_loss: 0.27172785997390747
train_iter_loss: 0.30626511573791504
train_iter_loss: 0.2369750589132309
train_iter_loss: 0.21767325699329376
train_iter_loss: 0.20912542939186096
train_iter_loss: 0.22655633091926575
train_iter_loss: 0.22429953515529633
train_iter_loss: 0.24362622201442719
train_iter_loss: 0.24297015368938446
train_iter_loss: 0.23609234392642975
train_iter_loss: 0.25286200642585754
train_iter_loss: 0.3222580850124359
train_iter_loss: 0.22950461506843567
train_iter_loss: 0.20478932559490204
train_iter_loss: 0.2131315916776657
train_iter_loss: 0.21981801092624664
train_iter_loss: 0.32030367851257324
train_iter_loss: 0.20140725374221802
train_iter_loss: 0.33320966362953186
train_iter_loss: 0.22459787130355835
train_iter_loss: 0.21472330391407013
train_iter_loss: 0.22235998511314392
train_iter_loss: 0.21520082652568817
train_iter_loss: 0.25240200757980347
train_iter_loss: 0.3234896957874298
train_iter_loss: 0.1957213133573532
train_iter_loss: 0.18151827156543732
train_iter_loss: 0.29249635338783264
train_iter_loss: 0.23739434778690338
train_iter_loss: 0.2347547560930252
train_iter_loss: 0.23562434315681458
train_iter_loss: 0.23866713047027588
train_iter_loss: 0.32209572196006775
train_iter_loss: 0.23142628371715546
train_iter_loss: 0.32077088952064514
train_iter_loss: 0.28737083077430725
train_iter_loss: 0.24560800194740295
train_iter_loss: 0.23520013689994812
train_iter_loss: 0.23316869139671326
train_iter_loss: 0.23478560149669647
train_iter_loss: 0.17617803812026978
train_iter_loss: 0.2380586862564087
train_iter_loss: 0.18242597579956055
train_iter_loss: 0.45831766724586487
train_iter_loss: 0.240400031208992
train_iter_loss: 0.19991444051265717
train_iter_loss: 0.2042361944913864
train_iter_loss: 0.20552189648151398
train_iter_loss: 0.183182492852211
train_iter_loss: 0.2330402135848999
train_iter_loss: 0.18141140043735504
train_iter_loss: 0.20744304358959198
train_iter_loss: 0.1705186516046524
train_iter_loss: 0.26859715580940247
train_iter_loss: 0.2654839754104614
train_iter_loss: 0.2218305915594101
train_iter_loss: 0.20908966660499573
train_iter_loss: 0.27485552430152893
train_iter_loss: 0.26730677485466003
train_iter_loss: 0.23565508425235748
train_iter_loss: 0.2687743008136749
train_iter_loss: 0.2633645832538605
train_iter_loss: 0.23938290774822235
train_iter_loss: 0.22037623822689056
train_iter_loss: 0.28824877738952637
train_iter_loss: 0.19144128262996674
train_iter_loss: 0.23069438338279724
train_iter_loss: 0.2907680571079254
train_iter_loss: 0.2610514461994171
train_iter_loss: 0.2216375470161438
train_iter_loss: 0.39217203855514526
train_iter_loss: 0.25210079550743103
train_iter_loss: 0.2062397450208664
train_iter_loss: 0.20091968774795532
train_iter_loss: 0.17675372958183289
train_iter_loss: 0.3538118898868561
train_iter_loss: 0.25109899044036865
train_iter_loss: 0.24867373704910278
train_iter_loss: 0.2424316257238388
train_iter_loss: 0.28786176443099976
train_iter_loss: 0.21988612413406372
train_iter_loss: 0.23318509757518768
train_iter_loss: 0.18087942898273468
train_iter_loss: 0.3379032611846924
train_iter_loss: 0.2272244691848755
train_iter_loss: 0.3095954954624176
train_iter_loss: 0.2979017198085785
train_iter_loss: 0.2609902620315552
train_iter_loss: 0.20587946474552155
train_iter_loss: 0.19998885691165924
train_iter_loss: 0.24271312355995178
train_iter_loss: 0.21903768181800842
train_iter_loss: 0.19955110549926758
train_iter_loss: 0.19044551253318787
train_iter_loss: 0.275864839553833
train_iter_loss: 0.2071082592010498
train_iter_loss: 0.1983635574579239
train_iter_loss: 0.25323566794395447
train_iter_loss: 0.2574925422668457
train_iter_loss: 0.2447974681854248
train_iter_loss: 0.20890818536281586
train_iter_loss: 0.22977593541145325
train_iter_loss: 0.22368496656417847
train_iter_loss: 0.24528561532497406
train_iter_loss: 0.25099116563796997
train_iter_loss: 0.27843719720840454
train_iter_loss: 0.41170182824134827
train_iter_loss: 0.30122289061546326
train_iter_loss: 0.3246401250362396
train_iter_loss: 0.20968954265117645
train_iter_loss: 0.34220051765441895
train_iter_loss: 0.24244476854801178
train_iter_loss: 0.350557804107666
train_iter_loss: 0.1994275599718094
train_iter_loss: 0.17991337180137634
train_iter_loss: 0.2703212797641754
train_iter_loss: 0.2548859715461731
train_iter_loss: 0.24973773956298828
train_iter_loss: 0.1804698258638382
train_iter_loss: 0.3060760796070099
train_iter_loss: 0.23353251814842224
train_iter_loss: 0.17388160526752472
train_iter_loss: 0.28408893942832947
train loss :0.2490
---------------------
Validation seg loss: 0.3043720249859792 at epoch 51
epoch =     52/  1000, exp = train
train_iter_loss: 0.23088710010051727
train_iter_loss: 0.17819952964782715
train_iter_loss: 0.21084679663181305
train_iter_loss: 0.22234460711479187
train_iter_loss: 0.2303762286901474
train_iter_loss: 0.339480459690094
train_iter_loss: 0.26520636677742004
train_iter_loss: 0.26105624437332153
train_iter_loss: 0.2611630856990814
train_iter_loss: 0.2358914017677307
train_iter_loss: 0.2448967844247818
train_iter_loss: 0.2293930947780609
train_iter_loss: 0.3376706540584564
train_iter_loss: 0.1963716447353363
train_iter_loss: 0.21065685153007507
train_iter_loss: 0.23268093168735504
train_iter_loss: 0.2689129710197449
train_iter_loss: 0.22979815304279327
train_iter_loss: 0.2470082938671112
train_iter_loss: 0.2572491466999054
train_iter_loss: 0.22834014892578125
train_iter_loss: 0.25638729333877563
train_iter_loss: 0.26001134514808655
train_iter_loss: 0.25084635615348816
train_iter_loss: 0.2062770426273346
train_iter_loss: 0.29652857780456543
train_iter_loss: 0.27263355255126953
train_iter_loss: 0.24305997788906097
train_iter_loss: 0.24091053009033203
train_iter_loss: 0.21533635258674622
train_iter_loss: 0.2447844296693802
train_iter_loss: 0.32151058316230774
train_iter_loss: 0.25945720076560974
train_iter_loss: 0.2186143845319748
train_iter_loss: 0.1837899386882782
train_iter_loss: 0.23927879333496094
train_iter_loss: 0.33917999267578125
train_iter_loss: 0.22669285535812378
train_iter_loss: 0.2648555338382721
train_iter_loss: 0.33574897050857544
train_iter_loss: 0.26801708340644836
train_iter_loss: 0.20359157025814056
train_iter_loss: 0.20914290845394135
train_iter_loss: 0.23517699539661407
train_iter_loss: 0.2558465301990509
train_iter_loss: 0.2627958655357361
train_iter_loss: 0.2876633405685425
train_iter_loss: 0.21883249282836914
train_iter_loss: 0.2093248814344406
train_iter_loss: 0.23323233425617218
train_iter_loss: 0.22667722404003143
train_iter_loss: 0.2338266670703888
train_iter_loss: 0.2192990779876709
train_iter_loss: 0.2257927507162094
train_iter_loss: 0.2469213455915451
train_iter_loss: 0.2569405436515808
train_iter_loss: 0.22762514650821686
train_iter_loss: 0.2308979630470276
train_iter_loss: 0.2323354035615921
train_iter_loss: 0.22090047597885132
train_iter_loss: 0.25237032771110535
train_iter_loss: 0.22638848423957825
train_iter_loss: 0.22438937425613403
train_iter_loss: 0.24976471066474915
train_iter_loss: 0.18675819039344788
train_iter_loss: 0.2729997932910919
train_iter_loss: 0.2547968029975891
train_iter_loss: 0.35717299580574036
train_iter_loss: 0.25331759452819824
train_iter_loss: 0.198277086019516
train_iter_loss: 0.21995607018470764
train_iter_loss: 0.21254634857177734
train_iter_loss: 0.2209734320640564
train_iter_loss: 0.21099963784217834
train_iter_loss: 0.2821214497089386
train_iter_loss: 0.22958262264728546
train_iter_loss: 0.185164213180542
train_iter_loss: 0.2169056087732315
train_iter_loss: 0.2113814651966095
train_iter_loss: 0.27877721190452576
train_iter_loss: 0.2160431146621704
train_iter_loss: 0.22495803236961365
train_iter_loss: 0.20856189727783203
train_iter_loss: 0.23053337633609772
train_iter_loss: 0.2279459685087204
train_iter_loss: 0.21082539856433868
train_iter_loss: 0.15947426855564117
train_iter_loss: 0.21052758395671844
train_iter_loss: 0.2681441903114319
train_iter_loss: 0.2795927822589874
train_iter_loss: 0.31247377395629883
train_iter_loss: 0.18511515855789185
train_iter_loss: 0.35381683707237244
train_iter_loss: 0.2498609870672226
train_iter_loss: 0.21249397099018097
train_iter_loss: 0.3738653063774109
train_iter_loss: 0.2912118434906006
train_iter_loss: 0.2962764799594879
train_iter_loss: 0.20645096898078918
train_iter_loss: 0.3256743550300598
train_iter_loss: 0.17478300631046295
train_iter_loss: 0.19499775767326355
train_iter_loss: 0.3097594380378723
train_iter_loss: 0.2625875771045685
train_iter_loss: 0.23955994844436646
train_iter_loss: 0.2624989449977875
train_iter_loss: 0.3218801021575928
train_iter_loss: 0.19709071516990662
train_iter_loss: 0.22259950637817383
train_iter_loss: 0.2705541253089905
train_iter_loss: 0.19815589487552643
train_iter_loss: 0.2358880192041397
train_iter_loss: 0.29616838693618774
train_iter_loss: 0.3287510871887207
train_iter_loss: 0.19340917468070984
train_iter_loss: 0.1864250898361206
train_iter_loss: 0.27413225173950195
train_iter_loss: 0.21616461873054504
train_iter_loss: 0.2730037569999695
train_iter_loss: 0.2055511176586151
train_iter_loss: 0.24468159675598145
train_iter_loss: 0.2931763827800751
train_iter_loss: 0.3301958441734314
train_iter_loss: 0.24655336141586304
train_iter_loss: 0.2453899085521698
train_iter_loss: 0.3800051510334015
train_iter_loss: 0.17363253235816956
train_iter_loss: 0.29954031109809875
train_iter_loss: 0.2641816735267639
train_iter_loss: 0.2537396550178528
train_iter_loss: 0.2257329374551773
train_iter_loss: 0.1797669529914856
train_iter_loss: 0.15391568839550018
train_iter_loss: 0.25185060501098633
train_iter_loss: 0.24038274586200714
train_iter_loss: 0.2407757192850113
train_iter_loss: 0.223907470703125
train_iter_loss: 0.21043363213539124
train_iter_loss: 0.3301306962966919
train_iter_loss: 0.26632437109947205
train_iter_loss: 0.2355172336101532
train_iter_loss: 0.3009571135044098
train_iter_loss: 0.2957382798194885
train_iter_loss: 0.21349777281284332
train_iter_loss: 0.23957861959934235
train_iter_loss: 0.23909726738929749
train_iter_loss: 0.2102249562740326
train_iter_loss: 0.207589790225029
train_iter_loss: 0.1826498806476593
train_iter_loss: 0.3169308304786682
train_iter_loss: 0.26484301686286926
train_iter_loss: 0.2186676561832428
train_iter_loss: 0.21425653994083405
train_iter_loss: 0.2569335997104645
train_iter_loss: 0.31016427278518677
train_iter_loss: 0.2378775179386139
train_iter_loss: 0.23198392987251282
train_iter_loss: 0.26687031984329224
train_iter_loss: 0.28010907769203186
train_iter_loss: 0.2732791304588318
train_iter_loss: 0.15214818716049194
train_iter_loss: 0.24531717598438263
train_iter_loss: 0.1907399743795395
train_iter_loss: 0.21718496084213257
train_iter_loss: 0.2677452862262726
train_iter_loss: 0.20069335401058197
train_iter_loss: 0.17253544926643372
train_iter_loss: 0.35248658061027527
train_iter_loss: 0.4378494620323181
train_iter_loss: 0.16065096855163574
train_iter_loss: 0.20563535392284393
train_iter_loss: 0.24021100997924805
train_iter_loss: 0.2787754535675049
train_iter_loss: 0.27165186405181885
train_iter_loss: 0.19556978344917297
train_iter_loss: 0.1939595341682434
train_iter_loss: 0.2980605363845825
train_iter_loss: 0.22435262799263
train_iter_loss: 0.2617400586605072
train_iter_loss: 0.2430737316608429
train_iter_loss: 0.22491736710071564
train_iter_loss: 0.19233980774879456
train_iter_loss: 0.22039954364299774
train_iter_loss: 0.2337854504585266
train_iter_loss: 0.32373321056365967
train_iter_loss: 0.23634646832942963
train_iter_loss: 0.2688102126121521
train_iter_loss: 0.42187556624412537
train_iter_loss: 0.24101069569587708
train_iter_loss: 0.34131500124931335
train_iter_loss: 0.30569028854370117
train_iter_loss: 0.23879054188728333
train_iter_loss: 0.2743455171585083
train_iter_loss: 0.19424192607402802
train_iter_loss: 0.16151539981365204
train_iter_loss: 0.17603853344917297
train_iter_loss: 0.24175339937210083
train_iter_loss: 0.2232208102941513
train_iter_loss: 0.3596721589565277
train_iter_loss: 0.2411876767873764
train loss :0.2479
---------------------
Validation seg loss: 0.3020838501177869 at epoch 52
epoch =     53/  1000, exp = train
train_iter_loss: 0.2578257620334625
train_iter_loss: 0.27935707569122314
train_iter_loss: 0.24337784945964813
train_iter_loss: 0.23839381337165833
train_iter_loss: 0.23433510959148407
train_iter_loss: 0.3226146399974823
train_iter_loss: 0.25844240188598633
train_iter_loss: 0.20907144248485565
train_iter_loss: 0.3705618381500244
train_iter_loss: 0.21410216391086578
train_iter_loss: 0.2265203297138214
train_iter_loss: 0.21212778985500336
train_iter_loss: 0.23248960077762604
train_iter_loss: 0.22798088192939758
train_iter_loss: 0.2596515715122223
train_iter_loss: 0.2598496079444885
train_iter_loss: 0.3047860264778137
train_iter_loss: 0.2399527132511139
train_iter_loss: 0.19978000223636627
train_iter_loss: 0.19193334877490997
train_iter_loss: 0.16147613525390625
train_iter_loss: 0.2348860651254654
train_iter_loss: 0.2707349359989166
train_iter_loss: 0.21236327290534973
train_iter_loss: 0.17280247807502747
train_iter_loss: 0.27043330669403076
train_iter_loss: 0.18446317315101624
train_iter_loss: 0.24682626128196716
train_iter_loss: 0.17218182981014252
train_iter_loss: 0.20738224685192108
train_iter_loss: 0.3439812660217285
train_iter_loss: 0.27994003891944885
train_iter_loss: 0.2893073260784149
train_iter_loss: 0.18979579210281372
train_iter_loss: 0.22867684066295624
train_iter_loss: 0.2782570421695709
train_iter_loss: 0.4047951400279999
train_iter_loss: 0.18992288410663605
train_iter_loss: 0.2240244299173355
train_iter_loss: 0.22849373519420624
train_iter_loss: 0.23956993222236633
train_iter_loss: 0.23814904689788818
train_iter_loss: 0.27244433760643005
train_iter_loss: 0.3153313994407654
train_iter_loss: 0.2704305946826935
train_iter_loss: 0.2355365753173828
train_iter_loss: 0.1712372601032257
train_iter_loss: 0.20544461905956268
train_iter_loss: 0.21153192222118378
train_iter_loss: 0.22064688801765442
train_iter_loss: 0.232041135430336
train_iter_loss: 0.21458189189434052
train_iter_loss: 0.25739604234695435
train_iter_loss: 0.25654149055480957
train_iter_loss: 0.24909542500972748
train_iter_loss: 0.2320912629365921
train_iter_loss: 0.25389280915260315
train_iter_loss: 0.2630814015865326
train_iter_loss: 0.2547588050365448
train_iter_loss: 0.18710346519947052
train_iter_loss: 0.21929283440113068
train_iter_loss: 0.20589104294776917
train_iter_loss: 0.20968271791934967
train_iter_loss: 0.18931324779987335
train_iter_loss: 0.21570420265197754
train_iter_loss: 0.2578575909137726
train_iter_loss: 0.1812640279531479
train_iter_loss: 0.4135224223136902
train_iter_loss: 0.21165601909160614
train_iter_loss: 0.19326816499233246
train_iter_loss: 0.21968835592269897
train_iter_loss: 0.2838946282863617
train_iter_loss: 0.2163245975971222
train_iter_loss: 0.21481306850910187
train_iter_loss: 0.2137485146522522
train_iter_loss: 0.20344945788383484
train_iter_loss: 0.2673061788082123
train_iter_loss: 0.2493644803762436
train_iter_loss: 0.2564017176628113
train_iter_loss: 0.3010583519935608
train_iter_loss: 0.2535350024700165
train_iter_loss: 0.4727901816368103
train_iter_loss: 0.26128312945365906
train_iter_loss: 0.23785986006259918
train_iter_loss: 0.30947601795196533
train_iter_loss: 0.2686099410057068
train_iter_loss: 0.24590978026390076
train_iter_loss: 0.3964221477508545
train_iter_loss: 0.2674691379070282
train_iter_loss: 0.3165726065635681
train_iter_loss: 0.22952504456043243
train_iter_loss: 0.22020934522151947
train_iter_loss: 0.1994742602109909
train_iter_loss: 0.21796932816505432
train_iter_loss: 0.19550840556621552
train_iter_loss: 0.23017409443855286
train_iter_loss: 0.20046751201152802
train_iter_loss: 0.28754255175590515
train_iter_loss: 0.27210527658462524
train_iter_loss: 0.2228306531906128
train_iter_loss: 0.2311297059059143
train_iter_loss: 0.24568533897399902
train_iter_loss: 0.2097369134426117
train_iter_loss: 0.21917851269245148
train_iter_loss: 0.20940712094306946
train_iter_loss: 0.23349756002426147
train_iter_loss: 0.2198956161737442
train_iter_loss: 0.21829041838645935
train_iter_loss: 0.31093016266822815
train_iter_loss: 0.2213548868894577
train_iter_loss: 0.30843791365623474
train_iter_loss: 0.1740279197692871
train_iter_loss: 0.29738208651542664
train_iter_loss: 0.27085715532302856
train_iter_loss: 0.22126413881778717
train_iter_loss: 0.22020401060581207
train_iter_loss: 0.26218685507774353
train_iter_loss: 0.18539223074913025
train_iter_loss: 0.20715513825416565
train_iter_loss: 0.2657962143421173
train_iter_loss: 0.29327890276908875
train_iter_loss: 0.2716616988182068
train_iter_loss: 0.2305033653974533
train_iter_loss: 0.2294592261314392
train_iter_loss: 0.259907066822052
train_iter_loss: 0.18233110010623932
train_iter_loss: 0.234125554561615
train_iter_loss: 0.2316613644361496
train_iter_loss: 0.2235952764749527
train_iter_loss: 0.19524075090885162
train_iter_loss: 0.2288016825914383
train_iter_loss: 0.2693333029747009
train_iter_loss: 0.26536694169044495
train_iter_loss: 0.2581452429294586
train_iter_loss: 0.3660578429698944
train_iter_loss: 0.3499872386455536
train_iter_loss: 0.2394934594631195
train_iter_loss: 0.23887503147125244
train_iter_loss: 0.20294448733329773
train_iter_loss: 0.38228923082351685
train_iter_loss: 0.28757935762405396
train_iter_loss: 0.34204399585723877
train_iter_loss: 0.24782784283161163
train_iter_loss: 0.20007704198360443
train_iter_loss: 0.22447793185710907
train_iter_loss: 0.21645472943782806
train_iter_loss: 0.385570228099823
train_iter_loss: 0.26173317432403564
train_iter_loss: 0.2093058079481125
train_iter_loss: 0.1962662935256958
train_iter_loss: 0.1861717402935028
train_iter_loss: 0.20402012765407562
train_iter_loss: 0.4092913269996643
train_iter_loss: 0.36776918172836304
train_iter_loss: 0.20982521772384644
train_iter_loss: 0.21325460076332092
train_iter_loss: 0.2921757400035858
train_iter_loss: 0.23693178594112396
train_iter_loss: 0.17315538227558136
train_iter_loss: 0.23813903331756592
train_iter_loss: 0.24021877348423004
train_iter_loss: 0.253747820854187
train_iter_loss: 0.22674024105072021
train_iter_loss: 0.253928542137146
train_iter_loss: 0.25877031683921814
train_iter_loss: 0.42290404438972473
train_iter_loss: 0.2897597849369049
train_iter_loss: 0.19874373078346252
train_iter_loss: 0.2307671308517456
train_iter_loss: 0.18224650621414185
train_iter_loss: 0.22891169786453247
train_iter_loss: 0.2581253945827484
train_iter_loss: 0.2481071799993515
train_iter_loss: 0.29169735312461853
train_iter_loss: 0.26855024695396423
train_iter_loss: 0.20207436382770538
train_iter_loss: 0.2525421380996704
train_iter_loss: 0.23075032234191895
train_iter_loss: 0.27957844734191895
train_iter_loss: 0.25800183415412903
train_iter_loss: 0.25807464122772217
train_iter_loss: 0.22720152139663696
train_iter_loss: 0.24163585901260376
train_iter_loss: 0.23184454441070557
train_iter_loss: 0.26170679926872253
train_iter_loss: 0.23477691411972046
train_iter_loss: 0.2030401974916458
train_iter_loss: 0.3004818260669708
train_iter_loss: 0.18495716154575348
train_iter_loss: 0.23285670578479767
train_iter_loss: 0.3673626780509949
train_iter_loss: 0.20954583585262299
train_iter_loss: 0.1776723712682724
train_iter_loss: 0.408308744430542
train_iter_loss: 0.2608003318309784
train_iter_loss: 0.26280760765075684
train_iter_loss: 0.21688154339790344
train_iter_loss: 0.1657491773366928
train_iter_loss: 0.21715663373470306
train_iter_loss: 0.29293301701545715
train loss :0.2493
---------------------
Validation seg loss: 0.30610916383986203 at epoch 53
epoch =     54/  1000, exp = train
train_iter_loss: 0.24748434126377106
train_iter_loss: 0.4928204119205475
train_iter_loss: 0.29008379578590393
train_iter_loss: 0.19550012052059174
train_iter_loss: 0.2511587142944336
train_iter_loss: 0.23811306059360504
train_iter_loss: 0.3903578817844391
train_iter_loss: 0.2007908672094345
train_iter_loss: 0.21666081249713898
train_iter_loss: 0.22652138769626617
train_iter_loss: 0.20840449631214142
train_iter_loss: 0.21839140355587006
train_iter_loss: 0.3341326415538788
train_iter_loss: 0.25148245692253113
train_iter_loss: 0.23538780212402344
train_iter_loss: 0.20543727278709412
train_iter_loss: 0.3027063012123108
train_iter_loss: 0.24677444994449615
train_iter_loss: 0.3284551203250885
train_iter_loss: 0.36004096269607544
train_iter_loss: 0.20548327267169952
train_iter_loss: 0.21790079772472382
train_iter_loss: 0.21445953845977783
train_iter_loss: 0.2419760674238205
train_iter_loss: 0.16811300814151764
train_iter_loss: 0.20760315656661987
train_iter_loss: 0.2516287565231323
train_iter_loss: 0.28744083642959595
train_iter_loss: 0.21633191406726837
train_iter_loss: 0.1926906257867813
train_iter_loss: 0.19436964392662048
train_iter_loss: 0.19910123944282532
train_iter_loss: 0.27142059803009033
train_iter_loss: 0.3401240408420563
train_iter_loss: 0.2309606969356537
train_iter_loss: 0.19986297190189362
train_iter_loss: 0.3010781705379486
train_iter_loss: 0.174235001206398
train_iter_loss: 0.21527019143104553
train_iter_loss: 0.29405248165130615
train_iter_loss: 0.2342049777507782
train_iter_loss: 0.21403662860393524
train_iter_loss: 0.293682336807251
train_iter_loss: 0.2133568376302719
train_iter_loss: 0.21637040376663208
train_iter_loss: 0.20779022574424744
train_iter_loss: 0.24714253842830658
train_iter_loss: 0.3125491738319397
train_iter_loss: 0.22566524147987366
train_iter_loss: 0.28842729330062866
train_iter_loss: 0.22421057522296906
train_iter_loss: 0.2039441019296646
train_iter_loss: 0.24245962500572205
train_iter_loss: 0.27012571692466736
train_iter_loss: 0.28145602345466614
train_iter_loss: 0.2613575756549835
train_iter_loss: 0.24133598804473877
train_iter_loss: 0.354170560836792
train_iter_loss: 0.21119770407676697
train_iter_loss: 0.20064705610275269
train_iter_loss: 0.26683375239372253
train_iter_loss: 0.19562093913555145
train_iter_loss: 0.24422599375247955
train_iter_loss: 0.2678487300872803
train_iter_loss: 0.23270894587039948
train_iter_loss: 0.18577119708061218
train_iter_loss: 0.20323385298252106
train_iter_loss: 0.34447816014289856
train_iter_loss: 0.18971875309944153
train_iter_loss: 0.22493889927864075
train_iter_loss: 0.36733537912368774
train_iter_loss: 0.37803807854652405
train_iter_loss: 0.3070884048938751
train_iter_loss: 0.2624390423297882
train_iter_loss: 0.2484631985425949
train_iter_loss: 0.29037150740623474
train_iter_loss: 0.1888391077518463
train_iter_loss: 0.3045874834060669
train_iter_loss: 0.22318106889724731
train_iter_loss: 0.35537010431289673
train_iter_loss: 0.2661658823490143
train_iter_loss: 0.22044865787029266
train_iter_loss: 0.21290089190006256
train_iter_loss: 0.23342499136924744
train_iter_loss: 0.2872296869754791
train_iter_loss: 0.21552816033363342
train_iter_loss: 0.19687819480895996
train_iter_loss: 0.2980770468711853
train_iter_loss: 0.2128821313381195
train_iter_loss: 0.1928565800189972
train_iter_loss: 0.20167303085327148
train_iter_loss: 0.25686049461364746
train_iter_loss: 0.26759904623031616
train_iter_loss: 0.2950296700000763
train_iter_loss: 0.2535727918148041
train_iter_loss: 0.2348572462797165
train_iter_loss: 0.25982505083084106
train_iter_loss: 0.2303198277950287
train_iter_loss: 0.2055903971195221
train_iter_loss: 0.2339159995317459
train_iter_loss: 0.20004749298095703
train_iter_loss: 0.22264058887958527
train_iter_loss: 0.260088711977005
train_iter_loss: 0.28241822123527527
train_iter_loss: 0.1921783983707428
train_iter_loss: 0.21381734311580658
train_iter_loss: 0.34410277009010315
train_iter_loss: 0.27829882502555847
train_iter_loss: 0.2635238766670227
train_iter_loss: 0.2526271343231201
train_iter_loss: 0.4553365707397461
train_iter_loss: 0.23906071484088898
train_iter_loss: 0.20475716888904572
train_iter_loss: 0.2096957564353943
train_iter_loss: 0.2852308750152588
train_iter_loss: 0.2552041709423065
train_iter_loss: 0.2749894857406616
train_iter_loss: 0.25686147809028625
train_iter_loss: 0.22024182975292206
train_iter_loss: 0.2542710304260254
train_iter_loss: 0.21283230185508728
train_iter_loss: 0.2805524468421936
train_iter_loss: 0.23628385365009308
train_iter_loss: 0.2415585070848465
train_iter_loss: 0.19272015988826752
train_iter_loss: 0.17502455413341522
train_iter_loss: 0.24800525605678558
train_iter_loss: 0.23729665577411652
train_iter_loss: 0.2208883911371231
train_iter_loss: 0.2402411550283432
train_iter_loss: 0.2714974880218506
train_iter_loss: 0.22850731015205383
train_iter_loss: 0.2068084329366684
train_iter_loss: 0.23220916092395782
train_iter_loss: 0.23070290684700012
train_iter_loss: 0.1641657054424286
train_iter_loss: 0.226573646068573
train_iter_loss: 0.3065468370914459
train_iter_loss: 0.20366136729717255
train_iter_loss: 0.21407102048397064
train_iter_loss: 0.20921260118484497
train_iter_loss: 0.2563880383968353
train_iter_loss: 0.2473040521144867
train_iter_loss: 0.32401785254478455
train_iter_loss: 0.1917790323495865
train_iter_loss: 0.20249441266059875
train_iter_loss: 0.23201100528240204
train_iter_loss: 0.21857576072216034
train_iter_loss: 0.25313475728034973
train_iter_loss: 0.21706917881965637
train_iter_loss: 0.2650102376937866
train_iter_loss: 0.1704944372177124
train_iter_loss: 0.18228162825107574
train_iter_loss: 0.1937921792268753
train_iter_loss: 0.27559688687324524
train_iter_loss: 0.2686328589916229
train_iter_loss: 0.2843453884124756
train_iter_loss: 0.20364999771118164
train_iter_loss: 0.18544434010982513
train_iter_loss: 0.23065027594566345
train_iter_loss: 0.21736519038677216
train_iter_loss: 0.17819903790950775
train_iter_loss: 0.2300015687942505
train_iter_loss: 0.25272494554519653
train_iter_loss: 0.2933727502822876
train_iter_loss: 0.2134636789560318
train_iter_loss: 0.242629274725914
train_iter_loss: 0.24356843531131744
train_iter_loss: 0.2708589732646942
train_iter_loss: 0.31056714057922363
train_iter_loss: 0.37784379720687866
train_iter_loss: 0.15007276833057404
train_iter_loss: 0.2157282531261444
train_iter_loss: 0.26689445972442627
train_iter_loss: 0.18126842379570007
train_iter_loss: 0.251240998506546
train_iter_loss: 0.2537402808666229
train_iter_loss: 0.23897212743759155
train_iter_loss: 0.19539882242679596
train_iter_loss: 0.23935504257678986
train_iter_loss: 0.2748282551765442
train_iter_loss: 0.22337689995765686
train_iter_loss: 0.1854884773492813
train_iter_loss: 0.3509514033794403
train_iter_loss: 0.1822524517774582
train_iter_loss: 0.2285517305135727
train_iter_loss: 0.32066261768341064
train_iter_loss: 0.3186495304107666
train_iter_loss: 0.19929243624210358
train_iter_loss: 0.23641440272331238
train_iter_loss: 0.2675061523914337
train_iter_loss: 0.24217627942562103
train_iter_loss: 0.34238940477371216
train_iter_loss: 0.21655859053134918
train_iter_loss: 0.262716680765152
train_iter_loss: 0.23750203847885132
train_iter_loss: 0.2412840723991394
train_iter_loss: 0.22732825577259064
train_iter_loss: 0.1786905974149704
train_iter_loss: 0.23209410905838013
train loss :0.2473
---------------------
Validation seg loss: 0.3049220832873066 at epoch 54
epoch =     55/  1000, exp = train
train_iter_loss: 0.1978318840265274
train_iter_loss: 0.28744226694107056
train_iter_loss: 0.38662829995155334
train_iter_loss: 0.21215908229351044
train_iter_loss: 0.2036447823047638
train_iter_loss: 0.22251220047473907
train_iter_loss: 0.1930324137210846
train_iter_loss: 0.22966371476650238
train_iter_loss: 0.2461080551147461
train_iter_loss: 0.18212899565696716
train_iter_loss: 0.22463782131671906
train_iter_loss: 0.19496546685695648
train_iter_loss: 0.19983749091625214
train_iter_loss: 0.28633740544319153
train_iter_loss: 0.16758230328559875
train_iter_loss: 0.37546712160110474
train_iter_loss: 0.19816258549690247
train_iter_loss: 0.1993212252855301
train_iter_loss: 0.22359830141067505
train_iter_loss: 0.22244791686534882
train_iter_loss: 0.176993265748024
train_iter_loss: 0.3176778554916382
train_iter_loss: 0.21505409479141235
train_iter_loss: 0.20718726515769958
train_iter_loss: 0.32156914472579956
train_iter_loss: 0.3370685577392578
train_iter_loss: 0.23184704780578613
train_iter_loss: 0.20121166110038757
train_iter_loss: 0.2588556706905365
train_iter_loss: 0.2355874925851822
train_iter_loss: 0.4270120859146118
train_iter_loss: 0.23892252147197723
train_iter_loss: 0.2364477813243866
train_iter_loss: 0.24588553607463837
train_iter_loss: 0.2491685450077057
train_iter_loss: 0.22031840682029724
train_iter_loss: 0.2877645194530487
train_iter_loss: 0.2648952305316925
train_iter_loss: 0.19786475598812103
train_iter_loss: 0.2432476133108139
train_iter_loss: 0.2017587274312973
train_iter_loss: 0.298769474029541
train_iter_loss: 0.2975994944572449
train_iter_loss: 0.16192497313022614
train_iter_loss: 0.23738700151443481
train_iter_loss: 0.20853376388549805
train_iter_loss: 0.2084532529115677
train_iter_loss: 0.22395697236061096
train_iter_loss: 0.26242679357528687
train_iter_loss: 0.21029797196388245
train_iter_loss: 0.22029165923595428
train_iter_loss: 0.23379066586494446
train_iter_loss: 0.25378555059432983
train_iter_loss: 0.28228044509887695
train_iter_loss: 0.25910690426826477
train_iter_loss: 0.17548896372318268
train_iter_loss: 0.21170936524868011
train_iter_loss: 0.2806392014026642
train_iter_loss: 0.2368459850549698
train_iter_loss: 0.2380322366952896
train_iter_loss: 0.2090190052986145
train_iter_loss: 0.19820262491703033
train_iter_loss: 0.21775609254837036
train_iter_loss: 0.20234692096710205
train_iter_loss: 0.27503228187561035
train_iter_loss: 0.1853446513414383
train_iter_loss: 0.22843529284000397
train_iter_loss: 0.25068899989128113
train_iter_loss: 0.310812771320343
train_iter_loss: 0.2530185580253601
train_iter_loss: 0.25556761026382446
train_iter_loss: 0.20630158483982086
train_iter_loss: 0.25005683302879333
train_iter_loss: 0.2305951565504074
train_iter_loss: 0.2290223240852356
train_iter_loss: 0.20234310626983643
train_iter_loss: 0.27687984704971313
train_iter_loss: 0.2501092851161957
train_iter_loss: 0.2742658257484436
train_iter_loss: 0.22982467710971832
train_iter_loss: 0.28575852513313293
train_iter_loss: 0.2302291840314865
train_iter_loss: 0.3618924617767334
train_iter_loss: 0.19775961339473724
train_iter_loss: 0.3253263533115387
train_iter_loss: 0.2901574671268463
train_iter_loss: 0.2465898096561432
train_iter_loss: 0.2647142708301544
train_iter_loss: 0.24026188254356384
train_iter_loss: 0.22098492085933685
train_iter_loss: 0.23519058525562286
train_iter_loss: 0.24880166351795197
train_iter_loss: 0.2002713680267334
train_iter_loss: 0.21592850983142853
train_iter_loss: 0.2560158669948578
train_iter_loss: 0.19658277928829193
train_iter_loss: 0.21289657056331635
train_iter_loss: 0.21063096821308136
train_iter_loss: 0.1845882385969162
train_iter_loss: 0.20956870913505554
train_iter_loss: 0.1854211539030075
train_iter_loss: 0.2573626935482025
train_iter_loss: 0.20720523595809937
train_iter_loss: 0.21621964871883392
train_iter_loss: 0.2316514402627945
train_iter_loss: 0.19223648309707642
train_iter_loss: 0.24921168386936188
train_iter_loss: 0.23720088601112366
train_iter_loss: 0.25505104660987854
train_iter_loss: 0.2859426438808441
train_iter_loss: 0.19182194769382477
train_iter_loss: 0.23395498096942902
train_iter_loss: 0.28025081753730774
train_iter_loss: 0.21675075590610504
train_iter_loss: 0.32853564620018005
train_iter_loss: 0.23438985645771027
train_iter_loss: 0.2908981442451477
train_iter_loss: 0.2579076588153839
train_iter_loss: 0.3515275716781616
train_iter_loss: 0.2106962352991104
train_iter_loss: 0.27855461835861206
train_iter_loss: 0.2476789355278015
train_iter_loss: 0.21210679411888123
train_iter_loss: 0.2064869999885559
train_iter_loss: 0.29128625988960266
train_iter_loss: 0.19476869702339172
train_iter_loss: 0.22726574540138245
train_iter_loss: 0.19748370349407196
train_iter_loss: 0.25515446066856384
train_iter_loss: 0.31258389353752136
train_iter_loss: 0.37314894795417786
train_iter_loss: 0.331714391708374
train_iter_loss: 0.20262187719345093
train_iter_loss: 0.19238056242465973
train_iter_loss: 0.23555459082126617
train_iter_loss: 0.3200843930244446
train_iter_loss: 0.21947433054447174
train_iter_loss: 0.26067742705345154
train_iter_loss: 0.20510391891002655
train_iter_loss: 0.3153057396411896
train_iter_loss: 0.3320351839065552
train_iter_loss: 0.26067182421684265
train_iter_loss: 0.2554013729095459
train_iter_loss: 0.23651741445064545
train_iter_loss: 0.20316462218761444
train_iter_loss: 0.1815117448568344
train_iter_loss: 0.25286948680877686
train_iter_loss: 0.24990540742874146
train_iter_loss: 0.25200244784355164
train_iter_loss: 0.30114343762397766
train_iter_loss: 0.3040725290775299
train_iter_loss: 0.23299072682857513
train_iter_loss: 0.21914279460906982
train_iter_loss: 0.30053839087486267
train_iter_loss: 0.2217998206615448
train_iter_loss: 0.35314685106277466
train_iter_loss: 0.20744681358337402
train_iter_loss: 0.23247769474983215
train_iter_loss: 0.2809874713420868
train_iter_loss: 0.20961233973503113
train_iter_loss: 0.22571749985218048
train_iter_loss: 0.22526441514492035
train_iter_loss: 0.20708857476711273
train_iter_loss: 0.3238413333892822
train_iter_loss: 0.28995248675346375
train_iter_loss: 0.21292151510715485
train_iter_loss: 0.20955736935138702
train_iter_loss: 0.21115709841251373
train_iter_loss: 0.18768833577632904
train_iter_loss: 0.19230987131595612
train_iter_loss: 0.19064919650554657
train_iter_loss: 0.34376466274261475
train_iter_loss: 0.19720211625099182
train_iter_loss: 0.19847449660301208
train_iter_loss: 0.26738154888153076
train_iter_loss: 0.26130223274230957
train_iter_loss: 0.24079109728336334
train_iter_loss: 0.2619818449020386
train_iter_loss: 0.18687042593955994
train_iter_loss: 0.24003198742866516
train_iter_loss: 0.2088271528482437
train_iter_loss: 0.3329099118709564
train_iter_loss: 0.22028441727161407
train_iter_loss: 0.21208150684833527
train_iter_loss: 0.1980961263179779
train_iter_loss: 0.3598376512527466
train_iter_loss: 0.2642780840396881
train_iter_loss: 0.34845441579818726
train_iter_loss: 0.2542763948440552
train_iter_loss: 0.25975295901298523
train_iter_loss: 0.288297563791275
train_iter_loss: 0.24772197008132935
train_iter_loss: 0.25983089208602905
train_iter_loss: 0.24238353967666626
train_iter_loss: 0.3089560270309448
train_iter_loss: 0.2335476279258728
train_iter_loss: 0.28587445616722107
train_iter_loss: 0.28527113795280457
train_iter_loss: 0.2687183916568756
train_iter_loss: 0.2233058512210846
train loss :0.2467
---------------------
Validation seg loss: 0.30126158218338805 at epoch 55
********************
best_val_epoch_loss:  0.30126158218338805
MODEL UPDATED
epoch =     56/  1000, exp = train
train_iter_loss: 0.23011799156665802
train_iter_loss: 0.21112920343875885
train_iter_loss: 0.17191702127456665
train_iter_loss: 0.29395535588264465
train_iter_loss: 0.19952714443206787
train_iter_loss: 0.2297283411026001
train_iter_loss: 0.1903044730424881
train_iter_loss: 0.25713953375816345
train_iter_loss: 0.268167108297348
train_iter_loss: 0.29006364941596985
train_iter_loss: 0.37326931953430176
train_iter_loss: 0.23762015998363495
train_iter_loss: 0.27593255043029785
train_iter_loss: 0.23075193166732788
train_iter_loss: 0.19720393419265747
train_iter_loss: 0.24939166009426117
train_iter_loss: 0.2027430236339569
train_iter_loss: 0.3091093897819519
train_iter_loss: 0.2417592853307724
train_iter_loss: 0.230865940451622
train_iter_loss: 0.22208869457244873
train_iter_loss: 0.21967081725597382
train_iter_loss: 0.24083074927330017
train_iter_loss: 0.19537602365016937
train_iter_loss: 0.24479441344738007
train_iter_loss: 0.32139402627944946
train_iter_loss: 0.22030793130397797
train_iter_loss: 0.26652294397354126
train_iter_loss: 0.28071609139442444
train_iter_loss: 0.22660580277442932
train_iter_loss: 0.2059313803911209
train_iter_loss: 0.2628908157348633
train_iter_loss: 0.2827533185482025
train_iter_loss: 0.19903291761875153
train_iter_loss: 0.26724857091903687
train_iter_loss: 0.3270047605037689
train_iter_loss: 0.19625625014305115
train_iter_loss: 0.30005839467048645
train_iter_loss: 0.26490938663482666
train_iter_loss: 0.20788459479808807
train_iter_loss: 0.249455526471138
train_iter_loss: 0.2664400041103363
train_iter_loss: 0.263032466173172
train_iter_loss: 0.23464864492416382
train_iter_loss: 0.18051370978355408
train_iter_loss: 0.24829088151454926
train_iter_loss: 0.2334597408771515
train_iter_loss: 0.284359335899353
train_iter_loss: 0.2260609120130539
train_iter_loss: 0.23921436071395874
train_iter_loss: 0.188712939620018
train_iter_loss: 0.20320440828800201
train_iter_loss: 0.24595120549201965
train_iter_loss: 0.20143455266952515
train_iter_loss: 0.20250089466571808
train_iter_loss: 0.2450045347213745
train_iter_loss: 0.30948176980018616
train_iter_loss: 0.24036358296871185
train_iter_loss: 0.2756618857383728
train_iter_loss: 0.21498507261276245
train_iter_loss: 0.2433037906885147
train_iter_loss: 0.2749257981777191
train_iter_loss: 0.21456284821033478
train_iter_loss: 0.33730387687683105
train_iter_loss: 0.20763280987739563
train_iter_loss: 0.20316201448440552
train_iter_loss: 0.24916893243789673
train_iter_loss: 0.26034781336784363
train_iter_loss: 0.24308890104293823
train_iter_loss: 0.271460622549057
train_iter_loss: 0.17743639647960663
train_iter_loss: 0.27938708662986755
train_iter_loss: 0.22458581626415253
train_iter_loss: 0.20637719333171844
train_iter_loss: 0.19803449511528015
train_iter_loss: 0.25064077973365784
train_iter_loss: 0.2127988487482071
train_iter_loss: 0.27134111523628235
train_iter_loss: 0.2075008898973465
train_iter_loss: 0.1754014492034912
train_iter_loss: 0.21890190243721008
train_iter_loss: 0.2629162669181824
train_iter_loss: 0.3165285289287567
train_iter_loss: 0.1749969869852066
train_iter_loss: 0.16614364087581635
train_iter_loss: 0.3331493139266968
train_iter_loss: 0.1747397929430008
train_iter_loss: 0.227590873837471
train_iter_loss: 0.2483091950416565
train_iter_loss: 0.24243110418319702
train_iter_loss: 0.226720929145813
train_iter_loss: 0.18114635348320007
train_iter_loss: 0.28065118193626404
train_iter_loss: 0.265149861574173
train_iter_loss: 0.21288056671619415
train_iter_loss: 0.3401600122451782
train_iter_loss: 0.23572836816310883
train_iter_loss: 0.16718582808971405
train_iter_loss: 0.45382142066955566
train_iter_loss: 0.20379135012626648
train_iter_loss: 0.2881805896759033
train_iter_loss: 0.3006366491317749
train_iter_loss: 0.322299063205719
train_iter_loss: 0.19019672274589539
train_iter_loss: 0.2569875121116638
train_iter_loss: 0.32716140151023865
train_iter_loss: 0.24140609800815582
train_iter_loss: 0.22624245285987854
train_iter_loss: 0.3454740047454834
train_iter_loss: 0.20968154072761536
train_iter_loss: 0.20078741014003754
train_iter_loss: 0.2186829000711441
train_iter_loss: 0.3041132986545563
train_iter_loss: 0.2011779248714447
train_iter_loss: 0.21623264253139496
train_iter_loss: 0.23394401371479034
train_iter_loss: 0.2659238576889038
train_iter_loss: 0.2537227272987366
train_iter_loss: 0.24783428013324738
train_iter_loss: 0.22242459654808044
train_iter_loss: 0.2228097915649414
train_iter_loss: 0.26242730021476746
train_iter_loss: 0.2350406050682068
train_iter_loss: 0.20141181349754333
train_iter_loss: 0.25184008479118347
train_iter_loss: 0.20982204377651215
train_iter_loss: 0.27594196796417236
train_iter_loss: 0.26138541102409363
train_iter_loss: 0.38213056325912476
train_iter_loss: 0.21876293420791626
train_iter_loss: 0.31052908301353455
train_iter_loss: 0.16099505126476288
train_iter_loss: 0.22168143093585968
train_iter_loss: 0.24532070755958557
train_iter_loss: 0.21457618474960327
train_iter_loss: 0.23412834107875824
train_iter_loss: 0.33151161670684814
train_iter_loss: 0.2410750687122345
train_iter_loss: 0.2010144144296646
train_iter_loss: 0.22743210196495056
train_iter_loss: 0.36201560497283936
train_iter_loss: 0.1913440227508545
train_iter_loss: 0.38633161783218384
train_iter_loss: 0.32215434312820435
train_iter_loss: 0.2525605857372284
train_iter_loss: 0.20968446135520935
train_iter_loss: 0.280897855758667
train_iter_loss: 0.18182744085788727
train_iter_loss: 0.2062719762325287
train_iter_loss: 0.24458254873752594
train_iter_loss: 0.25434696674346924
train_iter_loss: 0.2268420159816742
train_iter_loss: 0.21525399386882782
train_iter_loss: 0.18224239349365234
train_iter_loss: 0.23757003247737885
train_iter_loss: 0.21893149614334106
train_iter_loss: 0.25661778450012207
train_iter_loss: 0.27824899554252625
train_iter_loss: 0.3052222430706024
train_iter_loss: 0.27507275342941284
train_iter_loss: 0.28645309805870056
train_iter_loss: 0.21694351732730865
train_iter_loss: 0.25815653800964355
train_iter_loss: 0.19375497102737427
train_iter_loss: 0.23386937379837036
train_iter_loss: 0.28041890263557434
train_iter_loss: 0.21690690517425537
train_iter_loss: 0.2134922742843628
train_iter_loss: 0.22577503323554993
train_iter_loss: 0.3172059953212738
train_iter_loss: 0.24795927107334137
train_iter_loss: 0.2721799612045288
train_iter_loss: 0.30247026681900024
train_iter_loss: 0.2622375190258026
train_iter_loss: 0.2962997555732727
train_iter_loss: 0.24964065849781036
train_iter_loss: 0.17521807551383972
train_iter_loss: 0.3735601007938385
train_iter_loss: 0.2712401747703552
train_iter_loss: 0.18400850892066956
train_iter_loss: 0.2700174152851105
train_iter_loss: 0.19803529977798462
train_iter_loss: 0.344174325466156
train_iter_loss: 0.2169530987739563
train_iter_loss: 0.18916262686252594
train_iter_loss: 0.2601948380470276
train_iter_loss: 0.20636411011219025
train_iter_loss: 0.26979759335517883
train_iter_loss: 0.1957288235425949
train_iter_loss: 0.21009127795696259
train_iter_loss: 0.3954789936542511
train_iter_loss: 0.1624189019203186
train_iter_loss: 0.21829111874103546
train_iter_loss: 0.22338858246803284
train_iter_loss: 0.21013493835926056
train_iter_loss: 0.27683138847351074
train_iter_loss: 0.1981426626443863
train_iter_loss: 0.22737137973308563
train_iter_loss: 0.2868330776691437
train_iter_loss: 0.2681063413619995
train loss :0.2473
---------------------
Validation seg loss: 0.3044956622399249 at epoch 56
epoch =     57/  1000, exp = train
train_iter_loss: 0.27011364698410034
train_iter_loss: 0.3618275821208954
train_iter_loss: 0.2628282308578491
train_iter_loss: 0.25987309217453003
train_iter_loss: 0.3402290940284729
train_iter_loss: 0.28463903069496155
train_iter_loss: 0.2361501157283783
train_iter_loss: 0.18343576788902283
train_iter_loss: 0.18317446112632751
train_iter_loss: 0.21824681758880615
train_iter_loss: 0.2849698066711426
train_iter_loss: 0.3132014572620392
train_iter_loss: 0.2588982582092285
train_iter_loss: 0.21135717630386353
train_iter_loss: 0.19012616574764252
train_iter_loss: 0.2524910867214203
train_iter_loss: 0.3039492964744568
train_iter_loss: 0.22620292007923126
train_iter_loss: 0.19886207580566406
train_iter_loss: 0.21561796963214874
train_iter_loss: 0.19390393793582916
train_iter_loss: 0.3275228440761566
train_iter_loss: 0.3973237872123718
train_iter_loss: 0.27523553371429443
train_iter_loss: 0.2566085457801819
train_iter_loss: 0.38240954279899597
train_iter_loss: 0.3601963520050049
train_iter_loss: 0.2614579200744629
train_iter_loss: 0.1881716102361679
train_iter_loss: 0.20667101442813873
train_iter_loss: 0.4485194683074951
train_iter_loss: 0.2342686653137207
train_iter_loss: 0.22802384197711945
train_iter_loss: 0.20099155604839325
train_iter_loss: 0.2718619406223297
train_iter_loss: 0.237522691488266
train_iter_loss: 0.261103093624115
train_iter_loss: 0.2429174929857254
train_iter_loss: 0.2896749973297119
train_iter_loss: 0.22347375750541687
train_iter_loss: 0.2119329869747162
train_iter_loss: 0.15871623158454895
train_iter_loss: 0.26614677906036377
train_iter_loss: 0.21426333487033844
train_iter_loss: 0.16598719358444214
train_iter_loss: 0.204843670129776
train_iter_loss: 0.20623736083507538
train_iter_loss: 0.22604697942733765
train_iter_loss: 0.21271342039108276
train_iter_loss: 0.25021544098854065
train_iter_loss: 0.2202860563993454
train_iter_loss: 0.25340405106544495
train_iter_loss: 0.24592159688472748
train_iter_loss: 0.3458944261074066
train_iter_loss: 0.19633235037326813
train_iter_loss: 0.2528659999370575
train_iter_loss: 0.23359350860118866
train_iter_loss: 0.18075156211853027
train_iter_loss: 0.27504798769950867
train_iter_loss: 0.18079310655593872
train_iter_loss: 0.24972142279148102
train_iter_loss: 0.21000555157661438
train_iter_loss: 0.34755462408065796
train_iter_loss: 0.2830248475074768
train_iter_loss: 0.2637304365634918
train_iter_loss: 0.19817031919956207
train_iter_loss: 0.22744712233543396
train_iter_loss: 0.3237650990486145
train_iter_loss: 0.22769151628017426
train_iter_loss: 0.19811782240867615
train_iter_loss: 0.17842599749565125
train_iter_loss: 0.22594991326332092
train_iter_loss: 0.2651490271091461
train_iter_loss: 0.16304539144039154
train_iter_loss: 0.2550543248653412
train_iter_loss: 0.2549607455730438
train_iter_loss: 0.3185957670211792
train_iter_loss: 0.28352606296539307
train_iter_loss: 0.2047308385372162
train_iter_loss: 0.22823919355869293
train_iter_loss: 0.26362764835357666
train_iter_loss: 0.2639818787574768
train_iter_loss: 0.23509006202220917
train_iter_loss: 0.2512797713279724
train_iter_loss: 0.2962876558303833
train_iter_loss: 0.24314624071121216
train_iter_loss: 0.19197218120098114
train_iter_loss: 0.278312087059021
train_iter_loss: 0.27326762676239014
train_iter_loss: 0.2498759776353836
train_iter_loss: 0.1968642622232437
train_iter_loss: 0.26010823249816895
train_iter_loss: 0.29475677013397217
train_iter_loss: 0.29977521300315857
train_iter_loss: 0.2124805450439453
train_iter_loss: 0.2101874053478241
train_iter_loss: 0.21845652163028717
train_iter_loss: 0.25886061787605286
train_iter_loss: 0.2586410343647003
train_iter_loss: 0.2162155956029892
train_iter_loss: 0.18117155134677887
train_iter_loss: 0.2577608823776245
train_iter_loss: 0.2693686783313751
train_iter_loss: 0.22754192352294922
train_iter_loss: 0.3501123785972595
train_iter_loss: 0.21106088161468506
train_iter_loss: 0.25620120763778687
train_iter_loss: 0.3335268795490265
train_iter_loss: 0.27911075949668884
train_iter_loss: 0.2297416776418686
train_iter_loss: 0.25976213812828064
train_iter_loss: 0.263041228055954
train_iter_loss: 0.2166484147310257
train_iter_loss: 0.18297889828681946
train_iter_loss: 0.3298262059688568
train_iter_loss: 0.21735407412052155
train_iter_loss: 0.19715601205825806
train_iter_loss: 0.22655612230300903
train_iter_loss: 0.20677419006824493
train_iter_loss: 0.21026396751403809
train_iter_loss: 0.22556617856025696
train_iter_loss: 0.1927480548620224
train_iter_loss: 0.18959970772266388
train_iter_loss: 0.27182406187057495
train_iter_loss: 0.2682756185531616
train_iter_loss: 0.21295292675495148
train_iter_loss: 0.2108549028635025
train_iter_loss: 0.17994920909404755
train_iter_loss: 0.31102609634399414
train_iter_loss: 0.17677278816699982
train_iter_loss: 0.21751265227794647
train_iter_loss: 0.31683143973350525
train_iter_loss: 0.18962417542934418
train_iter_loss: 0.26020801067352295
train_iter_loss: 0.19847293198108673
train_iter_loss: 0.251804918050766
train_iter_loss: 0.20044821500778198
train_iter_loss: 0.27181151509284973
train_iter_loss: 0.25632625818252563
train_iter_loss: 0.18227505683898926
train_iter_loss: 0.20182916522026062
train_iter_loss: 0.26266855001449585
train_iter_loss: 0.22819654643535614
train_iter_loss: 0.28177404403686523
train_iter_loss: 0.21217766404151917
train_iter_loss: 0.25873804092407227
train_iter_loss: 0.1952420473098755
train_iter_loss: 0.2237251102924347
train_iter_loss: 0.23926813900470734
train_iter_loss: 0.2470470666885376
train_iter_loss: 0.19028101861476898
train_iter_loss: 0.19001930952072144
train_iter_loss: 0.2354026585817337
train_iter_loss: 0.3044451177120209
train_iter_loss: 0.32320764660835266
train_iter_loss: 0.22539068758487701
train_iter_loss: 0.3019010126590729
train_iter_loss: 0.1717222034931183
train_iter_loss: 0.20683623850345612
train_iter_loss: 0.28884583711624146
train_iter_loss: 0.2683757245540619
train_iter_loss: 0.27087321877479553
train_iter_loss: 0.16858473420143127
train_iter_loss: 0.3525036573410034
train_iter_loss: 0.22035571932792664
train_iter_loss: 0.23053811490535736
train_iter_loss: 0.23288050293922424
train_iter_loss: 0.29008743166923523
train_iter_loss: 0.21577905118465424
train_iter_loss: 0.19664208590984344
train_iter_loss: 0.2372724711894989
train_iter_loss: 0.20339207351207733
train_iter_loss: 0.21167591214179993
train_iter_loss: 0.27718111872673035
train_iter_loss: 0.3086754381656647
train_iter_loss: 0.21035441756248474
train_iter_loss: 0.3290505111217499
train_iter_loss: 0.19385115802288055
train_iter_loss: 0.28887203335762024
train_iter_loss: 0.19870249927043915
train_iter_loss: 0.22632034122943878
train_iter_loss: 0.19515067338943481
train_iter_loss: 0.2780299782752991
train_iter_loss: 0.20818474888801575
train_iter_loss: 0.19199638068675995
train_iter_loss: 0.20770227909088135
train_iter_loss: 0.24354130029678345
train_iter_loss: 0.22994078695774078
train_iter_loss: 0.4670570492744446
train_iter_loss: 0.2590997815132141
train_iter_loss: 0.28017160296440125
train_iter_loss: 0.19390547275543213
train_iter_loss: 0.23965446650981903
train_iter_loss: 0.23802009224891663
train_iter_loss: 0.3018309473991394
train_iter_loss: 0.24887973070144653
train_iter_loss: 0.30225080251693726
train_iter_loss: 0.22235482931137085
train_iter_loss: 0.25110068917274475
train_iter_loss: 0.264771431684494
train loss :0.2470
---------------------
Validation seg loss: 0.2981229815983547 at epoch 57
********************
best_val_epoch_loss:  0.2981229815983547
MODEL UPDATED
epoch =     58/  1000, exp = train
train_iter_loss: 0.16275173425674438
train_iter_loss: 0.26220110058784485
train_iter_loss: 0.21304531395435333
train_iter_loss: 0.2826574146747589
train_iter_loss: 0.27318519353866577
train_iter_loss: 0.34024327993392944
train_iter_loss: 0.25702640414237976
train_iter_loss: 0.17944109439849854
train_iter_loss: 0.21116147935390472
train_iter_loss: 0.2569388449192047
train_iter_loss: 0.2512369751930237
train_iter_loss: 0.24467399716377258
train_iter_loss: 0.35131779313087463
train_iter_loss: 0.2094108611345291
train_iter_loss: 0.21259666979312897
train_iter_loss: 0.19952180981636047
train_iter_loss: 0.22246971726417542
train_iter_loss: 0.2693833112716675
train_iter_loss: 0.2214944064617157
train_iter_loss: 0.3014940321445465
train_iter_loss: 0.21154837310314178
train_iter_loss: 0.2017260491847992
train_iter_loss: 0.2808491587638855
train_iter_loss: 0.2045629918575287
train_iter_loss: 0.24827007949352264
train_iter_loss: 0.2588006556034088
train_iter_loss: 0.22164812684059143
train_iter_loss: 0.2496301680803299
train_iter_loss: 0.33629685640335083
train_iter_loss: 0.2885937988758087
train_iter_loss: 0.19751103222370148
train_iter_loss: 0.20454421639442444
train_iter_loss: 0.19327323138713837
train_iter_loss: 0.2524368464946747
train_iter_loss: 0.19738364219665527
train_iter_loss: 0.19242335855960846
train_iter_loss: 0.29188910126686096
train_iter_loss: 0.2692401111125946
train_iter_loss: 0.3508327305316925
train_iter_loss: 0.2747136950492859
train_iter_loss: 0.27806055545806885
train_iter_loss: 0.2763727307319641
train_iter_loss: 0.18123483657836914
train_iter_loss: 0.20942005515098572
train_iter_loss: 0.20087403059005737
train_iter_loss: 0.20182064175605774
train_iter_loss: 0.2698751986026764
train_iter_loss: 0.24442946910858154
train_iter_loss: 0.21461132168769836
train_iter_loss: 0.2419947385787964
train_iter_loss: 0.20605508983135223
train_iter_loss: 0.1941874623298645
train_iter_loss: 0.3052164316177368
train_iter_loss: 0.20343655347824097
train_iter_loss: 0.24144668877124786
train_iter_loss: 0.3105941712856293
train_iter_loss: 0.2516496777534485
train_iter_loss: 0.20586106181144714
train_iter_loss: 0.22376923263072968
train_iter_loss: 0.17205055058002472
train_iter_loss: 0.24316059052944183
train_iter_loss: 0.233958438038826
train_iter_loss: 0.16752126812934875
train_iter_loss: 0.19979077577590942
train_iter_loss: 0.24812251329421997
train_iter_loss: 0.18349546194076538
train_iter_loss: 0.25939705967903137
train_iter_loss: 0.24099284410476685
train_iter_loss: 0.23234692215919495
train_iter_loss: 0.34871619939804077
train_iter_loss: 0.2295706421136856
train_iter_loss: 0.2818484306335449
train_iter_loss: 0.2476912885904312
train_iter_loss: 0.3468816876411438
train_iter_loss: 0.23765183985233307
train_iter_loss: 0.26601171493530273
train_iter_loss: 0.18841677904129028
train_iter_loss: 0.2536987066268921
train_iter_loss: 0.2933694124221802
train_iter_loss: 0.27309855818748474
train_iter_loss: 0.29212507605552673
train_iter_loss: 0.3507886528968811
train_iter_loss: 0.25370654463768005
train_iter_loss: 0.3766174912452698
train_iter_loss: 0.29706433415412903
train_iter_loss: 0.19872742891311646
train_iter_loss: 0.3425523042678833
train_iter_loss: 0.20833051204681396
train_iter_loss: 0.20022892951965332
train_iter_loss: 0.23584821820259094
train_iter_loss: 0.296761155128479
train_iter_loss: 0.21374747157096863
train_iter_loss: 0.2384079098701477
train_iter_loss: 0.27949365973472595
train_iter_loss: 0.20899733901023865
train_iter_loss: 0.21887719631195068
train_iter_loss: 0.26329290866851807
train_iter_loss: 0.25631076097488403
train_iter_loss: 0.2651049494743347
train_iter_loss: 0.2763719856739044
train_iter_loss: 0.23767602443695068
train_iter_loss: 0.29533615708351135
train_iter_loss: 0.3625311553478241
train_iter_loss: 0.29401347041130066
train_iter_loss: 0.1909814029932022
train_iter_loss: 0.2661319673061371
train_iter_loss: 0.25103193521499634
train_iter_loss: 0.2192230075597763
train_iter_loss: 0.2675888240337372
train_iter_loss: 0.2175835520029068
train_iter_loss: 0.20931249856948853
train_iter_loss: 0.28506553173065186
train_iter_loss: 0.25017619132995605
train_iter_loss: 0.23275883495807648
train_iter_loss: 0.22179192304611206
train_iter_loss: 0.21513091027736664
train_iter_loss: 0.19672249257564545
train_iter_loss: 0.43422335386276245
train_iter_loss: 0.32305943965911865
train_iter_loss: 0.20381523668766022
train_iter_loss: 0.24194765090942383
train_iter_loss: 0.2597157061100006
train_iter_loss: 0.20711784064769745
train_iter_loss: 0.2856706380844116
train_iter_loss: 0.21304935216903687
train_iter_loss: 0.18457552790641785
train_iter_loss: 0.20142172276973724
train_iter_loss: 0.1914161890745163
train_iter_loss: 0.2516035735607147
train_iter_loss: 0.21340034902095795
train_iter_loss: 0.22174446284770966
train_iter_loss: 0.28298014402389526
train_iter_loss: 0.20101919770240784
train_iter_loss: 0.22846728563308716
train_iter_loss: 0.20321430265903473
train_iter_loss: 0.3134050965309143
train_iter_loss: 0.262661874294281
train_iter_loss: 0.1919083446264267
train_iter_loss: 0.1939357966184616
train_iter_loss: 0.2279215008020401
train_iter_loss: 0.3124794661998749
train_iter_loss: 0.21736523509025574
train_iter_loss: 0.20705486834049225
train_iter_loss: 0.24649186432361603
train_iter_loss: 0.27569523453712463
train_iter_loss: 0.1602439433336258
train_iter_loss: 0.19449208676815033
train_iter_loss: 0.20546002686023712
train_iter_loss: 0.20008602738380432
train_iter_loss: 0.37821027636528015
train_iter_loss: 0.2910803556442261
train_iter_loss: 0.1995379477739334
train_iter_loss: 0.16885636746883392
train_iter_loss: 0.2579738199710846
train_iter_loss: 0.2325718104839325
train_iter_loss: 0.18200033903121948
train_iter_loss: 0.36006295680999756
train_iter_loss: 0.21822772920131683
train_iter_loss: 0.2188335359096527
train_iter_loss: 0.22743184864521027
train_iter_loss: 0.2782159149646759
train_iter_loss: 0.24825802445411682
train_iter_loss: 0.19972430169582367
train_iter_loss: 0.28271710872650146
train_iter_loss: 0.22647543251514435
train_iter_loss: 0.2786276936531067
train_iter_loss: 0.2927604913711548
train_iter_loss: 0.20596681535243988
train_iter_loss: 0.256119966506958
train_iter_loss: 0.2420172095298767
train_iter_loss: 0.3787997364997864
train_iter_loss: 0.20891611278057098
train_iter_loss: 0.18953603506088257
train_iter_loss: 0.28995636105537415
train_iter_loss: 0.22591708600521088
train_iter_loss: 0.242017462849617
train_iter_loss: 0.17796432971954346
train_iter_loss: 0.2590700387954712
train_iter_loss: 0.20365887880325317
train_iter_loss: 0.18045611679553986
train_iter_loss: 0.2351456582546234
train_iter_loss: 0.28703391551971436
train_iter_loss: 0.23826079070568085
train_iter_loss: 0.2023318111896515
train_iter_loss: 0.30019354820251465
train_iter_loss: 0.18809294700622559
train_iter_loss: 0.19755211472511292
train_iter_loss: 0.30039578676223755
train_iter_loss: 0.22430025041103363
train_iter_loss: 0.23904812335968018
train_iter_loss: 0.2813880145549774
train_iter_loss: 0.17855121195316315
train_iter_loss: 0.305187463760376
train_iter_loss: 0.1878008246421814
train_iter_loss: 0.28287768363952637
train_iter_loss: 0.15995121002197266
train_iter_loss: 0.2301650196313858
train_iter_loss: 0.2068892866373062
train_iter_loss: 0.241109237074852
train_iter_loss: 0.22403408586978912
train loss :0.2453
---------------------
Validation seg loss: 0.3032364247823661 at epoch 58
epoch =     59/  1000, exp = train
train_iter_loss: 0.21839483082294464
train_iter_loss: 0.25717225670814514
train_iter_loss: 0.21900004148483276
train_iter_loss: 0.21674637496471405
train_iter_loss: 0.2503511905670166
train_iter_loss: 0.2155798077583313
train_iter_loss: 0.21123400330543518
train_iter_loss: 0.23339152336120605
train_iter_loss: 0.2641281485557556
train_iter_loss: 0.19120851159095764
train_iter_loss: 0.2324294149875641
train_iter_loss: 0.2894791066646576
train_iter_loss: 0.2447427213191986
train_iter_loss: 0.20507563650608063
train_iter_loss: 0.22271957993507385
train_iter_loss: 0.3683287501335144
train_iter_loss: 0.21501320600509644
train_iter_loss: 0.35529613494873047
train_iter_loss: 0.22473520040512085
train_iter_loss: 0.22440700232982635
train_iter_loss: 0.20606990158557892
train_iter_loss: 0.35329678654670715
train_iter_loss: 0.42527228593826294
train_iter_loss: 0.2235792875289917
train_iter_loss: 0.16442477703094482
train_iter_loss: 0.27366605401039124
train_iter_loss: 0.31267741322517395
train_iter_loss: 0.1908835917711258
train_iter_loss: 0.28263425827026367
train_iter_loss: 0.2079082727432251
train_iter_loss: 0.2361956238746643
train_iter_loss: 0.3814357817173004
train_iter_loss: 0.21133014559745789
train_iter_loss: 0.2688545286655426
train_iter_loss: 0.31255629658699036
train_iter_loss: 0.2736360430717468
train_iter_loss: 0.21420282125473022
train_iter_loss: 0.2349056601524353
train_iter_loss: 0.3104346692562103
train_iter_loss: 0.20948681235313416
train_iter_loss: 0.20309753715991974
train_iter_loss: 0.23707418143749237
train_iter_loss: 0.2372647374868393
train_iter_loss: 0.21888625621795654
train_iter_loss: 0.20096302032470703
train_iter_loss: 0.2768656313419342
train_iter_loss: 0.18952283263206482
train_iter_loss: 0.22371870279312134
train_iter_loss: 0.2619597315788269
train_iter_loss: 0.27841588854789734
train_iter_loss: 0.1984100043773651
train_iter_loss: 0.28110939264297485
train_iter_loss: 0.1712157279253006
train_iter_loss: 0.2229713797569275
train_iter_loss: 0.24753281474113464
train_iter_loss: 0.23603399097919464
train_iter_loss: 0.3395666778087616
train_iter_loss: 0.36878082156181335
train_iter_loss: 0.22179017961025238
train_iter_loss: 0.1855066567659378
train_iter_loss: 0.21357323229312897
train_iter_loss: 0.2694442570209503
train_iter_loss: 0.22270214557647705
train_iter_loss: 0.21659907698631287
train_iter_loss: 0.30776697397232056
train_iter_loss: 0.2185376137495041
train_iter_loss: 0.28028038144111633
train_iter_loss: 0.20341874659061432
train_iter_loss: 0.22557467222213745
train_iter_loss: 0.24323010444641113
train_iter_loss: 0.21786202490329742
train_iter_loss: 0.21553421020507812
train_iter_loss: 0.26483431458473206
train_iter_loss: 0.21316124498844147
train_iter_loss: 0.1968892514705658
train_iter_loss: 0.3290520906448364
train_iter_loss: 0.23951493203639984
train_iter_loss: 0.18822647631168365
train_iter_loss: 0.2553121745586395
train_iter_loss: 0.1762182116508484
train_iter_loss: 0.22617988288402557
train_iter_loss: 0.30237939953804016
train_iter_loss: 0.2288820594549179
train_iter_loss: 0.2798101603984833
train_iter_loss: 0.20782147347927094
train_iter_loss: 0.2954254448413849
train_iter_loss: 0.22789156436920166
train_iter_loss: 0.39611512422561646
train_iter_loss: 0.23545405268669128
train_iter_loss: 0.26762139797210693
train_iter_loss: 0.3034292757511139
train_iter_loss: 0.20811381936073303
train_iter_loss: 0.20538076758384705
train_iter_loss: 0.21859532594680786
train_iter_loss: 0.35087698698043823
train_iter_loss: 0.30510076880455017
train_iter_loss: 0.17830340564250946
train_iter_loss: 0.24741335213184357
train_iter_loss: 0.2167464792728424
train_iter_loss: 0.20255301892757416
train_iter_loss: 0.3762017488479614
train_iter_loss: 0.2596261501312256
train_iter_loss: 0.3244934380054474
train_iter_loss: 0.21219053864479065
train_iter_loss: 0.2019423544406891
train_iter_loss: 0.22160407900810242
train_iter_loss: 0.21272030472755432
train_iter_loss: 0.2795088291168213
train_iter_loss: 0.2811558246612549
train_iter_loss: 0.4168739318847656
train_iter_loss: 0.19853737950325012
train_iter_loss: 0.29296761751174927
train_iter_loss: 0.20946016907691956
train_iter_loss: 0.2317432016134262
train_iter_loss: 0.16888178884983063
train_iter_loss: 0.21450386941432953
train_iter_loss: 0.24432575702667236
train_iter_loss: 0.19399920105934143
train_iter_loss: 0.3836398422718048
train_iter_loss: 0.22935916483402252
train_iter_loss: 0.17653782665729523
train_iter_loss: 0.22392472624778748
train_iter_loss: 0.23452651500701904
train_iter_loss: 0.36271604895591736
train_iter_loss: 0.258340060710907
train_iter_loss: 0.23553691804409027
train_iter_loss: 0.279967725276947
train_iter_loss: 0.20378558337688446
train_iter_loss: 0.3350847661495209
train_iter_loss: 0.2760949730873108
train_iter_loss: 0.22355830669403076
train_iter_loss: 0.24502255022525787
train_iter_loss: 0.2320747971534729
train_iter_loss: 0.2193593680858612
train_iter_loss: 0.2652425467967987
train_iter_loss: 0.23880164325237274
train_iter_loss: 0.22906771302223206
train_iter_loss: 0.15401139855384827
train_iter_loss: 0.19370108842849731
train_iter_loss: 0.20738953351974487
train_iter_loss: 0.23860830068588257
train_iter_loss: 0.3128430247306824
train_iter_loss: 0.35128143429756165
train_iter_loss: 0.2569393813610077
train_iter_loss: 0.2228756695985794
train_iter_loss: 0.20096750557422638
train_iter_loss: 0.24073220789432526
train_iter_loss: 0.20188777148723602
train_iter_loss: 0.2099028080701828
train_iter_loss: 0.21804507076740265
train_iter_loss: 0.2187674194574356
train_iter_loss: 0.26831239461898804
train_iter_loss: 0.2128896564245224
train_iter_loss: 0.21583223342895508
train_iter_loss: 0.19602425396442413
train_iter_loss: 0.17351387441158295
train_iter_loss: 0.16055777668952942
train_iter_loss: 0.26377004384994507
train_iter_loss: 0.16790379583835602
train_iter_loss: 0.25668370723724365
train_iter_loss: 0.21773096919059753
train_iter_loss: 0.2661321461200714
train_iter_loss: 0.21305690705776215
train_iter_loss: 0.1787647008895874
train_iter_loss: 0.2425657957792282
train_iter_loss: 0.3841085135936737
train_iter_loss: 0.24481934309005737
train_iter_loss: 0.2646835744380951
train_iter_loss: 0.2650797665119171
train_iter_loss: 0.2416197508573532
train_iter_loss: 0.1691702902317047
train_iter_loss: 0.2512832581996918
train_iter_loss: 0.23719961941242218
train_iter_loss: 0.251851350069046
train_iter_loss: 0.2529188096523285
train_iter_loss: 0.17433573305606842
train_iter_loss: 0.18436315655708313
train_iter_loss: 0.23805604875087738
train_iter_loss: 0.16887351870536804
train_iter_loss: 0.18425826728343964
train_iter_loss: 0.18844890594482422
train_iter_loss: 0.26388856768608093
train_iter_loss: 0.2129783034324646
train_iter_loss: 0.21738652884960175
train_iter_loss: 0.22245904803276062
train_iter_loss: 0.23167301714420319
train_iter_loss: 0.2035624086856842
train_iter_loss: 0.23285816609859467
train_iter_loss: 0.24658134579658508
train_iter_loss: 0.24191612005233765
train_iter_loss: 0.21197980642318726
train_iter_loss: 0.20125354826450348
train_iter_loss: 0.25220948457717896
train_iter_loss: 0.2847088873386383
train_iter_loss: 0.2062942385673523
train_iter_loss: 0.3154558837413788
train_iter_loss: 0.230415940284729
train_iter_loss: 0.28362661600112915
train_iter_loss: 0.29384365677833557
train_iter_loss: 0.1681157499551773
train loss :0.2444
---------------------
Validation seg loss: 0.302601279304275 at epoch 59
epoch =     60/  1000, exp = train
train_iter_loss: 0.27230703830718994
train_iter_loss: 0.2121184915304184
train_iter_loss: 0.26271679997444153
train_iter_loss: 0.3168821632862091
train_iter_loss: 0.23600831627845764
train_iter_loss: 0.15722113847732544
train_iter_loss: 0.3004356920719147
train_iter_loss: 0.3607369065284729
train_iter_loss: 0.3588199317455292
train_iter_loss: 0.20703768730163574
train_iter_loss: 0.18154743313789368
train_iter_loss: 0.2612399160861969
train_iter_loss: 0.2551153600215912
train_iter_loss: 0.17191478610038757
train_iter_loss: 0.21018028259277344
train_iter_loss: 0.1985527127981186
train_iter_loss: 0.19010427594184875
train_iter_loss: 0.2915968894958496
train_iter_loss: 0.2054559588432312
train_iter_loss: 0.3188712000846863
train_iter_loss: 0.17540663480758667
train_iter_loss: 0.2639886140823364
train_iter_loss: 0.24184271693229675
train_iter_loss: 0.21989767253398895
train_iter_loss: 0.21569378674030304
train_iter_loss: 0.29393425583839417
train_iter_loss: 0.37979355454444885
train_iter_loss: 0.21126653254032135
train_iter_loss: 0.31224745512008667
train_iter_loss: 0.23074504733085632
train_iter_loss: 0.2621007561683655
train_iter_loss: 0.2791104018688202
train_iter_loss: 0.20923517644405365
train_iter_loss: 0.19735655188560486
train_iter_loss: 0.28353217244148254
train_iter_loss: 0.2133626937866211
train_iter_loss: 0.20888735353946686
train_iter_loss: 0.3130335509777069
train_iter_loss: 0.30596697330474854
train_iter_loss: 0.21876928210258484
train_iter_loss: 0.28875425457954407
train_iter_loss: 0.1777241826057434
train_iter_loss: 0.2206757664680481
train_iter_loss: 0.19001244008541107
train_iter_loss: 0.22350403666496277
train_iter_loss: 0.2574562728404999
train_iter_loss: 0.1855347603559494
train_iter_loss: 0.34353107213974
train_iter_loss: 0.262215793132782
train_iter_loss: 0.2776840031147003
train_iter_loss: 0.2952650487422943
train_iter_loss: 0.24625904858112335
train_iter_loss: 0.17337074875831604
train_iter_loss: 0.39854151010513306
train_iter_loss: 0.1927417516708374
train_iter_loss: 0.23712104558944702
train_iter_loss: 0.18220669031143188
train_iter_loss: 0.26313716173171997
train_iter_loss: 0.21077671647071838
train_iter_loss: 0.2055259495973587
train_iter_loss: 0.23092325031757355
train_iter_loss: 0.24637901782989502
train_iter_loss: 0.24809834361076355
train_iter_loss: 0.2803044021129608
train_iter_loss: 0.21722473204135895
train_iter_loss: 0.21041955053806305
train_iter_loss: 0.33157652616500854
train_iter_loss: 0.19119839370250702
train_iter_loss: 0.2218226194381714
train_iter_loss: 0.25488972663879395
train_iter_loss: 0.28388774394989014
train_iter_loss: 0.2642379403114319
train_iter_loss: 0.25990960001945496
train_iter_loss: 0.3438361883163452
train_iter_loss: 0.1897757351398468
train_iter_loss: 0.22205750644207
train_iter_loss: 0.1908148229122162
train_iter_loss: 0.21534712612628937
train_iter_loss: 0.23818281292915344
train_iter_loss: 0.2636677324771881
train_iter_loss: 0.24725322425365448
train_iter_loss: 0.29715901613235474
train_iter_loss: 0.3418979346752167
train_iter_loss: 0.3882669508457184
train_iter_loss: 0.2871991991996765
train_iter_loss: 0.33564531803131104
train_iter_loss: 0.24264992773532867
train_iter_loss: 0.2054327130317688
train_iter_loss: 0.3045211136341095
train_iter_loss: 0.19254401326179504
train_iter_loss: 0.2524583041667938
train_iter_loss: 0.22950896620750427
train_iter_loss: 0.18955658376216888
train_iter_loss: 0.22717982530593872
train_iter_loss: 0.19158203899860382
train_iter_loss: 0.19240619242191315
train_iter_loss: 0.2318049669265747
train_iter_loss: 0.19677139818668365
train_iter_loss: 0.25662028789520264
train_iter_loss: 0.25275474786758423
train_iter_loss: 0.23390214145183563
train_iter_loss: 0.22592705488204956
train_iter_loss: 0.21436579525470734
train_iter_loss: 0.306887686252594
train_iter_loss: 0.2416762262582779
train_iter_loss: 0.16486184298992157
train_iter_loss: 0.2187969982624054
train_iter_loss: 0.2291407436132431
train_iter_loss: 0.36243775486946106
train_iter_loss: 0.22478017210960388
train_iter_loss: 0.24042081832885742
train_iter_loss: 0.21754515171051025
train_iter_loss: 0.33859899640083313
train_iter_loss: 0.20507311820983887
train_iter_loss: 0.22552669048309326
train_iter_loss: 0.2627147436141968
train_iter_loss: 0.26491495966911316
train_iter_loss: 0.2907162010669708
train_iter_loss: 0.22532859444618225
train_iter_loss: 0.2433784455060959
train_iter_loss: 0.18115992844104767
train_iter_loss: 0.2036283165216446
train_iter_loss: 0.23002856969833374
train_iter_loss: 0.4136638045310974
train_iter_loss: 0.16816122829914093
train_iter_loss: 0.3579750955104828
train_iter_loss: 0.3091214895248413
train_iter_loss: 0.185729518532753
train_iter_loss: 0.17417161166667938
train_iter_loss: 0.26157069206237793
train_iter_loss: 0.33676519989967346
train_iter_loss: 0.26063141226768494
train_iter_loss: 0.20406711101531982
train_iter_loss: 0.26291295886039734
train_iter_loss: 0.2109469622373581
train_iter_loss: 0.24199272692203522
train_iter_loss: 0.19082005321979523
train_iter_loss: 0.19017159938812256
train_iter_loss: 0.2680260241031647
train_iter_loss: 0.22802118957042694
train_iter_loss: 0.23070663213729858
train_iter_loss: 0.2229955792427063
train_iter_loss: 0.41454386711120605
train_iter_loss: 0.21090209484100342
train_iter_loss: 0.2539539635181427
train_iter_loss: 0.3271450698375702
train_iter_loss: 0.23296765983104706
train_iter_loss: 0.23926392197608948
train_iter_loss: 0.17575915157794952
train_iter_loss: 0.2379087507724762
train_iter_loss: 0.2023598700761795
train_iter_loss: 0.16566382348537445
train_iter_loss: 0.25335633754730225
train_iter_loss: 0.2023322433233261
train_iter_loss: 0.15483912825584412
train_iter_loss: 0.23708930611610413
train_iter_loss: 0.20500591397285461
train_iter_loss: 0.2406821846961975
train_iter_loss: 0.2860107719898224
train_iter_loss: 0.2653098404407501
train_iter_loss: 0.2202678769826889
train_iter_loss: 0.23287026584148407
train_iter_loss: 0.18750904500484467
train_iter_loss: 0.20745407044887543
train_iter_loss: 0.1892268806695938
train_iter_loss: 0.26114916801452637
train_iter_loss: 0.23835517466068268
train_iter_loss: 0.19585509598255157
train_iter_loss: 0.20623302459716797
train_iter_loss: 0.2693604528903961
train_iter_loss: 0.2640319764614105
train_iter_loss: 0.27231544256210327
train_iter_loss: 0.1917484700679779
train_iter_loss: 0.32414907217025757
train_iter_loss: 0.19534417986869812
train_iter_loss: 0.19326302409172058
train_iter_loss: 0.27369359135627747
train_iter_loss: 0.2689622938632965
train_iter_loss: 0.21461288630962372
train_iter_loss: 0.2549523711204529
train_iter_loss: 0.2910225987434387
train_iter_loss: 0.20627203583717346
train_iter_loss: 0.22120791673660278
train_iter_loss: 0.22564852237701416
train_iter_loss: 0.23814757168293
train_iter_loss: 0.3986252546310425
train_iter_loss: 0.2172153741121292
train_iter_loss: 0.22070588171482086
train_iter_loss: 0.18379007279872894
train_iter_loss: 0.2551482617855072
train_iter_loss: 0.2783602178096771
train_iter_loss: 0.19786550104618073
train_iter_loss: 0.2797169089317322
train_iter_loss: 0.17910563945770264
train_iter_loss: 0.2429155856370926
train_iter_loss: 0.18753227591514587
train_iter_loss: 0.2382451593875885
train_iter_loss: 0.24695253372192383
train_iter_loss: 0.3173346519470215
train_iter_loss: 0.24267688393592834
train loss :0.2458
---------------------
Validation seg loss: 0.30092972439696203 at epoch 60
epoch =     61/  1000, exp = train
train_iter_loss: 0.16410957276821136
train_iter_loss: 0.2626722455024719
train_iter_loss: 0.3502463400363922
train_iter_loss: 0.2911709249019623
train_iter_loss: 0.21080327033996582
train_iter_loss: 0.26838380098342896
train_iter_loss: 0.2251509726047516
train_iter_loss: 0.2163476198911667
train_iter_loss: 0.2436072826385498
train_iter_loss: 0.3104698359966278
train_iter_loss: 0.2090071141719818
train_iter_loss: 0.222662091255188
train_iter_loss: 0.2173040211200714
train_iter_loss: 0.21578365564346313
train_iter_loss: 0.40277302265167236
train_iter_loss: 0.22489558160305023
train_iter_loss: 0.28038597106933594
train_iter_loss: 0.2501406669616699
train_iter_loss: 0.4047640562057495
train_iter_loss: 0.19889409840106964
train_iter_loss: 0.2352420538663864
train_iter_loss: 0.2006688416004181
train_iter_loss: 0.20350801944732666
train_iter_loss: 0.22962334752082825
train_iter_loss: 0.24929408729076385
train_iter_loss: 0.24153569340705872
train_iter_loss: 0.2161538004875183
train_iter_loss: 0.18919000029563904
train_iter_loss: 0.19488851726055145
train_iter_loss: 0.16031548380851746
train_iter_loss: 0.20804201066493988
train_iter_loss: 0.24271656572818756
train_iter_loss: 0.23269353806972504
train_iter_loss: 0.21961846947669983
train_iter_loss: 0.28467291593551636
train_iter_loss: 0.2347354143857956
train_iter_loss: 0.19731639325618744
train_iter_loss: 0.23949788510799408
train_iter_loss: 0.23219580948352814
train_iter_loss: 0.2897505462169647
train_iter_loss: 0.2621098756790161
train_iter_loss: 0.23920802772045135
train_iter_loss: 0.3061627447605133
train_iter_loss: 0.21367578208446503
train_iter_loss: 0.1900349259376526
train_iter_loss: 0.16780899465084076
train_iter_loss: 0.42725276947021484
train_iter_loss: 0.2650543749332428
train_iter_loss: 0.23497679829597473
train_iter_loss: 0.20246630907058716
train_iter_loss: 0.2378416359424591
train_iter_loss: 0.2492298185825348
train_iter_loss: 0.2478553056716919
train_iter_loss: 0.22041729092597961
train_iter_loss: 0.23469007015228271
train_iter_loss: 0.2619660198688507
train_iter_loss: 0.20186832547187805
train_iter_loss: 0.19893808662891388
train_iter_loss: 0.2037392258644104
train_iter_loss: 0.21320807933807373
train_iter_loss: 0.2090798169374466
train_iter_loss: 0.315277099609375
train_iter_loss: 0.26421353220939636
train_iter_loss: 0.2636851370334625
train_iter_loss: 0.21703162789344788
train_iter_loss: 0.3454989492893219
train_iter_loss: 0.21936041116714478
train_iter_loss: 0.1929636150598526
train_iter_loss: 0.24901865422725677
train_iter_loss: 0.1653744876384735
train_iter_loss: 0.22270742058753967
train_iter_loss: 0.2200324833393097
train_iter_loss: 0.21411795914173126
train_iter_loss: 0.30931031703948975
train_iter_loss: 0.20726369321346283
train_iter_loss: 0.3913903832435608
train_iter_loss: 0.2985059916973114
train_iter_loss: 0.1897779405117035
train_iter_loss: 0.25406700372695923
train_iter_loss: 0.29480183124542236
train_iter_loss: 0.19634512066841125
train_iter_loss: 0.2681944668292999
train_iter_loss: 0.24576568603515625
train_iter_loss: 0.19043202698230743
train_iter_loss: 0.2842246890068054
train_iter_loss: 0.1765936315059662
train_iter_loss: 0.22855155169963837
train_iter_loss: 0.1811450719833374
train_iter_loss: 0.21815691888332367
train_iter_loss: 0.18677347898483276
train_iter_loss: 0.18962688744068146
train_iter_loss: 0.187010258436203
train_iter_loss: 0.3266753554344177
train_iter_loss: 0.27642855048179626
train_iter_loss: 0.29978033900260925
train_iter_loss: 0.3295709788799286
train_iter_loss: 0.2161637246608734
train_iter_loss: 0.21683691442012787
train_iter_loss: 0.21671032905578613
train_iter_loss: 0.20181334018707275
train_iter_loss: 0.23457388579845428
train_iter_loss: 0.2176496684551239
train_iter_loss: 0.24814417958259583
train_iter_loss: 0.32639285922050476
train_iter_loss: 0.19596734642982483
train_iter_loss: 0.21633119881153107
train_iter_loss: 0.2265274077653885
train_iter_loss: 0.20306527614593506
train_iter_loss: 0.21295176446437836
train_iter_loss: 0.2134607434272766
train_iter_loss: 0.22298288345336914
train_iter_loss: 0.35468679666519165
train_iter_loss: 0.31653091311454773
train_iter_loss: 0.3265995979309082
train_iter_loss: 0.2061639279127121
train_iter_loss: 0.3222029507160187
train_iter_loss: 0.271611750125885
train_iter_loss: 0.18014617264270782
train_iter_loss: 0.23459117114543915
train_iter_loss: 0.16348105669021606
train_iter_loss: 0.3914720118045807
train_iter_loss: 0.2170393019914627
train_iter_loss: 0.2354714721441269
train_iter_loss: 0.25173449516296387
train_iter_loss: 0.18862740695476532
train_iter_loss: 0.2837364971637726
train_iter_loss: 0.2998051047325134
train_iter_loss: 0.2136850506067276
train_iter_loss: 0.18479891121387482
train_iter_loss: 0.2402336448431015
train_iter_loss: 0.16094639897346497
train_iter_loss: 0.1760009229183197
train_iter_loss: 0.24141868948936462
train_iter_loss: 0.18829801678657532
train_iter_loss: 0.2803352177143097
train_iter_loss: 0.23152434825897217
train_iter_loss: 0.17988301813602448
train_iter_loss: 0.1943674236536026
train_iter_loss: 0.20071835815906525
train_iter_loss: 0.24100448191165924
train_iter_loss: 0.19216053187847137
train_iter_loss: 0.2436177134513855
train_iter_loss: 0.18505319952964783
train_iter_loss: 0.3490283191204071
train_iter_loss: 0.3364788591861725
train_iter_loss: 0.26154813170433044
train_iter_loss: 0.25063037872314453
train_iter_loss: 0.24114541709423065
train_iter_loss: 0.19281795620918274
train_iter_loss: 0.24177253246307373
train_iter_loss: 0.2767741084098816
train_iter_loss: 0.3044431209564209
train_iter_loss: 0.3168330192565918
train_iter_loss: 0.27778682112693787
train_iter_loss: 0.19320927560329437
train_iter_loss: 0.1885494738817215
train_iter_loss: 0.22494730353355408
train_iter_loss: 0.2741178274154663
train_iter_loss: 0.2306261509656906
train_iter_loss: 0.2689703106880188
train_iter_loss: 0.2114001214504242
train_iter_loss: 0.2769618630409241
train_iter_loss: 0.24486054480075836
train_iter_loss: 0.21512219309806824
train_iter_loss: 0.22238728404045105
train_iter_loss: 0.23858968913555145
train_iter_loss: 0.3335835635662079
train_iter_loss: 0.2542746961116791
train_iter_loss: 0.2395687848329544
train_iter_loss: 0.20804119110107422
train_iter_loss: 0.23251572251319885
train_iter_loss: 0.1957544982433319
train_iter_loss: 0.21993228793144226
train_iter_loss: 0.33129191398620605
train_iter_loss: 0.23157937824726105
train_iter_loss: 0.21523867547512054
train_iter_loss: 0.25175780057907104
train_iter_loss: 0.20407690107822418
train_iter_loss: 0.2583863437175751
train_iter_loss: 0.18366774916648865
train_iter_loss: 0.21512286365032196
train_iter_loss: 0.23191653192043304
train_iter_loss: 0.2850680649280548
train_iter_loss: 0.3265015780925751
train_iter_loss: 0.20282098650932312
train_iter_loss: 0.20425334572792053
train_iter_loss: 0.2927049994468689
train_iter_loss: 0.2645491361618042
train_iter_loss: 0.2318543791770935
train_iter_loss: 0.24401463568210602
train_iter_loss: 0.2929711937904358
train_iter_loss: 0.24887631833553314
train_iter_loss: 0.2548796534538269
train_iter_loss: 0.1672937124967575
train_iter_loss: 0.2213817536830902
train_iter_loss: 0.20889048278331757
train_iter_loss: 0.3562825918197632
train_iter_loss: 0.16132496297359467
train_iter_loss: 0.23614877462387085
train_iter_loss: 0.2036176323890686
train loss :0.2427
---------------------
Validation seg loss: 0.3020425885212871 at epoch 61
epoch =     62/  1000, exp = train
train_iter_loss: 0.21566903591156006
train_iter_loss: 0.22263701260089874
train_iter_loss: 0.2488662302494049
train_iter_loss: 0.18471258878707886
train_iter_loss: 0.22585831582546234
train_iter_loss: 0.17276188731193542
train_iter_loss: 0.376120924949646
train_iter_loss: 0.30423322319984436
train_iter_loss: 0.2975817024707794
train_iter_loss: 0.37003305554389954
train_iter_loss: 0.15706323087215424
train_iter_loss: 0.1499009132385254
train_iter_loss: 0.24394743144512177
train_iter_loss: 0.271612286567688
train_iter_loss: 0.18944352865219116
train_iter_loss: 0.20578348636627197
train_iter_loss: 0.2829782962799072
train_iter_loss: 0.20873236656188965
train_iter_loss: 0.36767831444740295
train_iter_loss: 0.3098556697368622
train_iter_loss: 0.24547997117042542
train_iter_loss: 0.19714698195457458
train_iter_loss: 0.20191320776939392
train_iter_loss: 0.22234110534191132
train_iter_loss: 0.20177660882472992
train_iter_loss: 0.2941177487373352
train_iter_loss: 0.321661114692688
train_iter_loss: 0.3560503125190735
train_iter_loss: 0.23311594128608704
train_iter_loss: 0.21219103038311005
train_iter_loss: 0.2336750328540802
train_iter_loss: 0.19335880875587463
train_iter_loss: 0.2214096486568451
train_iter_loss: 0.22900281846523285
train_iter_loss: 0.1882362812757492
train_iter_loss: 0.21211528778076172
train_iter_loss: 0.3948083519935608
train_iter_loss: 0.2293042242527008
train_iter_loss: 0.2042144536972046
train_iter_loss: 0.24495509266853333
train_iter_loss: 0.2891048192977905
train_iter_loss: 0.22814205288887024
train_iter_loss: 0.2993486523628235
train_iter_loss: 0.2723137438297272
train_iter_loss: 0.20147062838077545
train_iter_loss: 0.1655726581811905
train_iter_loss: 0.19696390628814697
train_iter_loss: 0.20107075572013855
train_iter_loss: 0.17855441570281982
train_iter_loss: 0.21066775918006897
train_iter_loss: 0.22232399880886078
train_iter_loss: 0.25573503971099854
train_iter_loss: 0.22286830842494965
train_iter_loss: 0.3269503116607666
train_iter_loss: 0.29774555563926697
train_iter_loss: 0.24866321682929993
train_iter_loss: 0.21153688430786133
train_iter_loss: 0.22678539156913757
train_iter_loss: 0.2924211919307709
train_iter_loss: 0.2558608055114746
train_iter_loss: 0.3346831798553467
train_iter_loss: 0.20420965552330017
train_iter_loss: 0.21010981500148773
train_iter_loss: 0.21447613835334778
train_iter_loss: 0.20596808195114136
train_iter_loss: 0.21325016021728516
train_iter_loss: 0.3141871392726898
train_iter_loss: 0.35010388493537903
train_iter_loss: 0.24187490344047546
train_iter_loss: 0.23324382305145264
train_iter_loss: 0.3315439820289612
train_iter_loss: 0.24843792617321014
train_iter_loss: 0.20011870563030243
train_iter_loss: 0.2473001927137375
train_iter_loss: 0.25367340445518494
train_iter_loss: 0.1892043948173523
train_iter_loss: 0.18614618480205536
train_iter_loss: 0.27887970209121704
train_iter_loss: 0.33170807361602783
train_iter_loss: 0.23479735851287842
train_iter_loss: 0.18641313910484314
train_iter_loss: 0.25629910826683044
train_iter_loss: 0.2521498501300812
train_iter_loss: 0.24780093133449554
train_iter_loss: 0.18404947221279144
train_iter_loss: 0.24109168350696564
train_iter_loss: 0.21955308318138123
train_iter_loss: 0.1714138388633728
train_iter_loss: 0.255007266998291
train_iter_loss: 0.1614784598350525
train_iter_loss: 0.38518571853637695
train_iter_loss: 0.23839803040027618
train_iter_loss: 0.3116723895072937
train_iter_loss: 0.2254655510187149
train_iter_loss: 0.19356393814086914
train_iter_loss: 0.2628732919692993
train_iter_loss: 0.1871655285358429
train_iter_loss: 0.15917500853538513
train_iter_loss: 0.22402258217334747
train_iter_loss: 0.3003840446472168
train_iter_loss: 0.264772891998291
train_iter_loss: 0.21557177603244781
train_iter_loss: 0.33354517817497253
train_iter_loss: 0.2689295709133148
train_iter_loss: 0.29725152254104614
train_iter_loss: 0.27715587615966797
train_iter_loss: 0.1643577665090561
train_iter_loss: 0.22253434360027313
train_iter_loss: 0.23969712853431702
train_iter_loss: 0.23178990185260773
train_iter_loss: 0.21669206023216248
train_iter_loss: 0.19002564251422882
train_iter_loss: 0.19327689707279205
train_iter_loss: 0.21881158649921417
train_iter_loss: 0.22707094252109528
train_iter_loss: 0.29303646087646484
train_iter_loss: 0.21130117774009705
train_iter_loss: 0.1824130415916443
train_iter_loss: 0.2612690329551697
train_iter_loss: 0.20870313048362732
train_iter_loss: 0.32339850068092346
train_iter_loss: 0.24986013770103455
train_iter_loss: 0.18940569460391998
train_iter_loss: 0.2685699462890625
train_iter_loss: 0.2561146020889282
train_iter_loss: 0.2352875918149948
train_iter_loss: 0.2262776792049408
train_iter_loss: 0.23262134194374084
train_iter_loss: 0.18386796116828918
train_iter_loss: 0.29417353868484497
train_iter_loss: 0.2261999398469925
train_iter_loss: 0.1685996800661087
train_iter_loss: 0.20564836263656616
train_iter_loss: 0.26650187373161316
train_iter_loss: 0.19464819133281708
train_iter_loss: 0.27150771021842957
train_iter_loss: 0.39473024010658264
train_iter_loss: 0.235752135515213
train_iter_loss: 0.21691034734249115
train_iter_loss: 0.2085263729095459
train_iter_loss: 0.18926769495010376
train_iter_loss: 0.18530374765396118
train_iter_loss: 0.2720397114753723
train_iter_loss: 0.24785426259040833
train_iter_loss: 0.2533939480781555
train_iter_loss: 0.23496131598949432
train_iter_loss: 0.21644891798496246
train_iter_loss: 0.31662389636039734
train_iter_loss: 0.21277348697185516
train_iter_loss: 0.2359595000743866
train_iter_loss: 0.22885781526565552
train_iter_loss: 0.29156506061553955
train_iter_loss: 0.25796258449554443
train_iter_loss: 0.25816047191619873
train_iter_loss: 0.3714713752269745
train_iter_loss: 0.2698436975479126
train_iter_loss: 0.17477424442768097
train_iter_loss: 0.21026329696178436
train_iter_loss: 0.2704581916332245
train_iter_loss: 0.18877899646759033
train_iter_loss: 0.23429559171199799
train_iter_loss: 0.22986170649528503
train_iter_loss: 0.2249574363231659
train_iter_loss: 0.22651344537734985
train_iter_loss: 0.31985780596733093
train_iter_loss: 0.21650515496730804
train_iter_loss: 0.24472561478614807
train_iter_loss: 0.2245747298002243
train_iter_loss: 0.27321767807006836
train_iter_loss: 0.35357874631881714
train_iter_loss: 0.2983889877796173
train_iter_loss: 0.2509482502937317
train_iter_loss: 0.16658027470111847
train_iter_loss: 0.22633565962314606
train_iter_loss: 0.22555656731128693
train_iter_loss: 0.33502092957496643
train_iter_loss: 0.24361750483512878
train_iter_loss: 0.1784704029560089
train_iter_loss: 0.24667972326278687
train_iter_loss: 0.22534877061843872
train_iter_loss: 0.19566582143306732
train_iter_loss: 0.20196031033992767
train_iter_loss: 0.220706045627594
train_iter_loss: 0.21990437805652618
train_iter_loss: 0.28342124819755554
train_iter_loss: 0.21939842402935028
train_iter_loss: 0.25005361437797546
train_iter_loss: 0.18025760352611542
train_iter_loss: 0.2078082263469696
train_iter_loss: 0.19972392916679382
train_iter_loss: 0.23674944043159485
train_iter_loss: 0.22176437079906464
train_iter_loss: 0.23794829845428467
train_iter_loss: 0.22207975387573242
train_iter_loss: 0.2119121551513672
train_iter_loss: 0.2155570685863495
train_iter_loss: 0.23988068103790283
train_iter_loss: 0.23329056799411774
train_iter_loss: 0.28229522705078125
train_iter_loss: 0.34843263030052185
train loss :0.2430
---------------------
Validation seg loss: 0.30331238780943853 at epoch 62
epoch =     63/  1000, exp = train
train_iter_loss: 0.2382494956254959
train_iter_loss: 0.20658229291439056
train_iter_loss: 0.2848973870277405
train_iter_loss: 0.23599651455879211
train_iter_loss: 0.3970186412334442
train_iter_loss: 0.2895774841308594
train_iter_loss: 0.21681348979473114
train_iter_loss: 0.19880281388759613
train_iter_loss: 0.22955553233623505
train_iter_loss: 0.24259300529956818
train_iter_loss: 0.2927497327327728
train_iter_loss: 0.29099422693252563
train_iter_loss: 0.2701587975025177
train_iter_loss: 0.26072555780410767
train_iter_loss: 0.2844621241092682
train_iter_loss: 0.2135552167892456
train_iter_loss: 0.34549373388290405
train_iter_loss: 0.24378226697444916
train_iter_loss: 0.22294430434703827
train_iter_loss: 0.2898499369621277
train_iter_loss: 0.2442246973514557
train_iter_loss: 0.2289183884859085
train_iter_loss: 0.2436225861310959
train_iter_loss: 0.26497629284858704
train_iter_loss: 0.2095118910074234
train_iter_loss: 0.42491447925567627
train_iter_loss: 0.21455775201320648
train_iter_loss: 0.21412256360054016
train_iter_loss: 0.37725046277046204
train_iter_loss: 0.2554156482219696
train_iter_loss: 0.16901801526546478
train_iter_loss: 0.1973707675933838
train_iter_loss: 0.20004722476005554
train_iter_loss: 0.19744688272476196
train_iter_loss: 0.2357698678970337
train_iter_loss: 0.19222702085971832
train_iter_loss: 0.20370349287986755
train_iter_loss: 0.21367760002613068
train_iter_loss: 0.21072342991828918
train_iter_loss: 0.2951553761959076
train_iter_loss: 0.24255821108818054
train_iter_loss: 0.14617972075939178
train_iter_loss: 0.2679675817489624
train_iter_loss: 0.2093336433172226
train_iter_loss: 0.29384830594062805
train_iter_loss: 0.22786997258663177
train_iter_loss: 0.20976373553276062
train_iter_loss: 0.19834579527378082
train_iter_loss: 0.26519331336021423
train_iter_loss: 0.2987387776374817
train_iter_loss: 0.19481094181537628
train_iter_loss: 0.17066684365272522
train_iter_loss: 0.19833877682685852
train_iter_loss: 0.18341077864170074
train_iter_loss: 0.23309969902038574
train_iter_loss: 0.3094286620616913
train_iter_loss: 0.2647809088230133
train_iter_loss: 0.2755068838596344
train_iter_loss: 0.21302436292171478
train_iter_loss: 0.23315145075321198
train_iter_loss: 0.25095853209495544
train_iter_loss: 0.22664490342140198
train_iter_loss: 0.21595704555511475
train_iter_loss: 0.22514623403549194
train_iter_loss: 0.21966610848903656
train_iter_loss: 0.19149823486804962
train_iter_loss: 0.23912662267684937
train_iter_loss: 0.23212581872940063
train_iter_loss: 0.2528575658798218
train_iter_loss: 0.25438472628593445
train_iter_loss: 0.2146119773387909
train_iter_loss: 0.17178575694561005
train_iter_loss: 0.21406961977481842
train_iter_loss: 0.1526501178741455
train_iter_loss: 0.19998455047607422
train_iter_loss: 0.22059834003448486
train_iter_loss: 0.31254974007606506
train_iter_loss: 0.22621116042137146
train_iter_loss: 0.20430991053581238
train_iter_loss: 0.2455451935529709
train_iter_loss: 0.25701770186424255
train_iter_loss: 0.21408192813396454
train_iter_loss: 0.32459506392478943
train_iter_loss: 0.18861712515354156
train_iter_loss: 0.2332138568162918
train_iter_loss: 0.34025838971138
train_iter_loss: 0.22041738033294678
train_iter_loss: 0.2666926681995392
train_iter_loss: 0.1788933128118515
train_iter_loss: 0.2628471553325653
train_iter_loss: 0.2590675354003906
train_iter_loss: 0.22951900959014893
train_iter_loss: 0.307246595621109
train_iter_loss: 0.31724900007247925
train_iter_loss: 0.21494385600090027
train_iter_loss: 0.22142580151557922
train_iter_loss: 0.22122755646705627
train_iter_loss: 0.19944480061531067
train_iter_loss: 0.18004350364208221
train_iter_loss: 0.23148001730442047
train_iter_loss: 0.22142156958580017
train_iter_loss: 0.2453233152627945
train_iter_loss: 0.17072229087352753
train_iter_loss: 0.1685670167207718
train_iter_loss: 0.22964347898960114
train_iter_loss: 0.22512643039226532
train_iter_loss: 0.3008453845977783
train_iter_loss: 0.34616807103157043
train_iter_loss: 0.18029816448688507
train_iter_loss: 0.2898262143135071
train_iter_loss: 0.3501366674900055
train_iter_loss: 0.192903071641922
train_iter_loss: 0.22916124761104584
train_iter_loss: 0.2025650292634964
train_iter_loss: 0.18974977731704712
train_iter_loss: 0.20194832980632782
train_iter_loss: 0.30802521109580994
train_iter_loss: 0.23081299662590027
train_iter_loss: 0.2505894899368286
train_iter_loss: 0.17986395955085754
train_iter_loss: 0.2715224325656891
train_iter_loss: 0.2552510201931
train_iter_loss: 0.3315151631832123
train_iter_loss: 0.2867262661457062
train_iter_loss: 0.2935430407524109
train_iter_loss: 0.3437773883342743
train_iter_loss: 0.2699181139469147
train_iter_loss: 0.2792344391345978
train_iter_loss: 0.3602656126022339
train_iter_loss: 0.30673956871032715
train_iter_loss: 0.2792268991470337
train_iter_loss: 0.3407953679561615
train_iter_loss: 0.1808668076992035
train_iter_loss: 0.24876916408538818
train_iter_loss: 0.21797344088554382
train_iter_loss: 0.18975330889225006
train_iter_loss: 0.21640053391456604
train_iter_loss: 0.19093622267246246
train_iter_loss: 0.24176327884197235
train_iter_loss: 0.27234765887260437
train_iter_loss: 0.33705106377601624
train_iter_loss: 0.26782241463661194
train_iter_loss: 0.22472992539405823
train_iter_loss: 0.35481345653533936
train_iter_loss: 0.17818352580070496
train_iter_loss: 0.2582640051841736
train_iter_loss: 0.20388635993003845
train_iter_loss: 0.20983189344406128
train_iter_loss: 0.21554981172084808
train_iter_loss: 0.22652210295200348
train_iter_loss: 0.24834837019443512
train_iter_loss: 0.29495769739151
train_iter_loss: 0.2591018080711365
train_iter_loss: 0.24996668100357056
train_iter_loss: 0.19054625928401947
train_iter_loss: 0.2767966091632843
train_iter_loss: 0.21885396540164948
train_iter_loss: 0.3630416691303253
train_iter_loss: 0.23711098730564117
train_iter_loss: 0.20373624563217163
train_iter_loss: 0.2665422558784485
train_iter_loss: 0.19408868253231049
train_iter_loss: 0.22509850561618805
train_iter_loss: 0.2178700715303421
train_iter_loss: 0.26212629675865173
train_iter_loss: 0.2307477444410324
train_iter_loss: 0.19853228330612183
train_iter_loss: 0.3113660216331482
train_iter_loss: 0.18869717419147491
train_iter_loss: 0.19489701092243195
train_iter_loss: 0.319689005613327
train_iter_loss: 0.20876124501228333
train_iter_loss: 0.2255769670009613
train_iter_loss: 0.22654740512371063
train_iter_loss: 0.20897072553634644
train_iter_loss: 0.21735678613185883
train_iter_loss: 0.2717054486274719
train_iter_loss: 0.21778619289398193
train_iter_loss: 0.1955660730600357
train_iter_loss: 0.24065102636814117
train_iter_loss: 0.255005419254303
train_iter_loss: 0.24275918304920197
train_iter_loss: 0.2626953721046448
train_iter_loss: 0.15875768661499023
train_iter_loss: 0.17227105796337128
train_iter_loss: 0.31051144003868103
train_iter_loss: 0.257040798664093
train_iter_loss: 0.27319127321243286
train_iter_loss: 0.3044080436229706
train_iter_loss: 0.22665998339653015
train_iter_loss: 0.2879098057746887
train_iter_loss: 0.21643973886966705
train_iter_loss: 0.28297239542007446
train_iter_loss: 0.20471692085266113
train_iter_loss: 0.20356778800487518
train_iter_loss: 0.23930566012859344
train_iter_loss: 0.18222130835056305
train_iter_loss: 0.23075902462005615
train_iter_loss: 0.22944413125514984
train_iter_loss: 0.24076873064041138
train loss :0.2439
---------------------
Validation seg loss: 0.30097088133389094 at epoch 63
epoch =     64/  1000, exp = train
train_iter_loss: 0.1844547688961029
train_iter_loss: 0.25226643681526184
train_iter_loss: 0.23714955151081085
train_iter_loss: 0.2300552874803543
train_iter_loss: 0.41330191493034363
train_iter_loss: 0.16117821633815765
train_iter_loss: 0.27938297390937805
train_iter_loss: 0.20754148066043854
train_iter_loss: 0.1918957531452179
train_iter_loss: 0.22914735972881317
train_iter_loss: 0.18787264823913574
train_iter_loss: 0.21907642483711243
train_iter_loss: 0.2808842062950134
train_iter_loss: 0.22307135164737701
train_iter_loss: 0.17851339280605316
train_iter_loss: 0.18399913609027863
train_iter_loss: 0.347425639629364
train_iter_loss: 0.24749982357025146
train_iter_loss: 0.22247333824634552
train_iter_loss: 0.222549706697464
train_iter_loss: 0.21440131962299347
train_iter_loss: 0.24657881259918213
train_iter_loss: 0.3329898715019226
train_iter_loss: 0.17620958387851715
train_iter_loss: 0.20208163559436798
train_iter_loss: 0.31083056330680847
train_iter_loss: 0.15771052241325378
train_iter_loss: 0.2513497769832611
train_iter_loss: 0.24950696527957916
train_iter_loss: 0.22095736861228943
train_iter_loss: 0.2174302041530609
train_iter_loss: 0.2667332589626312
train_iter_loss: 0.23970359563827515
train_iter_loss: 0.3043130934238434
train_iter_loss: 0.1808748096227646
train_iter_loss: 0.2261178344488144
train_iter_loss: 0.25718697905540466
train_iter_loss: 0.24985237419605255
train_iter_loss: 0.2800261974334717
train_iter_loss: 0.23172184824943542
train_iter_loss: 0.28287747502326965
train_iter_loss: 0.221012681722641
train_iter_loss: 0.21246123313903809
train_iter_loss: 0.32358282804489136
train_iter_loss: 0.22875303030014038
train_iter_loss: 0.19832433760166168
train_iter_loss: 0.32137081027030945
train_iter_loss: 0.19614046812057495
train_iter_loss: 0.2228507548570633
train_iter_loss: 0.27124908566474915
train_iter_loss: 0.21635355055332184
train_iter_loss: 0.24370750784873962
train_iter_loss: 0.32793208956718445
train_iter_loss: 0.3804676830768585
train_iter_loss: 0.2046785205602646
train_iter_loss: 0.2144862860441208
train_iter_loss: 0.18625755608081818
train_iter_loss: 0.2241298407316208
train_iter_loss: 0.24517330527305603
train_iter_loss: 0.24731817841529846
train_iter_loss: 0.32821595668792725
train_iter_loss: 0.1498187780380249
train_iter_loss: 0.2642534077167511
train_iter_loss: 0.24968388676643372
train_iter_loss: 0.20418193936347961
train_iter_loss: 0.38247162103652954
train_iter_loss: 0.2849653363227844
train_iter_loss: 0.26566290855407715
train_iter_loss: 0.1941731572151184
train_iter_loss: 0.2234426736831665
train_iter_loss: 0.2270601987838745
train_iter_loss: 0.3139958679676056
train_iter_loss: 0.25132080912590027
train_iter_loss: 0.2668108344078064
train_iter_loss: 0.2077350616455078
train_iter_loss: 0.25358256697654724
train_iter_loss: 0.21507173776626587
train_iter_loss: 0.2448214739561081
train_iter_loss: 0.17306871712207794
train_iter_loss: 0.25080248713493347
train_iter_loss: 0.31568849086761475
train_iter_loss: 0.20814724266529083
train_iter_loss: 0.22388331592082977
train_iter_loss: 0.2907316982746124
train_iter_loss: 0.18047139048576355
train_iter_loss: 0.17224939167499542
train_iter_loss: 0.17524386942386627
train_iter_loss: 0.22981129586696625
train_iter_loss: 0.23297998309135437
train_iter_loss: 0.22632472217082977
train_iter_loss: 0.23173847794532776
train_iter_loss: 0.29435065388679504
train_iter_loss: 0.18985801935195923
train_iter_loss: 0.21036656200885773
train_iter_loss: 0.2046099305152893
train_iter_loss: 0.24925678968429565
train_iter_loss: 0.2200903743505478
train_iter_loss: 0.17298822104930878
train_iter_loss: 0.23785662651062012
train_iter_loss: 0.2613123953342438
train_iter_loss: 0.16954472661018372
train_iter_loss: 0.2094753384590149
train_iter_loss: 0.19823037087917328
train_iter_loss: 0.24669113755226135
train_iter_loss: 0.23319949209690094
train_iter_loss: 0.30017945170402527
train_iter_loss: 0.3424191176891327
train_iter_loss: 0.23893004655838013
train_iter_loss: 0.22039172053337097
train_iter_loss: 0.21608270704746246
train_iter_loss: 0.3216937482357025
train_iter_loss: 0.3222687840461731
train_iter_loss: 0.21240867674350739
train_iter_loss: 0.2792440950870514
train_iter_loss: 0.32219377160072327
train_iter_loss: 0.16785839200019836
train_iter_loss: 0.24422237277030945
train_iter_loss: 0.27621617913246155
train_iter_loss: 0.19736382365226746
train_iter_loss: 0.2670193314552307
train_iter_loss: 0.37619611620903015
train_iter_loss: 0.21961408853530884
train_iter_loss: 0.19274432957172394
train_iter_loss: 0.25873294472694397
train_iter_loss: 0.2961008548736572
train_iter_loss: 0.28226953744888306
train_iter_loss: 0.29645946621894836
train_iter_loss: 0.20620658993721008
train_iter_loss: 0.2850896418094635
train_iter_loss: 0.21691882610321045
train_iter_loss: 0.18344469368457794
train_iter_loss: 0.21363729238510132
train_iter_loss: 0.24891023337841034
train_iter_loss: 0.20733393728733063
train_iter_loss: 0.29344308376312256
train_iter_loss: 0.2170618325471878
train_iter_loss: 0.24284972250461578
train_iter_loss: 0.1690375953912735
train_iter_loss: 0.3018181324005127
train_iter_loss: 0.22676417231559753
train_iter_loss: 0.19423986971378326
train_iter_loss: 0.2442755252122879
train_iter_loss: 0.17717263102531433
train_iter_loss: 0.22234518826007843
train_iter_loss: 0.32493194937705994
train_iter_loss: 0.23134246468544006
train_iter_loss: 0.1782781034708023
train_iter_loss: 0.29245030879974365
train_iter_loss: 0.3186517357826233
train_iter_loss: 0.20679563283920288
train_iter_loss: 0.26196640729904175
train_iter_loss: 0.1693519502878189
train_iter_loss: 0.34992122650146484
train_iter_loss: 0.17024531960487366
train_iter_loss: 0.2575904130935669
train_iter_loss: 0.20129963755607605
train_iter_loss: 0.26900261640548706
train_iter_loss: 0.2793964147567749
train_iter_loss: 0.2162373960018158
train_iter_loss: 0.18755395710468292
train_iter_loss: 0.2145092785358429
train_iter_loss: 0.22738859057426453
train_iter_loss: 0.18367649614810944
train_iter_loss: 0.19141077995300293
train_iter_loss: 0.23549295961856842
train_iter_loss: 0.24288204312324524
train_iter_loss: 0.19379188120365143
train_iter_loss: 0.36726877093315125
train_iter_loss: 0.38358262181282043
train_iter_loss: 0.2692776024341583
train_iter_loss: 0.23277315497398376
train_iter_loss: 0.18649594485759735
train_iter_loss: 0.21327877044677734
train_iter_loss: 0.2285739779472351
train_iter_loss: 0.1822313815355301
train_iter_loss: 0.24558940529823303
train_iter_loss: 0.2523496150970459
train_iter_loss: 0.21769894659519196
train_iter_loss: 0.2994493544101715
train_iter_loss: 0.23878413438796997
train_iter_loss: 0.28841423988342285
train_iter_loss: 0.2161056250333786
train_iter_loss: 0.29795289039611816
train_iter_loss: 0.23568077385425568
train_iter_loss: 0.2047964185476303
train_iter_loss: 0.1969800442457199
train_iter_loss: 0.22487033903598785
train_iter_loss: 0.2907733619213104
train_iter_loss: 0.24571019411087036
train_iter_loss: 0.2429070770740509
train_iter_loss: 0.24592073261737823
train_iter_loss: 0.23173819482326508
train_iter_loss: 0.2516723871231079
train_iter_loss: 0.2802601456642151
train_iter_loss: 0.245101198554039
train_iter_loss: 0.2759663462638855
train_iter_loss: 0.1550682634115219
train_iter_loss: 0.2685351073741913
train_iter_loss: 0.2524884343147278
train_iter_loss: 0.20442090928554535
train loss :0.2427
---------------------
Validation seg loss: 0.3055255784881565 at epoch 64
epoch =     65/  1000, exp = train
train_iter_loss: 0.24688434600830078
train_iter_loss: 0.25755274295806885
train_iter_loss: 0.31236666440963745
train_iter_loss: 0.20104621350765228
train_iter_loss: 0.1757999062538147
train_iter_loss: 0.32064008712768555
train_iter_loss: 0.3072054386138916
train_iter_loss: 0.2171725630760193
train_iter_loss: 0.34194645285606384
train_iter_loss: 0.23896025121212006
train_iter_loss: 0.307876855134964
train_iter_loss: 0.2320307493209839
train_iter_loss: 0.30959552526474
train_iter_loss: 0.22444887459278107
train_iter_loss: 0.19754287600517273
train_iter_loss: 0.21520455181598663
train_iter_loss: 0.27930209040641785
train_iter_loss: 0.2109231948852539
train_iter_loss: 0.2471006214618683
train_iter_loss: 0.2898786664009094
train_iter_loss: 0.2005128264427185
train_iter_loss: 0.24037368595600128
train_iter_loss: 0.19764338433742523
train_iter_loss: 0.3509376347064972
train_iter_loss: 0.23465098440647125
train_iter_loss: 0.21750633418560028
train_iter_loss: 0.27112412452697754
train_iter_loss: 0.207726389169693
train_iter_loss: 0.2770114243030548
train_iter_loss: 0.3148368000984192
train_iter_loss: 0.18406054377555847
train_iter_loss: 0.29240357875823975
train_iter_loss: 0.18714739382266998
train_iter_loss: 0.3538505733013153
train_iter_loss: 0.22364351153373718
train_iter_loss: 0.2630833387374878
train_iter_loss: 0.3078102767467499
train_iter_loss: 0.18982388079166412
train_iter_loss: 0.2904747724533081
train_iter_loss: 0.19940316677093506
train_iter_loss: 0.2787846326828003
train_iter_loss: 0.15905572474002838
train_iter_loss: 0.20223981142044067
train_iter_loss: 0.265402615070343
train_iter_loss: 0.26604321599006653
train_iter_loss: 0.2960934340953827
train_iter_loss: 0.21858268976211548
train_iter_loss: 0.20930476486682892
train_iter_loss: 0.2440856248140335
train_iter_loss: 0.19558866322040558
train_iter_loss: 0.21087998151779175
train_iter_loss: 0.24532832205295563
train_iter_loss: 0.17643503844738007
train_iter_loss: 0.20974481105804443
train_iter_loss: 0.2647149860858917
train_iter_loss: 0.25726163387298584
train_iter_loss: 0.17503513395786285
train_iter_loss: 0.18880827724933624
train_iter_loss: 0.18300041556358337
train_iter_loss: 0.21803711354732513
train_iter_loss: 0.20004265010356903
train_iter_loss: 0.2937086820602417
train_iter_loss: 0.2576523721218109
train_iter_loss: 0.19894355535507202
train_iter_loss: 0.201926589012146
train_iter_loss: 0.18331098556518555
train_iter_loss: 0.18959692120552063
train_iter_loss: 0.1764911562204361
train_iter_loss: 0.23424308001995087
train_iter_loss: 0.241828054189682
train_iter_loss: 0.22735793888568878
train_iter_loss: 0.2554748058319092
train_iter_loss: 0.2973291575908661
train_iter_loss: 0.387478768825531
train_iter_loss: 0.2591556906700134
train_iter_loss: 0.27037864923477173
train_iter_loss: 0.3798728883266449
train_iter_loss: 0.1928034871816635
train_iter_loss: 0.21447765827178955
train_iter_loss: 0.38550516963005066
train_iter_loss: 0.20212601125240326
train_iter_loss: 0.21764595806598663
train_iter_loss: 0.20314793288707733
train_iter_loss: 0.1879904419183731
train_iter_loss: 0.3060501217842102
train_iter_loss: 0.22515925765037537
train_iter_loss: 0.31847429275512695
train_iter_loss: 0.2263992577791214
train_iter_loss: 0.2614207863807678
train_iter_loss: 0.2656949758529663
train_iter_loss: 0.17714238166809082
train_iter_loss: 0.20424869656562805
train_iter_loss: 0.26353123784065247
train_iter_loss: 0.21580767631530762
train_iter_loss: 0.2488589882850647
train_iter_loss: 0.24837328493595123
train_iter_loss: 0.2441774159669876
train_iter_loss: 0.22386790812015533
train_iter_loss: 0.22403094172477722
train_iter_loss: 0.24896939098834991
train_iter_loss: 0.2706381678581238
train_iter_loss: 0.1856077015399933
train_iter_loss: 0.2316594272851944
train_iter_loss: 0.3406669795513153
train_iter_loss: 0.272758811712265
train_iter_loss: 0.19770628213882446
train_iter_loss: 0.2143765240907669
train_iter_loss: 0.16164064407348633
train_iter_loss: 0.26017332077026367
train_iter_loss: 0.1928325891494751
train_iter_loss: 0.2681258022785187
train_iter_loss: 0.1921507865190506
train_iter_loss: 0.2510310411453247
train_iter_loss: 0.2227390557527542
train_iter_loss: 0.21380767226219177
train_iter_loss: 0.2968474328517914
train_iter_loss: 0.19823989272117615
train_iter_loss: 0.22135376930236816
train_iter_loss: 0.20228707790374756
train_iter_loss: 0.20257125794887543
train_iter_loss: 0.23567456007003784
train_iter_loss: 0.2125827819108963
train_iter_loss: 0.2275574654340744
train_iter_loss: 0.21062329411506653
train_iter_loss: 0.2379615306854248
train_iter_loss: 0.3702806234359741
train_iter_loss: 0.21182894706726074
train_iter_loss: 0.22505299746990204
train_iter_loss: 0.23214146494865417
train_iter_loss: 0.21780143678188324
train_iter_loss: 0.21838024258613586
train_iter_loss: 0.2950166165828705
train_iter_loss: 0.17326216399669647
train_iter_loss: 0.24911846220493317
train_iter_loss: 0.2154863327741623
train_iter_loss: 0.22321520745754242
train_iter_loss: 0.2027541846036911
train_iter_loss: 0.21872420608997345
train_iter_loss: 0.3050687909126282
train_iter_loss: 0.17721456289291382
train_iter_loss: 0.1625494807958603
train_iter_loss: 0.18438901007175446
train_iter_loss: 0.23004750907421112
train_iter_loss: 0.24067462980747223
train_iter_loss: 0.23387226462364197
train_iter_loss: 0.24482373893260956
train_iter_loss: 0.25924545526504517
train_iter_loss: 0.29714104533195496
train_iter_loss: 0.21473215520381927
train_iter_loss: 0.39714983105659485
train_iter_loss: 0.20804375410079956
train_iter_loss: 0.239964097738266
train_iter_loss: 0.2639636695384979
train_iter_loss: 0.18174688518047333
train_iter_loss: 0.340526282787323
train_iter_loss: 0.24825474619865417
train_iter_loss: 0.2973461151123047
train_iter_loss: 0.2504940629005432
train_iter_loss: 0.23800593614578247
train_iter_loss: 0.2280346006155014
train_iter_loss: 0.2353743314743042
train_iter_loss: 0.3968599736690521
train_iter_loss: 0.255378395318985
train_iter_loss: 0.22530315816402435
train_iter_loss: 0.23718707263469696
train_iter_loss: 0.2275065779685974
train_iter_loss: 0.21953029930591583
train_iter_loss: 0.23825465142726898
train_iter_loss: 0.23674337565898895
train_iter_loss: 0.20966048538684845
train_iter_loss: 0.2224723845720291
train_iter_loss: 0.26077011227607727
train_iter_loss: 0.21923501789569855
train_iter_loss: 0.18538516759872437
train_iter_loss: 0.2633303105831146
train_iter_loss: 0.2978048324584961
train_iter_loss: 0.22182756662368774
train_iter_loss: 0.2809334993362427
train_iter_loss: 0.22649747133255005
train_iter_loss: 0.2247469574213028
train_iter_loss: 0.28897953033447266
train_iter_loss: 0.18989774584770203
train_iter_loss: 0.2385655790567398
train_iter_loss: 0.19494780898094177
train_iter_loss: 0.2650357186794281
train_iter_loss: 0.20451194047927856
train_iter_loss: 0.23813126981258392
train_iter_loss: 0.1905977725982666
train_iter_loss: 0.1791764348745346
train_iter_loss: 0.2165645956993103
train_iter_loss: 0.205073744058609
train_iter_loss: 0.20649921894073486
train_iter_loss: 0.19929926097393036
train_iter_loss: 0.3382689654827118
train_iter_loss: 0.20953695476055145
train_iter_loss: 0.23301298916339874
train_iter_loss: 0.2524136006832123
train_iter_loss: 0.18609261512756348
train_iter_loss: 0.31991294026374817
train_iter_loss: 0.1893046796321869
train loss :0.2413
---------------------
Validation seg loss: 0.30128908058944737 at epoch 65
epoch =     66/  1000, exp = train
train_iter_loss: 0.1831342577934265
train_iter_loss: 0.22056184709072113
train_iter_loss: 0.23118501901626587
train_iter_loss: 0.23824219405651093
train_iter_loss: 0.20899510383605957
train_iter_loss: 0.22723527252674103
train_iter_loss: 0.20082826912403107
train_iter_loss: 0.1950300633907318
train_iter_loss: 0.2512497007846832
train_iter_loss: 0.25608110427856445
train_iter_loss: 0.24228309094905853
train_iter_loss: 0.2613849639892578
train_iter_loss: 0.22255374491214752
train_iter_loss: 0.21657520532608032
train_iter_loss: 0.2551852762699127
train_iter_loss: 0.22159065306186676
train_iter_loss: 0.17955046892166138
train_iter_loss: 0.2563987970352173
train_iter_loss: 0.23560434579849243
train_iter_loss: 0.24211609363555908
train_iter_loss: 0.30410560965538025
train_iter_loss: 0.15523269772529602
train_iter_loss: 0.31093811988830566
train_iter_loss: 0.25659269094467163
train_iter_loss: 0.19973435997962952
train_iter_loss: 0.24906890094280243
train_iter_loss: 0.24192962050437927
train_iter_loss: 0.1992129236459732
train_iter_loss: 0.30605486035346985
train_iter_loss: 0.2576127350330353
train_iter_loss: 0.28642863035202026
train_iter_loss: 0.221607506275177
train_iter_loss: 0.19382791221141815
train_iter_loss: 0.22663728892803192
train_iter_loss: 0.18263742327690125
train_iter_loss: 0.26151883602142334
train_iter_loss: 0.263292133808136
train_iter_loss: 0.22770395874977112
train_iter_loss: 0.20409581065177917
train_iter_loss: 0.24877765774726868
train_iter_loss: 0.15931479632854462
train_iter_loss: 0.21242743730545044
train_iter_loss: 0.15289202332496643
train_iter_loss: 0.40915268659591675
train_iter_loss: 0.21848547458648682
train_iter_loss: 0.2391982078552246
train_iter_loss: 0.1579042673110962
train_iter_loss: 0.36632898449897766
train_iter_loss: 0.26788461208343506
train_iter_loss: 0.2148188352584839
train_iter_loss: 0.21801969408988953
train_iter_loss: 0.2540421187877655
train_iter_loss: 0.2201084941625595
train_iter_loss: 0.21368403732776642
train_iter_loss: 0.257691353559494
train_iter_loss: 0.20250725746154785
train_iter_loss: 0.28811773657798767
train_iter_loss: 0.3357694447040558
train_iter_loss: 0.35857516527175903
train_iter_loss: 0.25943320989608765
train_iter_loss: 0.2026047259569168
train_iter_loss: 0.1621914803981781
train_iter_loss: 0.2495322972536087
train_iter_loss: 0.27525538206100464
train_iter_loss: 0.26232972741127014
train_iter_loss: 0.24084053933620453
train_iter_loss: 0.20952580869197845
train_iter_loss: 0.19887405633926392
train_iter_loss: 0.17431682348251343
train_iter_loss: 0.32668936252593994
train_iter_loss: 0.23638957738876343
train_iter_loss: 0.2689321041107178
train_iter_loss: 0.21780887246131897
train_iter_loss: 0.27968668937683105
train_iter_loss: 0.2627790570259094
train_iter_loss: 0.19921985268592834
train_iter_loss: 0.1457018256187439
train_iter_loss: 0.21253758668899536
train_iter_loss: 0.1835651397705078
train_iter_loss: 0.2669816017150879
train_iter_loss: 0.2546634078025818
train_iter_loss: 0.2669762670993805
train_iter_loss: 0.2396436184644699
train_iter_loss: 0.23311950266361237
train_iter_loss: 0.21209397912025452
train_iter_loss: 0.24817083775997162
train_iter_loss: 0.3858505189418793
train_iter_loss: 0.23161637783050537
train_iter_loss: 0.2317628413438797
train_iter_loss: 0.3131711184978485
train_iter_loss: 0.20003920793533325
train_iter_loss: 0.3139071762561798
train_iter_loss: 0.2705304026603699
train_iter_loss: 0.18854054808616638
train_iter_loss: 0.22237591445446014
train_iter_loss: 0.22809761762619019
train_iter_loss: 0.230752095580101
train_iter_loss: 0.19087019562721252
train_iter_loss: 0.22639721632003784
train_iter_loss: 0.3772696554660797
train_iter_loss: 0.1974746733903885
train_iter_loss: 0.21877609193325043
train_iter_loss: 0.2031373828649521
train_iter_loss: 0.24662086367607117
train_iter_loss: 0.21838970482349396
train_iter_loss: 0.24699413776397705
train_iter_loss: 0.18241257965564728
train_iter_loss: 0.32323235273361206
train_iter_loss: 0.2191445678472519
train_iter_loss: 0.2440236657857895
train_iter_loss: 0.3105587065219879
train_iter_loss: 0.19487401843070984
train_iter_loss: 0.18378041684627533
train_iter_loss: 0.22786082327365875
train_iter_loss: 0.16424666345119476
train_iter_loss: 0.21802563965320587
train_iter_loss: 0.28606534004211426
train_iter_loss: 0.22557134926319122
train_iter_loss: 0.18640631437301636
train_iter_loss: 0.18790601193904877
train_iter_loss: 0.2275230884552002
train_iter_loss: 0.24064037203788757
train_iter_loss: 0.2583586871623993
train_iter_loss: 0.18617334961891174
train_iter_loss: 0.19840329885482788
train_iter_loss: 0.16202963888645172
train_iter_loss: 0.2260899692773819
train_iter_loss: 0.43271273374557495
train_iter_loss: 0.2539271414279938
train_iter_loss: 0.16926391422748566
train_iter_loss: 0.21022112667560577
train_iter_loss: 0.2036736011505127
train_iter_loss: 0.23430699110031128
train_iter_loss: 0.2547893226146698
train_iter_loss: 0.17900756001472473
train_iter_loss: 0.24842283129692078
train_iter_loss: 0.26501062512397766
train_iter_loss: 0.21548162400722504
train_iter_loss: 0.2882528603076935
train_iter_loss: 0.3325578272342682
train_iter_loss: 0.2615019381046295
train_iter_loss: 0.22909900546073914
train_iter_loss: 0.30100497603416443
train_iter_loss: 0.25050511956214905
train_iter_loss: 0.25918853282928467
train_iter_loss: 0.24785029888153076
train_iter_loss: 0.23066917061805725
train_iter_loss: 0.16653326153755188
train_iter_loss: 0.2685544192790985
train_iter_loss: 0.21404021978378296
train_iter_loss: 0.23223508894443512
train_iter_loss: 0.23297922313213348
train_iter_loss: 0.2515389919281006
train_iter_loss: 0.33494603633880615
train_iter_loss: 0.22711780667304993
train_iter_loss: 0.3500889539718628
train_iter_loss: 0.32358813285827637
train_iter_loss: 0.3154420852661133
train_iter_loss: 0.2826955020427704
train_iter_loss: 0.24995021522045135
train_iter_loss: 0.2930099070072174
train_iter_loss: 0.2587217092514038
train_iter_loss: 0.3166053295135498
train_iter_loss: 0.21332429349422455
train_iter_loss: 0.2795671820640564
train_iter_loss: 0.26635539531707764
train_iter_loss: 0.27817946672439575
train_iter_loss: 0.2093668133020401
train_iter_loss: 0.206369087100029
train_iter_loss: 0.17750124633312225
train_iter_loss: 0.2397817075252533
train_iter_loss: 0.19394473731517792
train_iter_loss: 0.26207032799720764
train_iter_loss: 0.21541036665439606
train_iter_loss: 0.2685590386390686
train_iter_loss: 0.22776059806346893
train_iter_loss: 0.23697200417518616
train_iter_loss: 0.23381397128105164
train_iter_loss: 0.32358109951019287
train_iter_loss: 0.256644070148468
train_iter_loss: 0.24534909427165985
train_iter_loss: 0.18462318181991577
train_iter_loss: 0.2443404644727707
train_iter_loss: 0.2134750932455063
train_iter_loss: 0.16652099788188934
train_iter_loss: 0.18126974999904633
train_iter_loss: 0.19924835860729218
train_iter_loss: 0.17709270119667053
train_iter_loss: 0.4165453016757965
train_iter_loss: 0.19055570662021637
train_iter_loss: 0.3170681893825531
train_iter_loss: 0.21505941450595856
train_iter_loss: 0.23627831041812897
train_iter_loss: 0.24137528240680695
train_iter_loss: 0.3455258309841156
train_iter_loss: 0.19102412462234497
train_iter_loss: 0.2100059986114502
train_iter_loss: 0.23926915228366852
train_iter_loss: 0.22178994119167328
train_iter_loss: 0.23799441754817963
train loss :0.2418
---------------------
Validation seg loss: 0.30647585463692556 at epoch 66
epoch =     67/  1000, exp = train
train_iter_loss: 0.30567342042922974
train_iter_loss: 0.26995593309402466
train_iter_loss: 0.29631635546684265
train_iter_loss: 0.22450004518032074
train_iter_loss: 0.20971335470676422
train_iter_loss: 0.25316622853279114
train_iter_loss: 0.17857681214809418
train_iter_loss: 0.25929296016693115
train_iter_loss: 0.34511351585388184
train_iter_loss: 0.2501184344291687
train_iter_loss: 0.20607337355613708
train_iter_loss: 0.24093560874462128
train_iter_loss: 0.22127792239189148
train_iter_loss: 0.28334274888038635
train_iter_loss: 0.2710455358028412
train_iter_loss: 0.3372991383075714
train_iter_loss: 0.20716305077075958
train_iter_loss: 0.24467551708221436
train_iter_loss: 0.24086378514766693
train_iter_loss: 0.4003223180770874
train_iter_loss: 0.22088852524757385
train_iter_loss: 0.20478542149066925
train_iter_loss: 0.17271123826503754
train_iter_loss: 0.31688445806503296
train_iter_loss: 0.18832896649837494
train_iter_loss: 0.2048734724521637
train_iter_loss: 0.2149866819381714
train_iter_loss: 0.3072103261947632
train_iter_loss: 0.2558344006538391
train_iter_loss: 0.17505107820034027
train_iter_loss: 0.24510754644870758
train_iter_loss: 0.2391674518585205
train_iter_loss: 0.2156817764043808
train_iter_loss: 0.2802015244960785
train_iter_loss: 0.24559368193149567
train_iter_loss: 0.3853866755962372
train_iter_loss: 0.19596169888973236
train_iter_loss: 0.34006327390670776
train_iter_loss: 0.19840513169765472
train_iter_loss: 0.18383672833442688
train_iter_loss: 0.26885178685188293
train_iter_loss: 0.20501267910003662
train_iter_loss: 0.29288920760154724
train_iter_loss: 0.2161363810300827
train_iter_loss: 0.19461797177791595
train_iter_loss: 0.2441312074661255
train_iter_loss: 0.22455742955207825
train_iter_loss: 0.2869948446750641
train_iter_loss: 0.22519350051879883
train_iter_loss: 0.26730450987815857
train_iter_loss: 0.36692920327186584
train_iter_loss: 0.25361230969429016
train_iter_loss: 0.21577070653438568
train_iter_loss: 0.26258575916290283
train_iter_loss: 0.17339012026786804
train_iter_loss: 0.20588111877441406
train_iter_loss: 0.18935677409172058
train_iter_loss: 0.21626830101013184
train_iter_loss: 0.2302612066268921
train_iter_loss: 0.23493801057338715
train_iter_loss: 0.3758944869041443
train_iter_loss: 0.21332873404026031
train_iter_loss: 0.22223134338855743
train_iter_loss: 0.20938457548618317
train_iter_loss: 0.268220990896225
train_iter_loss: 0.22569473087787628
train_iter_loss: 0.21610413491725922
train_iter_loss: 0.24711179733276367
train_iter_loss: 0.2090093344449997
train_iter_loss: 0.2329205721616745
train_iter_loss: 0.24123422801494598
train_iter_loss: 0.21415579319000244
train_iter_loss: 0.2199385017156601
train_iter_loss: 0.21431373059749603
train_iter_loss: 0.467227041721344
train_iter_loss: 0.277835488319397
train_iter_loss: 0.19517157971858978
train_iter_loss: 0.26773324608802795
train_iter_loss: 0.2939724624156952
train_iter_loss: 0.21896858513355255
train_iter_loss: 0.17573495209217072
train_iter_loss: 0.19726398587226868
train_iter_loss: 0.22652073204517365
train_iter_loss: 0.39278846979141235
train_iter_loss: 0.21602089703083038
train_iter_loss: 0.16158482432365417
train_iter_loss: 0.27936026453971863
train_iter_loss: 0.17617443203926086
train_iter_loss: 0.23006153106689453
train_iter_loss: 0.35737067461013794
train_iter_loss: 0.23092544078826904
train_iter_loss: 0.23839789628982544
train_iter_loss: 0.21775686740875244
train_iter_loss: 0.22230041027069092
train_iter_loss: 0.16014710068702698
train_iter_loss: 0.20127394795417786
train_iter_loss: 0.25015801191329956
train_iter_loss: 0.20691975951194763
train_iter_loss: 0.21766404807567596
train_iter_loss: 0.19145113229751587
train_iter_loss: 0.27410441637039185
train_iter_loss: 0.20769774913787842
train_iter_loss: 0.30279210209846497
train_iter_loss: 0.21500933170318604
train_iter_loss: 0.26777079701423645
train_iter_loss: 0.15917569398880005
train_iter_loss: 0.21409185230731964
train_iter_loss: 0.29218608140945435
train_iter_loss: 0.2639015018939972
train_iter_loss: 0.24872778356075287
train_iter_loss: 0.17269454896450043
train_iter_loss: 0.2030472755432129
train_iter_loss: 0.18558619916439056
train_iter_loss: 0.2793859541416168
train_iter_loss: 0.248752161860466
train_iter_loss: 0.19775764644145966
train_iter_loss: 0.21392303705215454
train_iter_loss: 0.2720663845539093
train_iter_loss: 0.26442891359329224
train_iter_loss: 0.18757924437522888
train_iter_loss: 0.22174172103405
train_iter_loss: 0.21158549189567566
train_iter_loss: 0.22588476538658142
train_iter_loss: 0.23147501051425934
train_iter_loss: 0.25889280438423157
train_iter_loss: 0.19879600405693054
train_iter_loss: 0.2446279674768448
train_iter_loss: 0.21244217455387115
train_iter_loss: 0.20057158172130585
train_iter_loss: 0.15207631886005402
train_iter_loss: 0.2022046446800232
train_iter_loss: 0.3167334496974945
train_iter_loss: 0.17949849367141724
train_iter_loss: 0.2218836545944214
train_iter_loss: 0.254443883895874
train_iter_loss: 0.30823802947998047
train_iter_loss: 0.219265878200531
train_iter_loss: 0.19291050732135773
train_iter_loss: 0.20368655025959015
train_iter_loss: 0.24091558158397675
train_iter_loss: 0.19292418658733368
train_iter_loss: 0.3015190660953522
train_iter_loss: 0.24165277183055878
train_iter_loss: 0.26715442538261414
train_iter_loss: 0.32930484414100647
train_iter_loss: 0.23666228353977203
train_iter_loss: 0.1859549880027771
train_iter_loss: 0.20874235033988953
train_iter_loss: 0.19688613712787628
train_iter_loss: 0.2301187664270401
train_iter_loss: 0.24136795103549957
train_iter_loss: 0.21505597233772278
train_iter_loss: 0.27532413601875305
train_iter_loss: 0.23244774341583252
train_iter_loss: 0.1807447224855423
train_iter_loss: 0.28253814578056335
train_iter_loss: 0.22172722220420837
train_iter_loss: 0.2196311354637146
train_iter_loss: 0.20521774888038635
train_iter_loss: 0.14844374358654022
train_iter_loss: 0.16046106815338135
train_iter_loss: 0.20490843057632446
train_iter_loss: 0.23356766998767853
train_iter_loss: 0.20492805540561676
train_iter_loss: 0.25960564613342285
train_iter_loss: 0.36258602142333984
train_iter_loss: 0.28148171305656433
train_iter_loss: 0.31826913356781006
train_iter_loss: 0.313795268535614
train_iter_loss: 0.3164465129375458
train_iter_loss: 0.3437689542770386
train_iter_loss: 0.1949012577533722
train_iter_loss: 0.2089119404554367
train_iter_loss: 0.2608838379383087
train_iter_loss: 0.21986694633960724
train_iter_loss: 0.1854698359966278
train_iter_loss: 0.29993560910224915
train_iter_loss: 0.1924571692943573
train_iter_loss: 0.23599161207675934
train_iter_loss: 0.2042190581560135
train_iter_loss: 0.2222547084093094
train_iter_loss: 0.26687777042388916
train_iter_loss: 0.20090070366859436
train_iter_loss: 0.24686892330646515
train_iter_loss: 0.23365598917007446
train_iter_loss: 0.18003134429454803
train_iter_loss: 0.2140503227710724
train_iter_loss: 0.20590074360370636
train_iter_loss: 0.18210294842720032
train_iter_loss: 0.15910160541534424
train_iter_loss: 0.1779152899980545
train_iter_loss: 0.24671243131160736
train_iter_loss: 0.39898720383644104
train_iter_loss: 0.28070488572120667
train_iter_loss: 0.2052382081747055
train_iter_loss: 0.2503618597984314
train_iter_loss: 0.21949970722198486
train_iter_loss: 0.2983495593070984
train_iter_loss: 0.19300603866577148
train_iter_loss: 0.3151719868183136
train loss :0.2406
---------------------
Validation seg loss: 0.30308408030080347 at epoch 67
epoch =     68/  1000, exp = train
train_iter_loss: 0.19802144169807434
train_iter_loss: 0.24013513326644897
train_iter_loss: 0.17317526042461395
train_iter_loss: 0.26548999547958374
train_iter_loss: 0.22674457728862762
train_iter_loss: 0.21708619594573975
train_iter_loss: 0.35003605484962463
train_iter_loss: 0.2426285445690155
train_iter_loss: 0.30467352271080017
train_iter_loss: 0.25452014803886414
train_iter_loss: 0.26185867190361023
train_iter_loss: 0.17499348521232605
train_iter_loss: 0.2047077715396881
train_iter_loss: 0.21748441457748413
train_iter_loss: 0.19353465735912323
train_iter_loss: 0.23308861255645752
train_iter_loss: 0.22197596728801727
train_iter_loss: 0.22678431868553162
train_iter_loss: 0.17923912405967712
train_iter_loss: 0.2376224547624588
train_iter_loss: 0.3175891637802124
train_iter_loss: 0.15169328451156616
train_iter_loss: 0.24298043549060822
train_iter_loss: 0.23916923999786377
train_iter_loss: 0.211403951048851
train_iter_loss: 0.23985551297664642
train_iter_loss: 0.4179532825946808
train_iter_loss: 0.2464834600687027
train_iter_loss: 0.24119748175144196
train_iter_loss: 0.23770129680633545
train_iter_loss: 0.17928501963615417
train_iter_loss: 0.20099805295467377
train_iter_loss: 0.19786337018013
train_iter_loss: 0.29517024755477905
train_iter_loss: 0.21001750230789185
train_iter_loss: 0.2643527090549469
train_iter_loss: 0.2069990038871765
train_iter_loss: 0.20008066296577454
train_iter_loss: 0.2557058334350586
train_iter_loss: 0.2573739290237427
train_iter_loss: 0.17912040650844574
train_iter_loss: 0.2642115652561188
train_iter_loss: 0.2274758517742157
train_iter_loss: 0.17914968729019165
train_iter_loss: 0.27536773681640625
train_iter_loss: 0.1355004906654358
train_iter_loss: 0.26069217920303345
train_iter_loss: 0.2138625532388687
train_iter_loss: 0.21572117507457733
train_iter_loss: 0.28749746084213257
train_iter_loss: 0.18503616750240326
train_iter_loss: 0.33579951524734497
train_iter_loss: 0.2353091537952423
train_iter_loss: 0.17833583056926727
train_iter_loss: 0.2470412403345108
train_iter_loss: 0.2143927365541458
train_iter_loss: 0.25425195693969727
train_iter_loss: 0.23504044115543365
train_iter_loss: 0.21154187619686127
train_iter_loss: 0.258192777633667
train_iter_loss: 0.28115785121917725
train_iter_loss: 0.32282617688179016
train_iter_loss: 0.2631217837333679
train_iter_loss: 0.21615074574947357
train_iter_loss: 0.2713119387626648
train_iter_loss: 0.21361945569515228
train_iter_loss: 0.24430187046527863
train_iter_loss: 0.2243799865245819
train_iter_loss: 0.18122737109661102
train_iter_loss: 0.22478394210338593
train_iter_loss: 0.24656566977500916
train_iter_loss: 0.2598826289176941
train_iter_loss: 0.21273212134838104
train_iter_loss: 0.18958061933517456
train_iter_loss: 0.27771371603012085
train_iter_loss: 0.25117143988609314
train_iter_loss: 0.15859180688858032
train_iter_loss: 0.17107312381267548
train_iter_loss: 0.2734607756137848
train_iter_loss: 0.20253324508666992
train_iter_loss: 0.1804809421300888
train_iter_loss: 0.266380250453949
train_iter_loss: 0.27499040961265564
train_iter_loss: 0.28050926327705383
train_iter_loss: 0.3322651982307434
train_iter_loss: 0.257030725479126
train_iter_loss: 0.32225871086120605
train_iter_loss: 0.2499052882194519
train_iter_loss: 0.2032821923494339
train_iter_loss: 0.17256644368171692
train_iter_loss: 0.20845387876033783
train_iter_loss: 0.21092329919338226
train_iter_loss: 0.2793772220611572
train_iter_loss: 0.24042625725269318
train_iter_loss: 0.18963220715522766
train_iter_loss: 0.1883670687675476
train_iter_loss: 0.16761335730552673
train_iter_loss: 0.21244753897190094
train_iter_loss: 0.3710653781890869
train_iter_loss: 0.29093137383461
train_iter_loss: 0.23964309692382812
train_iter_loss: 0.2434680014848709
train_iter_loss: 0.2413538247346878
train_iter_loss: 0.3988339900970459
train_iter_loss: 0.20747347176074982
train_iter_loss: 0.37462276220321655
train_iter_loss: 0.21011710166931152
train_iter_loss: 0.23273512721061707
train_iter_loss: 0.21555455029010773
train_iter_loss: 0.15943476557731628
train_iter_loss: 0.25236207246780396
train_iter_loss: 0.35697734355926514
train_iter_loss: 0.18746434152126312
train_iter_loss: 0.17844511568546295
train_iter_loss: 0.27106988430023193
train_iter_loss: 0.2219424843788147
train_iter_loss: 0.2534637451171875
train_iter_loss: 0.2410009801387787
train_iter_loss: 0.21872146427631378
train_iter_loss: 0.24127015471458435
train_iter_loss: 0.3264942169189453
train_iter_loss: 0.20197468996047974
train_iter_loss: 0.30444610118865967
train_iter_loss: 0.21529851853847504
train_iter_loss: 0.23791192471981049
train_iter_loss: 0.2808375060558319
train_iter_loss: 0.23151899874210358
train_iter_loss: 0.1792140156030655
train_iter_loss: 0.20612122118473053
train_iter_loss: 0.235099196434021
train_iter_loss: 0.1738954484462738
train_iter_loss: 0.33063018321990967
train_iter_loss: 0.21345478296279907
train_iter_loss: 0.22710685431957245
train_iter_loss: 0.236032173037529
train_iter_loss: 0.21616722643375397
train_iter_loss: 0.21144330501556396
train_iter_loss: 0.20797687768936157
train_iter_loss: 0.19753170013427734
train_iter_loss: 0.22562144696712494
train_iter_loss: 0.21037396788597107
train_iter_loss: 0.21200750768184662
train_iter_loss: 0.1724746823310852
train_iter_loss: 0.23439741134643555
train_iter_loss: 0.16870900988578796
train_iter_loss: 0.2599719166755676
train_iter_loss: 0.3062759339809418
train_iter_loss: 0.36501455307006836
train_iter_loss: 0.1630193293094635
train_iter_loss: 0.2492082417011261
train_iter_loss: 0.2945963442325592
train_iter_loss: 0.2729586362838745
train_iter_loss: 0.198614239692688
train_iter_loss: 0.21576476097106934
train_iter_loss: 0.261787474155426
train_iter_loss: 0.20838086307048798
train_iter_loss: 0.30051788687705994
train_iter_loss: 0.3315129578113556
train_iter_loss: 0.216826930642128
train_iter_loss: 0.2343014031648636
train_iter_loss: 0.18721140921115875
train_iter_loss: 0.2276804894208908
train_iter_loss: 0.24113038182258606
train_iter_loss: 0.2585568130016327
train_iter_loss: 0.21228444576263428
train_iter_loss: 0.24344943463802338
train_iter_loss: 0.30419644713401794
train_iter_loss: 0.24184376001358032
train_iter_loss: 0.17770156264305115
train_iter_loss: 0.18053027987480164
train_iter_loss: 0.2005622386932373
train_iter_loss: 0.203566312789917
train_iter_loss: 0.36388853192329407
train_iter_loss: 0.31814250349998474
train_iter_loss: 0.1952735036611557
train_iter_loss: 0.2296144813299179
train_iter_loss: 0.245887890458107
train_iter_loss: 0.3003271520137787
train_iter_loss: 0.18835654854774475
train_iter_loss: 0.1902109980583191
train_iter_loss: 0.2376791089773178
train_iter_loss: 0.2009260356426239
train_iter_loss: 0.1933126598596573
train_iter_loss: 0.2771809697151184
train_iter_loss: 0.22733326256275177
train_iter_loss: 0.234175905585289
train_iter_loss: 0.1698044389486313
train_iter_loss: 0.2873166799545288
train_iter_loss: 0.23303762078285217
train_iter_loss: 0.2153286188840866
train_iter_loss: 0.22208309173583984
train_iter_loss: 0.26677894592285156
train_iter_loss: 0.33064746856689453
train_iter_loss: 0.21466176211833954
train_iter_loss: 0.2587965130805969
train_iter_loss: 0.30182313919067383
train_iter_loss: 0.22788290679454803
train_iter_loss: 0.2868410050868988
train_iter_loss: 0.26799464225769043
train_iter_loss: 0.22059445083141327
train loss :0.2396
---------------------
Validation seg loss: 0.31111423347918493 at epoch 68
epoch =     69/  1000, exp = train
train_iter_loss: 0.21824195981025696
train_iter_loss: 0.2621518671512604
train_iter_loss: 0.16511355340480804
train_iter_loss: 0.21540656685829163
train_iter_loss: 0.23020441830158234
train_iter_loss: 0.23300985991954803
train_iter_loss: 0.19474457204341888
train_iter_loss: 0.28362542390823364
train_iter_loss: 0.32613906264305115
train_iter_loss: 0.2618650794029236
train_iter_loss: 0.2415313571691513
train_iter_loss: 0.2282128632068634
train_iter_loss: 0.16198524832725525
train_iter_loss: 0.20859098434448242
train_iter_loss: 0.24320799112319946
train_iter_loss: 0.1621103137731552
train_iter_loss: 0.2825130224227905
train_iter_loss: 0.16239848732948303
train_iter_loss: 0.24429704248905182
train_iter_loss: 0.25185829401016235
train_iter_loss: 0.20274615287780762
train_iter_loss: 0.2864646017551422
train_iter_loss: 0.31114378571510315
train_iter_loss: 0.20233254134655
train_iter_loss: 0.17166809737682343
train_iter_loss: 0.22906699776649475
train_iter_loss: 0.33061346411705017
train_iter_loss: 0.17993958294391632
train_iter_loss: 0.3371194303035736
train_iter_loss: 0.2304561734199524
train_iter_loss: 0.17116887867450714
train_iter_loss: 0.20835693180561066
train_iter_loss: 0.21230725944042206
train_iter_loss: 0.24585525691509247
train_iter_loss: 0.22518952190876007
train_iter_loss: 0.21544887125492096
train_iter_loss: 0.2560132145881653
train_iter_loss: 0.21379251778125763
train_iter_loss: 0.21595795452594757
train_iter_loss: 0.19558869302272797
train_iter_loss: 0.2759852111339569
train_iter_loss: 0.2510426640510559
train_iter_loss: 0.2974071502685547
train_iter_loss: 0.20173576474189758
train_iter_loss: 0.184794619679451
train_iter_loss: 0.2111857831478119
train_iter_loss: 0.26752758026123047
train_iter_loss: 0.2589195668697357
train_iter_loss: 0.23313124477863312
train_iter_loss: 0.3385998606681824
train_iter_loss: 0.25281938910484314
train_iter_loss: 0.24510958790779114
train_iter_loss: 0.19926904141902924
train_iter_loss: 0.25069689750671387
train_iter_loss: 0.22688394784927368
train_iter_loss: 0.32115238904953003
train_iter_loss: 0.25911134481430054
train_iter_loss: 0.2004867047071457
train_iter_loss: 0.20799392461776733
train_iter_loss: 0.3263096213340759
train_iter_loss: 0.21677738428115845
train_iter_loss: 0.38926833868026733
train_iter_loss: 0.23564089834690094
train_iter_loss: 0.2354421317577362
train_iter_loss: 0.30009034276008606
train_iter_loss: 0.18437935411930084
train_iter_loss: 0.1954580694437027
train_iter_loss: 0.27688807249069214
train_iter_loss: 0.19860947132110596
train_iter_loss: 0.2078559398651123
train_iter_loss: 0.24481379985809326
train_iter_loss: 0.25964245200157166
train_iter_loss: 0.1537199467420578
train_iter_loss: 0.2890760600566864
train_iter_loss: 0.20384076237678528
train_iter_loss: 0.32600104808807373
train_iter_loss: 0.2951304614543915
train_iter_loss: 0.2130671590566635
train_iter_loss: 0.19118617475032806
train_iter_loss: 0.24280069768428802
train_iter_loss: 0.16858837008476257
train_iter_loss: 0.28095054626464844
train_iter_loss: 0.2494693249464035
train_iter_loss: 0.19360320270061493
train_iter_loss: 0.20654569566249847
train_iter_loss: 0.16443923115730286
train_iter_loss: 0.20896613597869873
train_iter_loss: 0.24606111645698547
train_iter_loss: 0.24511413276195526
train_iter_loss: 0.15788592398166656
train_iter_loss: 0.35270005464553833
train_iter_loss: 0.15838798880577087
train_iter_loss: 0.22344820201396942
train_iter_loss: 0.24882391095161438
train_iter_loss: 0.2553847134113312
train_iter_loss: 0.3157326579093933
train_iter_loss: 0.2412872463464737
train_iter_loss: 0.26477229595184326
train_iter_loss: 0.2115715891122818
train_iter_loss: 0.2530469000339508
train_iter_loss: 0.4181169867515564
train_iter_loss: 0.25245311856269836
train_iter_loss: 0.2050715982913971
train_iter_loss: 0.17830482125282288
train_iter_loss: 0.25371700525283813
train_iter_loss: 0.22137300670146942
train_iter_loss: 0.2419741302728653
train_iter_loss: 0.21887682378292084
train_iter_loss: 0.29075610637664795
train_iter_loss: 0.21285322308540344
train_iter_loss: 0.22511886060237885
train_iter_loss: 0.2853868901729584
train_iter_loss: 0.24419575929641724
train_iter_loss: 0.2389460802078247
train_iter_loss: 0.19080255925655365
train_iter_loss: 0.23614172637462616
train_iter_loss: 0.1663721799850464
train_iter_loss: 0.2738289535045624
train_iter_loss: 0.2092885822057724
train_iter_loss: 0.21682602167129517
train_iter_loss: 0.1815023571252823
train_iter_loss: 0.26622945070266724
train_iter_loss: 0.17055490612983704
train_iter_loss: 0.2214364856481552
train_iter_loss: 0.26596251130104065
train_iter_loss: 0.2302630990743637
train_iter_loss: 0.23894546926021576
train_iter_loss: 0.2433859258890152
train_iter_loss: 0.23111268877983093
train_iter_loss: 0.23153331875801086
train_iter_loss: 0.19716069102287292
train_iter_loss: 0.24249452352523804
train_iter_loss: 0.1635703146457672
train_iter_loss: 0.205824613571167
train_iter_loss: 0.21290074288845062
train_iter_loss: 0.21498140692710876
train_iter_loss: 0.18947087228298187
train_iter_loss: 0.21718958020210266
train_iter_loss: 0.23616960644721985
train_iter_loss: 0.22275438904762268
train_iter_loss: 0.18278615176677704
train_iter_loss: 0.3496406376361847
train_iter_loss: 0.39628660678863525
train_iter_loss: 0.2154565304517746
train_iter_loss: 0.3547602891921997
train_iter_loss: 0.31808382272720337
train_iter_loss: 0.1799028217792511
train_iter_loss: 0.26919591426849365
train_iter_loss: 0.30697160959243774
train_iter_loss: 0.2786637246608734
train_iter_loss: 0.24268585443496704
train_iter_loss: 0.19088613986968994
train_iter_loss: 0.3000623881816864
train_iter_loss: 0.24065722525119781
train_iter_loss: 0.2363748848438263
train_iter_loss: 0.20959775149822235
train_iter_loss: 0.26012372970581055
train_iter_loss: 0.23182739317417145
train_iter_loss: 0.3676171898841858
train_iter_loss: 0.28727465867996216
train_iter_loss: 0.24199947714805603
train_iter_loss: 0.20536881685256958
train_iter_loss: 0.24853438138961792
train_iter_loss: 0.4380956292152405
train_iter_loss: 0.19045427441596985
train_iter_loss: 0.1997673213481903
train_iter_loss: 0.18226824700832367
train_iter_loss: 0.24160800874233246
train_iter_loss: 0.28381121158599854
train_iter_loss: 0.20496010780334473
train_iter_loss: 0.29401785135269165
train_iter_loss: 0.20711493492126465
train_iter_loss: 0.2727639377117157
train_iter_loss: 0.1894381195306778
train_iter_loss: 0.25607994198799133
train_iter_loss: 0.2636973559856415
train_iter_loss: 0.19679173827171326
train_iter_loss: 0.1979738026857376
train_iter_loss: 0.33554065227508545
train_iter_loss: 0.2064385563135147
train_iter_loss: 0.21767479181289673
train_iter_loss: 0.23134233057498932
train_iter_loss: 0.2121872454881668
train_iter_loss: 0.18014831840991974
train_iter_loss: 0.18883468210697174
train_iter_loss: 0.34595921635627747
train_iter_loss: 0.24330498278141022
train_iter_loss: 0.2647695243358612
train_iter_loss: 0.22415995597839355
train_iter_loss: 0.29395943880081177
train_iter_loss: 0.21994733810424805
train_iter_loss: 0.1871701180934906
train_iter_loss: 0.21380577981472015
train_iter_loss: 0.22287976741790771
train_iter_loss: 0.20129257440567017
train_iter_loss: 0.21627765893936157
train_iter_loss: 0.19924071431159973
train_iter_loss: 0.2449796348810196
train_iter_loss: 0.22318796813488007
train_iter_loss: 0.3082166612148285
train loss :0.2403
---------------------
Validation seg loss: 0.30763684093671023 at epoch 69
epoch =     70/  1000, exp = train
